job_title,clean_description,salary,state,sponsored,search_term
AWS Data engineer,contractsr aws data engineerremote project3 months plusrate doeexperienceexcellent communication skill requireddata lake storage and analytics experience on aws is muststrong aws experience with certification is requiredthanksanuranextphase systems6508876642job type contractexperienceaws 5 years requireddata engineer 10 years preferredlicenseaws preferred,,HI,True,data_engineer
Data Engineer,at ism connect we believe that success is achieved through teamwork we empower team members to make decisions and create an environment that makes everyone on the team betterjoin the analytics team that works in all of our business lines hone your skills in an exciting environment and have a measurable impact on a wellfunded and rapidly expanding business our venturebacked firm delivers innovative solutions to clientele from professional sports to some of the nation’s largest retailerswe are looking for a data engineer to join our analytics team to help design build and maintain a cloudbased etl pipeline feeding a cloudbased data warehouse which will support our analytics and data science efforts as our volume of data grows the data engineer will likely help out in other areas of the data science stack as well an engineer who is passionate about his or her work skilled at collaborating with coworkers and a positive and supportive presence in the office will be a particularly good fitspecific duties and responsibilitieshelp build and maintain a cloudbased scalable etl pipeline that ingests data from heterogeneous sourcesassist with design of a cloudbased data lake and data warehouseensure high data quality and availabilitytest the etl pipelinecontribute to other aspects of the data science workflowcomplete ad hoc data work as neededstay uptodate with etl advancements and best practiceseducation and experiencerelevant data engineeringdata science work experience in a corporate environment or similarpractical experience with etl and database technologiesexperience with amazon web services analytics and etl tools or similar cloudbased toolsrelational databases and columnar storagedata lake and data warehouse designexperience in other data science technologies r python etc and capabilities data analysis machine learning data visualization etc is helpfulexperience in a higher performance language such as c go etc is a bonusundergraduate or graduate degree in a technical field preferableskillsability to work and collaborate in a distributed team environmentwork with multiple internal teams to create deliverables for clients or for internal usageeffectively communicate project status blockers and questions to team membersselfmotivated and requires minimal managementability to learn new technologies and be involved in multiple projectstechnologyamazon web services analyticsetlglueathenakinesis firehoseauroraredshiftredshift spectrumspark pysparksqlmongodbpythonrgitbashbenefitsmeaningful work on worldclass and industrychanging productsamazing culture and a flat organizational structure100 covered premiums for medical dental life disability401k planultracasual dress work environmentflexible scheduledevice stipendism connect is an equal opportunity employer mfvdjob type fulltimeexperienceamazon web services analytics 1 year requiredpractical data sciencedata engineering 2 years requiredetl and database technologies 1 year requirededucationbachelors preferred,,PA,True,data_engineer
Data Engineer,data engineerdoers wanted dreamers encouragedour data engineer performs a wide range of job duties utilizing technical knowhow and an exceptional proactive customer service approach ensuring high levels of customer satisfaction maintains a very handson focus for technology matters combined with an affinity for solving complex technical issues and delivering projects on time and within budgetforesight culture is that of spirited team players in an environment energized by innovation and continuous improvement we truly believe it takes an entire team united behind something big so together we work hard we have fun we brainstorm we love ideas and we give highfives in the hallway foresight intelligence employees are encouraged to take a high degree of ownership and improve continuously we work in an environment where your voice matters and where your actions have a direct positive impact on the team and the customerreports to vice president of operationsjob duties and responsibilitiesidentify evaluate and recommend appropriate technologies and strategies for building products and delivering services from a database perspectiveassist in design and development of database systemssecure the database and ensure its integrityestablish the needs of users and monitor the useraccess model control access permissions and privilegesdevelop databases functions scripts stored procedures etc to collect process and present datamonitor performance and manage parameters of the database and provide fast query responses to frontend userssynchronize the conceptual design with the actual databaseenhance and refine the logical design of the databaseensure appropriate system storage requirementsupdate the database by installing and testing new versions of the dbmsdevelop and manage backups and construct recovery planscreate physical and logical database models according to business needs or requirementsprovide technical assistance to sort out database related issues identify errors and then resolve in a proper wayprepare documentation related to the databasework with dbas to manage the company databases effectivelyperforms other duties and responsibilities as required or assignedminimum requirementsbachelor’s degree in computer engineering or related field or equivalent knowledge skills and abilities in software engineering5 years of technical experience in a database engineering roleexcellent oralwritten communication skills and interpersonal skills with the ability to articulate ideas to both technical and nontechnical audiencesexpert with mssql familiarity with c programming conceptsinnovative selfmotivated and selfdirected with keen attention to detail exceptional service orientationability to work directly with customers understanding and fulfilling their needs in a competent mannerability to discern user requirements and develop specificationsexperience with microsoft system administration and web server configurationknowledge of internet protocols database management systems revision control systems information security vulnerabilities and risk managementpossessing a business understanding of the underlying dataability to follow projects through to completionability to learn new technologies quickly step outside your own comfort zone and handle unfamiliar challenges enthusiasticallyenjoys work overcoming obstacles is fun loves to help people and can work well independently or in groupsjob type fulltimeexperiencedata engineering 5 years preferredtechnical 5 years preferredc programming 1 year preferredmssql 5 years preferrededucationbachelors requiredlocationscottsdale az requiredwork authorizationunited states required,,AZ,True,data_engineer
Healthcare Data Engineer,product delivery engineerclearsense is building an endtoend data platform for healthcare companies based in the fastest growing markets around the world our product delivery team works directly with our customers to help solve their biggest challenges as a product delivery engineer pde you’ll help solve these challenges by building applications and configurations using the core platform and cuttingedge technologiesresponsibilitieswork with engineering to write platform configuration code for new featureslead the development execution and review of manual and automated test scriptsdevelop tools that provide customers with unprecedented transparency into their operationsbuild customer specific applications to streamline data integrationdetermine the best approaches to productize platform configurationauthor and maintain platform configuration documentationwrite sql queries to support product implementationsproficient programming skills to make minor modifications to existing java applications as neededrequirementsbachelors degree in a technical field or equivalent 4 years of experienceprogramming experiencestrong attention to detail able to take high level requirements and implement in a selfdirected daily basismotivated positive and constructive attitude—seeing challenges as opportunitiesability to operate in an agile startup environment with evolving requirementsstrong sql programming experience can be across any of the various rdbms such as oracle or sql server but this is a must have for this positionjava programming – competent proficiency is required go is a pluscomfortable using a shell to interact with linux or windowsprevious experience working in an agile environment is a plusstrong communication skillseducationbachelors degree in a technical field or equivalent 4 years of experiencelocationjacksonville fljob type fulltimeeducationbachelors preferredlocationjacksonville fl requiredwork authorizationunited states required,,FL,True,data_engineer
Data Engineer,"in this role the candidate will be responsible for performing data engineering duties such as planning developing testing maintaining and monitoring systems the candidate will report to the senior database engineer and work collaboratively with other teams to achieve business department and organizational goals the individual will also be responsible for developing implementing and overseeing secure database policies and procedures to ensure the integrity and availability of database systems

data engineer responsibilities
as part of the data engineering team provide support to java engineers for basic database administration needs such as tables indexes functions procedures etc
daily maintenance of database infrastructure mainly checking daily  nightly scheduler jobs backuprecovery and replication
understand business objectives and design services that couple business logic with code components for scalability and reusability
proficient in designing efficient and robust etl workflows
create or support creation of required reports in response to business user needs
monitor and report for critical production data systems
support multiple data systems in a production environment including dss oltp nosql and big data services
able to work with cloud computing environments
proactively monitor as well as troubleshoot problems escalated by the business  qa  analytics  development team in a timely manner
respond to and resolve sql database access and performance issues
candidate will be oncall and maybe required to work over weekend at times and will be part of a team in automating daily tasks using automated outofbox solution or shellperl scripting

data engineer requirements
34 years’ experience related to oracle db administration on unixlinus in a midtolargescale computing environment
strong understanding of database structures concepts principles and practices
experience in aws or google cloud computing environment
strong working knowledge of any nosql systems such as cassandra mongodb or dynamodb and elasticsearch
working knowledge of big data system such as hadoop mapreduce hive or spark along with resource management using yarn or mesos
proficient in python java andor r
experience in migrating from rdbms to nosql systems
strong sql ansi or other standard sql writing skills is a must
understanding of unixlinuxperl or bash shell scripting language
ability to architect highly scalable distributed systems
handson experience with pyspark or pytorch
working knowledge of apache kafka or aws sqs with kinesis data firehose
working knowledge of inmemory computing systems such as redis nuodb voltdb or gridgain",,NY,True,data_engineer
Data Engineer,data engineer  developerlooking to be part of an amazing team that is solving challenges growing and attracting attention plus do you want to work with data you can explain to your mom travelpass group is a closeknit group of technical marketing and business experts who are disrupting the travel industrywe are creating cuttingedge travel technology and data systems we uncover travel opportunities to help people travel more by saving money and booking easily since 2008 we have helped people book more than 8 million hotel rooms we have been recognized locally and nationally among the fastest growing companies and as a top workplace here’s a sample inc 5000 list of america’s fastestgrowing private companies utah business magazine fast 50 9 uv50 fastest growing companies in utah valley 9 mountain west capital network’s utah 100 22 deloitte technology fast 500 155 and the salt lake tribune top workplaceour data services team is looking for a mid to seniorlevel data engineerdeveloper with a passion for creating elegant yet simple data systems you’ll have opportunities to grow and be responsible for building and maintaining data pipelines making sure data is available and accessible and helping drive new innovation and insights via data management the ideal applicant will have strong development and systems skills and will provide the company with essential datakey responsibilities curate business critical data sets using our own data as well as external data setsprovide etl solutions to populate and enhance our data storesarchitect data pipelines to transform and validate datamaintain data quality and integrity across our systemsassist in data governance processes planning security and executionqualifications demonstrated strength in data modeling etl development and data warehousingextensive experience writing complex highlyoptimized queries across large data sets using sql postgres mysql or something similarstrong experience in python or similar languagesexperience with various aws services including rds s3 emr and rdsexperience consuming and cleansing data from thirdparty apis and other sources3 years of experience building software and working with dataexperience with big data technologies such as hive hadoop or sparkmotivated passionate and selfimprovingstrong organizational and analytical skills with an ability to extract meaning from dataexperience in our current technologies a bonus aws cloudsearch redshift athena golang rbenefits health insurance pto paid holidays 401k with matchingcompetitive compensation with quarterly bonusesflexible work schedule with remote daysfully stocked break room with game room and lounge areafun and casual company culture based upon respect and resultsgreat “friends and family” travel booking site that can save you and your friends a ton of cash we want you to experience traveljob type fulltime,,UT,True,data_engineer
Senior Data Engineer,job summarywe are hiring a senior data engineer for a new purposedriven vcbacked data and ai startup founded by adam bly adamblycombio we invite you to learn more about the vision and thesis for the company and the problems were setting out to solve here httpswwwlinkedincompulsewhyimstartingnewaicompanyadamblyresponsibilities and dutiesyou willarchitect and build key components of our first product working with large amounts of heterogeneous data and tackling highimpact technical challengesbuild products that help advance data science and machine learningcollaborate with experts in data science and ml and partners at top research labsleverage best practices in continuous integration and deliverybe part of the founding engineering team of the company and help shape our engineering culture values and ways of workingqualifications and skillsyou havea proven record of personally taking large data projects from ideation to implementationexpertise working with high volume heterogeneous data using distributed systems such as hadoop bigtable and cassandraexpertise architecting building and operating largescale batch and realtime data pipelines with data processing frameworks like scalding scio storm spark and dataflowstrong knowledge about data modeling data access and data storage techniquesexperience with agile developmentpreferably worked on graphs and open source datarelated projectsyou area systems thinker who is naturally predisposed to connecting dotsa scientificallyminded individual who generates hypotheses from observations conceives creative ways to test hypotheses presents arguments supported by data and changes your mind based on new datamissiondriven and passionate about the problems raised in the post shared aboveready to build something big and ambitious from the ground upjob type fulltimework authorizationunited states required,,NY,True,data_engineer
Data Engineer Internship,"internshipposition summary
the new york county district attorneys office has immediate openings for spring internships in its new law technology and innovation unit lti lti is charged with developing technology solutions to enterprisewide problems related to investigations evidence processing and case management interns will brainstorm problems and potential solutions with bureaus develop prototypes and contribute to existing data science projects and applications the lti intern will have latitude to apply his or her unique skillset to an evolving set of projects and tasks

responsibilities
•
work with those in your unit to understand case workflow and automate and streamline investigative steps wherever possible
•
develop technological infrastructure for your unit in the form of internal web applications or otherwise
•
develop tools to identify trends behaviors and patterns related to cases in your unit
•
work on cases directly wherever programming can speed up an investigation or bring in new insights
•
collaborate with others throughout the office to work on danywide applications and projects

qualifications
•
knowledge of python and preferably r and sql
•
experience developing internal web applications via flask django shiny bokeh html css javascript etc
•
experience working with databases
•
experience with data science
•
ability to make sense out of virtually any type of incoming file and extract and analyze the relevant data
•
ability to communicate effectively with anyone  other programmers internally or externally assistant district attorneys investigators or paralegals
•
driven to find ways to use technology to improve the way cases are brought in and investigated within your unit

educational requirements
•
currently enrolled in an undergraduate or graduate program in computer science or a related field

additional requirements
•
cover letter
•
unofficial transcript
•
previous data science project or portfolio
•
interest in law enforcement criminal justice or civic technology

commitmentapplicants must commit to a complete term
•
summer term june  august ï»¿10 weeks 35 hoursweek
•
fall term september  december 12 weeks minimum of 12 hoursweek
•
spring term february  may 12 weeks minimum of 12 hoursweek
the new york county district attorneys office is an equal opportunity employer",,NY,False,data_engineer
Data Engineer,"to be based in the south west we are looking for experienced data engineersinstallers of cat 5 6 and fibre optic cabling systems
location south west

type fulltime  subcontractor

rate negotiable salary depending on experience

you must be a qualified installer of cat5 cat6 and fibre the role is geared around carrying out new installations and fault diagnosis  repair work on existing infrastructure in our customer data centres

the range of installations we undertake in which you would be a part of

single and multisite solutions
design and installation
contract work and retained service
voice and data projects
cat5e cat6 cat6a cat7 specifications
fibre optics including blown splicing and pretermination
switches and routers
this role has become available due to expansion we have a closeknit team of engineers coupled with a high retention of employees

offers of employment are normally subject to satisfactory references and any other required preemployment checks in certain roles successful applicants will need to satisfy security requirements in order to gain access to our customer sites

all candidates will undergo a criminal reference check basic disclosure",,,False,data_engineer
Entry Level Data Engineer,"50000 a yearjob description

no computer science degree no problem we love selftaught developers
launchcode offers paid data engineering apprenticeships at one of our employer partners that include mastercard anheuserbusch boeing carnival cruise lines and many more more than 4 of 5 apprentices are offered a fulltime position with an average starting salary of 50000
we’re looking for applicants who are tenacious driven and know how to work a problem always digging deeper to learn how things work eager to squeeze some learning out of every experience we’re looking for you
we only accept applications through our website at
httpsbitly2oqizey

qualifications

passion drive and aptitude to succeed in technology
skills to analyze data using one or more of the following tools
python with bonus points for data science libraries such as pandas numpy and scikitlearn or some experience with r
sql including comfort with multitable joins views and stored procedures
data warehousing or etl process design
visualization tools such as tableau chartio powerbi or chartmaking libraries such as ggplot2
aws
the ability to work fulltime in the united states and a desire for your apprenticeship to become a fulltime job
we only accept applications through our website at
httpsbitly2oqizey
additional information

if you want to land a job in technology with launchcode but don’t yet have the required skills visit wwwlaunchcodeorggetstarted to see how we can still help
our stats
over 4 out of 5 launchcode apprentices get offered fulltime employment
on average last 84 days longer or shorter depending on the company
average starting salary after apprenticeship period 50000",50000.0,FL,False,data_engineer
Data Engineer,"book of the month is looking for a detailoriented software engineer to oversee our data warehouse and reporting infrastructure our user base generates millions of rows of data daily and our new data engineer will play a critical role in the way the company uses this information to make business decisions working closely with our director of engineering and director of data and analytics you’ll build out suite of internal tools that touch all parts of our business—including operations marketing product and customer experience—while scaling and maintaining our data infrastructure
what you’ll do here
etl design development and management
build new etl pipelines using python
scale out existing etl architecture to support our growing business and data including developing best practices for pipelines supported by batch vs streaming services
maintain and improve the reliability of the backend infrastructure and data quality eg build tools and alerts to monitor etl job status
data warehouse design development and management
oversee our data warehouse and bi servers
optimize data warehouse architecture to handle both automated data processing and ad hoc reporting
develop best practices for data storage
work closely with our analytics team to understand company reporting and optimize pipelines for reporting needs
work with analytics team to ensure data quality and reporting availability
what you bring to the table
1–2 years experience developing software
interest in data engineering and developing reporting platforms
highly proficient in writing complex sql queries to transform raw user action data into business data
experience with redshift athena s3 google big query vertica postgres or mysql databases
experience with python r bash or similar scripting languages
experience developing etl jobs
bonus points for but not required experience creating reports and data visualizations in a bi tool like microstrategy looker domo or chartio understanding cicd deployment pipelines experience with ecommerce subscription data
a little bit about us
book of the month uncovers the best new books and sharing them with 10 million readers every month founded in 1926 and relaunched in 2015 book of the month is an earlystage startup with a rich history and loyal user base—and we’re looking for the best people to join us
our benefits and perks
unlimited vacation days with a getyourworkdone policy
competitive compensation
medical vision dental and 401k plans
a dogfriendly office with an open floor plan
free books snacks beer seltzer",,NY,False,data_engineer
DATA ENGINEER,"you will have the opportunity to work as part of a team of highly technical engineers to design develop and maintain data acquisition pressing and management software the successful candidate will be highly motivated with a passion for technology and possess a strong computer science background in this role you will support the unique data driven research of our financial analysts this is a terrific opportunity for a skilled engineer to become a key contributor for our investment research business

qualifications

35 years of work experience designing and architecting big data systems using spark  hadoop  mapreduce
advanced degree in computer science  engineering or related field
experience building data models for normalizingstandardizing varied datasets for machine learning  deep learning
experience working on cloud infrastructure – aws
job expectations

independent selfstarter capable of architecting and implementing systems end to end
design standardized data model for over 10 data sources
build scalable connectivity pipelines to data sets and toolsets for easy definition of data cleaning and normalization to data model
email resume to infomsciencecom and include position for which you are applying",,NY,False,data_engineer
Data Engineer,"job description
we are a startup within one of the fastest growing and most strategic parts of amazon marketing insight owns the product technology and deployment roadmap for advanced analytics and insights products across our advertiser success team advertiser success is core to amazon’s growth as it helps our suppliers drive awareness consideration and purchase of their products by hundreds of millions of consumers around the world and generates revenue which helps us lower prices and invest in improvements to our customer experience we are a highly motivated collaborative and funloving team with an entrepreneurial spirit and bias for action with a broad mandate to experiment and innovate we are growing at an unprecedented rate with a seemingly endless range of new opportunities


we are looking for passionate data engineers to develop a flexible data model and optimize the consumption of massive data sources we require to generate unique insights data is at the center of every product we will develop as we create brand new systems that serve the needs of our large and growing base of advertisers you will share in the ownership of the technical vision and direction for advanced analytics and insight products you will be a part of a team of top notch technical professionals developing complex systems at scale and with a focus on sustained operational excellence members of this team will be challenged to innovate using big data technologies we are looking for people who are motivated by thinking big moving fast and changing the way customers use data to drive profitability if you love to implement solutions to hard problems while working hard having fun and making history this may be the opportunity for you
basic qualifications
bachelors degree in computer science engineering mathematics or a related technical discipline
4 years of industry experience in software development data engineering business intelligence data science or related field with a track record of manipulating processing and extracting value from large datasets
demonstrated strength in data modeling etl development and data warehousing
experience using big data technologies hadoop hive hbase spark emr etc
experience using business intelligence reporting tools tableau business objects cognos etc
knowledge of data management fundamentals and data storage principles
knowledge of distributed systems as it pertains to data storage and computing
preferred qualifications
experience working with aws big data technologies emr redshift s3
proven success in communicating with users other technical teams and senior management to collect requirements describe data modeling decisions and data engineering strategy
experience providing technical leadership and mentoring other engineers for best practices on data engineering
knowledge of software engineering best practices across the development lifecycle including agile methodologies coding standards code reviews source management build processes testing and operations
masters or phd in computer science mathematics statistics economics or other quantitative field",,NY,False,data_engineer
Data Engineer - Amazon Studios Research,"job description
thinking big
do you want to help shape the future of television using your data skills amazon studios unique approach is disrupting the entertainment industry with fan and award favorites like the marvelous mrs maisel jack ryan the man in the high castle and so many others

with a passion for all things television and transformative data insights amazon studios research has built and continues to evolve a robust platform that predicts models and tracks success at every stage of production from concept through release and beyond the research team is uniquely situated at the crossroads of creativity datadriven decisions customer experience and statistical analytics

the tools you build will help drive and define the future of television and movie content for millions of customers around the world
ownership insisting on the highest standards
as a data engineer you will be architecting building and supporting the analytic technologies that give internal customers timely flexible and structured access to their data as a means to optimize marketing scheduling and show development you will interact with team members and internal customers to gather requirements and build robust and secure data flows you will also own the design creation and management of extremely large datasets you will be designing implementing and operating stable and scalable solutions

excellent written and verbal communication skills are a must as the candidate will work closely with teams of diverse skills mindsets and backgrounds amazon data engineers are capable of much more than just thinking in terms of lines of code


the position is located in beautiful santa monica california
basic qualifications
3 years of data engineering or related experience data science business intelligence
firm grasp of relational database models aggregate and analytic functions as well as database and query optimization methods
ability to design develop and automate scalable etl and reporting solutions that transforms data into accurate and actionable business information
comfort in working with business customers to gather requirements and gain a deep understanding of varied datasets
expertise in the design creation management and business use of extremely large datasets
comfort with command line operations including authoring executing and maintaining bash scripts
preferred qualifications
experience with primary research andor entertainment data is a plus but by no means expected or required

direct experience with big data technologies such as spark hive python

experience with aws tools including redshift s3 elastic mapreduce emr elastic cloud compute ec2

familiarity with aws administrative tasks including managing access permissions and roles

experience with security methodologies related to encryption authentication and threat modelin",,CA,False,data_engineer
"Data Engineer, Baseball Operations","description
the new york yankees baseball operations department is accepting applications for an experienced data engineer with a focus on data quality analysis this position reports to our senior baseball operations executives and will assist in the development and maintenance of our data processing pipelines
primary responsibilities
prepare clean format analytical datasets for processing by data scientists
become an expert in our datasets their strengths and weaknesses and write code to pull and verify data in response to data scientist requests
using r visualize complex multisource data to pinpoint data quality issues
build automated pipelines for processing and cleaning data
conduct database feature engineering to support ongoing quantitative research
work with developers to create and deploy systems for anomaly detection
interface with data scientists software developers and other baseball operations staff as needed
design departmentwide principles and workflow for data quality management
serve as the main pointofcontact for questions about data structures definitions and quality


qualifications and experience
bachelor’s degree in computer science or related field
3 years of experience developing in sql preferably tsql
2 years of experience with data profiling data modeling and data pipeline development
2 years of experience developing in r or a similar statistical programming language including experience with data manipulation and visualization in that language
ability to write succinct code with optimal performance and simplicity
excellent communication and problemsolving skills – must be able to break down a complex task and put together an execution strategy with little guidance
an understanding of typical baseball data structures basic and advanced baseball metrics and knowledge of current baseball research areas


this description is intended to describe the type of work being performed by a person assigned to this position it is not an exhaustive list of all duties and responsibilities required by the employee the new york yankees is an equal opportunity employer the company is committed to the principles of equal employment opportunity for all employees and applicants for employment",,NY,False,data_engineer
Data Engineer,contractno optsgcusc preferablelong term contract rolelooking for only 28 years experience candidatesexperience with spark scala hadoop  java skillsjob type contract,,NY,False,data_engineer
Cloud Data Engineer - Apprentice,30000  37500 a yearthis is an apprenticeship opportunity candidates will be hired based on attitude and aptitude the successful candidate will be provided the required technical training and certification to grow into the role and launch a successful career in data engineeringwe’re looking for a cloud data engineer apprentice to contribute to growing data and analytical needs be part of the team that looks to build out nextgeneration hybrid data platform leveraging new technologies and techniques to maximize the value out of data assets and empower employees to innovatea requirement of the application process is to complete the following assessmenthttpssurveyharrisonassessmentscomdzwybw68yv6rresponsibilitiesact as champion to identify and respond to data needs for business users to use the analytics environmentwork with data architects to design and implement solutions to ingest transform connect store and expose homesite’s data to range of usersincorporate new data sources by building pipelines for automated and semiautomated data ingestion and data refreshmaintain existing scripts and develop new scripts in sql python and other languages as appropriate to parse clean transform and load datadevelop and maintain methods to match external data sources to homesite data using deterministic and probabilistic methodsdevelop and implement tests to ensure data quality and proper governance across all integrated datasetsqualificationsbachelor’s degree in computer science engineering or equivalent work experiencecandidates will have an understanding and some practical experience in the following areaspython and sql in windows and maclinux environmentrelational databases including postgresql and microsoft sql servercolumnar data structures like apache parquet and columnar databases like redshiftdistributed sql query engines like presto db and athenaamazon web services including redshift s3 kinesis glue and dynamodbwriting shell scripts for process automationtraining and development will be provided to develop skillsjob type fulltimesalary 3000000 to 3750000 yearexperienceredshift 1 year preferredpostgresql 1 year preferreddynamodb 1 year preferredapache 1 year preferredshell scripting 1 year preferrededucationbachelors requiredwork authorizationunited states required,33750.0,MA,True,data_engineer
LAN/WAN Data Engineer,"atni is looking for an experienced lanwan data engineer that is a selfstarter with exceptional attention to detail and is a skilled multitasker to join the team
you will be a key member of our wide area network deployment team with focus on insuring our data core which carries our entire customer base traffic our wireless network is complicated with 2g3g4g technologies running in multiple countries and your job will be to ensure that our wide area network data core which carries all of our customer’s traffic is as efficient and as fault tolerant as possible our customers like their data service to be fast and always on and it will be your responsibility to make sure that they are delighted with our service a big part of this job is troubleshooting at the routing and switching level and the ability to come up with creative solutions so if you like wearing your thinking cap this job might be for you
basic qualifications
bachelor’s degree in related field and 2 years of experience or associates degree and at least 3 years work experience in related field or equivalent related work experience
working knowledge of juniper networks gained through relevant experience vendor training andor college or technicalvocational school coursework
proficient in understanding of tcpip and routing protocols to include bgp and mpls
strong computer skills proficient in ms office
strong analytical skills to resolve problems
strong oral and written communication skills to coordinate repair efforts and prepare reports
strong interpersonal skills to coordinate efforts effectively between multiple groups
ability to work on call support as needed
preferred qualifications
previous experience as data network engineer
experience with snmp
experience with mobile ip and l2tp
certifications jncia jncis jncip etc
working exposure to wireless data network deployment
experience with some of the following standards  protocols mef ethernet bgp ibgp ospf qos cos mpls vrf vlans and vpns
experience with mobile wireless protocols specifically cdma gsm lte or is835

job duties include but are not limited to
design and implementation of core to edge network architecture and routing protocols on juniper platforms
operational support of data network including troubleshooting routing and switching issues
lanwan responsibilities including ip address management and documentation
engineering for growth and sustainability of the network
education and training of other individuals within the company regarding network routing
engineering and support of other systems supported by the data network organization
analysis for root cause determination of issues including recommendations for improvements
write review and implement methods of procedure
working directly with equipment vendors
other duties as assigned by management",,CO,True,data_engineer
Data Engineer,"to analyze data and informational requirements and provide the best data solutions to internal vanguard clients

duties and responsibilities
1 creates sophisticated data solutions to business problems
2 translates business specifications into design specifications and code responsible for writing complex programs ad hoc queries and reports using team procedures and tool selection guidelines ensures that all code is developed in a well structured manner  includes sufficient documentation  and is easy to maintain and reuse
3 continues to discover and implement new data sources and data integration techniques that are beneficial to clients who selfprovision data
4 leads all phases of development explains technical considerations at related meetings including those with internal clients and less experienced team members tests code thoroughly for accuracy of intended purpose
5 understands and enforces team development guidelines mentors staff with less experience resolves issues elevated from staff with less experience
6 partners with internal clients to enhance understanding of business functions and informational needs maintains a broad understanding of vanguard’s technologies tools and applications including those that interface with business area and systems
7 designs and conducts training sessions on tools and data sources used by the team and self provisioners provides supporting documentation to team members and business partners as needed
8 understands complies with and enforces team policies and procedures especially those for quality and productivity standards that enable the team to meet established milestones understands complies with and enforces all information security policies and procedures and verifies deliverables meet information security requirements abides by risk controls as defined in the team caf documentation
9 manages andor participates in special projects and performs other duties as assigned

qualifications
undergraduate degree in a related field or the equivalent combination of training and experience
master degree preferred
minimum of five years analyst developer or dba experience
strong sql and query performance tuning skills
extensive experience using one or more of the following data sources enterprise data warehouse vast vista adobe or tea leaf
advanced knowledge of one or more of the following cognos report studio sas sql aws python unix db2 and java tag management systems adobe and tea leaf
strong problem solving planning and communication skills
knowledge of the retail and institutional web site preferred
vanguard is not offering visa sponsorship for this position",,PA,True,data_engineer
Data Engineer,"job field rede  research  development
location tarrytown ny us
company basf corporation
job type standard
job id enus1803973

we are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race age citizenship color religion sex marital status national origin disability status gender identity or expression protected veteran status or any other characteristic protected by law
description
at basf we create chemistry through the power of connected minds by balancing economic success with environmental protection and social responsibility we are building a more sustainable future through chemistry as the world’s leading chemical company we help our customers in nearly every industry meet the current and future needs of society through science and innovation we achieve this through our commitment to continuous improvement and operational excellence which gives us the opportunity to set and deliver on ambitious longterm goals


we provide a challenging and rewarding work environment with a strong emphasis on process safety as well as the safety of our employees and the communities we operate in and are always working to form the best team—especially from within through an emphasis on lifelong learning and development this allows for our employees to innovate and generate new ideas put them into action and gain insights from them to further advance our collective expertise


data solutions form a core contribution to innovation data solutions comprise data ingestion data architecture as well as data visualization for all kinds of materials systems and processes at basf we support the live cycle of a material from ideation in research to quality management in production

the mission of the global data solutions team is to set up 21st century data architectures and build interfaces around them thereby making information accessible for and speeding up innovation in basf’s materials science research the data solutions team is recognized within basf’s research organization as the core competency center regarding data management in particular relational and graph databases and big data architectures hadoop



at basf we are constantly striving to become an even better place to work basf has been recognized by forbes magazine as one of america’s best employers in 2017 we strongly support the spirit of collaboration through effectively involving team members and colleagues from other relevant units when developing and executing strategies and projects come join us on our journey to create solutions for a sustainable future


data engineer 1803973 – tarrytown ny or wyandotte mi this role can be based in either location


where the chemistry happens
we are searching for a professional like yourself to play a key role in the execution of data solutions to accomplish project objectives supported by our data architects you will populate it architectures optimally suited for capturing storing integrating and provisioning primary lab data generated in our rd organization through application of intelligent data solutions you will enable researchers to access huge amounts of data swiftly your contribution allows for faster and more data driven decisions and shall help increasing efficiency of our rd efforts you will closely cooperate with rd engineering central functions and business units



you will be relied on to provide knowledge and expertise in data management data connectivity and visualization



formula for success



leveraging your academic background in natural sciences combined with a pronounced it affinity or experience in it with a strong interest in natural sciences you will contribute to a research direction that provides innovation and breakthrough advantages for the business by delivering tailored data solutions
your strong communication skills help to bridge the gap between it and realworld applications you will engage directly with chemical and biological labs analyze existing lab processes and develop a common understanding of the best data management solutions
relying on your strong programming skills preferably in python r andor java as well as interfacing environments based on these such as rshiny or dash you will contribute to the development of applications that make data architectures accessible to both lab technicians and business partners
your familiarity with different data base architectures both relational and nosql eg graph databases document stores etc will be critical to set up lasting data infrastructures tailored to the labs’ needs
create your own chemistry what we offer you


adding value to our customers begins with adding value to you youbasf is the suite of benefits perks programs and unique opportunities we offer to support you—the whole you—in all stages of your life and career with youbasf you create your own chemistry


the total rewards that you receive as a basf employee go way beyond a paycheck from competitive health and insurance plans to robust retirement benefits that include companymatching contributions to making sure you never stop learning we believe investing in you is investing in our success working for a large global organization you’ll have a chance to grow professionally and personally expand your network and build a rewarding and dynamic career




basf provides interesting and challenging learning and development opportunities to help you make the most of your talents and your job




qualifications  basf recognizes institutions of higher education which are accredited by the council for higher education accreditation or equivalent",,NY,True,data_engineer
GeoSpatial Data Engineer,75000  80000 a yearearthdefine is seeking a geospatial data engineer who is equal parts geospatial analyst data scientist and python hacker the successful candidate will build solutions for developing new geospatial products solve gis problems and provide gis support to internal teamswho you areyou are someone who brings a good mix of geospatial programming and data science skills you are excited by the prospect of learning and implementing new algorithms to improve classification workflows your geospatial and coding kungfu is strong and you enjoy building new skills you’ll be right at home here if you are organized cultivate strong relationships and push yourself and your team to the next level we expect our data engineer toembrace technology you have a proven ability to quickly learn and use new technologiesbe organized and detail oriented you will help plan and successfully deliver projects on time and within budget you are excellent at prioritization followthrough and time managementbe a natural problemsolver you anticipate challenges and opportunities within your work as it relates to our team and earthdefine’s goals and priorities and quickly generate creative solutions to meet our evolving needsbe collaborative we want to hear your opinions you will support the growth of your colleagues and help them create better solutions you have great interpersonal oral and written communication skillsthrive on change and ambiguity you can fully embrace a fastmoving organization you have a strong sense of urgency deadlines changing priorities and new projects don’t scare you instead they inspire you to rise to the occasion be willing to step up to the plate you’re eager to contribute and learn willing to provide solutions before we even know there are issues you are resourceful and acquire skills independentlyjob responsibilitiesdevelop data workflows leveraging bestinclass machine learning algorithms to classify ground cover from remote sensed imagery and lidarwrite maintainable python code for spatial data processingresearch identify and consolidate geospatial data over large geographical areas from multiple sources for input into classification workflows imagery lidar demographic data road networks etcdevelop algorithms and software eg arcmap addins scripts tools etc to process geospatial datamaintain and improve existing python codebaselearning new geospatial platforms programming languages tools as neededresearch new approaches to address geospatial data development challengesmanage small and large image classification projectsprovide training and support to other team membersunderstand and deliver on client expectations of our products and serviceswhat we are looking for ms phd in gisremote sensingdata science disciplines with strong analytical skills and 3 years of handson experience working intimately with geospatial dataproficiency with pythonexperience with machine learning data science and deep learningexperience implementing machine learning models in common ml frameworks tensorflow torch theano etcexperience working with multispectral imagery and lidar dataexperience with objectbased image classification and spatial modelingfamiliarity with open source geospatial libraries gdal ogr otb etcfamiliarity with scientific computing libraries like numpy scipy sklearn pandas etcstrong technical aptitude including the ability to quickly and efficiently learn applications systems policies and proceduresproven ability to lead and manage multiple projectsstrong organizational interpersonal and communication skillsa good sense of humor and comfort with ambiguityjob locationredmond wabefore you applyapplicants must be currently authorized to work in the united states without the need for additional visa sponsorship to apply for this position please send in your resume and a cover letter describing your experience working with python geospatial data collating fixing preprocessing normalizing rastervector data etc machine learning and any other experience that would make you a good fit for this roleabout usearthdefine is a growing mapping company transforming vast amounts of earth sensor data into consumable geospatial information products we have mapped millions of acres of highresolution land cover and tree data across the united states and continue to grow this unique data archive we have embraced big data challenges by building a unique technology platform capable of integrating large volumes of imagery vector and point cloud datasets to learn more about us please visit httpwwwearthdefinecomjob type fulltimesalary 7500000 to 8000000 yearexperiencegis 3 years preferredpython 2 years requiredmachine learning implementation 1 year preferrededucationmasters preferredwork authorizationunited states required,77500.0,WA,True,data_engineer
Data Engineer - Presto/Flink/Kafka/Spark - Early Stage Start...,ms or bs in computer science or software engineering required5 years of data engineering operations experience especially in the clouddirect experience in building large scale data platform including hadoop spark kafka flinkstorm hivepresto or druidverticapassionate about scalability and efficiency details and process orientedmust be local in san francisco bay areakubit is a venture backed early stage startup building a saas analytics platform for machine learning based diagnostics we currently have 5 engineers and are hiring more to growabout usfounder has 20 years of software experiences mostly in startups recent 7 years as cto of smule scaling engineering team 10x and operations 1000x httpswwwlinkedincominzhonglinglijoin an elite team focusing on execution build amazing products from 0 to 1 then scale and grow with the companyno red tape staying lean and mean a flat organization where everyone is hands on and get things donegenerous stock options and benefits including medicaldentalvision 401k and fsah1b and green card sponsorshipoffice is based in belmont ca with ample parking walking distance to caltrainplease don’t apply if you are looking for worklife balance or work from homeremote arrangementshave an inbox often with hundreds of unread emailsdidn’t read any technical or startup books in the last six monthswant inflated titles and can’t do hands on workwhat we are looking for selfmotivated individuals with a strong urge to make a difference and take chargeentrepreneur mindset effective contributors with strong leadershipstrong analytical and critical thinking skillsalways learning especially from failures humble and objective team playerexcited about the enormous potentials of data and analyticsjob type fulltimeexperiencemachine learning 1 year preferredhadoop 1 year requiredkafka 1 year requiredspark 1 year requirededucationbachelors requiredlocationsan francisco bay area ca required,,CA,True,data_engineer
Data Engineer,"data engineer – claims data science
description
the hartford financial services group is seeking an energetic and passionate data engineer as a member of the claim data science team this candidate will be responsible for designing developing and implementing data assets for a wide range of operational initiatives supporting the claims department
we seek candidates with a solid understanding of data architecture and principles of etl and data warehousing coupled with strong analytical communication interpersonal and business skills this position will be a key member of a crossfunctional business it and data science team developing deep insights using predictive models and artificial intelligence to enhance claim operations and outcomes this role will combine business and technical skills involving interaction with business customers data science partners internal and external data suppliers and information technology partners
responsibilities
 identify and analyze internal and external data sources for availability and quality
 perform data analysis to ensure accuracy of the data and determine applicability
 identify areas of opportunity to improve or enhance existing data processes
 support data assets and perform adoption activities including pseudo production maintenance quality measures documentation use case development and consulting activities
 partner with data scientists business partners and data suppliers to create innovative solutions and define business requirements
 relate the data to the business processes and communicate information regarding the availability quality and other characteristics of the data to a diverse audience
 perform cost benefit analysis of concepts and solutions to drive prioritization
 evolve and maintain a position as a developing subject matter expert and data consultant
 create and follow a strategic plan and report progress to management

qualifications

qualifications
experience  skills
candidates must have the technical skills to transform manipulate and store data the analytical skills to relate the data to the business processes that generates it and the communication skills to disseminate information regarding the availability quality and other characteristics of the data to a diverse audience
•
 experience accessing and retrieving data from large data sources
•
 experience with data modeling data warehousing tools and databases eg etl oracle teradata sql server
•
 experience in python andor r
•
 experience in creating and tuning sql queries
•
 ability to analyze source systems and provide business solutions
•
 selfstarter with a willingness to become a data expert and to learn new skills
•
 results oriented with the ability to multitask and adjust priorities when necessary
•
 ability to work independently or in a team environment with internal external customers
•
 ability to determine business solutions and translate into actionable steps
•
 experience with indexes and basic database design is a plus
•
 knowledge of insurance claims operations and analytics is a plus
•
 experience with medical and healthcare data is a plus
•
 bachelor degree or equivalent experience in related field required
behaviors at the hartford
•
 deliver outcomes – demonstrate a bias for speed and execution that serves our shareholders and customers
•
 operate as a team player – work together to drive solutions for the good of the hartford
•
 build strong partnerships – demonstrate integrity and build trust with others
•
 strive for excellence – motivate yourself and others to achieve high standards and continuously improve

equal opportunity employerfemalesminoritiesveteransdisabilitysexual orientationgender identity or expressionreligionage

 no agencies please 


job function
 data engineering
primary location
 united states
schedule
 fulltime
job level
 individual contributor
education level
 bachelors degree ±16 years
job type
 standard
shift
 day job
employee status
 regular
overtime status
 exempt
travel
 no
job posting
 oct 8 2018 14554 pm
remote worker option  yes",,,False,data_engineer
"Data Engineer Intern, Summer 2019","temporary internshipriot games was established in 2006 by entrepreneurial gamers who believe that playerfocused game development can result in great games in 2009 riot released its debut title league of legends to critical and player acclaim as the most played pc game in the world over 100 million play every month players form the foundation of our community and its for them that we continue to evolve and improve the league of legends experience

were looking for humble but ambitious razorsharp professionals who can teach us a thing or two we promise to return the favor like us you take play seriously youre passionate about games we embrace those who see things differently arent afraid to experiment and who have a healthy disregard for constraints

thats where you come in

intern with the data discipline
the data challenges at riot games are extensive and you can expect to level up in all data domains this includes software engineering distributed systems data modelling and machine learning

as a data engineer intern you may

contribute to engineering efforts in stream processing platforms aimed to unlock clean analytic data for all riot teams
learn the internals of building a robust endtoend data pipeline on all levels especially in software development databases infrastructure data modelling and data processing
contribute code to production data systems and gain strong software engineering practice
gain handson experience in distributed data processing technologies kafka spark and flink
learn techniques for high volume distributed data processing and storages
ensure the integrity availability and confidentiality of data database systems and supporting services
be involved in the data processing of hushhush unannounced titles that are being worked on in our skunkworks lab research and development

while our engineers come in all shapes and sizes and work with many technologies we expect every engineer at riot to be


playerfocused youre a gamer whose passion for games especially league of legends helps you stay focused on initiatives that make the difference to players in and out of the game
a threat to convention bored by whats considered traditional you constantly push past limits until the status is no longer quo you dont think outside the box because hey theres no box
focused on team you find shape and cultivate teams that dont just swing for the fences they jack that metaphorical baseball beyond the stars you help rioters develop the tools and creative atmosphere to shine but ultimately hold them accountable for making smart calls and delivering capitalv value
seriously playful you work hard but always leave time for pentakills whether youre grabbing a game of league in our onsite pc bang or rapidly sharing cat gifs you make time for daily play in all of its wonderful forms
humbitious youre ambitious but humble a state of being summed up by fans of portmanteau as humbitious always shooting for the stars you never forgo rounds of feedback from teammates players and partners who keep you from drifting off into space

to be eligible for an internship within the data discipline you should


be enrolled fulltime in a computer science or relative program for a minimum of 1 school term following your internship with riot
be returning to university following your internship as a junior or senior with only 12 years left before completing your program
have completed at least 1 competitive software development focused internship

we receive a lot of applications but well notice a fun wellwritten intro that shows us you take play seriously apply below and dont forget to include a resume and cover letter



to apply



please read through the internship page  httpswwwriotgamescomuniversityprograms  before applying it includes helpful information thatll increase your chances at landing the gig
your application must include a cover letter and resume in your application pitch share your summoner name and experience with league of legends why youre interested in riot what you want to learn and what we can learn from you help us understand why youre right for this team by sharing what youve done thats truly above and beyond and how that may relate to this internship opportunity there are 99 ways to impress us but an average pitch aint one

the application deadline for summer 2019 internships is december 31st 2018 applications received after this date wont be eligible for a summer 2019 internship we recognize that a great application takes time and effort so we promise to return the favor of your effort with a response by january 15th 2019",,CA,False,data_engineer
Data Engineer,100000  110000 a yearwe are redefining the guest experience at hotels worldwide our mission is to create a whole new way to travel taking advantage of cuttingedge mobile technologies to deliver a superior hotel stay we put guests in charge of what when and how they want their hotel to meet their needswe are building the nextgeneration hardware and software platform for the hospitality industry to meet these needs and are looking for brilliant and versatile team members who know the technology landscape and can craft simple and creative solutionswe are currently looking for a mid level to senior data engineer to assist our engineering and product teams in designing and implementing a new data pipeline and data solution to provide our business teams and our customers with valuable business insights based on the usage of our platform this is an opportunity to join a dynamic team and help define our data strategyjob responsibilitiesmanage our existing analytics solutions and improve them to satisfy business and product requirementsarchitect data pipelines to transform and validate datamaintain data quality and integrity across our systemscommunicate goals and progress to teams and stakeholdersassist in data governance processes planning security and executionjob requirementsexperienced in data modeling etl development and data warehousingexperience with various aws services including rds redshift and s3experience consuming and cleaning data from thirdparty apis and other sourcesexperience with big data technologies such as hive hadoop or sparkstrong organizational and analytical skills with an ability to extract meaning from datastrong communication skills to interact with stakeholders and customersstrong experience in python or similar languages is a plusjob type fulltimesalary 10000000 to 11000000 yearexperiencedata modeling 1 year requiredapi integration 1 year preferredhadoopspark hive 1 year requiredpython 1 year preferredaws services 1 year required,105000.0,CA,False,data_engineer
Data Engineer,company descriptionnovantas solutions is a division of novantas inc a new york based consulting firm that provides advisory services and decision support software to the financial services industry the firm focuses mainly on issues of revenue strategy which we describe as customer science” this may include work focused on segmentation product design pricing distribution management payment services sales execution effectiveness branding market mix management and customer experiencethe novantas solutions division delivers datadriven software products and services to accelerate revenue growth and increase profitability in the financial services industry our solutions leverage the models and insights accumulated through years of consulting to top banks and financial institutions our team members have the business expertise analytical skills and knowhow to implement creative practical solutions for our clientsjob descriptionwe find that the most successful candidates for the data engineer position are natural and relentless problem solvers who are passionate about working with data to solve business problems these individuals demonstrate ease with quantitative analysis can work well as part of small multidisciplinary teams have a keen interest in software engineering and are passionate about developing leading edge analytical business applicationsour data engineers are part of the engineering team responsible for data architecture backend development and maintenance of our proprietary decision support software applications they work closely with product management and the front end development team to ensure that our products are constantly improving and have leading edge functionalityresponsibilities collaborate with product management and other engineers on the team to make product improvements and develop new featureshandson sql server development stored procedures functions etcmigrate complex data processing from sql server to big data using spark scala in the near futurecreate and maintain detailed documentation and functional design specificationsdesign data architecture and etl processes on our nextgeneration big data stackperform ongoing backend database maintenance of existing applicationsprovide technical information to assist in the development of client facing product documentationauthor and participate in software design and code reviewsadhere to change management protocols and version controlpresent demonstrations of new features to internal product teams as well as high level firm leadership and partnersdesired skills and expertiseaspiring candidates should have the following background skills and characteristicsbachelors degree preferably in computer science or engineering field3 years of experience in database development or software engineeringfamiliarity with the design development and maintenance of bestinclass bi capabilities including data warehouse data structures and data pipelines spanning sparkhadoop and rdbms worldsexpertlevel database development experience in sql server preferably for reporting data marts and business intelligence solutions including writing stored procedures for complex business logic in tsqlfamiliarity of architectural design patterns for microservices leveraging relational and big data technologies is an added plusfamiliarity with agile development process svn or other change management protocols would be a plushandson development experience with big data technologies such as hadoop impala spark scala would be a plusproven track record of academic andor professional successexceptional analytical thinking ability ease with quantitative analysis and excellent problem solving skillsself–discipline and willingness to learnability to work well with others in a highpressure environmentexcellent verbal and written communication skillsonly local candidates are encouraged to apply we offer a competitive salary along with a complete benefits packagewe are proud to be an equal opportunity employer all candidates must possess work authorization which does not require sponsorship for a work visaplease visit wwwnovantascom for more informationjob type fulltimelocationnew york ny 10017 preferredwork authorizationunited states required,,NY,False,data_engineer
Data Engineer I (seeking the December 2018 graduate; start d...,"we are farmers

job summary

the data rotation program will allow recent college graduates to rotate through a 12 month program exploring different areas within the chief data officer’s cdo group individuals will rotate through 4 assignments of approximately 3 months duration determining where and how to make the strongest impact potential areas of placement include business intelligencedata delivery business unit data engineering financial data engineering customer master data engineering operational data engineering emergingbig data engineering data quality and data user support

we are seeking the december 2018 graduate this opening will offer a start date of january or february of 2019

essential job function
actively contribute to farmers insurance data endeavors to manage core business
drive customer centricity while developing breadth of skill and knowledge across the data domain
understand design and utilize data structures and content via established and emerging technologies
gain technical and subject matter expertise through professional development and exposure to senior leaders and visible assignments
build and develop competencies thru a combination of onthejob learning formal and informal mentorship and training that will enable the potential to take on significant ownership roles in the organization upon completion of the rotation program

education requirements
four year college degree in science technology engineering statistics mathematics

experience requirements
prior internship or relevant professional experience in it data is a plus


physical actions required job duties are essentially sedentary work consisting of occasional walking standing and lifting and or carrying 10lbs maximum
physical environment required job duties are normally performed in a climatecontrolled office environment


internal title sr data management analyst


farmers is an equal opportunity employer committed to the strength of a diverse workforce


dice

schedule fulltime

job posting 10172018",,CA,False,data_engineer
Data Engineer,"60000  65000 a yearthe agencythe department of city planning dcp plans for the strategic growth and development of the city through groundup planning with communities the development of land use policies and zoning regulations and sharing its perspectives on growth and community needs with sister agencies in collaboration with the office of management and budget ombdcps six strategic objectives include a catalyze longterm neighborhood improvement through integrated planning and targeted accompanying public investments b encourage housing production affordability and quality c promote economic development and job growth d enhance resiliency and sustainability of neighborhoods e ensure integrity timeliness and responsiveness in land use reviews and f supply objective data and expertise to a broad range of planning functions and stakeholderscentral to its mission dcp supports the city planning commission in its annual review of approximately 450 land use applications the department also works closely with omb in developing the tenyear capital strategy and helping administer the neighborhood development fund geared toward ensuring that growing neighborhoods undergoing rezoning have accompanying infrastructure investmentsthe new york city department of city planning is a great place to work  cultivating intellectual inspiration professional development and creativity visit our website at wwwnycgovplanning to access the full listing of job opportunities and to learn more about our great agencythe divisioninformation technology division itd is responsible for supporting the agencys technology footprint including technology infrastructure across five boroughs as well as workflow applications and databases for analytics and decisionmaking the division is comprised of 50 interdisciplinary staff with specialties in desktop support server engineering telecom application development database maintenance data processing data visualization and mapping amongst many others the division provides technology support for agency staff across five boroughswithin itd the enterprise data management edm section is responsible for creating and implementing the agencys data strategy and data governance policy updating and maintaining core citywide data sets in support of 911 dispatch and the operations of city agencies and improving the creation use and availability of geospatial data sets within the agencythe roleitds enterprise data management edm section is seeking a highlymotivated innovative data engineer to modernize data set development by automating processes and ensuring procedures are reproducible and transparent heshe will be involved in the design and implementation of the entire data pipeline from capturing and storing disparate data sources to processing that data and making that data available to dcp staff the data engineer will work across the agency to understand data needs and create systems that provide consistent and complete information to help solve business problems heshe will work to increase data literacy throughout the agency provide guidance on best practices collaborate with stakeholders write blogs and participate in both formal and informal data information sessions this work supports analyses used to inform important decisions such as the allocation of the neighborhood development fund designation of areas subjected to special zoning regulations and siting of new facilitiesdata engineering is a new unit within edm responsible for modernizing and improving some of the citywide data sets distributed on bytes of the big apple including plutomappluto zoning tax lots and the facilities database it works with agency planners to automate the creation of additional high value data sets that require frequent updates responsibilities will include develop and maintain data pipelines with a focus on writing scalable clean and faulttolerant code to handle disparate data sources work with agency staff to understand their business requirements and gather technical requirements for new data sets or updates to existing data sets collaborate with other engineers to design and implement edms next generation data warehouse system implement new product features and performance improvements to existing data products write and disseminate technical documentation and metadata help drive optimization testing and qaqc to improve data quality across the product and perform other related tasks

minimum qual requirements

1 a baccalaureate degree from an accredited college and two years of experience in community work or community centered activities in an area related to the duties described above or 2 high school graduation or equivalent and six years of experience in community work or community centered activities in an area related to the duties as described above or 3 education andor experience which is equivalent to 1 or 2 above however all candidates must have at least one year of experience as described in 1 above

preferred skills

strong sql experience postgresql  postgis experience developing and analyzing spatial data familiarity with python bash and javascript comfort with source control github and working in a linux environment interest in urban planning and knowledge of nyc geography and data strong analytical quantitative problemsolving and critical thinking skills excellent interpersonal verbal and written communication skills

to apply

click on apply now at the bottom of the postingplease be advised only candidates under consideration will be contactedappointments are subject to office of management and budget omb approvalthe candidate selected for this position must be a resident of the city of new york or become a resident within 90 days of appointmentauthorization to work in the united states is required for this position sponsorship is not available for this positionthe department of city planning is an equal opportunity employer and a copy of the equal opportunity programs is available in the human capital division the department makes available accommodations for disabled applicants

residency requirement

new york city residency is generally required within 90 days of appointment however city employees in certain titles who have worked for the city for 2 continuous years may also be eligible to reside in nassau suffolk putnam westchester rockland or orange county to determine if the residency requirement applies to you please discuss with the agency representative at the time of interview",62500.0,NY,False,data_engineer
E-Discovery Data Engineer,"an ediscovery data engineer in the advanced data services group at prosearch supports the custom data transformation needs of prosearch clients ediscovery data engineers at prosearch support quality and data integrity by

engineer and implement solutions and workflows for clients and internal teams
perform both standardized and adhoc data analysis reporting and modifications via sql
create implement and support custom event handlers
creatively utilize and combine existing scripts recipes and applications both proprietary and thirdparty to automate tasks and workflows
contribute to solution and script ownership including providing training and guidance on use and supporting enhancements and troubleshooting
apply",,CA,False,data_engineer
Data Engineer,contractsr data engineerwith tableau administrationlocation san josesunnyvale must have tableau administration related to application user admin and not necessarily servers and data visualization experience experience in at least one etl solutionssis informatica talend etc data engineering user trainingconsulting softwareproduct architecture scriptingdevelopment experience python sql is preferred understanding of acl load balancer proxy and other network configurations verbal  written communication customer focus teamworkcollaboration eye for automationjob type contractexperiencedata visualization 2 years preferredscripting 3 years preferredsql 6 years preferredadministrative 3 years preferredinformatica 5 years preferred,,CA,False,data_engineer
Big Data Engineer Internship,20000  80000 a yearparttime internshipour big data internship programs include the big data project development and big data training courses which guide the intern student how to finish the real cases in gosvea inc our aim is to establish the undergraduate and graduate students with characteristics unique to silicon valley now we are looking for internship candidates cptopt who are interested in big data fieldresponsibilityaccept onemonth training program in big dataorganize events and marketing activitiescreate contents for the website and social mediadevelop marketing channels app web site just one choice is okrequirementsbabs degree required at leastoptcpt are welcomed sponsor h1b for excellent peoplecomputer science business marketing or related major is our best choicecandidates must be fluent in both english and chinesejob types fulltime parttime internshipsalary 2000000 to 8000000 yeareducationbachelors preferred,50000.0,CA,False,data_engineer
Reliability Data Engineer,"overview
engineer will provide ramslcc systemproduct demonstration and validation so that the performance of the system is measured and formally documented the engineer manages the environmental fire and smoke requirements of developed and purchased products these activities are primarily for embedded electronics and mechanical products developed for railway brake and coupler systems
responsibilities
target responsibilities
derive validate and document failure rates modes and effects at product level
derive validate and document maintainabilitylcc data for products
provide detailed failure rate analysis on systems subsystems and components or equipment level  reliability prediction based on standard model test data and field data
perform qualitative  quantitative analysis with focus on failure rate allocations
support impact analysis of design change requests on ramslcc targets
setup and schedule interaction with customers to collect reliability data in a systematic and structured manner resulting in improved and updated understanding of field performance
trackanalyze field and test data for contractual compliance producing reliability reports and updates to rams database
review and understand the environmental fire and smoke fs industry regulations and customer requirements for the railway market
support ramslcc systems engineer with the development of environmental and fs documentation
manage and update the fs database checking validity and expiration date
qualifications

target qualifications
bs engineering minimum 1 years of experience in rams analysis
working knowledge in industry standards and analysis techniques iec 61508 en5012689 mil 756
experience with reliability and maintainability demonstrations
experience with conformity to flamesmokeenvironmental regulations for product design
understanding of problem solving root cause analysis and experience with segregating reliability failures from manufacturing defects and misdiagnosis
background with development of product maintainability and reliability prediction through test data field data analysis standard model calculations
working knowledge of pha sha ssha osha fmeca fta reliability and maintainability analysis is preferred
demonstrate engineering design skills with ramslcc focus
good writing and verbal communication skills related to technical items and reporting
functional knowledge of reliability maintainability rm processes and tools and skilled with graphical presentation databases spreadsheets and wordprocessing software
knowledgeable of rams tools and techniques
preferred working engineering knowledge of pneumatics embedded control electronics mechanical systems
preferred experience in transit or rail industry
us citizenship
code in123

li123",,SC,True,data_engineer
Data Engineer,"at brivo we are on a journey to transform the physical access control industry a critical piece of this transformation is a robust data infrastructure as a data engineer you will work with a brilliant team to architect a big data platform that is realtime stable and scalable in order to support data analytics reporting data visualization and machine learning you will help to build the data product with cuttingedge technology and best practices your input and contribution will have direct impact on our data strategy and overall product roadmap please join us to reshape how data is processed and analyzed in the security industry

responsibilities

design and develop etl for the new big data platform with open source technologies such as kafka spark and presto etc

implement and support streaming technologies such as kafka spark and kinesis to move data efficiently

refactor the existing data model into an easytomaintain data solution across the organization

work with agile teams to perform code reviews and participate in planning and design sessions

work with qc team to assure product quality

work with operations team to automate build and deployment from dev to prod

required qualifications

5 years of work experience with etl and data modeling

4 years of experience with open source technologies spark kafka presto hive cassandra etc

3 years of experience in architecting and building scalable data platforms processing data on a terabyte or petabyte scale

2 years of experience with aws  emr athena kinesis s3 ec2

expert in at least one sql language such as tsql or plsql

understanding of modern data structures and business intelligence reporting tools and track record of applying those on the job

ability to manage numerous requests concurrently and be able to prioritize and deliver

good communication skills and dynamic team player

preferred experience

experience in realtime analytics applications

experience in both batch and stream processing technologies

experience with java or scala programming languages

machine learning experience with spark or similar

education

bachelor’s degree in computer science computer engineering data science or related fields master’s and above preferred

about brivo

brivo is the original innovator of cloudbased physical security solutions for commercial buildings currently serving over ten million users brivo offers a unified security platform including access control mobile credentials mobile administration video surveillance identity federation visitor management and elevator control as a saas company brivo also offers a complete api platform service that empowers partners to build custom integrations and vertical market offerings our mission is to make the world a safer place by providing a subscriptionbased service for securing buildings using reliable convenient scalable cyberhardened technology

what’s it like to work at brivo

unlimited pto

casual and open work space

flexible work schedules

motivated coworkers in a collaborative and entrepreneurial environment

fun team environment with games potlucks parties and happy hours

agilescrum development

company sponsored team outings",,MD,True,data_engineer
Big Data Engineer,"contractjob title big data engineer

the retail distribution analytics rda teams mission is to dramatically transform clients current retail distribution strategy and performance around the globe by enabling the sales team to deepen and expand their relationships with financial advisors  home offices by leveraging data to provide thoughtful analytics and by delivering cutting edge technology tools  applications to the sales force the team currently consists of 50 people primarily located in new york princeton and san francisco

we are seeking a talented programmeranalyst with strong data management and etl development skills to join our team the candidate will work on all aspects of the data management process including the acquisition onboarding attribution and reporting of newly acquired data sets opportunities to migrate existing data acquisition and onboarding processes to new  strategic sources and protocols will also be a priority the work is expected to combine some project management and basic reporting in support of the teams overall goals to provide highquality data that supports analytics and the sales process in a timely fashion

top technical  programming skills – in particular sql python hadoop java and excel – are a must given the highly executionfocused nature of the work the ideal candidate will roll up their sleeves to ensure that their projects meet deadlines and will always look for ways to optimize processes in future cycles experience in project management and laying out and communicating a project schedule are also important

drive the onboarding and attribution of newly acquired data sets in to our database environment manage all aspects of the loading process monitor attribution throughout the process and identify ways to optimize the process each cycle identify investigate and resolve data discrepancies by finding the root cause of issues work with partners across various crossfunctional teams to prevent future occurrences proactively look for opportunities to optimize the data loading structure and develop new approaches to improve the onboarding and integrity of the data provide basic reporting and respond to inquiries asking for insights about the data sets from senior stakeholders in a timely fashion maintain a project management tracker and assist with the communication of the teams status and deliverables on a regular basis

skills
bachelors degree preference for economics finance or computer science or related fields preferred

49 years of experience developing in the hortonworks hadoop stack

python hadoop pyspark using apache spark sql server sql sybase

14 years of experience in the financial services sector preferably at a toptier asset manager investment bank or management consulting in a datadriven role or at a technology firm strong crossfunctional experience in data management onboarding and attribution of large data sets ability to interpret data to help in strategic decision making demonstrable problemsolving quantitative and analytical skills strategic and creative thinking track record of strong performance history of effective multitasking manage long complex projects alongside urgent highpriority tasks expectation setting escalation of issues where appropriate experience with financial markets working knowledge of the asset management andor financial services industry preferred solid proficiency in all microsoft office applications expert excel skills strong organizational planning and coordination skills ability to clearly articulate and present ideas both in writing and verbally to senior management as well as outside audiences experience in working on longterm projects and iterative development cycles where constant improvement is expected exceptional project management skills with attention to detail collegial orientation relationshipbuilder who is solutionsoriented comfortable interacting with all levels of management able to work effectively under pressure and in a rapidly changing environment in order to meet deadlines focused attention to detail and high standards for quality and accuracy in hisher work product professional positive demeanor collaborative teamoriented serviceoriented strong interest  curiosity about asset management industry

keywords
education
bachelors degree preference for economics finance or computer science or related fields preferred

skills and experience
required skills
multitasking

asset management

problemsolving

data management

microsoft excel

additional skills
data acquisition

database

apache spark

management consulting

engineer

excel

financial services

hadoop

java

microsoft office

project management

pyspark

python

quantitative

sql

sql server

sybase

databases

etl

finance

financial markets

ms sql server

retail

retail distribution

retail marketing

sales team

indny",,NJ,True,data_engineer
Senior Big Data Engineer,"req id 32804

at ntt data services we know that with the right people on board anything is possible the quality integrity and commitment of our employees are key factors in our company’s growth market presence and our ability to help our clients stay a step ahead of the competition by hiring the best people and helping them grow both professionally and personally we ensure a bright future for ntt data services and for the people who work here

ntt data services currently seeks a senior big data engineer to join our team in durham north carolina usnc united states us

the senior data engineer will be responsible for finding trends in datasets and developing workflows and algorithms to help make raw data more useful to the enterprise he or she will also be responsible for creating data acquisition strategy and develops data set processes

you should be enthusiastic about learning new technologies and be able to implement solutions using them to provide new functionality to the users or to scale the existing platform

excellent written and verbal communication skills are required as the person will work very closely with diverse teams having strong analytical skills is a plus

primary responsibility
as a senior data engineer you must be an expert with big data technologies like hadoop hive hbase spark and various aws technologies
you will architect and drive the build out of next generation data platform
you will build reusable code with the ability to scale with very large data volumes
everything you build will need to scale and perform
define and lead the frameworks for compliance with data management standards for emerging technologies streaming platforms cloud integration etc
you will drive the build out of next generation data platform
general responsibilities
be part of a core team leading migration to new data technologies for unstructured streaming and high volume data
overall accountability of your work and adopt established data management frameworks to prevent data lakes from becoming data swamps
provide senior level technical consulting to application development teams during application design and development for highly complex or critical projects
as a handson engineer you will influence all architecture decisions
job functions
provide technical leadership to build and implement data and big data solutions
articulate pros and cons of various technologies platforms and tools
demonstrated work experience with distributed scalable big data programming model and technologies such as hadoop hive pig etc
demonstrated handson experience with atleast one of the major hadoop distributions preferrably cloudera
deep technical expertise in hadoop eco system components
experience designing developing and implementing onlinemachine learning libraries
minimum experience

8 years’ experience in dimensional data modeling etl development and data warehousing
business consultingetl processes 5 years
big data  bdapache hadoop hdfsbasehivepigmahoutflumescoopmapreduceyarn 35 years
cloud dev and migrationawsanalyticsdwredshift  1 year

travel need locals
degree bachelors in computer science or equivalent work experience

desirable skills
master’s degree in information systems or a related field
hadoopcloud developer certification
experience deploying applications in a cloud environment ability to architect design deploy and manage cloud based hadoop clusters
exposure to cloud infrastructure
experience with redshift and other aws services

this position is only available to those interested in direct staff employment opportunities with ntt data inc or its subsidiaries please note 1099 or corp2corp contractors or the equivalent will not be considered we offer a full comprehensive benefits package that starts from your first day of employment

about ntt data services

ntt data services partners with clients to navigate and simplify the modern complexities of business and technology delivering the insights solutions and outcomes that matter most we deliver tangible business results by combining deep industry expertise with applied innovations in digital cloud and automation across a comprehensive portfolio of consulting applications infrastructure and business process services

ntt data services headquartered in plano texas is a division of ntt data corporation a top 10 global business and it services provider with 118000 professionals in more than 50 countries and ntt group a partner to 88 percent of the fortune 100 visit nttdataservicescom to learn more

ntt data inc the “company” is an equal opportunity employer and makes employment decisions on the basis of merit and business needs the company will consider all qualified applicants for employment without regard to race color religious creed citizenship national origin ancestry age sex sexual orientation gender identity genetic information physical or mental disability veteran or marital status or any other class protected by law to comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability the company will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the company would result",,NC,True,data_engineer
SENIOR DATA ENGINEER,"job details
description
we are looking for experienced data engineers to work on building operating and scaling next generation data platforms and tools that will power datadriven capabilities throughout the entire organization spanning areas such as business intelligence and reporting data science and data analytics

here at ultimate software we truly put our people first we strongly believe in teamwork and we encourage and trust our people to reach higher learn more and live up to their potential ultimate is ranked 1 on fortunes “best places to work in technology” for 2018 and 3 on the “100 best companies to work for” list in 2018 ultimate is also ranked 1 on the fortune’s “100 best workplaces for millennials” for 2018 and 3 on its best workplaces for diversity” list for 2017

primaryessential duties and key responsibilities
you will be responsible for handson development of frameworks and applications for largescale data processing
you will be expected to influence technical direction for the team leveraging your prior experiences and helping evaluate emerging technologies and approaches
you will help bring engineering maturity to a growing team that is at the center of a lot of critical initiatives for the company
required qualifications

significant experience doing handson development
understanding of distributed systems driving largescale data processing and analytics
familiarity or expertise with technologies like hadoop and related ecosystem spark kafka
experience shipping production code and working on real running systems at scale
experience building operational data pipelines
ability to work both collaboratively and autonomously
ability to communicate effectively listening presenting and questioning
strong organizational written and communication skills
preferred qualifications
exposure to largescale stream processing systems
deep expertise with one of the major hadoop distributions hortonworks cloudera etc
experience working in hybrid private  public cloud environments
experience working with javabased technologies and frameworks
development experience with one or more of java scala python
experience working with data science
experience working with bi and data warehousing tools
experience working with enterprise data where security is paramount and data governance is critical
experience with eventdriven architectures
experience working with agile methodologies
degree in computer science or a related technical field involving coding eg physics or mathematics or equivalent practical experience
physical requirements
no unique physical demands are required for this job
travel requirements
limited travel upon request less than 5


this job description has been written to provide an accurate reflection of the current job and to include the general nature of work performed it is not designed to contain a comprehensive detailed inventory of all duties responsibilities and qualifications required of the employees assigned to the job management reserves the right to revise the job or require that other or different tasks be performed when circumstances change

ultimate software will reasonably accommodate employees with disabilities as defined by the rehabilitation act of 1973 the americans with disabilities act ada and other appropriate statutes",,CA,True,data_engineer
Data Engineer (Legal),"job description
amazon legal is looking for an outstanding analytical and technically skilled bi engineer to join our legal technology team this position will be responsible for building and supporting business analytics and reporting for the amazon legal department as a whole

this role requires an individual with excellent statistical and analytical abilities deep knowledge of business intelligence solution and data engineering practices as well as outstanding business acumen and an ability to work with a variety of teams across amazon legal the successful candidate will be a selfstarter comfortable with ambiguity have a strong attention to detail an ability to work in a fastpaced environment and be driven by a desire to innovate in this space in this role the right person will be able to revolutionize the department’s monthly reporting processes and develop insightful and meaningful metrics and reports that enable decision making at all levels

primary responsibilities
support a platform providing secure access to departmental reporting across all areas of legal practice
interface with business customers and delivering complete bi solutions
model data and metadata to support adhoc and prebuilt reporting
own the design development and maintenance of ongoing metrics reports analyses dashboards etc to drive key business decisions
recognize and adopt best practices in reporting and analysis data integrity test design analysis validation and documentation
learn and understand a broad range of amazon’s data resources and know when how and which to use and which not to use
continually improve ongoing reporting and analysis processes automating or creating selfservice options
develop analytical tools to provide transparency into spend
create operational scorecards based on key metrics leveraging multiple different data sources to build a cohesive story
synthesize and translate complex findings into relevant and actionable insights
basic qualifications
5 years of relevant experience in a business intelligence role including data warehousing and business intelligence tools techniques and technology as well as experience in diving deep on data analysis or technical issues to come up with effective solutions experience in analytics business analysis or comparable consumer analytics solutions

bachelor’s degree in computer science engineering math finance statistics or related discipline or equivalent industry experience

excellent knowledge and expertise with sql olap and relational nosql  multidimensional databases

experience in data mining etl etc and using databases in a business environment with largescale complex datasets

knowledge and direct experience using business intelligence reporting tools like quicksight or tableau

proven ability to look at solutions in unconventional ways and see opportunities to innovate

excellent verbal and written communication and interpersonal skills to convey key insights from complex analysis in summarized business terms and an ability to effectively communicate with technical teams

amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation
preferred qualifications
experience with legal related data such as litigation legal billing patents ip or related fields

knowledge of aws infrastructure redshift nosql databases  associated technology

candidates with a phd or ms degree in a relevant field are preferred",,WA,False,data_engineer
Data Engineer - Fintech Start Up,95000 a yearfluz fluz is aiming to disrupt the global retail shopping experience through various consumer touch pointswe are a fintech company sitting in the intersection between blockchain social media payments and retailwe are a fastmoving company that has experienced rapid growthover the past year our team has grown from 5 members to over 45 and we are operating internationallywe are about to launch our us consumer cash back apwe are looking for a data engineer that will be responsible to set up the systems that will manage all of our transactional and user datathey will own the process of designing implementing and maintaining the systems used to collect and organize all data touch pointsthis position will report directly to the ceo and the company’s technical advisorsresponsibilitieswork with management and operations team to architectconnect all data points to a centralized point and configure all automated processes around thatown the process of selecting and implementing the reporting toolsintegrate all new data touch points in the the centralized reporting toolsconfigure customer data into enterprise grade crm toolscreate custom triggers with datasets to automate certain processesmonitor flow of data from various touchpoints to central system and upkeep systemshelp to monitor the production systems on a daily basis and respond immediately to any breakagesrequirementsexperience building out automationexperience with crm system configuration and customizationexperience with tableau or a similar systemlight understanding of distributed cloud and micro service architectureexperience with awsexperience with nosqlability to breakdown and articulate solutions to complex problemsknack for writing clean readable and maintainable codewillingness to learn and teachdesire to be involved in product definitiona love for automationstrong sense of urgency in a professional settingcompensation95000 plus annual bonus and other benefits competitive salaries team socials paid vacation days free coffee tea and snacks dog friendly office and insider accessyou will work withmaurice harary cofounder maurice is one of fluz fluz’s cofounders he leads business development efforts and product view a businessman at his core he loves to build  grow companies his personal hobby is building the fluz fluz companyandreas antrup board advisor andreas is one of fluz fluz’s board advisors with a technical focus when he is not advising fluz fluz he is managing a team of 400 ai developers at europe’s largest fashion retailer zolando andreas is focused on bringing the same best practices to fluz fluzragha srinivasan board advisor ragha acts as an involved board advisor for fluz fluz he supports the technical infrastructure development for the application when he is not advising fluz fluz he is leading the ai team at youtubeeric johnson product manager eric has been with fluz fluz since its inception he has witnessed it evolve into everything it is today and has a clear vision of where the company will be going he helps share that vision with all members of the team and implement the best user journey throughout the businesseeocall qualified applicants will receive consideration for employment without regard to race color religion gender gender identity or expression sexual orientation national origin genetics disability age or veteran statuslearn more about us at fluzfluzcomseniority levelmidsenior levelindustrymarketing and advertisingfintechmobile applicationsemployment typefulltimejob functionsdata mangementjob type fulltimesalary 9500000 yearexperiencedatabase management 1 year preferredtableau 1 year preferreddata engineering 1 year preferredcrm systems 1 year preferred,95000.0,NY,False,data_engineer
Data Engineer,"position summary
the new york county district attorneys office dany has an opening for a data engineer in its human trafficking response unit htru htru is responsible for the investigation and prosecution of sex and labor trafficking cases in manhattan it consists of speciallytrained adas analysts investigators and social workers who focus on developing proactive evidencebased prosecutions connecting victims to services and targeting individuals and businesses that permit trafficking to occur htru works closely with other areas of the office law enforcement agencies and nonprofit partners to target the business mechanisms of trafficking and disgorge traffickingrelated proceeds in this position the data engineer is responsible for providing highlevel confidential technical investigative support to htru

responsibilities include but are not limited to

work with those in your unit to understand case workflow and automate and streamline investigative steps wherever possible
develop technological infrastructure for your unit in the form of internal web applications or otherwise
develop tools to identify trends behaviors and patterns related to cases in your unit
work on cases directly wherever programming can speed up an investigation or bring in new insights
collaborate with others throughout the office to work on danywide applications and projects
partner with outside agencies or entities on datadriven projects
perform other related and necessary tasks as needed

qualifications

knowledge of python required
proficiency in microsoft sql or other rdbms experience
proven experience writing highquality code demonstrated through academic projects work experience andor an active github account
experience developing web applications via flask django html css and javascript
experience working with complex datasets
ability to communicate effectively with a broad spectrum of internal and external partners
motivation to find ways to use technology to improve the way cases are brought in and investigated within your unit

educational requirements

bachelors degree required
graduate degree in related field is preferred

commitment

one 1 year commitment to hiring unit

the new york county district attorneys office is an equal opportunity employer",,NY,False,data_engineer
Data Engineer - EAM,"job description

the enterprise asset management eam team is building the world’s most comprehensive and effective eam program and asset management database this is a huge challenge considering the considerable asset inventory and rapid growth of amazon to accomplish our goals we are interested in finding top candidates that are ready to take on challenges obsess over customers and lead change the eam programteam administrates the eam program via our software platform master data management strategy configuration and solutions deployment bi reporting and kpi development training and documentation the eam program is being deployed in the fulfillment centers data center and eu networks across many stakeholder groups

we are looking for a successful and outstanding mssql dbe de to help manage database support and operations for our highly complex and missioncritical systems these systems are critical to the enterprise asset management eam program and other related critical amazon applications the dba will be well versed in mssql data warehouse and integration technologies and will perform administration and engineering for multiple production databases the ideal candidate should have experience in the architecture design and implementation of large production systems with high transaction volumes the candidate will also be responsible for fastpaced complex distributed database environments supporting with large databases and complex integrations successful candidates will have the ability to rapidly troubleshoot complex technical problems under pressure


basic qualifications
bachelors degree andor masters degree in computer science with 5 years of industry experience
5 years of experience as a mssql dba or de in a high traffic transactional environment
experience with highvolume oltp  olap database systems
performance tuning of mssql plsql sql processes and queries
strong knowledge of systems architecture loosely coupled and distributed systems
day to day experience supporting highly scalable distributed service oriented systems
ability to work cooperatively with software engineers and system administrators
experience with system integrations etl data warehouse queries and stored procedures
strong understanding of fundamental relational database design data warehouse and business intelligence best practices methodologies and terminology
2 years working experience on infor eam software package including software configuration dashboard development using cognos business objects or ssrs reporting tools
one full cycle of software implementation experience is required
superior communication and analytical skills including strong ability to identify and solve ambiguous problems
strong knowledge in project development methodology clear verbal and written communication skills has the ability to handle daily activities in a dynamic environment and drive deliverables
preferred qualifications
master’s degree in computer science or related field with 10 years industry experience
4 years’ experience working with infor eam ion and other related eam packages
high attention to detail and proven ability to manage multiple competing priorities simultaneously
5 years’ experience in developing bi solutions using microsoft sql server analysis services ssas and reporting services ssrs
ability to build and maintain strong working relationships with dba and application teams
amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,WA,False,data_engineer
Data Engineer,data engineerabout usergo interactive is a market leader in datadriven hyperpersonalized adaptive algorithmic email journey design and deployment it’s a mouthful but very cool stuff that is driving enormous returns for our bluechip clients the best way to explain it would be to envision you’re reading your favorite magazine and with every page you turn and every issue you read it becomes more relevant to you we call it content science™ and we’re looking for an exceptional data engineer to join our teamplease apply with your resume and a thoughtful cover letter telling us why youre the best fit for the jobdescriptionthe data engineer is responsible for developing maintaining testing and evaluating data solutions systems in order to load transform and query large data sets from a variety of sourcesessential functionswork with our data scientists to create datadriven insights and reports for senior managementassist data scientists in developing processes to migrate data from various formats and data sourcesoracle mysql sybase flat files etc to database architecturedesign and implement tools to analyze very large data set of raw dataprocess unstructured data into a form suitable for analysisperform ad hoc data updates and other followon data servicesautomate recurring analytics reports for clientsqualificationsbachelor’s degree or higher in computer science information systems or related fieldhighly proficient in sql mysql postgresexpertise with relational databases implementation queries modelingworking knowledge of distributed data stores cassandra redshift hadoop hbaseproficient in scripting language of choice python r php rubyexpertise with optimizing query performancefamiliarity with nosql technologies mongo db dynamodbdeep understanding of data structures and schema designdetailoriented proactive problem solving skillsperksa comprehensive career development program and traininggym membershipbagel fridayssummer fridaysoffice bar cart produce healthy and unhealthy snacks nespressopool tablecompetitive vacation allowancecompanypaid office shutdown between christmas and new year’s dayhealth vision  dental benefits401k planreferral bonus programpetfriendly officefun company outings and eventsvery cool industrialstyle greenwich village studio spacethe best perk our people if you’re ready to join us apply nowjob type fulltime,,NY,False,data_engineer
Junior Data Engineer,"the role

we’re looking for someone to join our data team who relishes the opportunity to work in datasets with millions to billions of records at risc networks we are passionate about solving complex problems transforming data into information and creating real value for our customers we are looking for a fulltime junior data engineer located in our downtown asheville nc office in this role you will get to work with some of the largest organizations in the world helping them understand their it environments and bringing context to the decisions they are making

gotta have it

sql database experience
you’re a natural problem solver comfortable facing new challenges especially within it
you have the ability to meet deadlines and adjust to changing priorities
you’re a technologist who stays current with trends
love it

programming experience with scripting languages perl python shell
familiarity with version control systems like git
experience with computer networking
like it

experience aws glue and other services
experience with automated unit testing
culture

you have a cando actionoriented approach to your work
the idea of working for a small but growing company is appealing to you
you love to learn new things
your meme game is strong
about risc networks

founded in 2007 risc networks strives to unlock business potential by delivering more meaningful data analysis created by engineers we understand the needs of it leaders we endeavor to provide actionable intelligence that it professionals can use to plan for it change

risc networks mission is to improve the performance of our partners and customers businesses and make a difference in their lives by developing technology and research that supports an actionable approach and perspective for their it business

we’re nestled in downtown asheville nc in the heart of the blue ridge mountains there is a lot of great beer food and music as well as mountain biking kayaking hiking etc asheville consistently ranks in national polls of top 10 places to visit

compensation

this is a salaried position compensation is based on experience and skill set

401k 100 health care and pingpong table provided",,NC,False,data_engineer
big data engineer,20000  80000 a yearparttime internshipwe are seeking instructors of big data and deep learning inspire beginner data scientist and deep learning engineers to commit to building their career you’ll lead technical workshops teaching the basics of data science or deep learningresponsibilities lead great events as an instructor or speaker collaborate with tas that will help you deliver a great experiencerequirements 05 years experience as a data scientist or deep learning real project experiences  optcpt students are welcomed sponsor h1b for excellent candidates  fluent in both english and chinesjob types fulltime parttime internshipsalary 2000000 to 8000000 yearexperiencecpt coding 1 year preferred,50000.0,CA,False,data_engineer
Junior Data Engineer,"fusion is currently seeking an entrylevel data engineer to join our fastgrowing software development team the data engineering team is responsible for developing and maintaining the data processes for our clients tasks will include import and export of data data migration from legacy systems interface development reporting development as well as maintenance and support for all our existing data projects

about us

fusion was founded in 2006 and has since become a major disruptor in the corrections and public health sectors of government recognized by inc magazine as one of the fastest growing private companies in the united states fusion is looking to expand its handpicked team to include a candidate through this job placement

from a company culture perspective we are a vibrant and young group who have come together to be leaders in healthcare it and software for government agencies the office provides open working spaces several meeting areas as well as a café  gym on premise

because of the niche fusion belongs in as well as the business model we operate with we are looking for not only skilled and qualified candidates but also candidates who have an outgoing personality and fit well with our other team members

to date fusion has a phenomenal retention of our team members our fundamental belief is that employee satisfaction is critical to achieving our mission so we provide competitive compensation professional development career advancement opportunities and a supportive teambased atmosphere we also provide a full range of health related benefits including medical dental vision and 401k and we offer worklife enhancements like flexible hours business casual dress code and an easygoing corporate structure

fusion has been recognized by inc 5000 list of fastestgrowing private companies – thanks to the tireless efforts of our team if you are a talented professional and our mission speaks to you please speak to us

job roles

communicate with partner companies to develop and support bidirection data communication
migrate data for new clients from old systems to new systems
create meaningful insight with data to help our customers meet compliance standard
develop reports to allow customers to view their data in the format they request
meet with government clients to understand their environment and work with project managers to determine the optimal solution for their needs
work with project managers to create and execute a technical implementation plan for larger client roll outs
work closely with product management to understand current and new product features so they may be implemented correctly


required experience

javascript
sql plus if it is sql server
crystal reports or any comparable reporting tool
c
windows network experience
familiarity with most common structured or delimited file formats csv xml json etc
familiarity with data transfer methods sftp http tcp soap rest etc
qualifications

bachelor’s degree in computer science or any itrelated field
working hours

standard hours for this role are mf start between 8 and 9 expected to put in 8 hours
willingness to provide weekly oncall coverage rotationally
additional notes

it is not expected that applicants have any familiarity with fusion’s proprietary applications ge healthcare software or correctionspublic health business processes qualified candidates will be able to demonstrate experience in this role as well a demonstration of working well with the fusion team
this is an onsite fulltime salaried position",,NJ,False,data_engineer
Data Analyst,"data analyst


who we are
murmuration seeks meaningfully improved education outcomes for kids by providing information infrastructure and support for educationrelated public advocacy and community building efforts
one of murmurations key initiatives minsights is an online platform that allows users to aggregate data from a wide variety of sources such as partner organization’s member data publicly available data consumer data voterfile data and more this data can then be used by partners to activate and expand their supporter bases effectively and mobilize them for sustained political change we also use this data to build predictive machine learning models that improve our partners’ efficiency murmuration has the unique opportunity to build with partners a massive dataset that can leverage creative data science to profoundly change the way that advocacy efforts and service providers engage their bases
about the position
the data analyst has two main responsibilities first listening to our partners and staff to understand the questions and problems they have that can be answered with data second sourcing the answers and solutions to those questions and problems and presenting them in a clean concise way for both technical and nontechnical audiences to understand to do this you must be a creative multidisciplinarian who will work with all parts of the organization from analyzing and visualizing the data with other analysts to sourcing new data with the data manager and data engineer and sitting in on partner calls with our partnerships team
if you are interested in learning more about data education or politics this is a great chance to gain handson experience with a small but quickly growing organization
the data analyst will
work with the partner solutions team to understand the key questions and problems facing our partners in particular those that could be answeredtracked with data
work with each part of the murmuration team to identify internal reports that could improve how we do business
create analytic reports graphs and dashboards for murmuration and for partners answering their key business questions
be conversant in basic statistics and be able to perform our most common analytic operations using tools such as python sql tableau excel
become an expert in data visualization solutions and learn when and where to apply each solution
build and maintain a style guide for murmuration’s data visualizations and reports
document business requirements across all murmuration’s products
work with the data manager to craft data acquisition strategy for any key data we are
missing that lets us address the above questions and problems

candidate profile
the data and analytics teams are highly collaborative friendly and hardworking and we are looking for a data analyst who embodies those values
the ideal candidate is
datadriven
creative
flexible
a selfstarter
a constant learner
a problemsolver
an effective communicator
teamoriented and collaborative
able to multitask and prioritize work effectively
responsible and able to meet deadlines
passionate about education andor politics or interested in learning more
the ideal candidate will have a bachelor’s degree in political science sociology mathematics statistics education or other related field

we are relying on you to be our translator storyteller and problem solver you should always be listening and reading between the lines to try and identify problems our partners and staff are having which are often different from the problems they are describing you are comfortable being highly reactive to solving the questions of today while also proactively keeping an eye on longerterm questions of strategic interest we don’t expect you to solve every problem but you should be able to identify them and then work with the rest of murmuration to craft a solution you will need to walk the fine line of knowing enough of the technical details of our solutions to be factually correct without spending so much time on it that it detracts from the primary goal of presenting these solutions as clearly and cleanly as possible

location
this position will be based in new york ny and requires minimal travel
compensation
the data analyst position is a fulltime salaried position with a comprehensive benefits package compensation for this position is commensurate with experience

an equalopportunity employer with a commitment to diversity
murmuration is proud to be an equal opportunity employer and as an organization committed to diversity and the perspective of all voices we consider applicants equally of race gender color sexual orientation religion marital status disability political affiliation and national origin we reasonably accommodate staff members andor applicants with disabilities provided they are otherwise able to perform the essential functions of the job",,NY,False,data_engineer
Data Engineer,"arcblock is looking for an experienced data engineer who is passionate about building great products in the context of a diverse multifunctional and independent team

our systems need to meet remarkably high standards of quality performance and reliability operating around the clock on a massive scale if you are a talented detailoriented and enthusiastic professional who is passionate about new technologies including big data computer vision and machine learning then this is the right team for you

in this data engineering role you will work closely with product engineering teams and data scientists to tackle problems in onchainoffchain data mining anomaly detection personalization search ranking etc you will build endtoend data solution for the company from analytics event definition data collection etl jobs all the way down to key metrics visualization and matching learning model serving you will work closely with backend client and productbusiness team to delivery calibrated internal metricslearnings and best user experience for our customers and users

who we are

arcblock incis a global leader in the blockchain revolution we are building the firstlever blockchain 30 ecosystem designed to reimagine how blockchain apps and services are built arcblock is combining current and nextgeneration blockchain technologies with cloud computing and token economics that remove today’s technological limitations and deliver a complete framework to developers that empowers them to build blockchain decentralized applications service we’re excited to announce that the company is growing and we are looking to add to our industrybest talent and are looking for people who are excited about the future
why work here

a fastgrowing team of passionate people and a techfirst  usercentric blockchain business
autonomy and endtoend ownership
a unique culture that is driven by our common principles
competitive paytoken incentive plan full medical catered lunch and your choice of hardware
big opportunity for internal growth weekly bbls monthly retrospective bootcamp every 68 weeks tech conferencesopportunity to work from us and china and travel around the world etc
essential duties and responsibilities

primary focus on delivering endtoend solutions
build and work with various data pipelines
build the team capability for continuously multivar ab testing
build machine learning models and deliver the models to backend team
work closely with backend team to build anomaly detection engine for both customers and our own infrastructure
basic qualifications

bscmsc in computer science or related field
3 years of industry experience at least two of which in a data infrastructure related role
proven track record of building and operating scalable flexible and alwayson data pipelines
strong knowledge of scala and apache spark
a passion for shipping production quality code with good test coverage
ability to quickly evaluate and make tradeoff decisions on adopting emerging technologies
an understanding of supervised and unsupervised machine learning methods
preferred qualification

familiarity with blockchain concepts and algorithms
familiarity with amazon aws tools and technologies
demonstrated leadership abilities in an engineering environment in driving operational excellence and best practices
the ability to take raw product requirements and develop software solutions and designs to bring them to life
excellence in technical communication with peers and nontechnical cohorts",,WA,False,data_engineer
Senior Data Engineer,data engineerjoin our seasoned team of data engineering professionals to take your career to the next level as a data engineer you will face the most complex and uptodate challenges by helping our clients address their complex data management reporting and analytical challenges using big data technologies hadoop columnar nosql dbs python and cloud services aws azure gcpminimum requirements5 years of experience in working with global clients in data management and business intelligence using python and hadoop for data managementexperience in writing efficient data management code to support high performance parallelization requirements in complex environments such as distributed and high performance environments cloud and enterprise solutionsexperience in working closely with clientsbachelor’s degree in technology disciplinepreferred requirementsstrong linux and windows administration skillscertifications in cloud platform aws gcp azurestrong python programming and object oriented programming skillsexperience in hadoop based data managementmasters level educationskills  capabilitieswriting complex and high performance data pipelinesability to automate endtoend production data pipelines using automation technologies such as airflow aws emr hadoop aws lambda etcuser data and security administration including integration with enterprise directories and data encryptionstrong understanding of cloud server environmentsstrong understanding of sql 2 years programming languages and other scripting languages eg python perlstrong communication and project management skillsability to work effectively in a global teamjob dutiescreate high performance data pipelines to support complex data integration workflowsdevelop automation programs shell scripts and other utilities to support overall goal of end to end automationproduces a weekly status report documenting project health and progresssupport process flow analysis and etl process redesigndocument and gain approval for customer requirements definitionparticipate in completion and implementation solution documentationparticipate in user acceptance testing efforts as neededparticipate in training design documentation and delivery efforts in concert with other project team membersparticipate in internal projects as requiredjob type fulltimejob type fulltimeexperiencehadoop 1 year preferredaws 2 years requiredshell scripting 4 years requiredpython 2 years preferredsql 4 years required,,NC,True,data_engineer
Data Engineer,"job description summary
the data engineer contributes to the vision development and administration of hadoop enabled infrastructure as a core service to all business functions
job description
responsibilities
support the administration of on premise and cloud based hadoop clusters
make information available to large scale next generation predictive analytics applications
work with senior staff to build implement and support the data infrastructure ingest and transform data etlelt process
qualifications
bachelor’s degree in computer science software engineering or related field
one year of etl experience with hiveimpala – hue etl and advanced sql programming
understanding of the hadoop ecosystem eg hdfs mapreduce hbase pig scoop spark hive
understanding of data warehousing and bi concepts including hands on experience building etlelt data pipelines
preferred qualifications
1 years of java andor python development experience
1 years’ experience in the data warehouse space
1 years’ experience in custom etl design implementation and maintenance
1 years’ experience in writing sql statements
background working in cloud platforms such as azure or aws
behavioral  leadership competencies
ability to analyze data to identify deliverables gaps and inconsistencies
communication skills including the ability to identify and communicate data driven insights
ability in managing and communicating data warehouse plans to internal clients
attention to detail and results oriented with a strong customer focus
the ability to work within a team environment
problemsolving and communication skills
our culture
at transamerica we promote a future fit mindset what is a future fit mindset
acting as one fosters an environment of positive collaboration
accountability allows us to own the problem as well as the solution
agility inspires new ideas innovation and challenges the status quo
customer centricity encourages an above and beyond approach to our customer
working conditions
office environment",,CO,True,data_engineer
Data Processing/ Big Data Engineer,contractdata processing big data engineer 14376 we’re a science and technology company with a very human mission our client is looking for a big data engineer for their san jose ca location this is a contract positionresponsibilities build realtime big data pipelinenot doing analytics not front end this is berequired skillsback end javaspark  plusemr plusstream processing plus4 10 yrs big data processing experiencedistributed systems experiencedatabase can be hadoop cassandra mongo and any nosql db  does not matter which oneimportant note  the technology does not matterlooking for someone who has worked in building data platforms ie  ingesting housing data the data  so that other people can use it for analyticsposition logistics 612 month contractwhat’s in it for you competitive pay for contact with excellent stability and opportunity for growthgreat opportunity to enhance or solidify your skills with an excellent diverse and experienced teamwork on multiple projects allows you to get experience with a variety of technologies and teamsabout maxonic since 2002 maxonic has been at the forefront of connecting candidate strengths to client challenges our award winning dedicated team of recruiting professionals are specialized by technology are great listeners and will seek to find a position that meets the long term career needs of our candidates we take pride in the over 5000 candidates that we have placed and the repeat business that we earn from our satisfied clientsinterested in applyingwe can’t wait to see your resume please apply below with your most current resume and anything else you’d like us to know about you – commute preferences desired work environments etc we promise to get back to you within 24 hours or you can feel free to contact mani at 4087394900 x 125key words data pipeline big data spark plus back endjob type contract,,CA,True,data_engineer
Data Processing/ Big Data Engineer,101000  138000 a year indeed est contractdata processing big data engineer 14376 we’re a science and technology company with a very human mission our client is looking for a big data engineer for their san jose ca location this is a contract positionresponsibilities build realtime big data pipelinenot doing analytics not front end this is berequired skillsback end javaspark  plusemr plusstream processing plus4 10 yrs big data processing experiencedistributed systems experiencedatabase can be hadoop cassandra mongo and any nosql db  does not matter which oneimportant note  the technology does not matterlooking for someone who has worked in building data platforms ie  ingesting housing data the data  so that other people can use it for analyticsposition logistics 612 month contractwhat’s in it for you competitive pay for contact with excellent stability and opportunity for growthgreat opportunity to enhance or solidify your skills with an excellent diverse and experienced teamwork on multiple projects allows you to get experience with a variety of technologies and teamsabout maxonic since 2002 maxonic has been at the forefront of connecting candidate strengths to client challenges our award winning dedicated team of recruiting professionals are specialized by technology are great listeners and will seek to find a position that meets the long term career needs of our candidates we take pride in the over 5000 candidates that we have placed and the repeat business that we earn from our satisfied clientsinterested in applyingwe can’t wait to see your resume please apply below with your most current resume and anything else you’d like us to know about you – commute preferences desired work environments etc we promise to get back to you within 24 hours or you can feel free to contact mani at 4087394900 x 125key words data pipeline big data spark plus back endjob type contract,119500.0,CA,True,data_engineer
Data Engineer,fetch rewards is a fast growing technology company that is innovating and changing how consumers fulfill their grocery needs we are headquartered in the heart of downtown madison with another office in the chicago loop area our company currently provides two mobile applications in the mobile grocery market  shop fetch and fetch rewards  in both the android and ios platforms the mission of fetch is to provide easy access to the information and technology necessary for people to enjoy every stage in the life of food inspiration planning purchasing preparation and of course  eating we are looking for a data engineer to help us change the grocery shopping experiencethis data engineer position will be a unique opportunity to gain experience with end to end spectrum of data  analytics ranging from1 manage and augment the entire data pipeline from raw database to relevant structures in data warehouse2 partner with the client service teams to help create analytical solutions that help our clients get rich insights from our unique data repositories that include fetch app usage data shopper transaction data and other shopper  product dimensionsthis person will be a key member of the analytics team and report to the vp of analyticsresponsibilitiesmaintain and implement systems that ingest transform organize and expose data insightsautomate database processes to reduce admin time and human error ensure structures that are relevant for analytics purposescontribute to upgradingdeployingbuilding of reliable database solutionsintegrate and clean multiple data sources backup restore recovery troubleshooting and configuration managementintegrate security best practiceswrite complex stored procedures and optimize execution efficiencyparticipate in code and design reviewsdeploy releases to multiple environments and support other teams during releaseswork closely with application teams and business owners and develop a strong understanding of business logic and processesresearch and evaluate thirdparty tools to increase efficiencyrequirementsexperience with big data platforms like spark awsexperience with postgresql  redshiftunderstanding of database designarchitecture and operationsexpertise in data modeling query design and optimization stored proceduresexperience with a major bi technology set like tableau powerbi etcexperience with very large databases and distributed database environmentsability to work with and provide technical leadership to other team membersinnovative thinker who is positive proactive and readily embraces changesuperior conceptual and analytical abilities identifying opportunities for improvement through analysis and creative thinkingexperience with python a plusexperience with java a plusjob type fulltimeexperiencespark 1 year requiredredshift or postgresql 1 year required,,IL,True,data_engineer
Data Engineer,"100000 a yearbi data engineer

up to 100k per year

dc58748717

pinnacle partners is assisting our client in their search for a bi data engineer to add to their team located on north of indianapolis our client is seeking a strong analyst who can be business facing and have a technical foundation they can build upon with evolving tool sets this successful resource will be part of a team of engineers who are able to work with stakeholders business request digest and understand them pull data and put in to a visualization tool and them assist the business in understanding what the results are this is an excellent opportunity to lead bl modernization

responsibilities


detect design and execute internal process improvements such as automate manual testing redesign infrastructure optimizing data delivery and etc
form infrastructure required for loading of data transformation and extraction from a wide variety of data sources using sql and cloud based technologies
build analytic tools that can offer actionable insights into customer retention and acquisition
collaborate with stakeholders to support data infrastructure needs and assist with datarelated technical issues
design data tools for analytics and data scientist team members that aid them in optimizing and building the product
work in collaboration with analytics and data experts to seek greater functionality within data systems

requirements


at least 3 years of data engineering experience in the context of bi and data warehousing
expert knowledge of sql and working experience with writing queries and working with relational databases
working experience performing root cost analysis on external and internal data processes to answer specific business questions and identify ways to improve
form processes supporting data structures data transformation dependency metadata and workload management
demonstrated experience processing manipulating and extracting value from large datasets
able to visualize data preferably experience with tableau

terms

this is a direct hire opportunity with a salary up to 100k based on experience they offer excellent benefits including full medical benefits 401k match pto and great work life balance",100000.0,IN,False,data_engineer
Junior BI/SQL Developer / Data Analyst / Data Engineer ( All...,60000  75000 a yearcontractrecent graduates are welcome to apply cptopt acceptedwe provide free onboarding training for entrylevel employeesjob responsibilities design and create data model based on various business requirementcreate erd to the proposed databasecreate database objects such as tables views udfs and udps etcdesign packages related to the extraction transformation and loading etl process using microsoft sql server 2012 or laterresponsible for data profiling as well as sql and database tuning  optimizationanalyze the client requirements and design technical solutions based on those requirementsdevelop testing and implementation strategy conduct appropriate functional and performance testing to identify and resolve process bottlenecks and data quality issuesreviewing query performance and optimizing codedesigning and coding database tables to store the application’s datadata modeling to visualize database structureworking with application developers to create optimized queriescreating table indexes to improve database performance and apply appropriate index maintenanceensure code security and prevent sql injectionparticipate in development and creation of data warehousequalifications master’s degreein computer science cs information system is management of information system mis statistics analytical finance etc01 years of practical experience with microsoft sql server platform and etl as well as tsql transact sql stored procedures and triggersinterest in working with complex data sets and leading edge analytic technologies such as machine learning and power biability to write  troubleshoot sql code  design stored procedures functions tables views triggers indexes  constraintsknowledge of ms sql server 2012 or laterknowledge with ssrsssistsqlexcellent communication and analytical skillsability to work in team environment and client interfacing skillswork authorization status we accept us citizens gc ead etc we will sponsor h1b for the right candidatesjoining beaconfire solution  we welcome students on opteadh1bgcus citizensh1b visa sponsorship for students on optcompetitive salariesinterview guidance from experienced professionalsbeaconfire solution is an equal opportunity employer and an everified companyjob type fulltimesalary 6000000 yearjob types fulltime contractsalary 6000000 to 7500000 yeareducationmasters preferred,67500.0,NJ,False,data_engineer
Data Engineer,"zeus  flawless stays

founded in november 2015 and based in san francisco california zeus is shaking up the 12b corporate housing industry through its unique strategy of leasing unfurnished privatelyowned homes and converting them into expertly appointed fullservice corporate housing units for today’s global professional were passionate about delivering worldclass customer service and becoming the most trusted provider of corporate housing on earth with more than 350 homes in the san francisco bay area and los angeles and over 100000 nights booked we are well on our way to realizing our vision zeus has raised 141m in financing from initialized capital google ventures bowery capital and floodgate the zeus founders have all had previous exits and have worked in real estate and technology for over 10 years

the role

the data engineer is responsible for designing and developing robust scalable solutions for collecting and analyzing large data sets at zeus youll be creating and maintaining the data pipeline and set the foundation of data engineering in terms of technical choice and process
what you will do
architect develop and own data pipelines at enterprise level
writing robust programs for realtime acquiring data from various sources
work closely with data scientists to launch and maintain new pricing models build frameworks for model deployment
automate existing processes ensure stability and accuracy
what we are looking for
exceptional coding skills particularly in pythonruby
2 years of experience in a data engineering or data analytics role
expertise in database design and data warehousing concepts
proactive lead complex projects with a “cando” mentality
benefits
100 medical dental and vision coverage for employees and their dependents
parking commuter pass and education or certification expense coverage
20 days paid time off per year
catered daily team lunches
401k with matching
relocation package
zeus is an equal opportunity employer and does not discriminate on the basis of race color religion gender gender expression age national origin disability marital status sexual orientation or military status in any of its activities or operations

we do not accept calls from 3rd party recruiters",,CA,False,data_engineer
Data Engineer,"are you interested in products that make lives better for those most in need and help reshape healthcare in the us we are looking for an energetic and highly motivated data engineer to help launch customer implementations and analyze our database of patient medical record data you will be joining a fastgrowing vcbacked company with a unique team of seasoned professionals with a vast combined expertise in both the technical and the healthcare space
key responsibilities
launch new customer implementations of our population health and value based contracting products
analyze customer patient medical record data to mine a complete patient profile from electronic health records
develop quality measure analytics that provide insights about patient populations
enhance our data lake and data pipelines as we continue to normalize new data sources and leverage our big data assets
qualifications and experience
bachelor degree in computer science preferred
big data technologies in the cloud such as hadoop pig hive etc
traditional relational dbms as well as nosql
extract transformation and load etl tools and practices
data and object modeling
general software engineering principles such as oop solid etc
quick and eager to learn new technologies
strong individual contributor who is able to thrive in a dynamic and fast paced environment
competitive salary and benefits provided this position is located in new york city",,NY,False,data_engineer
Data Engineer - Alexa,"job description
interested in amazon alexa come work on it we’re building the speech and language solutions behind amazon echo and other amazon products and services we’re working hard having fun and making history

we are looking for candidates who want to help shape the future of humancomputer interactions specifically we are looking for an outstanding data engineer who is looking to work in a new space to help define how we use data to understand customer behavior and satisfaction in this role you will develop and support the analytic technologies that give our teams flexible and structured access to their data including implementation of a bi platform defining metrics and kpis and automating reporting and data visualization

the successful candidate will be an expert with sql etl and general data wrangling and have exemplary communication skills the candidate will need to be a selfstarter comfortable with ambiguity in a fastpaced and everchanging environment and able to think big while paying careful attention to detail

responsibilities

you know and love working with business intelligence tools can model multidimensional datasets and can partner with customers to answer key business questions you will also have the opportunity to display your skills in the following areas

design implement and support a platform providing ad hoc access to large datasetsinterface with other technology teams to extract transform and load data from a wide variety of data sources using sqlmanage aws resourcesmodel data and metadata for ad hoc and prebuilt reportinginterface with business customers gathering requirements and delivering complete reporting solutionsown the design development and maintenance of ongoing metrics reports analyses dashboards etc to drive key business decisionsrecognize and adopt best practices in reporting and analysis data integrity test design analysis validation and documentationcontinually improve ongoing reporting and analysis processes automating or simplifying selfservice support for customersparticipate in strategic  tactical planning discussions including annual budget processes
basic qualifications
bachelor’s degree in computer science mathematics statistics finance related technical field or equivalent work experience
relevant work experience in analytics data engineering business intelligence market research or related field
experience gathering business requirements using industry standard business intelligence tools to extract data formulate metrics and build reports
experience using sql etl and databases in a business environment with largescale complex datasets
preferred qualifications
graduate degree in computer science business mathematics statistics economics or other quantitative field
both technically deep and business savvy enough to interface with all levels and disciplines within the organization
demonstrated ability to coordinate projects across functional teams including engineering it product management marketing finance and operations
knowledge of advanced sql and a programming language
experience with data visualization using tableau or similar tools
experience with largescale data warehousing and analytics projects including using aws technologies – redshift s3 ec2 datapipeline and other big data technologies
proven track record of successful communication of analytical outcomes through written communication including an ability to effectively communicate with both business and technical teams
amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,WA,False,data_engineer
Associate Data Analyst/Engineer,"the opportunity

scholastic is seeking associate data analysts and data engineers to provide datadriven insights and execute recommendations as part of the analytics and data engineering teams the ideal candidate is highly analytical passionate about hypothesisdriven problemsolving and excellent at developing data solutions the role serves a range of functions across scholastic’s businesses covering financial analysis customer analytics data engineering web analytics and analysis of offline activities

the candidates individual strength and skill set will determine whether the position is a data analyst or a data engineer

your responsibilities

manage enterprise data across scholastics business unitsinterface with other developers product owners and business analysts to understand data needsdevelop and maintain scholastics data infrastructure to drive efficient and reliable processesidentify opportunities to improve scholastic operations and its supply chainutilize data to analyze the effectiveness of scholastic’s marketing efforts across channelsgenerate insights and recommendations that are aligned with business realities and scholastic’s mission and visiondevelop dashboards and improve reporting measures


how you can fit

undergraduategraduate degree in business computer science math engineering or other quantitative disciplinesstrong sql skills for purposes of data extraction transformation cleaning and analysisability to collaborate with data and software engineers as well as nontechnical business ownersexceptional problemsolving ability logical reasoning creative thinking and quantitative aptitudestrong excel sas r or python skills in analysis statistics and charting

preferred skills and knowledge

familiarity with bi and data visualization tools like tableau and lookerfamiliarity with web analytics tools such as google analytics and adobe analytics aka omnitureexperience in python scala or java is a plusexperience using big data technologies like hadoop hive and spark is a plus


about scholastic

scholastic corporation nasdaq schl is the worlds largest publisher and distributor of childrens books a leading provider of print and digital instructional materials for prek to grade 12 and a producer of educational and entertaining childrens media the company creates quality books and ebooks print and technologybased learning programs classroom magazines and other products that in combination offer schools customized solutions to support childrens learning both at school and at home the company also makes quality affordable books available to all children through schoolbased book clubs and book fairs with a 98year history of service to schools and families scholastic continues to carry out its commitment to open a world of possible for all children learn more at scholasticcomaboutscholastic

about the associate program

scholastic’s technology associate program is designed to identify train and promote the next generation of leaders each newhire class receives comprehensive training and is quickly given responsibility to deliver on business goals using industryleading tools partners and technology – all while working in an agile iterative model that emphasizes collaboration transparency and goaloriented development",,NY,False,data_engineer
Data Engineer,"imagine what you could do here at apple new ideas have a way of becoming great products services and customer experiences very quickly bring passion and dedication to your job and theres no telling what you could accomplish
the fraud engineering algorithms and risk group is responsible for combating fraud and abuse for internet software and services at apple in this role you will be tasked with building missioncritical robust and scalable distributed systems that can keep pace with data across a number of highprofile and largevolume apple cloud properties you will chip in to building the nextgeneration libraries platforms and data pipelines to empower us to rapidly build and deploy complex models to production

key qualifications
ms or bs in computer science or related field
3 or more years experience building largescale distributed systems
exceptional analytical and programming skills
experience in scala or java
superior knowledge with at least two of the following spark mapreduce hdfs cassandra kafka
description
we engineer highquality scalable and resilient distributed systems that power data exploration model building and production models our core systems need to work seamlessly across different execution contexts realtime near realtime and batch you will support diverse data analytics stacks such as spark hadoop kafka cassandra and beyond
we work at an unusual intersection of huge data volumes and adversaries that are continuously adapting which means we are operating at and beyond the limits of conventional alternative data systems on our team you can be sure that every commit you make will come with the satisfaction that you are helping protect and improve the user experience of hundreds of millions of users
this role requires indepth knowledge with cuttingedge data analytics technologies tuning troubleshooting and scaling these big data technologies are a key part of our work where having a curiosity with the internal workings of these systems is key to being successful this is a hardcore software engineering role where a large part of an engineers time is spent writing code with the remainder being spent on designing and architecting systems tuning and debugging alternative data systems supporting production systems and supporting our data scientists

education
bs in math computer science or equivalent experience
apple is an equal opportunity employer that is committed to inclusion and diversity we also take affirmative action to offer employment and advancement opportunities to all applicants including minorities women protected veterans and individuals with disabilities apple will not discriminate or retaliate against applicants who inquire about disclose or discuss their compensation or that of other applicants",,CA,False,data_engineer
Data Engineer - Maps Traffic Team,"when will rush hour start how long will it take for a traffic jam to clear up how will my route be affected by a nearby ball game we believe these questions are important to you and we strive to answer them for you
we are the traffic team at apple and we are looking to hire a data engineer to help us answer questions like these we process anonymized location data from a vast number of ios devices and combine it with other data sources to extract valuable insights such as speed information

key qualifications
our teams main responsibility is to measure and predict speeds for every road in the world and all in realtime these speed values heavily influence routing and etas as well as traffic display on the map your work will impact millions of people’s lives every single day
excellent java scripting skills
strong product sense and ability to empathize with user needs
strong experience in data analytics and meaningful tools
bias for action
understanding of location data
frontend experience a plus
description
you will be a key member of our team crafting implementing and evaluating the system that expertly processes a massive stream of gps and sensor data at apple you will help make contributions towards the quality of our data pipelines the testing methodology and testing automation
this is a timely opportunity to work on exciting and challenging problems you are selfmotivated and handson you love using concrete approaches to develop metrics for product quality and measure improvements and you have a strong focus on user needs
you also speak java and know how to deeply impact products

education
bsc or msc in computer science or a quantitative field
additional requirements
while the following skills are not necessary they may be helpful to being successful in this role
 understanding of location data
 knowledge and experience with scala",,CA,False,data_engineer
Big Data Engineer,contractwe are looking for an bigdata engineer one of direct client in nyc nyif interested please reply back with your word format resumerate and availability we need to close this position asap appreciate your immediate responsejob title bigdata engineer  2 positions locations nyc ny  raleigh ncduration  long termcomplete descriptioncloudera java scala spark are key skills· 5 years of distributed system design and development data analysis and warehousing· strong handson programming using java python rdbms and sql scala· 2 years of deep understanding and programming on cloudera and hortonworks· expertise in distributed file systems and streaming applications spark kinesis kafka· expertise in design of nontrivial etl applications using flume sqoop oozie pig etc· expert in nosql data solutions keyvalue columnar document graph time series· experience configuring managing monitoring tuning and debugging hadoop clusters· expertise in search technologies elastic search splunk is a huge plus· expertise in high performance rest based web service frameworks· familiarity with agile development using scrum and xp methodologiesnice to have· certification in cloudera and hortonworks ecosystems· certification in apache spark 20job type contract,,NY,False,data_engineer
Bioinformatics Data Engineer,"job description

camp4 is seeking a creative and experienced bioinformatics data engineer passionate about joining a team that utilizes integrated and diverse datasets proprietary and external as a key component to its gene circuitry platformtm for drug discovery and development this role is responsible for developing and implementing camp4’s data architecture including data storage management processing and retrievability the ideal candidate should have a solid bioinformatics and computer science training extensive experience with largescale genomic data management familiar with open source bioinformatics tools and databases next generation sequencing ngs analysis annotation and visualization tools the successful candidate will collaborate closely with data analysts as well as experimental biologists to ensure camp4’s gene circuitry platformtm realizes its full potential to discover and develop drugs with higher probability of success reports to the head of data sciences
key responsibilities

oversee organizing processing quality assurance and visualization of internal and external datasets
manage data storage solutions and scientific computing resources local  cloud
build data access portals and visualization of omics data
perform ngs data processing analysis and interpretations
design and assemble hypothesisspecific datasets for machine learning purposes
develop processes contribute to compliance policy setting and present solutions to diverse internal audiences
qualifications
phd in bioinformatics computational biology genomicsor a relatedfield or ms with prior experience 3 years in computational biomedical research
proficient in r python and sql with experience in linux environment and cloudbased computing
solid expertise in ngs pipeline development and workflow management
extensive experience in processing rnaseq chipseq and atacseq
handson experience in interactive visualization tools rshiny or d3
strong organizational skills and interest in exploring new technologies and platforms
knowledge of transcriptional regulation epigenetics signal transduction is preferred
detailoriented team player mentality good communication and troubleshooting skills
passionate about realizing the potential of fundamental scientific discoveries to the bettering of patients’ lives and health
about camp4
founded in 2016 and focused on a core mission of realizing a world with ‘an effective treatment option for every patient’ camp4 therapeutics evolved from seminal discoveries made by company founders dr richard young and dr leonard zon characterizing the ways in which dynamic cell signaling networks control the expression of genes operating at the intersection of genomics computational biology and data sciences camp4 has extended this foundational work creating a unique gene circuitry platformtm to amplify the value of cellular and genetic insights to better understand how genes are controlled by signaling pathways in specific disease states by generating proprietary 4d maps camp4 can identify derisked druggable targets produce actionable insights and improve therapeutic predictability potentially addressing hundreds of diseases and benefiting millions of patients globally
find out more at wwwcamp4txcom",,MA,True,data_engineer
Research and Development Data Engineer,"are you a never give up problemsolver do you thrive in a dynamic environment as a data engineer you will help deliver faster decisionmaking within rd to allow for faster launch timing gotomarket on initiatives and enable costsavings efforts we believe data modeling wrangling mapping and formatting to enable advanced modeling and analytics will be the foundation of your role

what will i do
at this job you will balance multiple projects at different stages of development at a time in addition you will need to maintain high level of curiosity and creativity to learn daily on many fronts you should be selfmotivated and able to drive technical insights into actions that improve business results

we offer you
truly significant work from the beginning
mentorship coaching training and guidance
work with worldrenowned technologies in some interesting ways
the chance to influence the direction and future of our leading products",,OH,True,data_engineer
Data Engineer,"about the company


clarifai is an artificial intelligence company that excels at visual recognition we do not sell an abstract futuristic technology  we sell a solution that people can use today to solve realworld problems we believe that the same ai technology that gives big tech companies a competitive edge should be available to developers and businesses thats why we build products to make it easy quick and inexpensive for them to innovate with ai go to market faster and build better customer experiences we make teaching ai just as accessible as we make using ai which is why our technology is the most personalized unbiased accurate solution in the market

we have secured 40m in funding up to date backed by menlo ventures google ventures usv nvidia qualcomm osage lux capital ldv capital and corazon capital to continue to succeed we need people like you to join the team

clarifai is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse workforce

your impact


as our first data engineer at clarifai you will own the existing data stores as well as work closely with other engineering teams to deliver a future vision for data at clarifai your expertise in managing ever growing data sets will be put to immediate use in simplifying optimizing and consolidating our existing data stores

your opportunity


you will be focus on creating and maintaining systems to ensure clarifais internal systems run correctly you will be ensuring internal data is properly measuring external usage devising and implementing new ways to utilize existing data and working closely with data analytics to provide insight into business decisions you will be reporting to the head of infrastructure but will often operate crossfunctionally by working with our business intelligence and data strategy teams you will be working out of our new york office as part of the infrastructure team you will help them maintain responsibility for the overall availability and reliability of the products we provide you will work with the other engineering teams to ensure they have the tools and resources they need to deliver the best product for our customers

what you bring



24 years of experience as a data engineer or a similar role
you program in python golang c andor java
you are well versed in observability reliability and security best practices
you are an expert at optimizing usage of common cloud datastores both sql and nosql and their open source alternatives
you have experience with automating via infrastructureascode both cloud and physical database deployments
ability to complete a task with little supervision organized ability to work on multiple projects at once
experience working with remote peopleworking remotely
experience working in a tech startup
we prefer experience with container orchestration eg kubernetes mesos eks gke et al
experience with distributed storage eg ceph efs hdfs et al is also a huge plus
must be able to start as soon as possible but no later than november

objectives


in your first month you will start off by learning the ropes you will


develop an understanding of our current data stores and use cases
scale existing data warehousing practices
work with internal customers to identify potential new data services

3 months later you will use your understanding of clarifais infrastructure to find the critical areas to address you will


improve reliability of existing data pipelines
develop insights as to a more efficient subscription and billing system
programmatically ensure consistency across multiple data stores for existing data as scale increases

6 months down the road your understanding of current and future projects will allow you to proactively work to scale our products and our engineering practices you will


scale our data stores to meet the unique requirements for our internal data strategy team
deploy and maintain a scalable subscription and billing system

in 12 months your deep understanding of our product and infrastructure will be critical in determining the future vision for our infrastructure you will


continue to scale our existing billing system and data stores for a rapidly growing engineering organization and product suite
identify large future data initiatives the infrastructure layer should be focusing on ensuring we remain ahead of any scaling bottlenecks and product requirements

in the future youll continue to ensure our products scale to meet growing customer demand and our engineering team has the tools and platforms they need to deliver new products faster than before",,NY,False,data_engineer
Data Engineer,"make things that matter at plated our teams are making healthy and tasty eating part of everyday living what we build as a team has a major impact on our customers and were passionate about doing whats best for them

as a member of our data science team youll help build features on our distributed data platform that enable our teams and our customers make better decisions youll work collaboratively with analysts and data scientists to shorten the time between insight and action and farm to table while being able to explore innovative technologies and methodologies for producing data and decisions at scale

what youll do with us

develop and maintain data pipelines and applications in collaboration with internal teams such as marketing culinary operations and product and external teams at albertsons
productionize machine learning models and automated decision making processes at scale and across companies
abstract and accelerate the model development process through engineering tools and processes
create new features for our distributed data workflow and processing systems
collaborate with internal teams to translate new analytics requirements into features for our analytics applications and data warehouse
maintain and improve the reliability of the backend infrastructure and data quality
develop and maintain data environments that help us meet our financial and regulatory requirements

what youre bringing to us

understanding of security and privacy and how related policies manifest themselves in code
curiosity for the unknown and unknowable
eagerness to learn and teach new skills and test new technologies
ability to self manage organize and prioritize while collaborating across multiple work streams
aptitude for understanding and untangling complex code
a sense of community collaboration and flexible communication style to accommodate an onsite and remote team
understanding of data modeling and data architecture design best practices

what youve worked on before

3 years handson development experience working on full life cycle information management or data science projects including data warehousing business intelligence machine learning or etl extract transform load
undergraduate degree in computer science information systems or other quantitativeengineering field
experience in sql and python specifically for data applications
experience with etl process design and maintenance preferably open source tools like airflow
experience working with various data storage mechanisms rdbms nosql and columnoriented dbms

working at plated

plated brings together exceptional food unparalleled creativity and innovative technology to redefine the dinner experience our team is solving bigpicture problems in a collaborative datadriven environment weve built together—and were looking for the best people to join us

our benefits and perks expanding all the time

the best part a free weekly plated box
unlimited vacation days with a get your work done policy that respects your time
competitive compensation
customizable medical vision and dental plans and a 401k plan
annual education stipend for your career development
newly renovated office in chelsea manhattan with an open floor plan beautiful demo kitchens and adorable office dogs
daily breakfast afternoon snacks and test kitchen samples
company events cultural clubs and foodrelated activities

",,NY,False,data_engineer
Data Engineer,"parttimewho are we

since 2011 general assembly has transformed tens of thousands of careers through pioneering experiential education in todays most indemand skills as featured in the economist wired and the new york times ga offers training in web development data design business and more both online and at campuses around the world our global professional community boasts 40000 full and parttime alumni — and counting
in addition to fostering career growth for individuals ga helps employers cultivate top tech talent and spur innovation by transforming their teams through strategic learning more than 21000 employees at elite companies worldwide have honed their digital fluency with our corporate training programs ga has also been recognized as one of deloittes technology fast 500 and fast company has dubbed us leaders in worldchanging ideas as well as the 1 most innovative company in education

ga has a remotefriendly culture with offices around the world if you prefer the office our headquarters are located in new york city twice a year the entire product team gets together in new york for a week of team building workshops lightning talks urban adventures and an epic hackathon

as part of the engineering team we collaborate with application engineers and business owners to build and manage a wide variety of data sets deliver nearrealtime monitoring of key business metrics model events as well as provide longer term trend analysis we are proud of using new tech and always researching alternatives we are super happy with our new open source data pipeline and need more engineers to grow it

responsibilities include

we are looking for a data engineer that loves data your responsibilities include…


development of data marts and rollup tables
api feeds automation
work on the data pipeline that feeds our data warehouse from a variety of sources
assist with the development of a bi strategy to support current and future needs through technology
support and advise all parts of the global business on their data needs
write robust welltested production code in support of the business intelligence systems
develop and maintain monitoring alerting and anomaly detection services
understand what data is needed and how it will be presented in visualization tools like looker

must have

3 years experience in the data field
etldata manipulation in python java perl or any language python preferred
strong sql skills experience creating data marts andor star schemas
be able to translate business requirements into deliverables
comfortable writing code that pulls data from apis and storing in database
excellent communications skills

nice to have

familiar with visualization tools like tableau looker looker preferred
event modeling
experience with a columnar datastore preferably redshift
familiar with any monitoring system like new relic
machine learning experience

benefits

remote  flexible working hours
highly competitive salary
generous parental leave
annual education allowance
gym allowance
apple macbook pro  external monitor

usa specific


flexible pto
401k retirement plan
health dental  vision insurance
company iphone

who can apply

you are living in or willing to selfrelocate to


the usa in any of these states ca co ct dc fl ga il ks ma ny nc tx va wi andor wa

",,,False,data_engineer
Data Engineer - Hockey Operations,"position description
the boston bruins hockey operations department is accepting applications for an experienced data engineer this position reports to our director of hockey analytics and will assist in the development of our database systems and infrastructure as well as the creation and maintenance of our data processing pipelines

responsibilities
build automated pipelines for acquiring processing and cleaning data from different sources and providers manage data flow into centralized databases
conduct database feature engineering to support departmental research
prepare clean and format analytical data sets for processing by analysts
develop processes for monitoring and testing data quality across multiple sources diagnose and resolve data quality issues to ensure accuracy
use and create tools for data manipulation visualization reporting
define storage security and backup procedures serve as main resource for departmental support and data maintenance
take ownership of database structure  manage with longterm stability in mind while delivering shortterm results
interface with analytics and other hockey operations staff and execute exploratory research and analysis as needed

qualifications
bachelor’s degree in computer science data science engineering it or related field
preferred postgraduate education or 24 years related work experience
 3 years of experience developing in sql or aws redshift
2 years of experience with data profiling modeling and data pipeline development
2 years of experience developing in python r or similar language
familiarity with apis and machine learning a plus
experience manipulating large and complex data sets
excellent written and verbal communication ability – desire to be part of a group and to put the needs of the team first
problemsolving skills – must be able to assess tasks and react to requests independently if necessary
ability to take initiative work in a fastpaced environment and consistently meet deadlines
a knowledge and passion for working in sport hockey knowledge is a plus but candidates should have an understanding of typical data structures and research areas in sport

we are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability status protected veteran status or any other characteristic protected by law",,MA,False,data_engineer
"Data Engineer, Amazon Devices","job description
the amazon devices team designs and engineers highprofile consumer electronics including the bestselling kindle family of products we have also produced groundbreaking devices like echo look and echo show fire tv and amazon dash our team is serious about great scalable design and redefining best practices with a cloudbased approach to scalability and automation

what will you help us create

amazons devices technology team is looking for a talented data engineer with a strong background in etl data warehousing and interest in linking data to key business trends you will work closely with the business and technical teams to analyze many nonstandard and unique business problems and use creativeproblem solving to deliver actionable output your work will have a direct impact on the daytoday decision making in the operations  supply technology business domain
basic qualifications
bachelor’s degree or higher in an engineering or technical area such as computer science physics mathematics statistics engineering or similar
3 years in with and detailed knowledge of data warehouse technical architectures infrastructure components etl elt and reportinganalytic tools and environments data structures
3 years of demonstrated quantitative and qualitative data experience
3 years of experience in data management  data quality control experience
preferred qualifications
advanced knowledge and expertise with data modelling skills advanced sql with redshift oracle mysql and columnar databases
knowledge of enterprise reporting tools like tableau
experience with aws
a track record of problem solving using software systems and the desire to create and maintain data warehouse systems
proficient in the composition of advanced sql analytical functions
proven track record of identifying metric variances and delivering solutions to address the changes
ability to effectively communication with both business and technical teams
a selfstarter who loves data and who enjoys spotting the trends in it
lab126 is part of the amazoncom inc group of companies and is an equal opportunityaffirmative action employer – minority  women  disability  veteran  gender identity  sexual orientation
d2ctech tag",,CA,False,data_engineer
Data Engineer,"job summary
we are looking for a data engineer to join our growing team of analysts and developers the data engineer will lead efforts to expand and optimize our data infrastructure as well as optimize the data flow for our business intelligence team the ideal candidate will have handson development experience using industry standard etl tools combined with experience with standard database technologies the individual will be expected to work with team members across multiple areas of the cavaliers operating company’s organization often playing several different roles within a project life cycle excellent requirements gathering and communication skills are a must this role will reside between the cavaliers operating company’s business intelligence and information technology teams and will provide an opportunity to gain endtoend experience in delivering best of breed business intelligence solutions cavaliers operating company’s business intelligence practice encompasses data strategy data transformation database technologies business intelligence predictive analytics descriptive analytics targeted digital marketing solutions and more

responsibilities
 assemble large complex data sets that are analysisready
 design implement and continuously optimize the organization’s customer data strategy
 serve as the technical lead for data warehousingintegration projects
 provide thought leadership and lead efforts to design data integration and governance architecture and implement extract transform and load etl jobsprocesses detailed data warehouse models and data mappings
provide consultation on best practices and standard practices to internal team members and thirdparty partners
 lead design and buildout of infrastructure in conjunction with thirdparty to support information management and data integration
 provide strategic and tactical guidance with respect to customer data best practices and attention to quality documentation within cleveland cavaliers and partnering organizations
 perform performance optimization and tuning on new andor existing data warehouse implementations provide detailed documentation end user training and knowledgetransfer services to end users and partners of the cavaliers operating company
 develop and maintain expertise in advanced andor emerging data management and analytical information technologies such as data warehouse data lake big data data warehouse appliances and data virtualization continue professional and technical growth through corporate and personnel initiatives
 must possess solid organization skills with the ability to communicate effectively with internal stakeholders and vendors

qualifications
demonstrated ability in data modeling etl development and data warehousing
 experience building data products incrementally and integrating and managing data sets from multiple sources
 industry experience as a data engineer or related specialty eg software engineer business intelligence engineer data scientist business analyst with a track record of manipulating processing and extracting value from large data sets
 experience with a dw technology redshift sql server etc and relevant data modeling
coding proficiency in at least one modern programming language eg sql python
 experience processing large amounts of data in various formats and processing data in batch mode and streaming mode
 exposure and knowledge of security encryption and data governance
 experience with scalable service architecture and design
 experience working with aws technologies – redshift s3 ec2 datapipelines lambda etc
 experience working with microsoft and azure technologies – sql server blobs functions dynamics crm etc
 experience with automation and deployment eg azure devops cloudformation
knowledge and direct experience using business intelligence reporting tools tableau ssas cubes powerbi etc
 experience building flexible data apis that consumers use to power other parts of the business
 awareness of best practices to secure data and processes from unauthorized access
 strong interpersonal skills with the technical and business community
 passion for using data to drive business decisions
ability to work under minimal supervision
excellent written and verbal communication skills
we are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability status protected veteran status or any other characteristic protected by law",,OH,False,data_engineer
Data Engineer - SQL / Big Data / Java,"your consulting projects will include integrating data in a virtual manner for operational andor informational purposes  integration of 100 data sources for a customer service multichannel it infrastructure implementation of logical data warehouses and virtual datamarts to enable modern business intelligence solutions integration layers for hadoopbased data lakes and support for agile operational reporting on a diverse big data infrastructure are just a few flavours of your future projects

be part of an elite team in a rapidly growing international software product company your career with us will combine cutting edge technology exposure to worldwide clients across all industries financial services automotive insurance pharma etc exciting growth path for technical product and customerfacing roles direct mentorship and access to senior management as part of a global team your mission is to help our clients and prospects to realize their full potential through accelerated adoption and productive use of denodos data virtualization capability in many solutions

location new york ny
duties  responsibilities

as a data engineer virtualization fm you will successfully employ a combination of high technical expertise client communication and coordination skills between clients and internal denodo teams to achieve your mission

conception implementation and execution of customerspecific integration projects based on the denodo platform
education coaching and support during the introduction as well as ongoing projects of the denodo platform to achieve high level of client satisfaction
diagnose and resolve clients inquiries related to operating denodo software products in their environment
participate in problem escalation and call prevention projects to help clients and other technical specialists increase their efficiency when using denodo products
contribute to knowledge management activities and promote best practices for project execution
implement product demos and pilots to showcase data virtualization in enterprise scenarios cloud deployments and big data projects
provide timely prioritized and complete customerbased feedback to product management sales support andor development regarding client’s business cases requirements and issues
location
new york ny
function
engineering

qualifications
desired skills  experience
experience range 25 years fresh graduates must be topranked and exceptionally qualified
university degree relating to information systems or computer science bachelor or master degree
understanding of data integration flavors
solid understanding of sql and good grasp of relational and analytical database management theory and practice good knowledge of software development and architectural patterns
technical skills include java development jdbc xml web service related apis experience with version control systems eg svn git
basic experience in big data nosql and inmemory environments is welcome
experience in windows  linux and unix operating systems in server environments
personal and relationship qualities professional curiosity and the ability to enable yourself in new technologies and tasks active listener curiosity and continuous learning creativity team worker
communications good writtenverbal communication skills in english other international languages a plus are essential for interaction with clients making presentations attending meetings and writing technical documentation
willingness to travel
employment practices
we are committed to equal employment opportunity we respect value and welcome diversity in our workforce",,NY,False,data_engineer
Data Engineer - Santa Clara,"help build technology that saves lives

leantaas is a fast growing healthcare predictive analytics company that uses sophisticated math and lean principles to make healthcare providers more efficient


our technology helps millions of people wait less at hospitals and specialty clinics across the country
our customers include some of the nation’s largest hospitals including stanford ucsf newyorkpresbyterian the university of texas md anderson cancer center and more
our team includes veteran executives and the brightest minds from google mckinsey stanford mit duke berkeley uiuc and more
we are a series b company backed by multiple prominent investors in the healthcare space

you will work in a small data ingestion team that will focus on

understanding ehr data models and develop and refine ehr queries to fetch the data we need we work with several ehrs such as epic cerner meditech mckesson paragon etc this requires research and intuition  you’ll have to navigate your way through complex models
working with data teams at customer sites to ensure that the data is complete accurate and aligned with the structure we expect to see for the product this requires a lot of data reverse engineering  you’ll have to figure out what data should look like and what may have gone wrong and get to the bottom of it this is perhaps the most fascinating part of this job
working with engineering and infrastructure teams to make our predictive models work at scale this requires refactoring sophisticated algorithms and leveraging tools like hadoop and spark to improve efficiency and performance

must have

bs or ms preferred with major in statistics andor computer science
12 years professional experience as a data engineer no experience is also ok if you can demonstrate exceptional skillsabilities
strong r or python skills and data analysis skills  many times you will need to reverseengineer the data there’s typically not good documentation available for the ehr data models you will work with however you’ll need to find out what each column means and how to read different dimensions and values
strong data analytics skills  you should love to work with data and solve challenging data problems patiently
good communication skills  you will work directly with customers and therefore need to communicate well

nice to have

experience with data analysis tools such as tableau
experience with python data frameworks such as numpy etc
experience working with ehrs
experience working on etl

",,CA,False,data_engineer
Data Engineer,"comcast brings together the best in media and technology we drive innovation to create the worlds best entertainment and online experiences as a fortune 50 leader we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines we are at the forefront of change and move at an amazing pace thanks to our remarkable people who bring cuttingedge products and services to life for millions of customers every day if you share in our passion for teamwork our vision to revolutionize industries and our goal to lead the future in media and technology we want you to fastforward your career at comcast
data engineerour new york data science team is building critical prototypes that serve our growing business our systems serve billions of requests and process terabytes of raw data in a single day we are looking for problem solvers who embrace challenges with complex requirements and build prototypes that can validate business goals we need engineers who are ready to make an impact and deliver quality softwareresponsibilities  work with different teams to design technical data storage and processing solutions work with data scientists to create efficient and scalable data pipelines in aws for data modeling design develop and test datadriven workflows follow updates in different freewheel backend components and contribute to the longterm roadmap for freewheels data strategy drive the optimization testing and tooling to improve data quality improve performance availability and scalability of our backend systemsabout you  bachelors or masters degree in computer science or similar field of study 2 years of experience building large scale big data applications skilled with scalahadoop and database general concepts proficient with linux commands and environments proficient with 23 programming languages including scalapython fast to pick up new languages handson experiences with data processing or analysis systems is strongly preferred experiences with hadoopsparkkafkaprestoetc are strongly preferred experiences with aws or other cloud technology are strongly preferred known for being a smart analytical thinker who approaches their work with logic and enthusiasm detail oriented flexible and can work well in a global teamoriented environment
comcast is an eoeveteransdisabledlgbt employer",,NY,False,data_engineer
Big Data Engineer,contractthe candidate is expcted to have 56 years of good experience with proven experience with hadoop technologies  spark hbase hive pig good knowledge in backend programming specifically java js nodejs and ooad writing highperformance reliable and maintainable code translate complex functional and technical requirements into detailed design good knowledge of database structures theories principles and practices ability to write pig latin scripts hands on experience in spark data processing hiveql familiarity with data loading tools like flume sqoop knowledge of workflowschedulers like oozie analytical and problem solving skills applied to big data domain good aptitude in multithreading and concurrency concepts,,NY,False,data_engineer
Big Data Engineer,"specific information related to the position is outlined below to apply click on the button above you will be required to create an account or sign in with an existing account your account will provide you access to your application information

should you have a disability and need assistance with the application process please request a reasonable accommodation by emailing bbt accessibility or by calling 8663626451 this email inbox is monitored for reasonable accommodation requests only any other correspondence will not receive a response


regular or temporary
regular

language fluency english required

work shift
1st shift united states of america
please review the following job description

primary job responsibilities involve supporting ingestion and transformation pipelines that handles data for analytical or operational uses across broad line of business needs areas and enterprise data domains the data engineer often works as a dedicated member of support teams focused on providing production stability data processing workflows that will be used by analytics groups and data scientists who are interrogating information for predictive analytics machine learning and data mining purposes in many cases the support engineer also works with business units and departments in proactively identifying data quality issues and coordinating with the development groups to ensure data accuracy to business analysts leadership groups and other end users to aid in ongoing operational insights


an independent  selfmotivated lead support engineer must be versed in broad approaches to data architecture and applications and will develop componentsapplications by studying operations and designing and developing reusable services and solutions that support the automated ingesting profiling and handling of structured and unstructured data


essential duties and required skills
following is a summary of the essential functions for this job other duties may be performed both major or and minor which are not mentioned below specific activities may change from time to time
510 years software development programming or support experience in enterprise web cloud applications
35 years of experience in data modeling data design and persistence eg warehousing data marts data lakes
exposure to functional imperative and objectoriented languages and methodologies
experience with supporting big data and hadoop
experience with big data approaches and technologies including hadoop cloudera utilities spark kafka hive oozie experience with angular jshtml5node js are big plus
experience with sql mysql postgres and nosqlmongodbhbaseredis database is expected
proficiency with linux operating systems especially troubleshooting and loghandling of applications deployed in linux
exposure to programming languagestools including c java python ruby scala sql and scripting java python spark sql hive javascript shell scripts
experience supporting largescale web services restful apis
has led or been directly involved with the investigation and resolution of incidents and complex data issues in a production setup
experience working in an agile environment
explores examines and interprets large volumes of data in various forms and recommends additional sources of data for improvements
indbbtit
experience in data management best practices realtime and batch data integration and data rationalization
ability to prioritize well communicate clearly have a consistent track record of commitment and accountability for level0 level1 and level2 support as well as excellent troubleshooting skills
understand the relationships across business information and units of data collaborate with business and other departments to identify data usage patterns and to formulate business names definitions and data quality rules for data elements
understand database performance factors and trends pertaining to very large database design and collaborate with dbas for resolving performance bottlenecks
pursue continuous improvements based on lessons learned and industry best practices
understand the goals and risks associated with the business and technical requirements and offer counsel on risk mitigation and the alignment of data solution with objectives
coach and mentor support team members
demonstrate a team orientation by working closely and effectively with business partners development teams and outside services
ability to apply systems thinking for solutions by considering broad potential alternatives and impact areas
ability to travel as needed occasionally overnight

desired skills
knowledge of and experience working in devops environments is desirable previous experience in the financial services industry is a plus experience with performance tuning and documenting changes exposure to container technologies docker or similar and orchestration is a plus experience with metadata capture management informatica big data management and platforms",,NC,True,data_engineer
Senior Data Engineer,company overview we are visionaries focused and determined to disrupt the enterprise software management industry in affiliation with insite group and its core values univers will deliver the next generations top notch it platforms to the enterprise management of construction companies and many other industriespurpose responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for cross functional teams the senior data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projectsessential functions create and maintain optimal data pipeline architectureassemble large complex data sets that meet functional  nonfunctional business requirementsidentify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etcbuild the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using aws relational and big data technologiesbuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metricswork with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needskeep our data separated and secure across national boundaries through multiple data centers and aws regionscreate data tools for analytics and data science team members that assist them in building and optimizing our product into an innovative industry leaderwork with data and analytics experts to strive for greater functionality in our data systemsqualifications bs computer science or information technology or equivalent work experienceminimum 7 10 years developing and designing rdbms and big data architectures2 years experience designing nosql data stores such as aws redshift spectrum cassandra hadoop mongodb etcexperience with cloud deployments and cicd pipelines is a plusexperience developing for microservice architectures is a plusexperience in building data stores for rest apisstrong understanding of object oriented design principlesexperienced with agile methodologies such as kanbancapable of performing structured testing on features and doing research in production issueswe offer your voice matters our unique open source culture gives you the opportunity to impact our continuously evolving companyexplore our hotels associates receive hotel and restaurant discounts  perks at any of our propertiescontinued leadership education program we offer an ongoing insite leadership series isls weekly webinars elearning coursesenjoy the holidays we offer seven 7 paid holidays throughout the yearemployee social events quarterly themed luncheonsexceptional benefits including elective medical dental vision and shortterm disability coveragecompany paid basic life insurance add longterm disability and employee assistance program eappaid time off ptocelebrate you choose one 1 paid day of personal celebration each year to use however you choosejob type fulltimeeducationbachelors preferred,,FL,True,data_engineer
Data Engineer,"overview


at perficient you’ll deliver missioncritical technology and business solutions to fortune 500 companies and some of the most recognized brands on the planet and you’ll do it with cuttingedge technologies thanks to our close partnerships with the world’s biggest vendors our network of offices across north america as well as locations in india and china will give you the opportunity to spread your wings too

we’re proud to be publicly recognized as a “top workplace” year after year this is due in no small part to our entrepreneurial attitude and collaborative spirit that sets us apart and keeps our colleagues impassioned driven and fulfilled

perficient is on a mission to help the healthcare industry take advantage of modern data and analytics architectures tools and patterns to improve the quality and affordability of care this is an excellent opportunity for the right individual to assist perficient and its customers to grow the capabilities necessary to improve care through better use of data and information and in the process take their career to the next level

perficient currently has a career opportunity for a data engineer located in boston ma

job overview

as a data engineer you will participate in all aspects of the software development lifecycle which includes estimating technical design implementation documentation testing deployment and support of application developed for our clients as a member working in a team environment you will work with solution architects and developers on interpretationtranslation of wireframes and creative designs into functional requirements and subsequently into technical design

responsibilities
lead the technical planning  requirements gathering phases including estimate develop test manage projects architect and deliver
serve as a technical lead and mentor provide technical support or leadership in the development and continual improvement of service
develop and maintain effective working relationships with team members
demonstrate the ability to adapt and work with team members of various experience level
qualifications
passionate coders with 35 years of application development experience
proficiency with spark with pythonjava a must
expert knowledge of developing in cloudera environments using spark and cloudera tools such as navigator and manager
cloudera certification highly preferred
knowledge of hadoop tools such as flume sqoop and oozie
knowledge of data formats and etl and elt processes in a hadoop environment including hive parquet mapreduce yarn hbase and other nosql databases
experience in dealing with structured semistructured and unstructured data in batch and realtime environments
experience with working in aws environments including ec2 s3 lambda rds etc familiarity with devops and cicd as well as agile tools and processes including git jenkins jira and confluence
client facing or consulting experience highly preferred
skilled problem solvers with the desire and proven ability to create innovative solutions
flexible and adaptable attitude disciplined to manage multiple responsibilities and adjust to varied environments
future technology leaders dynamic individuals energized by fast paced personal and professional growth
phenomenal communicators who can explain and present concepts to technical and nontechnical audiences alike including high level decision makers
bachelor’s degree in mis computer science math engineering or comparable major
solid foundation in computer science with strong competencies in data structures algorithms and software design
knowledge and experience in developing software using agile methodologies
proficient in authoring editing and presenting technical documents
ability to communicate effectively via multiple channels verbal written etc with technical and nontechnical staff
perficient fulltime employees receive complete and competitive benefits we offer a collaborative work environment competitive compensation generous worklife opportunities and an outstanding benefits package that includes paid time off plus holidays in addition all colleagues are eligible for a number of rewards and recognition programs including billable bonus opportunities encouraging a healthy worklife balance and providing our colleagues great benefits are just part of what makes perficient a great place to work

more about perficient

perficient is the leading digital transformation consulting firm serving global 2000 and enterprise customers throughout north america with unparalleled information technology management consulting and creative capabilities perficient and its perficient digital agency deliver vision execution and value with outstanding digital experience business optimization and industry solutions

our work enables clients to improve productivity and competitiveness grow and strengthen relationships with customers suppliers and partners and reduce costs perficients professionals serve clients from a network of offices across north america and offshore locations in india and china traded on the nasdaq global select market perficient is a member of the russell 2000 index and the sp smallcap 600 index

perficient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability status protected veteran status or any other characteristic protected by law

disclaimer the above statements are not intended to be a complete statement of job content rather to act as a guide to the essential functions performed by the employee assigned to this classification management retains the discretion to add or change the duties of the position at any time
lidc1",,MA,True,data_engineer
Senior Data Engineer,reenvision patient care as a call9 team member you will operate at the nexus of clinical excellence engineering innovation and progressive enterprise in a culture that fosters ingenuity and innovation by joining the call9 team you’ll not only be a part of the future of healthcare you’ll be integrally involved in shaping itabout call9call9 is recreating the patient experience by bringing care to the patient our innovative model connects offsite physicians with onsite emergency medicine trained firstresponders via a proprietary telemedicine platform born of silicon valley and improved every day by our physician and product teams call9 provides a spectrum of emergency followup and palliative care services at the patient’s bedside in skilled nursing facilities snfs our physician team prevents harmful and unnecessary transfers to the hospital delivering high quality valuebased care that improves outcomes saves money and provides a superior experience for the patient their family and our physiciansresponsibilitiesmaintaining scaling and improving our data warehousing system using rails and sqlbuilding systems that will integrate with external nursing facility emr’s in a reusable scalable wayverifying system security and integrity is being maintainedworking with product engineers to determine how to structure data needed to meet business requirementstesting reliability of our external data pipelines to ensure data is extracted and processed correctlymentoring and growing other engineerswho you areyou like to dig into the details and you enjoy finding the reason behind requestsyou love mentoring and growing other engineers and you have experience in seeing projects fail and succeedyou care about why youre building software and want to work on data that impacts healthcare directlytechnologies we useruby on railslookersqlpythonhl7 interfacesrequirementsbs degree in computer science or equivalent5 years of software development experience3 years working on a data warehouse ideally in an architectsenior positioncall9 provides equal opportunity in employment for all qualified persons and prohibits discrimination in employment on the basis of race color religion creed sex sexual orientation perceived sexual orientation gender identity marital status national origin ancestry age veteran status disability unrelated to job requirements genetic information military service or other protected status as may be mandated by applicable federal state and local law all personnel actions including but not limited to those relating to compensation benefits termination training and education are based on the principle of equal employment opportunityjob type fulltimeexperiencesoftware development 5 years requireddata warehouse 3 years requirededucationbachelors preferred,,NY,True,data_engineer
Data Engineer,contractjob summaryjob title data engineer iiilocation menlo park caduration 12 monthsresponsibilities and dutiesdutiesapply proven expertise and build highperformance scalable data warehouse applicationsecurely source external data from numerous global partnersintelligently design data models for optimal storage and retrievaldeploy inclusive data quality checks to ensure high quality of dataoptimize existing pipelines and implement new ones maintenance of all domainrelated data pipelinesownership of the endtoend data engineering component of the solutioncollaboration with the program’s smes data scientistsqualifications and skillsskillscompetence with relational databases oracle mysql verticaexperience working with tableaucoding and scripting experience with python sqljob types fulltime contractexperiencetableau 4 years required,,CA,True,data_engineer
"Data Engineer, Payments ML","job description
are you ready to own all the data infrastructure and pipelines for a machine learning product amazon payment products is a growing business with an established ml team we are looking for a technical leader to join our team of machine learning scientists software developers research scientists this technical leader will lead our data engineering team and own all data infrastructure for our machine learning launching new capabilities and experiences for amazon customers

in this role you will work closely with machine learning scientists product managers and sdes on launch decisions you will drive high value customer actions and influence senior management decisions and metrics you will provide proactive deep insights into metrics driving the business on a regular cadence the right candidate will be passionate about working in with large datasets and emerging businesses

over time you will lead the development of statistical and other machine learning models you will work closely with our engineering teams to influence the product roadmap and implement solutions designed to improve operations and controls reporting

outstanding leadership data engineering expertise and a keen interest in machine learning are required for this role strong interpersonal and communication skills are key

basic qualifications
bachelor’s degree in math computer science engineering finance statistics or a related technical field5 years of professional experience and passion for working with large data sets plus deep experience in statistical analysis advanced modeling techniques data mining and business analysisagile project management experience and ability to drive successful endtoend project executionability to thrive in an environment that is tasked with providing datadriven decision support and business intelligence that is timely accurate and actionablehands on experience with aws data products including emr s3 redshift as well as sql excel data mining data visualization software
preferred qualifications
ability to think big understand business strategy provide consultative business analysis and leverage technical skills to create insightful effective bi solutionshands on experience with data extraction manipulation statistical analysis and predictive modelingexperience in machine learning decision trees multivariate and logistic regression etcproven track record of strong verbalwritten communication  data presentation skills including an ability to effectively communicate with both business and technical teams
amazon is an equal opportunity employer",,WA,False,data_engineer
Data Engineer,hihope you are doing greatplease review the below job description and let me know if you would be interested if yes please share me a copy of your latest resume and let me know the best time to connect with youjob title data engineerjob location nyc nydirect hireprimary skill redshift python r glue crawler kinesis kinesis firehose hadoopsecondary skill snowflake h2o jupyter neptune alationjob type fulltime,,NY,False,data_engineer
Big Data Engineer - Bachelors (Full Time) – United States,"what you’ll do
 design and deliver automated transformation of large data sets influencing mapreduce streaming and other new technologies
 use hbase elasticsearch etc to ingest transformed data at scale
 collaborate with security experts to deliver highimpact webbased apis
 implement highvolume data integration solutions
 analyze monitor and optimize for performance
 produce and maintain highquality user documentation
who youll work with
join us as we transform the world of tomorrow develop creative ideas on how to work better and smarter influence and participate in toppriority projects that have a real impact
who you are
 recent graduate or on your final year of studies toward a bachelors degree in computer science or a related technical field
 minimum of a 30 gpa or equivalent
 track record of developing technology to enable large scale data transformation
 strong java experience and handson hadoop ecosystem experience – hbase hive spark etc
 possess knowledge of software engineering standard methodologies
 real passion for solving hard problems and exploring new technologies
 excellent communication and user documentation skills
why cisco
at cisco each person brings their own rare talents to work as a team and make a difference
yes our technology changes the way the world works lives plays and learns but our edge comes from our people
 we connect everything – people process data and things – and we use those connections to change our world for the better
 we innovate everywhere  from launching a new era of networking that adapts learns and protects to building cisco services that accelerate businesses and business results our technology powers entertainment retail healthcare education and more – from smart cities to your everyday devices
 we benefit everyone  we do all of this while striving for a culture that empowers every person to be the difference at work and in our communities
colorful hair don’t care tattoos show off your ink like polka dots that’s cool pop culture geek many of us are be you with us wearecisco
univsoftwarejobs sto softwareengineer computerscience security wearecisco
this position is available to bachelors level students positions are located east coast west coast and central us not all positions offer sponsorship or are available at all locations relocation is available for some locations and or positions
cisco is an affirmative action and equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion gender sexual orientation national origin genetic information age disability veteran status or any other legally protected basis
cisco will consider for employment on a case by case basis qualified applicants with arrest and conviction records",,CA,False,data_engineer
Data Engineer,"about kraken

kraken is one of the largest and most successful bitcoin exchanges in the world and we’re growing faster than ever we’re looking for people who constantly push themselves to think differently and chart exciting new paths in a rapidly growing industry kraken is a diverse group of dreamers and doers we truly believe our success depends on having both in spades join us and the movement to change the way the world thinks about money
learn more about us

read our reviews on glassdoor
follow us on twitter
catch up on our blog

about the role

this role is fully remote

our engineering team is having a blast while delivering the most sophisticated cryptotrading platform out there help us continue to define and lead the industry
responsibilities
build scalable and reliable data pipeline that collects transforms loads and curates data from internal systems
augment data platform with data pipelines from select external systems
ensure high data quality for pipelines you build and make them auditable
drive data systems to be as near realtime as possible
support design and deployment of distributed data store that will be central source of truth across the organization
build data connections to companys internal it systems
develop customize configure self service tools that help our data consumers to extract and analyze data from our massive internal data store
evaluate new technologies and build prototypes for continuous improvements in data engineering
requirements
5 years of work experience in relevant field data engineer dw engineer software engineer etc
experience with data warehouse technologies and relevant data modeling best practices
experience building data pipelinesetl and familiarity with design principles
excellent sql skills
proficiency in a major programming language eg java c etc andor a scripting language javascript python etc
experience with business requirements gathering for data sourcing
check out all our open roles at httpsjobslevercokraken we’re excited to see what you’re made of

we’re powered by people from the around the world with their own unique backgrounds and experiences we value all krakenites and their talents contributions and perspectives",,,False,data_engineer
PMC: Data Engineer,"pmc data engineer

fastgrowing media company penske media corporation pmc seeks a data engineer to support our product editorial and sales teams by expanding scaling and managing our data architecture and data lake

why work with us
work on some of the largest trusted brands in entertainment and fashion news including variety wwd and robb report
own your work high responsibility and high autonomy
we’re a stable growing company with a startup mentality
agile scrum environment with small focused teams


as our data engineer your role is critical in expanding the datadriven culture at pmc working side by side with the data science and data engineering teams you will utilize bigquery airflow and machine learning to build data products to service the entire business this position requires strong interpersonal and communication skills and the ability to interact effectively with people at various levels of the organization our saas partners and with our hundreds of data providerssources you are a quick learner and hungry to make sure you have a deep understanding of the meaning behind all measures dimensions and kpis of the business you are also ready to expand your data skills into the data science field to go beyond data architecture and help the business gain competitive advantages in the marketplace

this position will report to pmc’s director of data architecture

job duties
write articulate compelling summaries to communicate results of your hypothesis iterations analysis model development and which inform how the business should act
ai multivariant testing
bigquery ml tensorflow and user behavior algorithms
anomaly and pattern detection
airflow and kubernetes development
mentor other data engineers
plan direct and build analytics solutions with a team of data science other big data engineers consultants and visualization experts


job requirements and experience
strong sql python and java
excellent communication with nontechnical staff members to optimize their data workflows and uncover hidden optimizations
experience with airflow and complex dags
predictive modeling and applied statistical analysis
machine learning with clickstream or online behavioral data a plus ga dfp krux programmatic
experience in digital media or content publishing is a plus


about pmc
penske media corporation pmc is a leading digital media and information services company whose awardwinning content attracts a monthly audience of more than 180 million and empowers more than 1 million global ceos and business thoughtleaders in markets that impact the world our dynamic events data services and rich content entertain and educate today’s fashion retail beauty entertainment and lifestyle sectors headquartered in new york and los angeles with additional offices in 11 countries worldwide penske media is the way global influencers are informed connected and inspired to learn more about pmc and its iconic brands visit wwwpmccom",,NY,False,data_engineer
Sr Data Engineer II (Data Science),"job description
this opportunity is for a senior data engineer de within audible’s data science group in this role you will be a member of an interdisciplinary team of data scientists data engineers and software development engineers this team will be responsible for modeling many business areas such as customer engagement marketing content management recommendations and more

you have a passion for big data and its supporting technologies and platform components you will be an enabler for cutting edge modeling efforts passionate about accessing moving processing and managing terabytes of data in a performant scalable faulttolerant way and will display your strong problemsolving ability in different environments

you will be able to thrive in the powerful advanced environment that makes audible such a unique company in the area of dataprocessing technology and will be offered a perfect mix of responsibility and mentoring you will also be exposed to modeling tasks further downstream of the data science value creation process

key responsibilities
apply business understanding and a technology knowhow to cutting edge data science problems
play a leading role in architecture design and implementation of next generation bi solutions
play a leading role in optimally acquiring crunching and understanding for machine learning ml and modeling by data scientists
effectively communicate with various teams and stakeholders escalate technical and managerial issues at the right time and resolve conflicts
peer review work actively mentor more junior members of the team improving their skills their knowledge of our systems and their ability to get things done

how does amazon fit in

were a part of amazon they are our parent company and its a great partnership youll get to play with all of amazons technologies like ec2 sqs and s3 but it doesnt stop there audible is built on amazon technology and youll have insight into the inner workings of the worlds leading ecommerce experience theres a lot to learn

if you want to own and solve problems work with a creative dynamic team fail fast in a supportive environment whilst growing your career and working on a platform that powers web applications used by millions of customers worldwide we want to hear from you
basic qualifications
degree in computer science engineering mathematics physics or a related field
5 years of building large scale dataprocessing systems with experience in big data technologies such as mapreduce hadoop aws emr spark kafka aws kinesis or equivalent
expertise in database technologies such as aws redshift with proficiency in sql
proficiency in java scala or python on linux platforms
proficiency in shell scripting
preferred qualifications
experience working with data science teams
experience with aws cloud technologies such as elastic map reduce emr kinesis athena
experience working with agile methodologies in a data engineering environment
strong problemsolving skills with the ability to navigate highly complex and ambiguous situations
strong interpersonal skills and the ability to work effectively across teams
great communication skills  ability to think creatively and adapt the message to the audience can provide information to technical and nontechnical stakeholders alike and guide them to confidently informed decisions
willingness to learn be open minded to new ideas and different opinions yet knowing when to stop analyze and reach a decision


audible is an equal opportunity employer – minority  women  disability  veteran  gender identity  sexual orientation",,NJ,False,data_engineer
Data Engineer,"commonbond is building a valuesdriven customercentric financial services company our mission is to change the way people think about student loans we accomplish this with lower interest rates a stateofthe art technology platform and caring customer service we also are the only financial services company with a 1for1 social program for every loan funded we fund the education of a child in the developing world commonbond has been named to the worlds 50 most innovative companies by fast company the 50 best places to work by inc and the forbes fintech 50 we are backed by great investors have an awesome team and are looking for our next great team member

commonbond is seeking a selfguided flexible database engineer who will be responsible for identifying database requirements by analyzing our lending applications business systems and operations evaluating existing data systems and designing and implementing new systems additional responsibilities include but not limited to


work with software developers to optimize data architecture and data access patterns
develop data extract transform load etl and migration tools
design and operate and maintain our core business data warehouse
ownership of operational stability of production transactional and warehouse postgres and redshift databases
installing revised or new systems by proposing specifications and flowcharts recommending optimum access techniques coordinating installation requirements
manage database schema maintenance and migration
guide data analysts in adopting best practices with their sql queries
monitor production databases troubleshoot and resolve incidents
preparing users by conducting training providing information resolving problems
maintain quality service by establishing and enforcing organization standards

desired qualifications


minimum qualifications

4 years experience with database management security data maintenance
knowledge of postgres redshift etl and java or python or go
knowledgeable about data modelling data access and data storage techniques
you care about agile software processes datadriven development reliability and responsible experimentation
demonstrated ability to lead great performing direct and indirect cross functional teams
a deep affinity for data expert level analytical skills and an intense customer focus
professional but not stuffy – were sharp and competent but also fun
experience in financial services is great but more important is your ability to learn fast
team player – you want to be relied upon and you understand how others make your goals achievable
sense of urgency – you want to go move make things happen and shake things up
nimble – able to handle changing tasks and priorities and adapt quickly

we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,NY,False,data_engineer
"Data Engineer, Analytics","facebooks mission is to give people the power to build community and bring the world closer together through our family of apps and services were building a different kind of company that connects billions of people around the world gives them ways to share what matters most to them and helps bring people closer together whether were creating new products or helping a small business expand its reach people at facebook are builders at heart our global teams are constantly iterating solving problems and working together to empower people around the world to build community and connect in meaningful ways together we can help people build stronger communities — were just getting started
do you like working with big data do you want to use data to influence product decisions for products being used by hundreds of millions of people every day if yes we want to talk to you our data warehouse team works very closely with product managers product analysts and internet marketers to figure out ways to acquire new users retain existing users and optimize user experience  all of this using massive amounts of data in this role you will see a direct link between your work company growth and user satisfaction you will be working with some of the brightest minds in the industry and youll get an opportunity to solve some of the most challenging business problems on the web and mobile internet at a scale that few companies can match


this is a full time position based in our office in new york
responsibilities

inform influence support and execute our product decisions and product launches

manage data warehouse plans for a product or a group of products

interface with engineers product managers and product analysts to understand data needs

partner with product and engineering teams to solve problems and identify trends and opportunities

build data expertise and own data quality for allocated areas of ownership

design build and launch new data extraction transformation and loading processes in production

support existing processes running in production

define and manage sla for all data sets in allocated areas of ownership

work with data infrastructure to triage infra issues and drive to resolution
minimum qualifications

bsba in technical field computer science or mathematics

4 years experience in the data warehouse space

4 years experience in custom etl design implementation and maintenance

4 years experience working with either a map reduce or an mpp system

4 years experience with schema design and dimensional data modeling

4 years experience in writing sql statements

ability to analyze data to identify deliverables gaps and inconsistencies

communication skills including the ability to identify and communicate data driven insights

ability in managing and communicating data warehouse plans to internal clients
preferred qualifications

4 years experience using python or java",,NY,False,data_engineer
Arity - Big Data Engineer,"founded by the allstate corporation in 2016 arity is a data and analytics company focused on improving transportation we collect and analyze enormous amounts of data using predictive analytics to build solutions with a single goal in mind to make transportation smarter safer and more useful for everyone
at the heart of that mission are the people that work here—the dreamers doers and differencemakers that call this place home as part of that team your work will showcase both your intelligence and your creativity as you tackle real problems and put your talents towards transforming transportation
that’s because at arity we believe work and life shouldn’t be at odds with one another after all we know that your unique qualities give you a unique perspective we don’t just want you to see yourself here we want you to be yourself here


job description

data science incorporates techniques across many disciplines – including mathematicsstatistics computer programming data engineering and etl software development and high performance computing – with traditional business expertise with the goal of extracting meaning from data to optimize future business decisions individuals in this field should be an expertfluent in several of these disciplines and sufficiently proficient in others to effectively design build and deliver end to end predictive analytics products to optimize future decisions individual demonstrates sufficient analytic agility to quickly develop new skills across these disciplines as those disciplines evolve the big data engineer job family is accountable for end to end engineering of data solutions which includes designing and building systems for data storage and analytics that enable allstate analysts to make better decisions to achieve allstate’s goals
this role is responsible for driving multiple complex tracks of work to deliver big data solutions enabling advanced data science and analytics this includes working with the team on new big data systems for analyzing data the coding  development of advanced analytics solutions to makeoptimize business decisions and processes integrating new tools to improve descriptive predictive and prescriptive analytics and discovery of new technical challenges that can be solved with existing and emerging big data hardware and software solutions
this role contributes to the structured and unstructured big data  data science tools of allstate from traditional to emerging analytics technologies and methods the role is responsible for assisting in the selection and development of other team members



job responsibilities

executes complex functional work tracks for the team
partners with atsv teams on big data efforts
partners closely with team members on big data solutions for our data science community and analytic users
leverages and uses big data best practices  lessons learned to develop technical solutions used for descriptive analytics etl predictive modeling and prescriptive “real time decisions” analytics
influence within the team on the effectiveness of big data systems to solve their business problems
participates in the development of complex technical solutions using big data techniques in data  analytics processes
supports innovation regularly provides new ideas to help people process and technology that interact with analytic ecosystem
participates in the development of complex prototypes and department applications that integrate big data and advanced analytics to make business decisions
uses new areas of big data technologies ingestion processing distribution and research delivery methods that can solve business problems
understands the big data related problems and requirements to identify the correct technical approach
works with key team members to ensure efforts within owned tracks of work will meet their needs
drives multiple tracks of work within the research group
identifies and develops big data sources  techniques to solve business problems
comingles data sources to lead work on data and problems across departments to drive improved business  technical results through designing building and partnering to implement models
manages various big data analytic tool development projects with midsize teams
executes on big data requests to improve the accuracy quality completeness speed of data and decisions made from big data analysis
uses learns teaches and supports a wide variety of big data and data science tools to achieve results ie r etl tools hadoop and others
uses learns teaches and supports a wide variety of programming languages on big data and data science work ie java c python and perl
trains more junior engineers



job qualifications

3  4 years of experience or equivalent skills  ability
master’s or phd preferred in a quantitative or scientific field such as computer science computer engineering or equivocal experience
experience in using software development to drive data science  analytic efforts
experience with database  etl technologies
experience with various data types eg relational unstructured hierarchical and linked “graph” data
experience in developing managing and manipulating large complex datasets
experience in working with statistical software such as sas spss matlab r cart etc
proven ability to code and develop prototypes in languages such as python perl java c r sql and xslt
ability to communicate and present advanced technical topics to general audiences
understanding of predictive modeling techniques a plus




that’s the daytoday now let’s talk about the rest of it as we mentioned arity was founded by the allstate corporation but you’ll be working for—and at—arity it’s the best of both worlds you’ll get access to the full suite of allstate benefits and work in a fastpaced startup culture that’s more than just free breakfasts brain breaks and ping pong it’s a culture that encourages you to be you
sound like a fit apply now we can’t wait to meet you
aritycom instagram twitter linkedin


allstate generally does not sponsor individuals for employmentbased visas for this position

effective july 1 2014 under indiana house enrolled act hea 1242 it is against public policy of the state of indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the united states a member of the indiana national guard or a member of a reserve component

for jobs in san francisco please click here for information regarding the san francisco fair chance ordinance

for jobs in los angeles please click here for information regarding the los angeles fair chance initiative for hiring ordinance

it is the policy of allstate to employ the best qualified individuals available for all jobs without regard to race color religion sex age national origin sexual orientation gender identitygender expression disability and citizenship status as a veteran with a disability or veteran of the vietnam era",,IL,True,data_engineer
"Data Software Engineer, Data Engineer Python Software Engine...","100000  140000 a yearworking directly with the two founders of this profitable 30 person startup whom bivium has placed multiple engineers to find a great data integration engineer

target salary in the 100130k ish range  other great benefits  this role is a data engineer  a software engineer with the flair to do heavy data engineering but not a pure data scientist this role is about engineering things

the founders had a prior very profitable sale of their last startup in the same data space

you must know python beyond academics or school projects and have a flair for data

should have great communication skills positive attitude and real smarts

hq in the heart of bostons financial district in top grade office space lunch every day and a gym on their floor health insurance premiums fully covered by the company competitive compensation with an opportunity to earn equity in a profitable startup


some of things youll be working on

design build and document or find  use scalable robust tools to manage and store data
 interact with outside data vendors to create file formats that contain required data
 migrate and optimize existing data processing to updated formats
 provide transparency on the state of the data processing workflow
 implement automated testing on existing and new components
 create tools to automatically compare data sets and output differences concisely

  

to learn more  scottbiviumgroupcom

about me  the bivium group scott dunlop on linkedin

i am the recruiter people work with who dont work with recruiters

for over 20 years ive been bostons leading software engineersoftware developer recruiter with nearly 100 public linkedin recommendations  im exclusively focused on the software engineering market in boston  im always looking to expand  build strong longterm relationships with exceptional clients and talent

  






python software engineer data engineer data software engineer data science devops unix scott dunlop bivium group",120000.0,MA,True,data_engineer
Data Quality Engineer,"the data quality engineer will write testing plans and routines manage continuous integration and regression testing processes and be the point person for clearing data for release according to delivery specifications the technician must be able to function effectively in a highvolume rapid delivery environment in which publicly available data must meet data security and accessibility specifications without fail additional responsibilities work with product managers and development leads to create testing strategies work with data engineers to develop automated tests design monitor and maintain qa reports kpis  quality trends for the internal data systems create test plans and test cases execute and automate test cases and perform bug tracking help create and implement quality processes and requirements knowledgeable about industry data compliance strategies and practices such as continuous integration regression testing and versioning familiarity with triple stores and related technologies such as rdf sparql shacl and linked data is a strong plus ability to readwrite sql queries is a plus experience working in a big data environment dealing with large diverse data sets familiarity with python is a plus bachelors in computer science or information systems or 2 years’ experience with corporate data management systems in highcompliance contexts
the data quality engineer provides continuous automated and manual testing of data sets for use in internal data systems and for delivery from internal systems to clients within disney such data sets can be in several formats depending on supplier systems and client requirements including json xml csv or rdf the data quality engineer works in the data technology team with the senior staff data engineer and the data engineer 588469",,CA,True,data_engineer
Big Data Engineer,"about the opportunity
an asset management company in new york city is actively seeking a new big data engineer for a promising position with their growing staff in this role the big data engineer will be responsible for working on collecting storing processing and analyzing of huge data sets to design the optimal software solutions apply today

company description
asset management company

job description
the big data engineer will be responsible for
working closely with financial analysts to develop new algorithms to automate the investment process
processing unstructured data into a form suitable for analysis
supporting business decisions with ad hoc analysis as needed

required skills
8 years of strong programming experience in python or c 6 years of strong sql experience including designing data warehouse schemas and tuning performance of very complex sql queries
bachelors degree in a related field
experience processing large amounts of structured and unstructured data at scale including writing scripts web scraping calling apis writing sql queries etc
ability to clean and scrub noisy datasets
ability to build custom software tools
experience with awsemr and other web services
great interpersonal skills
excellent communication skills written and verbal
strong attention to detail
highly organized
able to multitask efficiently and effectively

desired skills
experience with statistical analysis data mining machine learning natural language processing or information retrieval
experience with spark and mapreduce
experience with data visualization tableau",,NY,True,data_engineer
Sr Data Engineer,"at tmp worldwide we ask ourselves important questions to find the big story behind the data were a robust team of analysts problem solvers learners and ideachurners working to solve complex problems for our clients

the sr data engineer s role is to bridge the gap between our business and client needs and the data engineers this includes participation in requirements gathering analysis planning and developing solution this individual will have a passion for data and experience using tools to interact and analyze it
responsibilities
what does a great sr data engineer do

gathers requirements analyzes creates design documents and performs impact analysis
partner with senior leaders from product engineering and performance media analysts to identify opportunities for improvement and drive decisionmaking
transform raw data into meaningful and impactful analysis characterized by strong data governance technique transparency and aggressive documentation
builds processes to validate and ensure data integrity
creates test plans test cases test scripts and performs testing of the related environments
act as an internal consultant to help business users develop enhance and maintain the metadata layers reports report definitions and dashboards
raise the skill level of entire analyst team through the creation of exemplary work mentorship and the introduction of better practices processes and tools
assist users with problems and resolves issues independently


qualifications
requirements for consideration
3 years of experience writing queries against traditional relational and dimensional databases
2 years of experience building interactive dashboards with tableau
an indepth knowledge of data visualization theory and technologies strongly preferred
demonstrated advanced query development and design using sql
2 years of experience using microsoft sql server or similar technologies
2 years of experience working with nontraditional databases including more than one of the following systems spark hadoop cloudera mongodb teradata hive azure cassandra etc a plus
2 years of experience with data warehouses data marts and olap technologies
experience in google cloud services strongly preferred
experience with web services integration architectures including soap and rest a plus
experience with agile methods a plus

join the global leader in talent acquisition technologies thats committed to finding new ways to leverage software strategy and creative to enhance our clients employer brands  across every connection point
were looking for unconventional thinkers relentless collaborators and ferocious innovators talented individuals who are ready to work towards solutions that transform the way employers and job seekers connect

gdmediaanalytics
gddataanalytics apply",,IL,True,data_engineer
Data Engineer,"data engineer
as a data engineer for slalom consulting youll work in small teams to deliver innovative solutions on amazon web services azure and google cloud using core data warehousing tools hadoop spark event stream platforms and other big data related technologies in addition to building the next generation of data platforms youll be working with some of the most forwardthinking organizations in data and analytics
who are you
you’re a smart collaborative person who is passionate about technology and driven to get things done
you’re not afraid to be bring your authentic self to work
you embrace a continuous learner mentality
what technologies will you be using
everything it’s about using the right technologies to solve problems and playing with new technologies to figure out how to apply them intelligently we are tool and technology agnostic so we work across the board
qualifications
bachelor’s degree in computer engineering computer science or related discipline
57 years relevant experience
understand different types of storage filesystem relation mpp nosql and working with various kinds of data structured unstructured metrics logs etc
4 years of experience working with sql
experience with setting up and operating data pipelines using python or sql
2 years of experience working on aws gcp or azure
experience working with relational databases
strong analytical problemsolving ability
great presentation skills
great written and verbal communication skills
selfstarter with the ability to work independently or as part of a project team
capability to conduct performance analysis troubleshooting and remediation
experience working with data warehouses such as redshift bigquery and snowflake
exposure to open source and cloudspecific data pipeline tools such as airflow glue and dataflow
what does our recruitment process look like
﻿our process is highly personalized some candidates complete their process in one week others can take several weeks or even months deciding to take a new job is a big decision so regardless how long or short the process may be for you the most important thing is that you find your dream job

slalom is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability status protected veteran status or any other characteristic protected by law",,CA,False,data_engineer
Data Engineer,100000  200000 a yearare you an experienced data engineer who is seeking an opportunity in a java focused data engineering organizationwe have partnered up with a financial serie a funded company based in atlanta georgia who is seeking to expand their development team of data engineers the data engineer will partner with other businesses in developing analytical tools to improve market efficiency this position will consist of analyzing data identifying trends and identifying technological opportunities for the businessthis company is looking for those who have a supreme understanding of java and can apply those understandings into the development of their unique artificial intelligence ideally you should have experience in machine learning and be able to recognize when something is optimal or obsoleteyour opportunity lies herewhat will you be doingworking on complex data applicationsusing high performance code java and scalaleading project developments and experiments in data scienceworking with a team of 510 other engineersdesign and develop new features for a company with 80 employeesrequired skillsbachelor’s degree or advanced degree master’s phd in the field of computer science engineering or mathematics3 years of experience in software engineering including testing and deploying software systems2 years professional experience in java or scalaunderstanding of a variety of data science algorithmsexceptional analytical and bigdata skillswhat will i get marketleading salary plus bonuses401kflexible vacationquarterly incentivesflexible working hourshealth dental vision coveragedon’t miss out on this lifechanging opportunity apply nowjob type fulltimesalary 10000000 to 20000000 year,150000.0,GA,False,data_engineer
"Data Engineer, Analytics, Intern","internshipfacebooks mission is to give people the power to build community and bring the world closer together through our family of apps and services were building a different kind of company that connects billions of people around the world gives them ways to share what matters most to them and helps bring people closer together whether were creating new products or helping a small business expand its reach people at facebook are builders at heart our global teams are constantly iterating solving problems and working together to empower people around the world to build community and connect in meaningful ways together we can help people build stronger communities — were just getting started
would you like to work with big data do you want to use data to influence product decisions for products being used by over half a billion people every day if yes we want to talk to you our data warehouse team works very closely with product managers product analysts and internet marketers to figure out ways to acquire new users retain existing users and optimize user experience  all of this using massive amounts of data in this role you will see a direct link between your work company growth and user satisfaction you will work with some of the brightest minds in the industry and youll have the opportunity to solve some of the most challenging business problems on the web and mobile internet at a scale that few companies can match

this is an internship position based in menlo park seattle or new york
responsibilities

architect implement and deploy new data models and data processes in production

perform data analysis to generate business insights

interface with engineers product managers and product analysts to understand product goals and data needs

build data expertise and own data quality for allocated areas of ownership

manage data warehouse plans for a product or a group of products

support critical data processes running in production
minimum qualifications

pursuing a bs ms or phd degree in one of the following areas computer science mathematics physics or related technical field preferred

programming expertise in a language of your choice

knowledge of sql

knowledge of database systems

curious selfdriven analytical and excited to play with data

ability to thrive in a fast paced work environment

returning to at least one semester of school at the end of internship",,WA,False,data_engineer
Data Engineer,"auth0 a global leader in identityasaservice idaas provides thousands of enterprise customers with a universal identity platform for their web mobile iot and internal applications its extensible platform seamlessly authenticates and secures more than 15b logins per month making it loved by developers and trusted by global enterprises auth0 has raised more than 110 million to date and continues its global growth at a rapid pace we are consistently recognized as a great place to work based our outstanding leadership and dedication to company culture and are looking for the best people to join our incredible team spread across more than 35 countries

auth0 is loved by developers and trusted by global enterprises more than 500000 unique users visit auth0com each month due to our compelling content and the functionality of our identity platform our mission is to simplify developers lives improve security and reduce identity tco for our enterprise customers by making identity simple secure and extensible we strive to maintain a welcoming and inclusive culture built on the principle of no bap no bs no aholes no politics

as data engineer you will convert the data we process everyday from our users into actionable information to better understand our customers and give them an even better service every day
responsibilities
transform data from different data sources to integrate with our data warehouse in redshift
create etls to transform that data into usable formats
design and develop reports to help make business decisions
design infrastructure components
integrate to other external systems like stripe zendesk and others
skills and abilities
experience as a data engineer
desire to learn about auth0s business
experience with r and r studio
experience with sql python and bash
experience with bi reporting tools like tableau

auth0 is an equal employment opportunity employer auth0 conducts all employmentrelated activities without regard to race religion color national origin age sex marital status sexual orientation disability citizenship status genetics or status as a vietnamera special disabled and other covered veteran status or any other characteristic protected by law auth0 participates in everify and will confirm work authorization for candidates residing in the united states",,,False,data_engineer
Data Engineer,"about us
healthlinecom is the fastestgrowing health information site on the planet every month over 80 million people count on our talented teams to support guide and inspire them toward the best possible health outcomes for themselves and their families we create authoritative content that’s highly relevant approachable and actionable and we complement that with a culture of genuine compassion in short we’re changing the consumer health information business and we need exceptional people like you to help us do it if you share our vision for a stronger healthier world please explore healthline media and let’s talk

healthline has also recently become a certified great place to work you can check out our review and get a better idea of what its like to work  healthline here httpreviewsgreatplacetoworkcomhealthline

location
san francisco ca

about the team
the healthline date engineering team is committed to creating a positive contribution to the health and wellness of our users by using data we have an opportunity to build a data platform with collaboration with the product and business intelligence team we are using some of the leading edge cloud technologies from google to process all the data that is generated by our users we strive to be a fastmoving team that supports each other along the way which requires each of us to be committed to the team and aligned with our goalsvalue

about the role
as a data engineer you will be working closely with the sr director of data engineering as one of the very first member data team it’s an opportunity to have significant input into the technical direction and architecture of our new data platform you will also work closely with product management and various business owners to build an infrastructure this is critical to the success of the company
what are your qualifications
proficiency with python and sql required
proficiency with mysql
experience with bigquery
experience with gcp and it’s services
nice to have
knowledge of statistics
aws data pipeline
data studio
tableau
adtech andor cdp experience a big plus
what you’ll do and how you’ll make an impact
build and support our data pipelines to help power our dashboards reports and analytics teams
work together with the engineering and product team come up with better and more efficient ways to collect and process the data generated
collect and process data from our ad event aggregation and various 3rd party systems
reasons why you should apply
you are psyched as opposed to wary to take the lead on making the platform a central part of the product offering
you want to be a part of creating a culture within a small team
you strive for simplicity even for complex problems
why you’ll love working at healthline …
we are the fastest growing health information site on the planet and the 2nd largest health site in the us per comscore over 80 million people count on our talented teams to support guide and inspire them toward the best possible health outcomes for themselves and their families
we are a purposedriven organization with a vision to create a stronger healthier world
we work together to achieve our mission with humility and genuine respect for each member of our team
we are smart innovative and inspiring changemakers
transparency and honesty earn us the trust of each other and our users
we feel with our users and are committed to being their true ally in their lifelong pursuit of health and wellbeing
we’re all in for having fun living well and promoting good health we’re proving that you can work hard and be happy
we’ve got cozy canine companions in the office pooches make healthline hq fun
a smart experienced leadership team that wants to do it right and is open to new ideas
we offer competitive compensation packages and comprehensive health benefits
does this sound like it was written for you excellent please apply and let’s explore this together

healthline media is committed to a policy of equal employment opportunity and will not discriminate on any legally recognized basis including but not limited to race color religion sex sex stereotyping pregnancy which includes pregnancy childbirth and medical conditions related to pregnancy childbirth or breastfeeding gender gender identity gender expression national origin age mental or physical disability ancestry medical condition marital status military or veteran status citizenship status sexual orientation genetic information or any other status protected by applicable law we also provide reasonable accommodations to qualified individuals with disabilities in accordance with the americans with disabilities act as amended and applicable state and local law no person shall be excluded from participation in be denied the benefits of or be subjected to discrimination on the basis of these factors if you require an accommodation in the application process please advise your recruiter",,CA,False,data_engineer
Data Engineer,contracttitle data engineerlocation san jose ca 95110duration 6 monthsduties design build and manage complex analytics data models in hivehadoop for gtm analytics team across all customer journey from acquisition engagement and retention the analytics data marts will be used by data analysts in gtm analytics and other team to do deep dive analysis build analytics dashboard or other data science projectdesign build deploy and maintain new data models etl pipeline with sql query python oozie and other script language and createmaintain workflow using oozieensure overall data qualityskills querying and manipulating large data sets for analytical purposes using sqllike languages hive is strongly preferredexperience with hadoopbig data environments to synthesize and analyze dataprofessional experience in the data warehouse spacegood attention to detail and ability to qa multiple data sourcesexperience working on building scalable etl pipelines data warehousing and schema modelingexperience working with oozie workflowexperience with script language such as python2  3 years of relevant experienceeducation degree in computer sciencecomputer engineering or a related fieldjob type contractexperiencehadoop 2 years requiredpython 2 years requiredsql 2 years requiredhive 1 year requireddata engineer 3 years requiredoozie 1 year preferred,,CA,False,data_engineer
Jr Data Engineer,junior data engineermsi is working with one of the world’s largest fastest growing best companies in the world to hire top tier individuals with an education or career background in data consolidation import and export of data and excel the junior data engineer will be working as part of a dynamic team and will play a critical role in a best in class fortune top 20 companyoverviewthe qualified candidate needs to have data analytic skills who can sort through 2000 components 100 pdf files and 100 excel spreadsheet with five thousand lines effectivelythe majority task of this job is to sort through equipment data and navigate through the various internal and external web portalscreate and compile equipment bill of material trackercreate and maintain metrics and dashboardsdocument review comparison of data from one source to another identifying missing data elements data entry maintaining spreadsheets submit applications and requests via online web portalsengage with manufacturers to obtain equipment test reportsdocument meeting notes and follow up with action itemsrequired skillsexpertise in excel or other data analytic programming language skillability to create pivot tablesimportation and exportation of data from multiple data sources and consolidating into one data sourcerepositorybeing careful about comparing data from one source to another and being able to clearly identify missing data elements efficient data entry maintaining spreadsheets attention to detailability to learn and master at different online web portalsweb interface  web design skillsstrong administrative and project management skills with the ability to schedule meetings via microsoft outlook and communicatemeet with stakeholderspreferred skillsability to understand compliance regulationselectrical equipment knowledgejob type fulltime,,WA,False,data_engineer
Data Engineer,"lendkey is solving a complex challenge – to improve lives with lending made simple – by helping financial institutions compete in the digital age and provide a delightful customer experience while providing borrowers with the simple transparent digital borrowing experience they have come to expect and desire lendkey works with hundreds of credit unions and banks to conduct their education finance and home improvement loan programs
we are looking for a data engineer to help us build our data pipeline data warehouse and technical data structure across the firm our data capabilities and culture are still in the early stages so this is an opportunity to build a data platform from the ground up
what you’ll do
partner with the product and engineering teams to develop scalable extensible systems
be the driving force behind the roadmap to normalize all of our transactional data disparate systems and transfer of data in way that creates a flexible and scalable data solution
develop data governance policies  appropriate structures to ensure adherence to those policies
ensure that solutions work well within our current code environment that technical data initiatives are aligned effectively with development staff and work to understand how other tiers in the technology stack influence data quality including apis orms object relational mapping and user interface
responsible for managing the full lifecycle of the data pipeline and warehouse solution including the architecture design development implementation and support of the data warehouse
participate in creating the data design of all transactional data stores across business units and technology stacks
work with end users to translate business questions and requirements into applications that employ the appropriate reporting tools
assist in monitoring and troubleshooting system performance reliability availability and recoverability of all data stores
requirements
what we’re looking for
culture fit
strong desire to work for a missionbased organization that emphasizes the importance of providing exceptional customer service and aligned with our core values truthful at all times helpful to teammates clients and customers present committed  engaged to their teams and work driven to be courageous to make an impact and diligent  conscientious in executing every element of work
technicalbusiness experience
bachelor’s degree in computer science or related field
5 years overall experience working in development and enterprise data architecture
experience and background in building data platforms for financial services
minimum 3 years of experience with enterprise data architecturedesign
minimum 3 years of experience in software development with deep experience in objectoriented functional objectfunctional language and one of the major sql relational datastores we are a sql server and mysql shop",,NY,False,data_engineer
Data Engineer,"60000 a yearfreightwaves a trucking financial instruments and market data analytics startup is looking for a data engineer

founded by a group of successful transportation technology executives freightwaves is focused on helping transportation companies mitigate market price volatility and providing a realtime supplydemand map of the us transportation market

job description

build relational databases tables views stored procedures batch jobs and reports

develop procedures and code to monitor data from vendors our own etl process and data readiness in production
proactively find data problems early and resolve batch job failures even outside normal business hours
run adhoc queries to support analysis in editorial sales marketing and data science departments
solve database performance issues via indexing normalizing hardware replication

manage data retention to prevent loss while minimizing storage cost

education skills  experience

minimum of a bachelor degree in computer science engineering other scientificquantitative field
required 3 years of experience with relational database operations and administration

strong quantitative orientation with excellent research and analytic skills that will support in depth analysis

ability to quickly learn about new data and design an appropriate storage schema
understanding of the difference between performance of highread versus highwrite database designs

strong communication skills both written and verbal

transportation industry experience is preferred but not required

document store  nosql experience is preferred but not required

programming experience in r python or other non database languages preferred but not required

we offer

an excellent startup work environment flat hierarchies and short decision paths

competitive salary and bonus potential packages

a generous benefits package including 100 employer paid health dental life and vision insurance unlimited vacation plan workout benefits industry education and companypaid travel to industry events studentloan reimbursement pet insurance family bank account merchant discount program and much more

stock options

training programs and career development opportunities

flexible working hours and worklifebalance options",60000.0,TN,False,data_engineer
Data Engineer (T),55  57 an hourcontractdata engineerjob description7 or more years of relevant industry 5 years of domain experienceprovide systems engineering and development as required with specific emphasis on kafka rabbitmq and big data middle tier frameworks provide system enhancements and codebase deliveries as neededthis position is responsible for onboarding qa and analyses of data sets this role will also interface with business and product owners to understand requirements and ensure that data sets are accurate timely and available to support the business needsresponsibilities include ability to interpret data sets and define process and procedures to ensure data is received to spec and in a timely and accurate manneridentify and address issues with data setsensure appropriate procedures are in place to meet soc 3 compliance proceduresensure excellent communication procedures are in place viadailymonthlyweekly reporting to advise status of data sets and that end users are informed of data statuswork with business and product owners to develop procedures methods code to provide efficient tools and products to meet the needs of the end userssupport all internal teams as needed to address questions regarding data quality status etl and other platform related questions and concerns that may arise qualifications and education requirementsstrong working knowledge of sql python and other database query related languagesexperience in application development “big data” analytics and ability to deliver customer focused products that are simple and easy for end users to interpretjob types fulltime contractsalary 5500 to 5700 hourexperiencekafka 1 year requireddata engineering 7 years requiredbig data 3 years requirededucationbachelors requiredlocationhicksville ny preferredwork authorizationunited states preferred,,NY,False,data_engineer
Data Engineer (Manufacturing Gaming Plant),"acara solutions formerly superior group is helping our redmond wa client to find a data engineer to join their electronics plant that is assembling a gaming device this is a direct salaried position with full benefits the manufacturing data engineer position will be the subject matter expert on our manufacturing execution system mes leading efforts to maintain the system manage data quality reportanalyze production data and lead the effort to maximize proper use of the mes systems critical emphasis on integration and communication between different systems you will slice and dice data sets move data between different locations and develop programsscripts to automate the transactions of data to and from many different systems once the data is in the proper place you’ll develop quick simple and easy user interfaces used by office staff executives and factory floor personnel doing their daily jobs this position requires a lot of customerfacing interaction become the subject matter expert on the configuration and data structures of our manufacturing execution system mes assisting engineers with knowledge on how the system is used to create npis processes reports and other tasks work with manufacturingengineering teams to analyze production operations data understand daily kpis document daily manufacturing reports understand and help develop manufacturing processes in order to create the proper data required develop and maintain enduser programs web applications and reports develop and maintain backend server services to integrate data between different systems and databases this includes sql server databases xml formatted data csv net interfaces com interfaces web services and plain text formats data mining and harvesting maintain database queries data modules bug fixesjira develop and maintain microsoft sql server code including views stored procedures triggers ssis dts replication linked servers indexing and maintenance plans refactor existing legacy software programs and code when appropriate relational database design and optimization application security documentation from a technical and enduser perspective while this position is very much a data engineering job you must have an appreciation for other it roles their small technology group is an integrated team sys admins sometimes write simple code and coders sometimes assist with sys admin tasks you must be used to wearing multiple hats
required skills  qualifications
bachelor’s degree in computer science data engineering or related discipline or 10 years general softwaredata engineering experience or equivalent combination of education and experience
min 5 years of data engineering experience
minimum 2 years of manufacturing industrial or ecommerce experience
min 2 years of etl or data integration experience
min 1 years of parametric data passfail experience
min 2 years of experience with at least 3 of the following aspnet c com interfaces and tsql
min 1 year of experience with web application frameworks such as mvc webform or others
min 1 year of experience with scripting languages such as javascript batch or powershell
min 1 year of experienc with source control and code versioning svn git or other experience
min 3 years of experience with ms office suite advanced excel access outlook powerpoint etc




preferred
experience with advanced analytics platforms such as tableau microsoft bl or others

go beyond wwwsuperiorjobscom
eeo employer  minorities  females  disabled  veterans  sexual orientation  gender identity",,WA,True,data_engineer
"Senior Associate, Data Engineer- IHM","title senior associate data engineer

duties dfs corporate services llc seeks senior associate data engineer in riverwoods illinois to work with business clients to design develop test and deliver solutions that meet customer requirements develop data driven solutions with current and next generation big data technologies to meet evolving business needs develop greenfield capabilities leveraging open source nextgeneration technologies code and integrate open source solutions into an enterprise hadoop ecosystem utilize multiple development languagestools such as python spark hive r and java participate in prototype solutions by integrating various open source components operationalize open source dataanalytic tools for enterprise use provide support for deployed data applications and analytical models by being a trusted advisor to data scientists and other data consumers by identifying data problems and guiding issue resolution with partner data engineers and data providers provide subject matter expertise in the analysis preparation of specifications and plans for the development of data processes ensure proper data governance policies are followed by architecting and building data lineage quality checks and data classification systems and frameworks promote a riskaware culture ensure efficient and effective risk and compliance management practices by adhering to required standards and processes
skills
requirements  master’s degree or foreign equivalent in computer science mathematics computer engineering or a related field and one 1 year of experience in job offered or related position coding and integrating open source solutions into an enterprise hadoop ecosystem developing realtime data ingestion and streamanalytic solutions using technologies including kafka apache spark nifi python hbase and hadoop utilizing multiple development languages and tools including python spark hive r java and utilizing technologies including sas sql and tableau

qualified applicants please apply directly through our website wwwmydiscovercareercom for job id 45361 by clicking on “apply now” no calls equal opportunity employerdisabilityvet

we are an equal opportunity employer and do not discriminate against any employee or applicant for employment because of race color sex age national origin religion sexual orientation gender identity status as a veteran and basis of disability or any other federal state or local protected class",,IL,True,data_engineer
Master Data Engineer,"as a master data engineer you will provide engineering leadership to create and enhance data solutions enabling seamless integration and flow of data across our data ecosystem which includes aws additionally you will provide senior level technical consulting to peer data engineers during design and development for highly complex and critical data projects some of these projects will include designing and developing data ingestion and processingtransformation frameworks leveraging open source tools such as nifi lambda step functions java python spark etc additionally you will work on real time processing solutions using tools such as flink storm kafka and kinesis you will deploy application code using cicd tools and techniques and provide support for deployed data applications and analytical models
this role will sit in our state of the art downtown chicago location at 350 n orleans
responsibilities

develop data driven solutions utilizing current and next generation technologies to meet evolving business needs
ability to quickly identify an opportunity and recommend possible technical solutions
utilize multiple development languagestools such as python spark hbase hive microsoft r java to build prototypes and evaluate results for effectiveness and feasibility
work heavily within the aws ecosystem using aws services
operationalize open source dataanalytic tools for enterprise use
develop realtime data ingestion and streamanalytic solutions leveraging technologies such as kafka apache spark nifi python hbase kinesis and emr
custom data pipeline development cloud and locally hosted
work heavily within the hadoop ecosystem and migrate data from teradata to hadoop
provide support for deployed data applications and analytical models by being a trusted advisor to data scientists and other data consumers by identifying data problems and guiding issue resolution with partner data engineers and source data providers
provide subject matter expertise in the analysis preparation of specifications and plans for the development of data processes
ensure proper data governance policies are followed by implementing or validating data lineage quality checks classification etc
promote a riskaware culture ensure efficient and effective risk and compliance management practices by adhering to required standards and processes
skills
skills required

aws data services lambdaglue emr kinesis step functions data pipeline
deep understanding of the hadoop technology stack
building custom nifi processors
data pipeline development
experience in developing python  r applications
spark application coding in scala  python pyspark
deep knowledge and very strong in sql and relational databases
strong in unix  shell scripting
experience in creating very efficient hiveql and sparkql queries and can educate peers on the topic
bachelors degree in computer science related field or equivalent work experience
leadership skills

7 years of experience of being a lead engineer and able to coachprovide guidance to peer and junior engineers
excellent written and verbal communication presentation and professional speaking skills
collaborative individual who excels in working within a team and with business partners to identify develop and deliver innovative data solutions
influencing skillsability must be able to work with effectively with different levels of management and all business areas
ability to demonstrate leadership to managers and peer level staff
ability to build and leverage external relationships
decision making abilities while gathering information and then put your decisions into action
passionate learner who enjoys education through class room training and selfdiscovery on a variety of emerging technologies
like
we are an equal opportunity employer and do not discriminate against any employee or applicant for employment because of race color sex age national origin religion sexual orientation gender identity status as a veteran and basis of disability or any other federal state or local protected class",,IL,True,data_engineer
Data Engineer,"about your role

as a data engineer on the commerce team you will integrate data from a variety of sources and surface it in our reporting platform so that users can make datadriven decisions and derive insights you will also provide data analysis reports and dashboards to your team and dotdash as a whole as a data engineer you will facilitate the free and open use of data across the organization and encourage data culture through weekly meetings outreach and technical consulting

about your contributions
analyze raw data to answer ad hoc questions
map business rules onto our raw data to enrich customer reporting
build reports and dashboards to drive insights
work collaboratively to solve data challenges for your team
build and maintain data integrations
find ways to use new and exciting technology to solve data challenges
about you
proficient writing sql queries to analyze data
experience with a bi reporting platform looker quicksight tableau
strong analytical and problem solving skills
experience building data integrations with python spark or java
comfortable with the linux cli
looker and lookml experience a plus
about us
for more than 20 years dotdash brands have been helping people find answers solve problems and get inspired we are one of the top20 largest content publishers on the internet according to comscore a leading internet measurement company and reach more than 30 of the us population every month our brands collectively have won more than 20 industry awards in the last year alone and most recently dotdash was named publisher of the year by digiday a leading industry publication our brands include verywell the spruce the balance investopedia lifewire tripsavvy and thoughtco
dotdash embraces inclusivity and values our diverse community we are committed to building a team based on qualifications merit and business need we are proud to be an equal opportunity employer and do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,NY,False,data_engineer
Big Data Engineer - Masters (Full Time) – United States,"what you’ll do
 design and deliver automated transformation of large data sets influencing mapreduce streaming and other new technologies
 use hbase elasticsearch etc to ingest transformed data at scale
 collaborate with security experts to deliver highimpact webbased apis
 implement highvolume data integration solutions
 analyze monitor and optimize for performance
 produce and maintain highquality user documentation
who youll work with
join us as we transform the world of tomorrow develop creative ideas on how to work better and smarter influence and participate in toppriority projects that have a real impact
who you are
 recent graduate or on your final year of studies toward a masters degree in computer science or a related technical field
 minimum of a 30 gpa or equivalent
 track record of developing technology to enable large scale data transformation
 strong java experience and handson hadoop ecosystem experience – hbase hive spark etc
 possess knowledge of software engineering standard methodologies
 real passion for solving hard problems and exploring new technologies
 excellent communication and user documentation skills
why cisco
at cisco each person brings their own rare talents to work as a team and make a difference
yes our technology changes the way the world works lives plays and learns but our edge comes from our people
 we connect everything – people process data and things – and we use those connections to change our world for the better
 we innovate everywhere  from launching a new era of networking that adapts learns and protects to building cisco services that accelerate businesses and business results our technology powers entertainment retail healthcare education and more – from smart cities to your everyday devices
 we benefit everyone  we do all of this while striving for a culture that empowers every person to be the difference at work and in our communities
colorful hair don’t care tattoos show off your ink like polka dots that’s cool pop culture geek many of us are be you with us wearecisco
univsoftwarejobs sto softwareengineer computerscience security wearecisco
this position is available to masters level students positions are located east coast west coast and central us not all positions offer sponsorship or are available at all locations relocation is available for some locations and or positions
cisco is an affirmative action and equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion gender sexual orientation national origin genetic information age disability veteran status or any other legally protected basis
cisco will consider for employment on a case by case basis qualified applicants with arrest and conviction records",,CA,False,data_engineer
Data Engineer,"at pandora were a unique collection of engineers musicians designers marketers and worldclass sellers with a common goal to enrich lives by delivering effortless personalized music enjoyment and discovery people—the listeners the artists and our employees—are at the center of our mission and everything we do actually employees at pandora are a lot like the service itself bright eclectic and innovative collaboration is the foundation of our workforce and we’re looking for smart individuals who are selfmotivated and passionate to join us be a part of the engine that creates the soundtrack to life discover your future at pandora
job description
data engineers at pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day data engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections billions of events per day
responsibilities
at pandora the data team supports a variety of business functions including our science marketing product finance and sales teams you should have a solid understanding of java software development and take personal responsibility for testing the code you write you should have strong academic credentials and a degree in computer science or a related field you should be enthusiastic about learning new technologies and skills you must be capable of managing your time well and working collaboratively excellent communication skills both written and verbal are required
qualifications
3 years development experience of which 13 years are focused on data or analytics engineering working with big data technologies hadoop ie mapreduce hdfs tez hive spark
experience with one of the following distributed databases mysql postgres redis nosql or newsql
experience developing in one of the following java scala cc or python
experience developing for linuxbased deployment platforms developing scalable multithreaded server side software for deployment
experience developing sql applications of significant complexity
experience developing service oriented architecturesorchestration including the support of data science
experience with api designdevelopment ie rpc rest json xml soap
significant experience unit testing with frameworks ie junit
“were considering candidates for multiple positions and levels successful candidates will be placed at appropriate level depending on their qualifications or experience”

pluses
experience collaborating with data scientists exposure to machine learning algorithms andor statistical modeling methods
experience with recommender or search systems
experience with apache spark and kafka
experience working across the full technology stack
babs or above in computer science or a related field
pandora is committed to diversity in its workforce pandora is an equal employment opportunity employer and considers qualified applicants without regard to gender sexual orientation gender identity race veteran or disability status women and people of color are encouraged to apply
pandora is also a vevraa federal contractor pandora requests priority referrals of protected veterans from each esds as required by regulation
if you believe you need a reasonable accommodation in order to search for a job opening or to apply for a position please contact us by sending an email to disabilitypandoracom this email box is designed to assist job seekers who require a reasonable accommodation to the application process a response to your request may take up to two business days
in your email please include the followingthe specific accommodation requested to complete the employment applicationthe location or office to which you would like to applythe subject of the email should read request for reasonable accommodation",,CA,False,data_engineer
Data Engineer,"named as one of las best places to work in 2018 prodege llc parent company of rewards community swagbuckscom  cashback shopping sites mypointscom  shopathomecom has awarded over 500 million to its members our business solutions brands prodegemr market research prodegedr direct response  prodegevn video network allow our partners to reach influence and acquire consumers online

join prodege and help us create rewarding moments for consumers around the world
we are currently looking for a data engineer to join our team as a key member of our technology and business intelligence team this position will
design build and maintain data loading routines using a variety of tools including open source etl tools stored procedures scripting and programming languages such as java c python etc
improve the performance and scale of our data operations to deliver information on a realtime basis
design build and maintain data qa routines to ensure that our systems deliver quality information to our customers
contribute to the design and architecture of our enterprise data infrastructure
work closely with endusers and technical team members on data ingestion projects investigating and solving data and reporting problems
skills and experience required
5 years development experience using mysql oracle or other relational database software experience experience writing and optimizing complex sql queries
5 years developing back end data processing routines for data warehouses or any backend data system using open source tools andor high level languages
5 years experience developing database related software using java c c etc
excellent verbal and written communication skills
bs computer science math physics or equivalent experience
knowledge of bi analytical tools a plus
our accolades
los angeles business journal – best places to work august 2018 2017 2016 2014  2013
the 2016  2017 career launching companies wealthfront
inc 500 – fastest growing private companies
deloitte’s technology fast 500
los angeles business journal – fastest growing companies
los angeles business journal– best places to work
president josef gorowitz  ernst  young 2014 entrepreneur of the year los angeles advertising category
president josef gorowitz  socal tech top 50 executives award 2013
ceo chuck davis – los angeles venture association lava hall of fame honoree
cfo brad kates  los angeles business journal 2014 cfo of the year winner
cto shane o’neill  los angeles business journal 2014 cio of the year finalist",,CA,False,data_engineer
"Data Engineer, Business Intelligence","the role

as a data engineer on the business intelligence team you will lead data collection and performance improvement efforts across multiple data sources and platforms

responsibilities


design develop deploy and manage a reliable and scalable data analysis pipeline using technologies including python and aws
facilitate the transfer of data from internal sources to external tools and platforms
facilitate the transfer of data from external sources to our analytics database
identify gaps in our data collection and collaborate with product and engineering on data capture specifications
compile and reconcile data from multiple sources
develop a vision to extendimprove our existing analytics and reporting technology stack
stay up to date with the latest technologies and trends in analytics

requirements


strong understanding of sql and relational databases
experience in database administration is strongly preferred
experience building and maintaining batch processes using aws data pipeline airflow luigi cron quartz etc
experience inspecting moving and transforming data on the nix command line using shell scripts unix tools such as sed awk cut sort etc or higher level languages like pythonperlruby
3 years technology experience working in an engineeringdevelopmentdata warehouse team or alternatively organization
a solid foundation in computer science fundamentals with particular expertise in data structures algorithms and design
experience building systems that must deal with the complexities of integrating with third parties

",,NY,False,data_engineer
Quant Developer/Data Engineer - Investment Bank,"are you a talented quant developerdata engineer that wants to get closer to the business are you passionate about data and how it can be used in investing if so we need people like you to help us

build solutions to collect enrich and automate data for use in customer experience enhancement and alpha generation
creation of new capabilities and modules in our data pipeline
develop reporting and data visualization solutions as well as looking to build out a dynamic platform

a brand new group within the investment banks corporate client solutions ccs business based around big data machine learning and artificial intelligence the team will leverage inhouse cutting edge knowledge and data to develop predictive analytics models and research to systematically identify traditional investment banking opportunities across advisory and capital markets the team is embedded within the business and will partner with different teams across ccs advisory and capital markets globally to develop innovative client and transaction targeting solutions and expand the department into new areas

you have

bachelor’s degree in stem or finance related disciplines
5 to 10 years experience programing with multiple technologies and software design within investment banking or hedge fund industries is essential
experience working in a multilayered distributed architecture is essential
experience with working in hadoop and distributed computing frameworks is a plus
understanding of data science machine learning and ai is a plus
strong analytical and problem solving skills data analysis and requirement documentation
outstanding data skills
excellent project management skills and ability to prioritize issues
excellent oral and written communication organizational and client facing skills
strong interest in working in investment banking and financial services

you are

ready to join a fast growing team in a dynamic and challenging environment
relentless in pursuing new ideas and selfimprovement
ability to selfmanage and prioritize workload
full of energy and able to persevere through technical issues
a team player willing to learn  share solutions and best practices from your colleagues
performance and detailoriented

expert advice wealth management investment banking asset management retail banking in switzerland and all the support functions thats what we do and we do it for private and institutional clients as well as corporations around the world

we are about 60000 employees in all major financial centers in more than 50 countries do you want to be one of us
together that’s how we do things we offer people around the world a supportive challenging and diverse working environment we value your passion and commitment and reward your performance

keen to achieve the worklife agility that you desire were open to discussing how this could work for you and us

why ubs video
are you truly collaborative succeeding at ubs means respecting understanding and trusting colleagues and clients challenging others and being challenged in return being passionate about what you do driving yourself forward always wanting to do things the right way does that sound like you then you have the right stuff to join us apply now
ubs is an equal opportunity employer we respect and seek to empower each individual and support the diverse cultures perspectives skills and experiences within our workforce",,NY,False,data_engineer
Siri - Data Engineer,"play a part in the next revolution in humancomputer interaction contribute to a product that is redefining mobile computing create groundbreaking technology for largescale systems spoken language big data and artificial intelligence and work with the people who built the intelligent assistant that helps millions of people get things done — just by asking join the siri team
key qualifications
strong data analytical skills
excellent coding skills in one or more of following languages — python shell scripts java etc
experienced in big data processing tools development andor web crawling
outstanding communication skills
gradings tasks and tools preferred eg for transcribing speech audio labeling tasks language translation etc
knowledge in the field of language technologiesnlp such as language modeling machine translation text mining parsing etc
multilingual speaker
description
we are looking for highly motivated engineers to fulfill our data needs and drive the product quality to the next level you will be working closely with a group of talented researchers and engineers on the groundbreaking machine learning technologies your responsibilities include data creation data management processing pipeline and tools development the role also involves the collaborations with other multifunctional teams on data related projects
education
bs or ms in computer science or equivalent experience",,CA,False,data_engineer
Data Engineer (US 0365),"what’s your new role about
we’re hiring a data engineer to join our growing data science and analytics team at opta this engineer will work on a growing multidisciplinary team that is responsible for the development and implementation of advanced sport metrics the analytics team builds data science models logic and metrics based on sport data those data and metrics are then sold through opta’s api and user interfaces to external customers in the media and professional sports
on the job you will have a major influence over the new frameworks and pipelines we are building to productize our models and metrics we are looking for someone who relishes the design process and can work with high autonomy this is an individual contributor role that will have opportunities to work on high impact and new projects
here’s your role broken down not all of it just the most important stuff
projects you will work on
message based near real time data pipelines
distributed message based near real time data pipelines
batch analytics based data pipelines
machine learning model storage serving versioning and monitoring
model feature storage
simple front ends
technologies you will touch
rabbitmq
kafka
exadata
hdfs
spark
redis
python
airflow
during the first month you will
meet the rest of the team and our internal stakeholders
learn about the data science models and logic that have been developed and those currently in development
learn about the current implementations of our models
learn about opta and perform’s current data infrastructure and future plans
begin work on some of our current projects
during the first three months you will
develop a close working relationship with the data scientists and analysts on the team
take ownership over a project that’s in its development phase
set the team’s best practices with regards to data engineering
contribute to an inquisitive respectful and fun work environment
during the first year you will
take at least one project into production
see the outputs of your work being sold in the market
blog or speak about the pipeline you took ownership on
take a mentorship role with the data scientists with regards to data engineering
learn machine learning and statistics concepts to supplement your work
do you have these essentials
3 years of data engineering with major contributions to the projects you work on
experience designing solutions to complex data problems
experience with simple message based systems
experience with batch etl
experience with data warehousing
experience coding in python
an interest in data science and machine learning
it would be great if you had these desirables too
experience with kafka and spark
experience with scala
experience with orchestration frameworks like airflow or luigi
here’s a little more about us
at perform group we like to consider ourselves a progressive dynamic fun and fastpaced global sports media broadcasting company we are passionate about what we do and good at it too we have over 2800 employees with an extensive network of freelance specialists we have a strong team with experts from netflix prime video bbc iplayer youview and now tv we’re growing rapidly and launching into new global markets every year
dazn is our sports streaming service that allows fans to watch their sport their way live or ondemand with access to the world’s best sports fans can watch their favourite teams leagues and players anytime anywhere for one simple affordable price and with no longterm contract dazn has over 8000 live events a year and features the widest array of live sports ever offered on one tv service dazn can play pause and rewind anytime with no commercial interruptions and no longterm commitments
dazn is currently available in canada germany austria switzerland and japan on most connected devices including smart tvs smartphones tablets and games consoles in 2018 we’re soon to be launching in the us and italy
find out more at wwwperformgroupcom and httpmediadazncom

the benefits you will enjoy when you join will include…
25 days’ annual leave increasing by 3 days after 3 years single cover aviva private medical insurance life assurance 4x annual salary matching pension contributions up to 5 travel loan cycle to work scheme and more
and there’s more…… you’ll have access to the performdazn online learning portal mindtools and be part of our career deal which aims to support your continued professional development we also have a structured management development programme and a financially rewarding ‘refer a friend’ scheme if you fancy a move abroad perform are currently seeking the best talent in the world
please note – some of these benefits will be available to you upon successful completion of your probation
apply here",,NY,False,data_engineer
Data Engineer,60000  85000 a yearnew grads welcomewe are looking for a database engineer to join the data engineering team the role will be responsible for designing developing and improving our data technology for our enterpriseclass applications the ideal candidate will have experience with etl process database architecture and a solid understanding of data processing using a combination of python shell scripting and phpin this position youll be responsible forwill be required to write “clean” welldesigned codeability to analyze client feeds for accuracy and standardsidentifies and maintains company databases including data sources data structures data organization and data optimizationtroubleshoot test and maintain the core product software and databases to ensure strong optimization and functionalitycontribute in all phases of the development lifecycle and other various projectsdevelop and deploy new features using agile and similar methodologiesassist in the review of datasystem performance and the development and implementation of improvementssupport production processing by troubleshooting and resolving issues that arise around data processing performance and setupdesign develop and maintain efficient and robust etl workflows which produce data extracts and process feeds between various internal and thirdparty partnersbecome a subject matter expert for the internal etl processesyou might be a good fit if you haveat least 3 years of experience with database design optimization and tuningat least 2 years of experience using githubat least 1 years of experience in continuous integration and development methodologies tools such as jenkins2 years of experience in an agile development environmentknowledge of aws or similar cloud computing platformsbsms degree in computer science mis engineering or a related subject or equivalent experiencedata integration and a good understanding of etl data warehousing and data mart conceptsmust have a solid understanding of relational databases and sqlgit or other version control toolsautomation and continuous integrationcomfortable with shell scripting in a unix environmentbackground in healthcare data is a plusstrong organizational and communication skills both written and verbaljob type fulltimesalary 6000000 to 8500000 yearexperienceusing github 2 years preferredinternship 2 years preferredlocationlyndhurst nj requiredwork authorizationunited states required,72500.0,NJ,False,data_engineer
Data Engineer,contractjob functionsbuild an understanding of data sources and downstream systemsliaise with key stakeholders to understand requirements business definitions and the potential value of different data setssupport design implement and document solutions for loading piping and exposing data from multiple sourcessupport and build wellengineered data systems to support analytical needs using aws assure accuracy of data processing and outputs through consistently high software development skills adherence to best practice thorough testing and peer reviewshabitually approach problem solving with creativity and resourcefulness carefully evaluate risks and determine correct courses of action when completing tasksskillsabilitiesdemonstrable professional experience designing building and maintaining data systems and processes using aws big data platformdemonstrable handson professional data analytics skills using python sql java is a plusexcellent verbal and written communications skills with the ability to clearly present ideas concepts and solutionsdemonstrated willingness and ability to effectively work with various team members when gathering requirements delivering solutions and eliciting suggestions and feedbackextremely quick learner both in terms of new technical skills and acquiring domain knowledgeexperienceexperience working in python development environments for data wrangling and analytics5 years as data engineer or equivalent roleexpertise using cloudbased systems and services to acquire and deliver data via apis and flat filesextensive handson experience working with data using sqlextensive handson experience working with aws s3 redshift glue a pluseducationbachelor’s degree in computer science or closely related disciplinejob type contractexperiencecloudaws 5 years requiredpython 5 years requirededucationbachelors requiredlicensew2 required,,NY,False,data_engineer
Big Data Engineer,"contractour client is seeking a big data engineer for a 3 month contract to hire opportunity in plano tx qualifications
8  years of professional experience
3 years of experience with big data technology and analytics
3 years of experience in etl and elt data modeling
experience working with traditional warehouse and correlation into hive warehouse on big data technologies
experience setting data modeling standards in hive
developing automated methods for ingesting large datasets into an enterprisescale analytical system using scoop spark and kafka
experience with streaming stacks like nifi and pyspark
understanding of big data tools eg nosql db hadoop hbase and api development consumption
proficiency in using query languages such as sql hive
understanding of data preparation and manipulation using datameer tool
knowledge of soa iaas and cloud computing technologies particularly in the aws environment
knowledge of setting standards around data dictionary and tagging data assets within datalake for business consumption
experience in one or more languages eg python or java groovy
experience with data visualization tools like tableau
identifying technical implementation options and issues
partners wand communicates crossfunctionally across the enterprise
ability to explain technical issues to senior leaders in nontechnical and understandable terms
foster the continuous evolution of best practices within the development team to ensure data standardization and consistency
experience in agile software development paradigm eg scrum kanban
strong written and verbal communication",,TX,True,data_engineer
Data Engineer,contractjob summarytitle data engineer location seattle waduration 6 months with possible extension or conversionmust have previous experience in sqletl developmentrequired skills a desire to work in a collaborative intellectually curious environment degree in computer science engineering mathematics or a related field and 2 years industry experience demonstrated ability in data modeling etl development and data warehousing data warehousing experience with oracle redshift teradata etc experience with big data technologies hadoop hive hbase pig spark etcpreferred skills  industry experience as a data engineer or related specialty eg software engineer business intelligence engineer data scientist with a track record of manipulating processing and extracting value from large datasets coding proficiency in at least one modern programming language python ruby java etc experience buildingoperating highly available distributed systems of data extraction ingestion and processing of large data sets experience building data products incrementally and integrating and managing datasets from multiple sources query performance tuning skills using unix profiling tools and sql linuxunix including to process large data sets experience with awsregardssandeeplead recruitment650 249 3775job type contractexperienceetl 3 years requiredhadoop big data hive hbase 2 years requireddata engineering 5 years required,,WA,True,data_engineer
Lead Data Engineer,as a lead data engineer you have a solid understanding of both the business and the technical aspects of bi in relation to digital media business you will drive the completion of projects within the established scope while simultaneously planning for and managing unknown future bi requirements in a dynamic environmentresponsibilities include design model and develop data sets to support reporting and analytics in a cloud environmentetl development perform all aspects of programming assignments and assist with systems designdevelop and maintain a technical metadata framework and repository of data events and etl operationsmanage and administer analytics tools and tag management systemshelp plan and maintain the technical infrastructure its configuration performance and storage requirements with consideration of tiered data and data archivinggenerate adhoc queries and reports based on business requirementsprovide ongoing evaluations of technology solutions and capabilities to ensure alignment with business objectives identify areas of risk while monitoring the current environment and potential improvement areaswork with business stakeholders to gather analyze and translate requirements in bi reporting area – either recommending an existing solution developing a solution or synthesizing delivery requirements to engineering teams for developmentactively question and challenge customers to understand their requirements and reach the best solutions near and long termunderstand and adhere to development and documentation standards database design andstoragesuccessfully implement process improvements impacting own work and work of othersoncall application support is requiredqualities  experience were seeking 5 years of toptier data engineering experience at least 2 years on cloud infrastructureworking knowledge of digital media ecosystem including how digital video streaming ad servers dsps ssps workexperience working in a mix of cloud and enterprise data environments with real world implementation of data collection and processing on aws environmentknowledge of web technologies and online advertising systemsexperience with realtime big data analyticsexperience with hadoop mapreduce spark flink andor other big data processing platformsexcellent knowledge of olap conceptsfamiliarity with columnar databases like redshift vertica etcprogramming language such as java and scripting languages like python ruby and unix shell scriptsexperienced working in a fastpaced hightech environment preferably software development and comfortable navigating conflicting priorities and ambiguous problemsexperience with data visualization tools such as looker tableaugreat communication and collaboration skills across technical and nontechnical stakeholdersa bachelor’s degree in computer science or equivalent preferredjob type fulltimeeducationbachelors preferred,,CA,True,data_engineer
Sr. Hadoop Engineer,senior hadoop engineerarchitectthe position avalon consulting llc is seeking a senior hadoop engineerarchitect to act as a consultant with clients through the design development installation and securing of big data solutions preferred locations include  washington dc dallas austin chicago denver or minneapolis however avalon is open to candidates in all major us cities candidates will travel to various client sites based on needs 50 travel summary description as a senior hadoop engineerarchitect you will solve problems for clients using big data and hadoop ecosystem technologies you will help them select the appropriate hadoop nosql and search components to use design a solution to solve their business and technical problems and then present your solution to the client furthermore the consultant will be responsible for deployment or conversion of the solution with aligned security controlsjob duties perform structured data analytics on hadoop using various methods for sql on hadoop including hive impala and spark sql  experience with other spark components is a plusintegrate hadoop with existing rdbms systems to implement twotiered edw  etl solutions offloading data and processing to achieve the best costbenefit for the overall systemimplement and train machine learning algorithms using big data to help understand and use large datasetsconsult with client to address data governance and security requirementsperform performance tuningperform poc deployments and conversionsinstall technical security controlsselect the right approach of technology depending on data type and latency requirements for batch interactive and streaming data analyticstrain clients in usage and features of big data technologies through inperson training sessions speaking at conferences and blog postsadminister solutions for clientsrequired experience bachelor’s degree in computer science information systems or other related fielda minimum of ten years’ work experience designing developing and deploying application and systems using multiple paradigms and development methodologiesa minimum of three years’ work experience developing systems using hadoop nosql and search technologiesrequired technical skills deep hadoop development and administration experiencedeep java or scala development experienceknowledge of scripting languages python bash ruby perl and at least one sql variantknowledge and use of etl tools and methodsability to install and configure components in the unixlinux environmentexperience following the software development lifecycle preferably agileuse of version control systems such as git or svnbasic comprehension of distributed systems and how they workbasic understanding of networking and data centerspossess a one or more technical certifications such ascertified information systems security professional cisspinternational information systems security certification consortium isc2microsoft certified technology specialist mctswindows 7 administrationhortonworks apache hadoop 20 certified developerhortonworks certified hadoop 2x administratorcloudera certified professional ccpccp data engineercloudera certified associate ccacca spark and hadoop developercca data analystcca administratorcloudera certified administrator ccaknowledge skills and abilities intellectual curiosity and demonstrated critical thinking and creative problem solving abilitytrack record of learning new technologies and methods quicklyability to architect designs and solutions based on client problemsability to program a solution based on provided designability to see proscons for approaches and reason about themproven experience explaining complex topics to others and communicating effectively with clientsability to work independently and as a part of a team of other consultants andor client representativesexperience working in a consultative role with external or internal clientsability to travel up to 50process of candidacy after reading this job description if you believe your skills and experience are a good initial match for this position and our firm we invite you to send your resume using the link belowthe search will be conducted in a thoughtful thorough and consistent manner with a conscious effort to preserve the confidentiality of all candidates the talent acquisition team is committed to offering each potential candidate the same consideration throughout the process there is a strong sense of urgency to fill this vital rolewe offer marketcompetitive compensation performance incentives and a full benefits package that includes health dental vision and life insurance holidays  vacations all inquiries will be kept confidential apply now to explore our opportunitiesjob type fulltimeeducationbachelors preferredlocationwashington dc preferredwork authorizationunited states required,,DC,True,data_engineer
Data Engineer,"contracta cuttingedge telecommunication analytics company in los angeles ca is looking for a senior data engineer aws to join their team for an immediate contract position as a senior data engineer you bring marketing analytics and data technologies together to deliver bestinclass insights
senior data engineer responsibilities
lead adoption of new data technologies by creating easy to use scalable frameworks that address needs of data processing operational team
automate processes by reverse engineering and optimizing data flows and analyst experience
apply data engineering to analytical data pipelines
participate in establishing best practices while team is transitioning to new technologies tools and infrastructure
recommend and implement process improvements
maintain specifications and meta data follow and develop best practices
coach and technically train data analysts
senior data engineer qualifications
strong data management skills accessing and reading raw data files creating data structures data processing merging handling missing values programming and debugging data validation
sound knowledge of relational structured semistructured and unstructured data systems and the experience to know when to use each type of system
experience working with a range of data systems eg spark hive postgres mysql
must have strong sqlsparksql and pythonpyspark programming skills
must have proven experience with python data type projects list tupal dict
must have reporting experience using kpis
experience working in aws is required
strong data management skills accessing and reading raw data files creating data structures data processing merging handling missing values programming and debugging data validation
analytical and bi reporting experience desirable
bachelors degree in computer science mathematics economics or experience in related analytical field
about profiles
an awardwinning marketing and creative technology staffing agency profiles places the highest caliber candidates in fortune 500 companies and successful organizations across the country our experienced recruiters focus on candidates drawn from the top 20 of job seekers nationwide profiles professionals are available for contract contracttohire and direct hire positions headquartered in baltimore md profiles has regional offices in philadelphia richmond and washington dc
have you considered a contract position profiles offers the following benefits competitive salary 401k plan weekly paycheck and bonus pay health vision and dental insurance online software and soft skill training
new job opportunities are listed daily – wwwcareerprofilescom
indml",,CA,True,data_engineer
Lead Data Engineer,"contractlead data engineer
primary location – merrimack new hampshire
vsoft consulting is an endtoend recruiting and staffing solution provider known for our ability to provide highly qualified consultants for any project at any scale
what makes us different our expertise is derived from over 20 years of delivering worldclass it staffing consulting engineering and managed services to fortune 1000 and midmarket companies in the us canada and asia vsoft is a trusted partner with experience across diverse technology stacks to help business get it done
like what you hear apply with vsoft today
vsoft consulting is currently hiring for a lead data engineer for our premier client in merrimack new hampshire this is a 6 month contract position in the financial services industry

what you’ll need
education and experience »
15 years of experience defining data architecture solutions and establishing common data capabilities for enterprises
6 years of experience building distributed solutions in spark mapreduce and other mpp system with associated data models and datastores ie redshift cassandra hbase parquet
2 years of experience working with aws cloud data engineering stack including ec2 s3 emr kinesis glue and other aws services
proven experience creating actionable data and analytics strategies for compliance risk and financial intelligence business functions
solid experience optimizing the hive queries using partitioning and bucketing techniques
handson experience with apache nifi kafka python and spark preferably on aws
experience defining technology blueprints and roadmaps collaboratively defining solutions and enabling architecture capabilities
experience in tool selection conducting rapid pocs and recommending use case appropriate technologies
experience writing high quality code in python and one another oop language java scala c go etc
experience with structuredunstructuredsemistructured data ingestion and processing
experience with automation and deployment jenkins cloudformation chef etc
experience working with rdbm systems particularly familiarity with sql
experience in working with unix shell scripts


what you’ll do
job responsibilities »
design build and implement scalable streaming data pipelines and etl frameworks to increase data access and decrease analysis and decision times across the organization
own software throughout the entire development life cycle – design code test automate and deploy
share ideas to improve our client’s product and processes and provide feedback


interested
qualified candidates should send their resumes to sksinghvsoftconsultingcom
vsoft consulting group is headquartered in louisville ky with strategic locations in india and across the us including madison chicago denver harrisburg and atlanta known as an agile innovative technology services company we were recently rewarded the large business of the year award from louisville business first and were recognized among the top 100 fastest growing staffing companies in north america vsoft has a wide variety of partnerships across diverse technology stacks and holds such titles as mulesoft certified delivery resource oracle gold partner servicenow partner microsoft partner and cisco registered partner amongst many others
for more information or to view all our open jobs please visit wwwvsoftconsultingcom or call 844 4258425",,NH,True,data_engineer
Junior Data Engineer,"
rapp dallas is looking for a junio data engineer



to join our rapidly growing technology team


about rapp

our purpose

we are the agency absolutely utterly fiercely focused on the individual we use our data technology and creative smarts to make meaningful connections with every single person a brand knows

our family

we are part of the das group which is in turn a part of omnicom this group also includes ddb bbdo omd phd and other wellknown acronyms

our home

a hop skip and jump from dfw airport and a quick uber to all the sights sounds bbq and tacos of the dallasfort worth metroplex

our clients

from opening a checking account to buying a sweet new ride to biting into a big mac® we provide smart solutions for companies like toyota mcdonalds txu energy and more

about you

as a junior data engineer you define solutions for the use extraction and manipulation of data  driven by the balanced combination of business needs and consumer preferences you work in close collaboration with multidisciplinary teams to provide the data needed in the optimal format for making critical realtime decision

you can communicate through a project with ease and understanding and you know your tools like the back of your hand

you are experienced with writing complex sql statements and mapping relational database structure you strive in designing  continuously improving data workflows using enterprise campaign management solutions such as adobe campaign unica eloqua marketo andor salesforce marketing cloud
you may have experimented in the past with bi tools such as tableau domo or qlikview and have rpython in your radar

most importantly not only can you do the job you can explain it to a relative and they actually understand you are selfdirected highly motivated and have fun while working hard in a fastpaced environment",,TX,False,data_engineer
Data Engineer,contractdutiesmanage data warehouse plans for a product or a group of productsinterface with product managers analysts and engineers to understand data needsdesign build optimize launch and support new and existing data models and etl processes in productionsupport existing processes running in productiondefine and manage sla for all data sets in allocated areas of ownershipwork with data infrastructure to triage infra issues and drive to resolutionbuild data expertise and own data quality for allocated areas of ownershipskills2 years handson experience in custom etl design implementation and maintenance2 years handson experience in sql or similar languages and development experience in at least one scripting language python preferred2 years’ experience in the data warehouse space with schema design and dimensional data modelingability to write efficient sql statementsexcellent communication skills and proven experience in building datadriven projects from definition through interpretation and executionexperience with large data sets hadoop and data visualization tools such as tableau qlik view etcexperience initiating and driving projects to completion with minimal guidancejob type contract,,CA,False,data_engineer
Data Engineer,about us we are an international company with offices in the uk portugal andus the virtual forge works with organisations to create digital and technology platforms to drive transformation develop capabilities and deliver digital and transactional experiences that buildbusinessaround the worldwe are looking for a talented data engineer to work with us on a dynamic project for one of our international clientsyou will be based on our cool offices in doylestown parole overview we are seeking a data engineer to join our growing team this person will be responsible for working across several data warehousing reporting and data integration projects assisting with the development of data best practices and governance building reporting infrastructure creating adhoc reports and helping to optimize data flow and collectionthe ideal candidate has knowledge of and is excited to learn about all aspects of data from multiple complex sources and domains and who enjoys optimizing data systems and building them from the ground up the data engineer will support our developers database architects data analysts and data scientists and will ensure optimal data delivery architecture is consistently present across projects they will also support nontechnical colleagues in the collection and appropriate use of data they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by datacross systemintegration traditional and nontraditional forms of etlduties and responsibilities data modeling – evaluate structured and unstructured data determine the most appropriate schema for new tables fact tables data marts etcdata integration – incorporate new business and system data into client data warehouses while maintaining enterprise best practices and adhering to data governance standardsetl and reporting – apply business rules to data to migrate from source to target using etl tools or scripting languages validate data to ensure quality collaborate with colleagues across the enterprise to scope requests extract data from various data sources validate results create relevant data visualizations and share withrequester develop dashboards and automate refreshes as appropriategovernance  best practices – adhere and contribute to enterprise data governance standards assemble large complex data sets that meet business requirementskpi development  develop analytics thatutilizedata resources to provide actionable insights operational efficiency and other key business performance metricstechnical support  work with stakeholders including client and internal company teams to assist with datarelated technical issues and support their data infrastructure needsessential skills bachelor’s degree in computer related field23 years of business intelligencedata warehousing experience preferably across multiple domains and indepth in at least 1proficient at integrating predictive and prescriptive models into applications and processesexperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementbuild processes supporting data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsstrong communication and organizational skillsstrong analytic skills related to working with structured and unstructured datasetsrdbms  strong skills in sql andmysql scripting  python proficiencypreferred skills experience with big data and hadoopexposure to streamprocessing systemsexposure to objectorientedobject programming python java etcexposure to visual analytics tools qliksense tableau power bi etcdata science  machine learning experiencefamiliarity withagilemethodology for developmentjob type fulltimeeducationbachelors preferred,,PA,False,data_engineer
Data Engineer - SQL / Big Data / Java,"job description

the opportunity
your consulting projects will include integrating data in a virtual manner for operational andor informational purposes  integration of 100 data sources for a customer service multichannel it infrastructure implementation of logical data warehouses and virtual datamarts to enable modern business intelligence solutions integration layers for hadoopbased data lakes and support for agile operational reporting on a diverse big data infrastructure are just a few flavours of your future projects

be part of an elite team in a rapidly growing international software product company your career with us will combine cutting edge technology exposure to worldwide clients across all industries financial services automotive insurance pharma etc exciting growth path for technical product and customerfacing roles direct mentorship and access to senior management as part of a global team your mission is to help our clients and prospects to realize their full potential through accelerated adoption and productive use of denodos data virtualization capability in many solutions

location new york ny
duties  responsibilities

as a data engineer virtualization fm you will successfully employ a combination of high technical expertise client communication and coordination skills between clients and internal denodo teams to achieve your mission

conception implementation and execution of customerspecific integration projects based on the denodo platform
education coaching and support during the introduction as well as ongoing projects of the denodo platform to achieve high level of client satisfaction
diagnose and resolve clients inquiries related to operating denodo software products in their environment
participate in problem escalation and call prevention projects to help clients and other technical specialists increase their efficiency when using denodo products
contribute to knowledge management activities and promote best practices for project execution
implement product demos and pilots to showcase data virtualization in enterprise scenarios cloud deployments and big data projects
provide timely prioritized and complete customerbased feedback to product management sales support andor development regarding client’s business cases requirements and issues

qualifications

desired skills  experience
experience range 25 years fresh graduates must be topranked and exceptionally qualified
university degree relating to information systems or computer science bachelor or master degree
understanding of data integration flavors
solid understanding of sql and good grasp of relational and analytical database management theory and practice good knowledge of software development and architectural patterns
technical skills include java development jdbc xml web service related apis experience with version control systems eg svn git
basic experience in big data nosql and inmemory environments is welcome
experience in windows  linux and unix operating systems in server environments
personal and relationship qualities professional curiosity and the ability to enable yourself in new technologies and tasks active listener curiosity and continuous learning creativity team worker
communications good writtenverbal communication skills in english other international languages a plus are essential for interaction with clients making presentations attending meetings and writing technical documentation
willingness to travel
additional information

employment practices
we are committed to equal employment opportunity
we respect value and welcome diversity in our workforce
we do not accept resumes from headhunters or suppliers that have not signed a formal fee agreement therefore any resume received from an unapproved supplier will be considered unsolicited and we will not be obligated to pay a referral fee",,NY,False,data_engineer
Data Engineer,"smartasset is a financial technology company that empowers people with automated personalized financial advice its proprietary technology uptotheminute research and automated financial modeling software simulate the impact of different decisions on peoples personal finances enabling millions of people to make smart financial decisions for more information visit wwwsmartassetcom to learn more about smartadvisor visit httpssmartassetcomfinancialadvisor

we are looking for a talented data engineer to join our growing data engineering team and help us design and implement the next version of our integrated data platform we take a wholistic view of the firms data from cloud storage to sales contracts and provide centralized and actionable views to build research monitoring and reporting tools for this youll need to be a tenacious and creative problem solver with the ability to quickly prototype solutions youll also need to be proactive and have a desire to mingle with the product and business facing groups to understand what drives their processes and turn that insight into great tools to help grow the smartasset business

candidates should have


24 years professional development experience with at least 1 year of python
familiarity with etl concepts
working front end knowledge  htmlcssjquery
solid sql skills
good knowledge of pandas and some hands on data experience
knowledge of linux environments  bash ssh crontab etc
working knowledge of statistics
a desire to learn about all facets of the smartasset business

ideal to have


46 years of professional development experience with 12 years data engineering experience
etldata pipelining experience
experience with bi tools  looker tableau etc
full stack experience
mathstats background
experience with aws servicesec2
experience using cloud storage solutions
data science experience

",,NY,False,data_engineer
Data Engineer,"the data intelligence group at balyasny asset management is seeking a data engineer to help build out a data acquisition platform that empowers our product and data science teams to deliver timely and accurate data the data acquired by this platform drives investment decisions across the firm the optimal candidate will have some handson development experience with an excellent technical background the candidate will have a penchant for building maintainable and scalable systems
in the role of data engineer the employee will be responsible for the following
designing building and administering our data acquisition platform to ensure smooth daytoday operation over hundreds of data sets
working directly with product and portfolio managers to understand our customers’ data needs and provide endtoend data solutions that address requirements
investigate data issues working with data providers to ensure seamless interconnection between different data sets
full lifecycle development including requirement architecture implementation testing and release
develop written documentation of infrastructure including processes and procedures
help to develop and test robust business continuitydisaster recovery processes
perform with minimum supervision exercising sound judgment
help identify and automate manual processes


qualifications  requirements

in order to effectively represent the company and communicate with clients the employee must be someone who has
degree in computer science or closely related field or code school graduate
02 years professional development background
experience with python java c or similar language a plus
unix linux and database experience sql mysql postgresql redis
familiarity with object oriented development approach
analytical skills – ability to troubleshoot and logically assess problems and determine solutions
documentation skills – ability to represent ideas requirements and problems in clear and concise documents",,NY,False,data_engineer
Data Engineer,"job description
who we are
hbc is a diversified global retailer focused on driving the performance of high quality stores and their allchannel offerings growing through acquisitions and unlocking the value of real estate holdings
founded in 1670 hbc is the oldest company in north america our portfolio today includes formats ranging from luxury to premium department stores to off price fashion shopping destinations with more than 480 stores and over 66000 employees around the world
our leading banners across north america and europe include hudson’s bay lord  taylor saks fifth avenue saks off 5th galeria kaufhof the largest department store group in germany and belgium’s only department store group galeria inno
we have significant investments in real estate joint ventures hbc has partnered with simon property group inc in the hbc global properties joint venture which owns properties in the united states and germany in canada hbc has partnered with riocan real estate investment trust in the riocanhbc joint venture
a truly global corporate citizen hbc is committed to responsible business practices to bring about positive change and we work hard to shape a sustainable future for people and the planet our philanthropic initiatives help create healthy families strong communities and sport excellence in the cities and countries in which we operate around the world while striving to create innovative programs and resources that provide flexibility for worklife balance in order to maintain a positive working environment

what this position is all about
the data engineer is responsible for database architecture elt process development data management policy development and support and qa activities of data management developments also responsible for coordinating with the various it and functional system owners to design and deliver integrated data management solutions toward operational efficiency and a high data quality standard in the provisioning and distribution of enterprise data

who you are

you get things done by engaging in high level teamwork and flexing your interpersonal skills
you are keenly interested in telling stories and making cases via data analytics trend graphs and metrics
you have a proven ability to multitask in a fast paced environment you have been described by past peers and managers as having “excellent interpersonal verbal and communication skills”

you also have

bachelor of science degree in computer science mathematics or engineering plus 5 years of relevant experience in database development software engineering or related occupation
experience providing management support business intelligence and datawarehouse or datafocused systems integration solutions using proven methodology framework
solid sqlplsql skills and strong understanding of oracle database data structures data quality and cleansing strategies
experience with etl processes and tools
proficiency in metadata management master data management data governance and data solutions management
ability to produce quality technical analysis covering data data mapping and process mapping
demonstrated knowledge in all areas of product development life cycle
broad knowledge of it systems processes and controls
experience with office automation tools including word excel visio

as data engineer you will
build  enhance data models and database architecture for enterprise data model
help define data standards and implement best practices working with the other members of the data management team
evaluate design and develop functional specifications through detailed technical requirements document
evaluate mdm applications developments or models and provide recommendations for improvements
evaluate existing database structures and recommend improvements
build andor maintain elt processes in support of the enterprise model
evaluate and help select various data warehousing tools and components

your life and career at hbc
be part of a worldclass team work with an adventurous spirit think and act like an owneroperator
exposure to rewarding career advancement opportunities from retail to supply chain to digital or corporate
a culture that promotes a healthy fulfilling worklife balance
benefits package for all eligible fulltime employees including medical vision and dental
an amazing employee discount

thank you for your interest with hbc we look forward to reviewing your application

hbc provides equal employment opportunities eeo to all employees and applicants for employment without regard to race color religion sex national origin age disability or genetics in addition to federal law requirements hbc complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities this policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation and training
hbc welcomes all applicants for this position should you be individually selected to participate in an assessment or selection process accommodations are available upon request in relation to the materials or processes to be used",,NY,False,data_engineer
Data Engineer,"code pilot is replacing the crusty old resume with a data science based portfolio for engineers and were looking for a data engineer with data integration expertise and a passion for changing the data landscape if you are interested in working for a data driven company on the edge of industry disruption wed love to talk with you and if we ask you about bulk batch high volume data processing and your eyes light up and your brain goes into overdrive were talking to the right person



we are looking for


a new team member to support the data development  processing for one of our hiring partners


what will keep you challenged



design develop automate monitor and maintain extract transform load etl data movement applications using our preferred etl tools and techniques
performance tune etl applications to manage high volume batch data transfer to and from internal and external system locations
troubleshoot data issues recommend test and implement solutions
develop and document technical requirements and solutions
participate in design and code reviews
troubleshoot issues making recommendations and delivering on those recommendations
engage in project planning and delivering to commitments
participate in daily standup meetings planning meetings and review sessions using scrum  agile methodology
interact with crossfunctional teams to ensure complete delivery of solutions
assist with configuration of applications software


which traits contribute to your success



passion  for software development algorithms design patterns clean code agile processes data structures
humility  outstanding engineers display inverse proportions of talent to humility
mission oriented  a dogged commitment to getting the job done is crucial
highly competent  software engineering at the top level requires highly motivated individuals who are constantly learning and adapting
highly adaptive  mike tyson said it best everyone has a plan till they get punched in the mouth developing software at the top level requires incredibly adaptability and agility nothing ever goes the way you want and anything valuable probably doesnt exist the way you want it
ship or quit  high performance software teams have one unifying quality they ship a lot so if youre a fellow ship talker youll love it here



some technologies you will be working with



etl tools ie ab initio pentaho talend ssis
programming languages java groovy javascript sql or plsql
sql and relational platforms postgresql oracle
revision control eg subversion
nosql databases cassandra


why code pilot


code pilot is a new startup and relatively unheard of were currently 4 people all cofounders based in austin tx given the rigor and process we adopt to hire engineers you might be asking yourself why invest your time and effort to simply apply

were hoping if youve reached this part of the posting youve already noticed the care and attention weve invested in how we hire engineers were not interested in the instant gratification someone can provide by being able to code and frankly as an engineer who is passionate about the craft you shouldnt be either were passionate about the discipline of engineering and what it takes to develop world class engineers to that end we dont care if youve got 1 year or 20 years experience we dont care if you went to mit or are selftaught hell we dont care if your favorite programming language is ruby although we will help you forget everything you know about it pretty quickly what we care about is your insatiable desire to be pressure tested in a credible engineering environment that brings out your best",,NY,False,data_engineer
Data Architect,data engineerjob location ustxarlingtonduration permanentoverviewwe are expanding our efforts into complementary data technologies for decision support in areas of ingesting and processing large data sets including data commonly referred to as semistructured or unstructured data our interests are in enabling data science and search based applications on large and low latent data sets in both a batch and streaming context for processing to that end this role will engage with team counterparts in exploring and deploying technologies for creating data sets using a combination of batch and streaming transformation processes these data sets support both offline and inline machine learning training and model execution other data sets support search engine based analytics exploration and deployment of technologies activities include identifying opportunities that impact business strategy collaborating on the selection of data solutions software and contributing to the identification of hardware requirements based on business requirements responsibility also includes coding testing and documentation of new or modified scalable analytic data systems including automation for deployment and monitoring this role participates along with team counterparts to develop solutions in an endtoend framework on a group of core data technologiesresponsibilitiesjob dutiescontribute to the evaluation research experimentation efforts with batch and streaming data engineering technologies in a lab to keep pace with industry innovationwork with data engineering related groups to inform on and showcase capabilities of emerging technologies and to enable the adoption of these new technologies and associated techniquescontribute to the definition and refinement of processes and procedures for the data engineering practicework closely with data scientists data architects etl developers other it counterparts and business partners to identify capture collect and format data from the external sources internal systems and the data warehouse to extract features of interestcode test deploy monitor document and troubleshoot data engineering processing and associated automationqualificationsknowledge2 years of handson experience with sql data modeling and relational databases such as oracle db2 and postgres1 years of experience with software engineering to include java scala and pythonexperience with processing large data sets with kafka rabbitmq flume hadoop hbase cassandra andor spark or similar distributed systemexperience with nosql data stores such as mongodb cassandra hbase redis riak or other technologies that embed nosql with search such as marklogic or lily enterprisebachelors or higher degree in computer science or other quantitative discipline or equivalent work experienceexperience or familiarity with etl and business intelligence technologies such as informatica datastage ab initio cognos businessobjects or oracle business intelligenceskillsability to quickly prototype and perform critical analysis and use creative approaches for solving complex problemsexcellent written and verbal communication skillsjob type fulltimeexperienceit 5 years requiredsolr 1 year preferredhbase 2 years requiredspark 2 years required,,TX,True,data_engineer
Data Engineer,you get a kick when mining through heaps of data and understand the underlying technologies of working with bigdata your primary responsibility will be to assimilate data from various sources across the stack and build a system from groundup so that it is easy to query and visualize key business metrics you should be proficient in a few of these or similar technologies mongodbsql hadoop mapreduce redshift python r,,WA,False,data_engineer
BI Data Engineer,"come join workfront one of the hottest companies in cloud computing as recognized by forbes magazine located in the heart of silicon slopes workfront is the leader in enterprise work and project management meeting our mission to become the authoritative source for work hundreds of thousands of enterprise users leverage workfronts saas solution to make their work faster and more efficient taking projects to a higher level

as part of the analyticsbi team the data engineer helps leaders and analysts throughout the organization get the data they need to further accelerate our growth the team helps the business define analytics needs and translates that into actionable data models that are both robust and easy for business users to understand this position will work closely with business groups to understand and solve problems and questions that will help them understand our business and contribute to a data driven culture our data engineers build clean and easy to understand data models that the rest of the business can use to provide insights

job responsibilities


work with business stakeholders to understand analytics needs and architect solid data models which will provide the insights they need
improve overall robustness and efficiency of existing data marts
design and build robust data models in redshift which combine multiple data sources
build data models that are easy to use and understand by business stakeholders
clearly document and demonstrate the functionality and power of data models to the business
provide accurate and actionable data to the organization

experience


expert sql programmer
at least 4  5 years designing and building actionable data models for use in business intelligence tools
strong understanding of star schema and kimball methodology
experience building slowly changing dimensions
working knowledge of code repositories preferrably git
transforming data to meet business needs
exposure to tableau power bi clik quicksight or other bi tools
strong experience working with multiple business groups to meet their analytics needs
experience validating and performing quality assurance on data as it flows from the sources to data models and visualizations

bonus skills


experience with aws redshift vertica greenplum netezza or other mpp databases
past experience building sales funnel and marketing attribution data models
understanding of salesforce marketo netsuite and other enterprise systems

",,UT,False,data_engineer
Big Data Engineer,contractexcellent opportunity with established retail domain clientlocation sunnyvalemy direct client is looking for a data engineerskillssql etl teradata spark hadoop3 or more years of progressively complex related experiencehas strong knowledge of large scale search applications and building high volume data pipelinesexperience building data transformation and processing solutionsknowledge in hadoop architecture hdfs commands and experience designing  optimizing queries against data in the hdfs environmentinterested candidates please submit resume through indeedbhavya ll technical recruiter ll flextonjob types fulltime contract,,CA,False,data_engineer
Data Engineer,the data engineer is responsible for defining implementing configuring and maintaining the tools and systems deployed to continuously monitor and gather data on the performance and availability of highlydemanding voip and unified communications systems and applications that continuant manages for its customersjob duties setup and configure monitoring systems to ensure continuous monitoring of critical aspects and parameters of the managed uc equipmentpropose evaluate and participate in selection of new monitoring tools and products to be deployed in the customer’s environmentdevelop extended monitoring functionality such as custom tests and scripts targeted to specific attributes of unified communications equipmentperform manual data gathering and extraction from multiple raw data and sql repositories automate the data extraction process where possibleload data in continuant’s central data repositoryperform systems administration and maintenance on existing monitoring tools and systemsrequirements linux systems administrationknowledge of snmpscripting and programing in bash andor pythonsql knowledge will be considered an advantageknowledge of or experience with any voipuc system by the following manufacturers will be considered a strong advantage cisco microsoft lyncskype for business avaya siemens nortelitil knowledge or experience will be considered an advantageat least 2 years’ experience in it systems monitoringevent management or related positionbachelor’s degree in computer science or related field or equivalent experiencebenefits medical dental and vision insurancewellness reimbursementmatching 401k programpaid time offtraining creditonsite gym and massageready to meet us send your resume to our talent team using the apply linklearn more at wwwcontinuantcomcontinuant takes pride in having a dynamic diverse workforce we are an equal opportunity employer drug test and criminal background check are required at the time of employmentcontinuant is a drug free work environment any candidate that tests positive for marijuana or any controlled substance andor alcohol during a preemployment drugalcohol screening will not be eligible for hirejob type fulltimelocationtacoma wa preferredwork authorizationunited states required,,WA,False,data_engineer
Data Engineer - Business Intelligence,"about convene

at convene were changing the way the world works by transforming the way businesses work by partnering with the largest landlords in commercial real estate we design and service the next generation office building – one that feels more like a fullservice lifestyle hotel our integrated workplaceasaservice platform gives building tenants and enterprise clients access to a growing network of premium meeting and event spaces flexible workspaces hospitality services and curated experiences for users all connected by convenes proprietary technology platform


founded in 2009
locations in new york city boston philadelphia and washington dc opening in la in 2018 and plans to expand globally
launched convene workplace in 2017
ranked 11 workplace in new york in 2017 by fortune magazine
ranked 30 in 2017 linkedin annual list of industry disruptors

about the role

we are looking for a data engineer to join the convene team where you will apply your enthusiasm in working with data along with your curiosity and ingenuity to develop a data infrastructure and solutions that will enable convene to transform the workplace as a part of the core teams early formation you will be at the center of creating the data platform and tools that will fuel the datadriven products and features built by developers and that will power the solutions that enable analytic and business teams to answer questions and gain insights that inform new strategies you will be in a pivotal role creating the foundation for a robust reliable and efficient data architecture that scales with convenes continued growth

about you


care deeply about transforming data into business value with speed while also establishing high data quality and scalability
analyticminded self starter with an eye for detail and resourcefulness to create new innovative data solutions services and reusable components
collaborative adaptive and comfortable owning and driving ambiguous projects to successful completion
8 years of handson data engineering experience in
data modeling and database design building flexible schemas analytic data models and warehouses
working with relational databases column stores nosql databases experience with aws services strongly preferred s3 redshift
coding in python java and writing complex sql
developing and maintaining scalable data pipelines ingesting data from a variety of source systems including crm erp and others
consuming and writing apis
workflow management preferably knowledgeable using a platform such as airflow
profiling and analysis of source system and ingested data
leveraging and modifying open source libraries to build custom frameworks
establishing data governance and management practices
familiarity with bi tools including looker and tableau multiple analytic disciplines and also machine learning techniques
able to communicate clearly with technical and business audiences at executive and team levels
you have fun while you work and are a pleasure to work with
you inspire others and want to be inspired by being a part of the ground level of a rapidly growing and successful company

what youll do


build our data infrastructure including ingest data from a variety of internal and external sources into a data lake and build a data warehouse flexible data models and other reusable data solution components to be leveraged by product analytic teams and for advanced analytic models
work with internal subject matter experts product and development teams to understand business data objectives and design and implement scalable data pipelines and eltetl frameworks to increase data access and decrease analysis and decision times
own data quality throughout data life cycles including acquisition cleaning processing and validation providing requirements feedback for identified data variability and gaps
share ideas to improve data solutions and processes make decisions that have a significant impact and provide recommendations that continually enhance data solutions for increasingly complex product and analytic solutions
explore new technologies and have fun applying new tools and better ways to turn data into products intelligence and advanced analytic solutions

",,NY,False,data_engineer
Data Engineer - Breast Imaging Research Center,"the senior software engineer data engineer will be part of a dynamic multidisciplinary competitive and collaborative team with motivation and purpose to create tools to leverage the latest advances in data science machine learning and deep learning to impact healthcare across a spectrum of focus areas including medical imaging diagnostics clinical informatics and population health to this end there is a wealth of raw medical record data that includes over 6 petabytes of data that can be mined in the pursuit of building ai models

the incumbent will successfully demonstrate the ability to work independently as necessary identify solutions where impediments have previously existed and bring an energy drive and determination to pull the team on a forward trajectory and deliver technological advancements to usher next generation imaging diagnostics into the forefront

principal duties and responsibilities

relevant activities include but are not limited to the following
· write clean maintainable performance code ensuring data is flowing smoothly between source and destination
· transform normalize and merging multiple sources of data in both batch and streaming environments with a solid level of comfort
· build pipelines that feed data scientists with data develop and manage extraction tools wrap the data send it forward in the data pipeline correct transform and enrich the data quickly and efficiently load bulk data
· work tightly with the broader date science and software team to identify optimum pathway to a successful product
· take responsibility for strengthening the team by facilitating the adoption of processes that will allow us to work faster and hire exceptional teammates
· use the mgh and radiology values to govern decisions actions and behaviors these values guide how we get our work done patients affordability accountability  service commitment decisiveness innovation  thoughtful risk and how we treat one another diversity  inclusion integrity  respect learning continuous improvement  personal growth teamwork  collaboration



skills  competencies required

· strong sense of urgency and proactiveness
· ability to function effectively and independently in a fastpaced environment organize and prioritize work independently and meet tight deadlines
· selfmotivated with an entrepreneurial mindset and ability to learn quickly
· strong analytical planning organization and time management skills with a strong attention to detail
· excellent interpersonal skills to effectively communicate with technical teams crossfunctional teams and staff at all levels of the organization including both technical and nontechnical personnel
· ability to successfully negotiate and collaborate with others of different skill sets backgrounds and levels within and external to the organization
· ability to effectively conduct meetings and lead and facilitate large working sessions with all levels of staff and across various stakeholder groups
· demonstrates strong evidence of algorithmic and structured thinking with an intuition for logic pattern matching whatif analysis problem decomposition and synthesis
· demonstrated ability to organize and incorporate complex systems requirements into product features and prioritize features effectively


working conditions
· working with our team on site as well as traveling to meet collaborators at multiple sites in the local boston area
· occasional travel 1 monthyear to professional seminars and conferences


qualifications
bachelor’s degree or equivalent combination of education and demonstrated frontend experience required computer science engineering or equivalent undergraduate and graduate degrees are preferred though not strictly required necessary

experience

required
· a minimum experience of 3 years in data engineering
· clear demonstrable evidence of exceptional productivity and performance in competitive environments

preferred
· familiarity with linux ubuntu system administration docker vmware nfs mounts and large scale data management strongly preferred
· familiarity with dicom  dicom web strongly preferred
· expert knowledge of python and git expert knowledge of database software sql  variants are strongly preferred
· familiarity with flask micro service with containers and net are strong pluses
· familiarity with common tools for machine learning ie tensorflow pytorch and sklearn and general scientific computing are pluses
· knowledge of software team management philosophies eg agile scrum and various product managementsoftware development tools are pluses
· experience with software development for healthcare products as well as familiarity with common clinical scenarios regulatory and quality standards payer and provider considerations are beneficial but not necessary
 eeo statement
massachusetts general hospital is an equal opportunity employer by embracing diverse skills perspectives and ideas we choose to lead applications from protected veterans and individuals with disabilities are strongly encouraged

primary location
 maboston175 cambridge  mgh
work locations

175 cambridge  mgh
175 cambridge street
 boston 02114
job
 ithealth itinformaticsengineer
organization
 massachusetts general hospitalmgh
schedule
 fulltime
standard hours  40
shift
 day job
employee status
 regular
recruiting department  mgh radiology research
job posting
 oct 16 2018",,MA,False,data_engineer
Data Engineer,"fusion is currently seeking a midlevel data engineer to join our fastgrowing software development team the data engineering team is responsible for developing and maintaining the data processes for our clients tasks will include import and export of data data migration from legacy systems interface development reporting development as well as maintenance and support for all our existing data projects

about us

fusion was founded in 2006 and has since become a major disruptor in the corrections and public health sectors of government recognized by inc magazine as one of the fastest growing private companies in the united states fusion is looking to expand its handpicked team to include a candidate through this job placement

from a company culture perspective we are a vibrant and young group who have come together to be leaders in healthcare it and software for government agencies the office provides open working spaces several meeting areas as well as a café  gym on premise

because of the niche fusion belongs in as well as the business model we operate with we are looking for not only skilled and qualified candidates but also candidates who have an outgoing personality and fit well with our other team members

to date fusion has a phenomenal retention of our team members our fundamental belief is that employee satisfaction is critical to achieving our mission so we provide competitive compensation professional development career advancement opportunities and a supportive teambased atmosphere we also provide a full range of health related benefits including medical dental vision and 401k and we offer worklife enhancements like flexible hours business casual dress code and an easygoing corporate structure

fusion has been recognized by inc 5000 list of fastestgrowing private companies – thanks to the tireless efforts of our team if you are a talented professional and our mission speaks to you please speak to us

job roles

communicate with partner companies to develop and support bidirection data communication
migrate data for new clients from old systems to new systems
create meaningful insight with data to help our customers meet compliance standard
develop reports to allow customers to view their data in the format they request
meet with government clients to understand their environment and work with project managers to determine the optimal solution for their needs
work with project managers to create and execute a technical implementation plan for larger client roll outs
work closely with product management to understand current and new product features so they may be implemented correctly


required experience

javascript
sql plus if it is sql server
crystal reports or any comparable reporting tool
c
windows network experience
familiarity with most common structured or delimited file formats csv xml json etc
familiarity with data transfer methods sftp http tcp soap rest etc
qualifications

3 years of professional software development experience
bachelor’s degree in computer science or any itrelated field
working hours

standard hours for this role are mf start between 8 and 9 expected to put in 8 hours
willingness to provide weekly oncall coverage rotationally
additional notes

it is not expected that applicants have any familiarity with fusion’s proprietary applications ge healthcare software or correctionspublic health business processes qualified candidates will be able to demonstrate experience in this role as well a demonstration of working well with the fusion team
this is an onsite fulltime salaried position",,NJ,False,data_engineer
Data Engineer,115000  170000 a yearjob summary this opportunity is within the data engineering group working with technology platforms and datasets that enable systems and people to uncover new insights and finetune operations to meet business goals they need your help with designing and building thesekey responsibilitiesapply broad knowledge of technology options technology platforms design techniques and approaches across the data engineering ecosystem to design systems that meet business needsplay a leading role in building systems and datasets using software engineering best practices data management fundamentals data storage principles recent advances in distributed systems and operational excellence best practicesanalyze source systems define underlying data sources and transformation requirements design suitable data models and document the designspecificationsdemonstrate passion for quality and productivity by use of efficient development techniques standards and guidelineseffectively communicate with various teams and stakeholders escalate technical and managerial issues at the right time and resolve conflictspeer review work actively mentor more junior members of the team improving their skills their knowledge of our systems and their ability to get things donebasic qualificationsa bachelors degree or higher in computer science with industry experience8 years of building large scale dataprocessing systems with 4 years in big data technologies such as mapreduce hadoop spark kafka or aws equivalentsexpertise in database technologies such as aws redshift with proficiency in sqlexperience designing and coding in python on linux platformshands on experience in data warehouse dwh environment with data integrationetl of large and complex data setsdata modeling skills such as star snowflake schema design for dwhexpertise in performance tuning and scalingfamiliarity with business intelligence bi and visualization platforms such as microstrategy and aws quicksightpreferred qualificationsextensive knowledge of bi and visualization platforms such as microstrategy and aws quicksightexperience with aws cloud technologies such as elastic map reduce emr kinesis athenaexperience working with agile methodologies in a dwh bi environmentabout the company our client is a seller and producer of spoken audio entertainment information and educational programming on the internet they are looking for creative developers and engineers to help build technologies that continuously improve the listening experience teams at the company have the freedom to utilize the technologies that best suit their needs whether those are open source internal or third party teams are empowered to make their own decisions about what works best for them our client also encourages the use of open source software and contributions back to projects join us in helping to bring inspiration and entertainment to our growing base of global listenerssalary and benefits salary range 115k  170k a yearmedical benefits starting day 1 401k match disability  fsa23 days of pto  9 paid holidaystuition reimbursementfree catered lunchfree parkingparental leave160mo stipend for public transportation500mo stipend to put towards rentmortgage if residence is in newarkrelocation is available – depending on the level the candidate is hired for depends on the amount of relo available there are lump sum and assisted move options available it starts at 10000 for lump sumwork life balance what does that mean to youflexibility – work from home appointments etccasual  friendly environmentcan arrive as early as you’d like or come in as late as 930 just get permission from manager – the earlier employees come in earlier they can leavejob type fulltimesalary 11500000 to 17000000 yearexperiencebuilding large scale dataprocessing systems 8 years requiredpython on linux platforms 2 years requireddata warehouse dwh environment 2 years requireddata modeling skills such as star or snowflake schema 1 year requiredaws redshift 2 years requiredbig data technologies 4 years requirededucationbachelors required,142500.0,NJ,False,data_engineer
"Data Engineer, Hockey Operations - Boston Bruins (Full Time)","position details
the boston bruins hockey operations department is accepting applications for an experienced data engineer this position reports to our director of hockey analytics and will assist in the development of our database systems and infrastructure as well as the creation and maintenance of our data processing pipelines
responsibilities
build automated pipelines for acquiring processing and cleaning data from different sources and providers manage data flow into centralized databases
conduct database feature engineering to support departmental research
prepare clean and format analytical datasets for processing by analysts
develop processes for monitoring and testing data quality across multiple sources diagnose and resolve data quality issues to ensure accuracy
use and create tools for data manipulation visualization reporting
define storage security and backup procedures serve as main resource for departmental support and data maintenance
take ownership of database structure  manage with longterm stability in mind while delivering shortterm results
interface with analytics and other hockey operations staff and execute exploratory research and analysis as needed
qualifications
bachelor’s degree in computer science data science engineering it or related field
preferred postgraduate education or 24 years related work experience
3 years of experience developing in sql or aws redshift
2 years of experience with data profiling modeling and data pipeline development
2 years of experience developing in python r or similar language
familiarity with apis and machine learning a plus
experience manipulating large and complex data sets
excellent written and verbal communication ability – desire to be part of a group and to put the needs of the team first
problemsolving skills – must be able to assess tasks and react to requests independently if necessary
ability to take initiative work in a fastpaced environment and consistently meet deadlines
a knowledge and passion for working in sport hockey knowledge is a plus but candidates should have an understanding of typical data structures and research areas in sport
more information
to be considered for this role please submit responses to the below questions you may attach your answers as a cover letter to your application
how did you hear about this job
describe your experience writing in sql including years experience
describe your experience writing in r or a similar language what packages do you use the most
describe your experience developing data pipelines
describe briefly what steps you would take to identify data biases or inconsistencies in a new or unfamiliar data set
have you ever worked with data sets from hockey or another sport before if so please describe the data and how it was used
tell us why you love sports and want to be part of a team environment",,MA,False,data_engineer
Senior Data Engineer,"shutterfly is seeking an experienced senior data engineer with software engineering skills to join the data warehouse development team you will own manage and drive endtoend solutions and data infrastructure you will work with analytics and business partners to deliver data solutions in support of insights and analysis of a multimillion customer ecommerce business with both internal and external data if you like applying your expertise with datawarehousing technical concepts cs fundamentals and data and system architecture to multiterabyte multisource data come join the shutterfly data warehouse development team


responsibilities
build data expertise and own data quality for the pipelines you build
architect build and launch new data models and data marts that provide intuitive analytics to your customers
design build and launch extremely efficient  reliable data pipelines to move data both large and small amounts into and out of the shutterfly data warehouse
design and develop new systems and tools to enable folks to consume and understand data faster
use your coding skills across a number of languages including python and java
have a clear understanding of the reportsanalysesinsights to be driven by data and build data solutions to optimally support the analytics needs
integrate third party data to enrich our data environment and enable new analytic perspectives
become fully immersed in the context of business development and partner business initiatives
work across multiple teams in high visibility roles and own solutions endtoend
work with program managers business partners and other engineers to develop and prioritize project plans
qualifications
5 years of experience with implementing big data business solutions at productions scale
expert knowledge of sql
history of building maintaining and automating reliable and efficient etl elt jobs
strong cs fundamentals and experience developing with objectoriented programming java python
expertise with dimensional warehouse data models star snowflake schemas
experience with cloud data warehouses like google bigquery and amazon redshift is preferred
experience with multiterabyte mpp relational databases such as teradata and concepts
understanding of hadoop or spark including manipulating data with with pig hive and potentially with java or python
understanding of streaming technologies and concepts used with data warehouses is preferred
understanding of automation and orchestration platforms such as automic formerly uc4 and airflow",,CA,True,data_engineer
Senior Big Data Engineer,contractfull benefits – medical dental vision 401k and moreare you a senior java engineer with strong data experience including expertise in big data technologies like hdfs pig hive oozie hbase and spark have you worked with realtime data pipelines using technologies such as kafka and stormhighlight group seeks a senior data engineer to join our team in supporting a fortune 50 global leader in digital and mobile on a fulltime contract basisthe ideal candidate will have 5 years’ of software development experience with a focus on java big data and realtime data pipelinesduties and responsibilities work on development initiatives as part of the clients growth marketing team in an agile environmentclosely interact with our stakeholders product ownersmanagers business analysts others for clarity on sprint items and for verification of developed solutionsparticipate in team activities such as sprint grooming sessions project or product discussions brown bagsfollow appropriate coding standards and best practices as applicable document your work wellparticipate in code reviews for your peers collaborate with your peers for finding solutions to complex problems share knowledge with your peers and also learn from them as requiredwork on operational and production support for the applications we build and maintainwork towards quarterly team and organizational goals that should be result oriented and measurablequalifications 5 years of overall experience in software developmentstrong demonstrable experience working on realtime data pipelines using technologies such as kafka and stormstrong data engineering experience with demonstrable skills building data pipelines from structured and semistructured data sources data cleansing formatting and storing data into reporting tablesstrong scripting experience using pythonperlshellstrong programming experience with javastrong experience with relational database systems such as oracle mysqlstrong experience working on bi tools such as tableau microstrategy looker etcpreferred qualificationsexperience with big data technologies  hdfs pig hive oozie hbase spark etcexperience working with restful apijob type fulltimeexperiencesoftware development 5 years requiredrelational database 3 years requiredstorm 3 years requiredkafka 3 years requiredscripting python perl shell 3 years requiredjava 5 years requiredbig data 5 years requiredspark 3 years requiredlocationbay area ca requiredwork authorizationunited states required,,CA,True,data_engineer
Data Engineer - highly sophisticated cloud analytics platfor...,"130000  150000 a yeardata engineer  highly sophisticated cloud analytics platform

data engineer for a small team that develops a highly sophisticated cloud based analytics platform that helps their customers big and small make critical investment decisions lots of new development and a great opportunity for the data engineer to impact design and selection of technology as the new data platform continues to expand

looking for an experienced data engineer with a production development background in both linux and windows enterprise environments strong relational database management systems experience mysql ms sql oracle and nosql databases and tools cassandra elasticsearch hadoop hbase mongo redis etc strong coding in chops in either python java or scala is required interest in financial data andor machine learning is a plus

great opportunity for a midlevel data engineer or senior data engineer looking to take on a technical leadership role as this highly impactful team continues to grow

located in boston base salary is highly competitive and compensation will also include strong bonus and equity

for more info contact bivium founder jamie leblanc  jamiebiviumgroupcom


the bivium group is a leading recruitment firm in boston that specializes exclusively in the software engineering market in boston  for the past 16 years

bivium founder jamie leblanc has a degree in mechanical engineering and has been a key member of several startups  a technical software recruiter who understands software and the technologies used to build it jamie is a top ranked technical recruiter in boston with 80 written recommendations on linkedin that has been expertly recruiting and placing software engineers for nearly 20 years

visit our website to view more of bostons best software engineer jobs here
you can also signup for our job alert email to be automatically notified of any new jobs meeting your criteria here

computer science data engineering mathematics data structures big data aws etl data transformation data platform hadoop cloudera mapr emr python scala java boston software jobs jamie leblanc bivium jamiejobs",140000.0,MA,True,data_engineer
Data Engineer,"data engineer job description
responsibilities for data engineer
create and maintain optimal data pipeline architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and aws ‘big data’ technologies
build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics
work with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
qualifications for data engineer
advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
s3 redshift etl tools knowledge is required
experience building and optimizing ‘big data’ data pipelines architectures and data sets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
strong analytic skills related to working with unstructured datasets
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores
we are looking for a candidate with experience in a data engineer role who has attained a graduate degree in computer science statistics informatics information systems or another quantitative field they should also have experience using the following softwaretools
experience with aws cloud services ec2 emr rds redshift",,NY,False,data_engineer
Data Engineer,quest analytics is a missiondriven healthcare data company trusted by the nations largest health plans and over 500000 doctors we are dedicated to providing consumers with convenient access to an adequate network of doctors and hospitals and an uptodate accurate directory of providers our culture is collaborative pragmatic and fastpacedwere looking for talented entrepreneurially minded and datadriven people who also have a passion for helping people  and having a ton of fun while theyre at itjoin us to revolutionize healthcare dataabout the role are you looking for a data role where you can have a high degree of freedom a huge impact on a product’s future and work with an amazing team we may have the right opportunity for youwe’re searching for a passionate data quality engineer  someone who lives and breaths data desires and produces highquality data sets we want someone who makes datadriven decisions and loves running experiments to deliver value to our customersyour responsibilities we are building a data operations team to tackle betterdoctor’s diverse data challenges you will analyze and optimize data in our data pipeline which intakes validates and distributes provider data to our clients you will provide data to both our data scientists and product teams refining and improving our data qualitysome projects you will work on anomaly detection in data sources by identifying the root causes of data integrity issues and creating corrective processes and systems to prevent reoccurrenceparticipate in our data release process and partner with teams to iterate on and improve existing data pipelinelead definition for data quality and build a reliable audit process that ensures and improves public facing data qualitydevelop specifications for data integrity checks that need to be enforced across the data pipelinework with the data science team to convert specifications into an automated processwhat we expect from you bachelor’s degree or higher in computer science or a related field3 years of experience in a relevant industryexperience writing and executing complex sql queriesexperience managing and optimizing sql databasesexperience with development in one or more of the following python r scala sqlexperience with data processing frameworks and data warehouses such as hadoop spark redshiftbonus points for experience working with healthcare dataexperience with looker tableau and other bi toolsexperience with databricks analysis platformexperience with building and operating data pipelinesexperience with machine learningjob type fulltimeexperiencesoftware development 2 years preferredwork authorizationunited states preferred,,CA,False,data_engineer
Data Engineer - Lending,"job description
the data engineer de will be a key member of the technical team at amazon lending contributing to a new and rapidly growing line of business for amazon this person will take the lead on optimizing our data architecture for the heavy analytics needed for this business
the role presents a significant intellectual and technical challenge with enormous opportunity for business impact amazon is expanding into lending services and has launched with the small business segment we believe we are in a unique position to serve our customers with exceptional value due to our deep understanding and insight into our base coupled with our datagrounded analytic and customerfocused approach to building products

we are looking for a talented and passionate data professional that can design a highquality and scalable analytic infrastructure that can automate our decisionmaking processes a successful candidate will be innovative technically versatile and be able to interact with customers to gather requirements and deliver the right set of data to support business growth

the key strategic objectives for this role include
a innovating to deliver missioncritical near realtime data feeds to optimize the business
b delivering a robust flexible and scalable data analytics environment to support amazon lending as it grows deeper in its existing lines of business and expands to new geographies customer segments and products
c collaborate with technical teams legal finance operations and product managers to drive process improvement and track progress against goals
basic qualifications
we are looking for data engineers who have a passion for supplying their clients with meaningful and trustworthy data you know and love working with analytic tools can write excellent sql and unix scripts can partner with customers to answer key business questions and you are an advocate for your customers you are analytical and creative and you don’t quit

you should also have the following skills or experiences
bachelors degree in cs or related technical field
5 years experience in data warehousing
strong data modeling and sql skills
excellent troubleshooting and problem solving skills
passion for learning and using new technologies
effective communication and strong collaboration skills
preferred qualifications
experience partnering with business owners directly to understand their requirements and provide data which can help them observe patterns and spot anomalies
proficient in big data processing eg hive scala
expertise in mpp and nosql persistent storage solutions
experience integrating with 3rd party data providers",,WA,False,data_engineer
Data Engineer - University Students,"qualifications
university student in their final year in a computer science engineering or equivalent program expected graduation date of december 2018 or may 2019
or currently completing your first year in a nonbusiness 2year masters program and have less than 2 years of work experience
experience in multiple database technologies such as distributed processing spark hadoop emr traditional rdbms ms sql server oracle mysql postgresql mpp aws redshift teradata nosql mongodb dynamodb cassandra neo4j titan
ability to structure and analyze data in appropriate framework eg excel access vba sql
passion for data tools and processes to drive business insights
strong analytical thinking process management and quality control
ability to quickly understand and appreciate underlying business context problems and objectives of analytical projects
clear communication skills to run well defined analyses and produce reports
excellent time management skills
who youll work with
you’ll work with a technology team in one of our north american offices to conduct full life cycle analysis of data sets including implementing data acquisition cleansing transformation and upload activities
you will work closely with data science product management product design and scrum master team members data engineers are staffed on engagements or product teams and are expected to leverage expertise to solve some of the most pressing and complex issues at clients
please review the team options and locations below to clarify your application preferences
mckinsey analytics geospatial  waltham healthcare analytics  delivery new york waltham ingenuity new york waltham pharma and medical products new york public and social sector new york waltham washington dc you will apply an analytical entrepreneurial mindset to foster innovation driven by analytics design thinking mobile and social by developing new productsservices and integrating them into our client work
digital mckinsey new york city you will work across industries and functions on projects spanning from it modernization and strategy to agile cloud cybersecurity and digital transformation
what youll do
you will provide analysis analytical modeling andor visualization of data sets using relevant data tools
in this role youll identify possible trends and patterns in the data and communicate relevant findings that help support problem solving insight generation and decision making youll apply your understanding of client data sets and intended use to effectively capture validate cleanse transform and upload data youll perform quality checks to ensure consistency integrity and robustness of data youll proactively identify potential issues eg inconsistencies with data quality collection or reporting youll support solution delivery team often remotely in managing client data
youll leverage standard reporting to clearly articulate findings to solution delivery team or client team you will be responsible for coding and scripting sql for automating data transformation and loading specified by delivery team you will perform impactful data enrichment based on understanding of the sectorindustry and types of data that are available in the space",,NY,False,data_engineer
Data Engineer,a data engineer opportunity is currently available at the lebermuth company lebermuth specializes in essential oils for fragrance and flavor applications our business segments include resale of purchased raw materials and the development and sale of manufactured fragrance and flavor blends we’re seeking an experienced person who can support our continued growththe data engineer contributes to lebermuth strategic initiatives and operational efficiency by transforming data from internal and external sources into information critical to business decisionsresponsibilitiesexperience in at least two of these databases sql nosql db2 and big datalead data modeling data architecture and data governance projectslead data migration integration and consolidation activitiesprovide graphical representations of data trends and statisticsprovide ongoing reports in part through development of dashboardswork closely with lebermuth it personnel and vendors to ensure ongoing technical support for the organizationcommunicate project status updates to lebermuth team members on a regular basiscollaborate with lebermuth management to prioritize information reporting needsprovide research and analytical services to lebermuth team memberscollectmine data to be studiedfilter and clean data to remove errors and ensure consistency develop strategies to optimize data qualitysummarize data findings in formats understandable to end usersidentify analyze and interpret trends or patterns in complex data setsrecommend opportunities for business process improvements to lebermuth decision makersidentify drivers in data and focus on solutions in fulfilling project requestsremain current on the various options available for data analytics tools softwarehardware updates system upgrades and other it enhancementsqualified candidates have a bachelor’s degree preferably in mathematics economics computer science information management or statistics and 5 to 8 years’ experience in a data development data modeling data architect or similar role or equivalent combination of education and experience from which comparable knowledge skills and abilities have been achieved knowledge base representative of the position includes technical expertise with data models database design data mining and data extraction and transformation with reporting and statistical packages for analyzing large data sets advanced knowledge of databases ie db2 and sql server and advanced skill set with microsoft excel some programming experience is preferred to aid in understanding of business processes and to correct errors or repair data knowledge of manufacturing inventory control and order processing software ie erp crm is also preferredfor consideration of this opportunity please submit your resume through indeedwe invite you to explore lebermuth at wwwlebermuthcom eoe mf d vjob type fulltimeexperiencedata engineering 5 years requirededucationbachelors preferred,,IN,False,data_engineer
Data Engineer,80000  150000 a yearcontractdata engineer java python c goadvanced knowledge of java familiarity of pythonfamiliarity with hadoop stack spark aws glue aws athena etcdiverse data storage technologies rdbms sql server mysql elasticsearch dynamodb s3 etcjob type contractsalary 8000000 to 15000000 yearexperiencedynamodb 1 year preferredspark 1 year preferredgo 1 year preferredcc 1 year preferredjava 1 year preferred,115000.0,CA,False,data_engineer
Data Engineer,"at toptal we measure everything and always rely on data to guide all of our initiatives including both our longterm strategy and our daytoday operations
as a data engineer your main goal is to be one step ahead of data scientists and analysts and support them by providing infrastructure and tools they can use to deliver endtoend solutions to business problems that can be developed rapidly and maintained easily this is more than building and maintaining etl pipelines we need innovation creativity and solutions that will have significant impact on our velocity we in turn will give you autonomy and freedom to turn your ideas into reality
this is a remote position that can be done from anywhere however we do things like rent out hotels in africa or mansions in thailand and you will certainly be invited to come work with us
responsibilities
build scalable highly performant infrastructure for delivering clear business insights from a variety of raw data sources
develop batch  realtime analytical solutions prototypes and proofs of concept for selected solutions
implement complex analytical projects with a focus on collecting managing analyzing and visualizing data
build frameworks and tools to empower our data scientists and analysts
be in constant communication with team members and other relevant parties and convey results efficiently and clearly
requirements
working experience with python pandas prior experience with luigi is a plus
working experience with scala and airflow is a big plus
familiarity with google cloud platform eg gcs and bigquery is a plus
working experience with dimensional modeling and rails is a plus
familiarity with the basic principles of distributed computing and data modeling
extensive experience with objectoriented design and coding and testing patterns including experience with engineering software platforms and data infrastructures familiarity with functional programming concepts is a plus
outstanding communication and interpersonal skills
be excited about collaborating daily with your team and other groups while working via a distributed model
be eager to help your teammates share your knowledge with them and learn from them
be open to receiving constructive feedback
you must be a worldclass individual contributor to thrive at toptal",,,False,data_engineer
Intern-Data Engineer,"internshippalo alto networks is the fastestgrowing security company in history and a sixtime gartner magic quadrant leader for our innovation and ability to execute named best place to work by the silicon valley business journal we offer the chance to be part of an important mission ending breaches and protecting our way of digital life if you are a motivated intelligent creative and hardworking individual then this job may be for you
description
palo alto networks® is the nextgeneration security company leading a new era in cybersecurity by safely enabling applications and preventing cyber breaches for tens of thousands of organizations worldwide if you are motivated intelligent creative hardworking and want to make an impact then this job is for you

our summer internship program mayaugust or juneseptember provides you

11 mentorship
fun and engaging events that inspire your intellectual curiosity
opportunities to expand your knowledge and work on challenging projects
connections to other interns recent grads and employees across the company as well as our leaders

data operations at palo alto networks is a back bone for marketing data science team our mission is data readiness from where it is to where it needs to be with greater precision speed and quality we eat drink and sleep data that helps data scientist discover predictions for sales and marketing we integrate automate and optimize various systems with api design and develop and build data warehouse in big data architecture we are looking for a talented and motivated intern that can turn into a fulltime member of our team after they graduate

learning opportunities

you will learn data integration in a production environment
you will be exposed to api calls integrating 3rd party information
you will get a chance to work on latest big data technology in hadoop

skills sets

the successful applicant should…
have string plsql skillscomfortable with database architecture data warehouse conceptsunderstanding of hadoop or similar cloud db architectureknowledge on etl is requiredexperience with python scripting languagedevelop data visualization for data quality dashboardsgood communication and documentation skillsability to deal with ambiguity  work independently

requirements – to apply you must be pursuing a 4year undergraduate degree a 2year master’s degree or a doctorate degree and returning to school in the fall you must have authorization to work within the united states

palo alto networks is the fastestgrowing security company in history and a sixtime gartner magic quadrant leader for our innovation and ability to execute named best place to work by the silicon valley business journal we offer the chance to be part of an important mission ending breaches and protecting our way of digital life if you are a motivated intelligent creative and hardworking individual then this job may be for you
description
palo alto networks® is the nextgeneration security company leading a new era in cybersecurity by safely enabling applications and preventing cyber breaches for tens of thousands of organizations worldwide if you are motivated intelligent creative hardworking and want to make an impact then this job is for you

our summer internship program mayaugust or juneseptember provides you

11 mentorship
fun and engaging events that inspire your intellectual curiosity
opportunities to expand your knowledge and work on challenging projects
connections to other interns recent grads and employees across the company as well as our leaders

data operations at palo alto networks is a back bone for marketing data science team our mission is data readiness from where it is to where it needs to be with greater precision speed and quality we eat drink and sleep data that helps data scientist discover predictions for sales and marketing we integrate automate and optimize various systems with api design and develop and build data warehouse in big data architecture we are looking for a talented and motivated intern that can turn into a fulltime member of our team after they graduate

learning opportunities

you will learn data integration in a production environment
you will be exposed to api calls integrating 3rd party information
you will get a chance to work on latest big data technology in hadoop

skills sets

the successful applicant should…
have string plsql skillscomfortable with database architecture data warehouse conceptsunderstanding of hadoop or similar cloud db architectureknowledge on etl is requiredexperience with python scripting languagedevelop data visualization for data quality dashboardsgood communication and documentation skillsability to deal with ambiguity  work independently

requirements – to apply you must be pursuing a 4year undergraduate degree a 2year master’s degree or a doctorate degree and returning to school in the fall you must have authorization to work within the united states
 learn more about palo alto networks here and check out our fast facts",,CA,False,data_engineer
Senior Data Engineer,contractjob summaryurgent needed data engineersimmediate interviews within 24 hrsjd is provided upon requestjob type contract,,CA,False,data_engineer
BIG DATA ENGINEER/TRAINEE,"this position will require relocation to client locations after appropriate training as a data engineer you should be familiar with and have handson experience with all aspects of big data engineering from data ingestion of various types of sources and common data cleansing and transformation techniques alternatively you must have 34 years of strong javaj2ee database and data warehouse etl data modeling analytics experience ability to develop debug and deploy applications using common ides in a linux environment is requiredrequired experience

big data engineer 1 years
javaj2ee developer 3 years
required education
minimum of bachelor’s degree in engineering master’s preferred",,,False,data_engineer
Data Engineer,100000  140000 a yearoptomi in partnership with a leading global asset management and financial services company is seeking a data engineer for their owings mills md locationsthe data engineer will be joining a team that will help create maintain and optimize a new cloudbased data architecture that will support multiple investment business lines and will make architectural and design recommendations that will help facilitate the determination buysell investment decisions in a highly dynamic team environmentwhat the right professional will enjoyhelp establish best practices in big data technologies and data warehouse to collect and analyze large volumes of data advancing the state of the art in efficiency optimization predictive analytics and bi selfreporting toolsjoin an emerging technical team of data engineers delivering a wide array of big data and selfservice reporting solutions that use cutting edge technologieshelp guide the organization in efficient data and resource management best practices with cloud based big data data warehouse and reporting platforms and servicesapply today if your background includes you have a bachelor’s degree in computer science or related field and have 5 years of relevant work experience in business intelligence data engineering data warehousing or a similar fieldyou remain active in learning emerging practices and technologies in the bidw and data science spaceyou are comfortable and confident in your knowledge of multiple database programming languages and your knowledge of relational and columnar databasesyou have experience integrating data from multiple data sources and have processed large amounts of unstructured datayou have experience with aws big data components apache spark hadoop presto etc and continuous integration tools teamcity octopus jenkins etc is desired but not requireddata engineer job responsibilities provide significant contributions to the growth of our data infrastructuredesign develop test and deploy business intelligence solutionsdesign and document data structuresmodels and data flowsinteract with various business units and technical teams to gather requirementsreview optimize and document current etl processesensure data quality completeness and accuracycollaborate with team members in code reviews discovering better practices and patterns and continuous improvementsjob type fulltimesalary 10000000 to 14000000 yearlicenseus citizen or green card preferred,120000.0,MD,False,data_engineer
Data Engineer,"the data engineer is responsible for data acquisition strategies and integration scripting and tools data migrations conversions purging and backups fulfills data acquisition strategy requirements they work with product financial control analysts users and other stakeholders to understand business requirements and supports data architecture to translate into data acquisition strategies


the data engineer will author artifacts defining standards and definitions for storing processing and moving data including associated processes and business rules additionally the data engineer will map the details within these their artifacts to business processes nonfunctional characteristics qa criteria and technical enablement the role is responsible to be constantly thinking through the needs of the business to support efficient and error free processes


the data engineer will be responsible for finding trends in datasets and developing workflows and algorithms to help make raw data more useful to the enterprise he or she will also be responsible for createing data acquisition strategy and develops data set processes
designs and implements standardized data management procedures around data staging data ingestion data preparation data provisioning and data destruction scripts programs automation assisted by automation etc
ensures quality of technical solutions as data moves across healthfirst environments
provide insight into the changing data environment data processing data storage and utilization requirements for the company and offer suggestions for solutions
ensures managed analytic assets support healthfirst’s strategic goals by creating and verifying data acquisition requirements and strategy
develop construct test and maintain architectures
align architecture with business requirements and use programming language and tools
identify ways to improve data reliability efficiency and quality
conduct research for industry and business questions
deploy sophisticated analytics programs machine learning and statistical methods
prepare data for predictive and prescriptive modeling and find hidden patterns using data
use data to discover tasks that can be automated
create data monitoring capabilities for each business process and work with data consumers on updates
aligns data architecture to healthfirst solution architecture contributes to overall solution architecture
help maintain the integrity and security of the company data
minimum qualifications
bachelor’s degree in computer engineering or related field
7 years’ experience in a data engineering
10 years’ experience in data programing languages such as java or python
4 years’ experience working in a big data ecosystem processing data includes file systems data structuresdatabases automation security messaging movement etc
3 years’ experience working in a production cloud infrastructure


preferred qualifications
proven track record of success directing the efforts of data engineers and business analysts within a deadlinedriven and fastpaced environment
hands on experience in leading healthcare data transformation initiatives from onpremise to cloud deployment
demonstrated experience working in an agile environment as a data engineer
hands on work with amazon web services including creating redshift data structures accessing them with spectrum and storing data in s3
knowledge of sql and multiple programming languages in order to optimize data processes and retrieval
proven results using an analytical perspective to identify engineering patterns within complex strategies and ideas and break them down into engineered code components
knowledge of providersponsored health insurance systemsprocesses and the healthcare industry
experience developing prototyping and testing engineered processes products or services
proven ability to work in distributed systems
proficiency with relational graph and nosql databases required expertise in sql
must be able to develop creative solutions to problems
demonstrates critical thinking skills with ability to communicate across functional departments to achieve desired outcomes
excellent interpersonal skills with proven ability to influence with impact across functions and disciplines
ability to work independently and as part of a team
ability to manage multiple projectsdeadlines identifying the necessary steps and moving forward through completion
skilled in microsoft office including project powerpoint word excel and visio

we are an equal opportunity employer applicants and employees are considered for positions and are evaluated without regard to mental or physical disability race color religion gender national origin age genetic information military or veteran status sexual orientation marital status or any other protected federal stateprovince or local status unrelated to the performance of the work involved

if you have a disability under the americans with disability act or a similar law and want a reasonable accommodation to assist with your job search or application for employment please contact us by sending an email to careershealthfirstorg or calling 2125191798  in your email please include a description of the accommodation you are requesting and a description of the position for which you are applying only reasonable accommodation requests related to applying for a position within healthfirst management services will be reviewed at the email address and phone number supplied thank you for considering a career with healthfirst management services


eeo law poster and supplement",,NY,False,data_engineer
Jr. Data Engineer,"junior data engineer
we build products that help people protect their privacy and security on their mobile phones and we are looking for new team members to help fuel the growth of our innovative suite of mobile apps
robokiller blocks robocalls then gets revenge on telemarketers while trapcall unmasks blocked calls protecting users from all kinds of phone harassment spoofcard lets consumers change their caller id to keep their number secure and tapeacall allows users to record calls on their iphones if these are products you are excited about wed like to learn more about you
we are looking for an enthusiastic data engineer to join our organization in this role you will work closely with our engineers analysts and product owners to develop and optimize data infrastructure and tools that empower advanced analytics the right candidate will be knowledgeable and excited about continuously improving the data management practice by implementing data technologies that power our analytics efforts
responsibilities
design administer and maintain an analytical data warehouse and data lake
build a batch and realtime data pipeline to ingest and process data from various sources such as mobile applications product backends and thirdparty partners
build internal tools and services that will boost our data operations
assist productmarketing analytics and engineering teams with datarelated technical issues to support their data infrastructure needs
facilitate data governance practice to document profile and manage data across multiple products and platforms
qualifications
0  2 years of data or relevant engineering experience developing scalable data pipelines
fluency in sql and programming languages python java javascript go etc
handson experience with relational database and nonrelational data stores
familiarity with creating etl processes for large scale data warehouses
understanding of fundamental software engineering principles
the ability to work effectively in a team environment with a positive “get stuff done” attitude and a passion for data engineering practices
pluses
experience with various cloud services like gcs gke pubsub dataproc etc
knowledge of dimensional data warehouse modeling
knowledge of big data ecosystem and related technologies such as hadoop spark and cassandra
familiarity with relevant frameworks and tools such as airflow pandas spark and more
previous experience on data management practice is a plus
active involvement in open source software development is also a plus
what you can expect
opportunities to grow
an awesome collaborative fun place to work
coworkers who will make you feel like family but challenge you to be your best
in headquarters
a wellstocked kitchen with breakfast and lunch options almost every day
an onsite gym facility with a wellness program
a game room and lounge so you can relax and recharge as needed
we want “a” players who are driven to achieve but know that teamwork is the key to their own success we are a successful selffunded company with a fantastic silicon valley style office and a culturefirst personality if you think you are a good fit please first take a close look at our robokiller trapcall tapeacall and spoofcard products and tell us how your story and experience can help shape teltechs future",,NJ,False,data_engineer
Data Engineer - Marketing,"consensys is a venture production studio and the leading technology firm in blockchain globally we deliver products solutions and platforms built using blockchain technology to transform how business is done in complex network of buyers suppliers and consumers

our teams are busy at work building the future of identity financial markets commerce the music industry security and infrastructure and more to accomplish this weve built out a flat organizational structure which we call the consensys mesh a network of individuals  teams working autonomously and towards the same goal our mission is to use these decentralized solutions to fundamentally reshape the economic social and political operating systems of the planet if you are someone that thrives in a fastpaced environment where being selfdirected determined and resilient are a requirement we would love for you to join us

about the role
consensys is looking for an experienced analyticsdata engineer who will play an integral part in building out the companys data infrastructure they will be responsible for integrating data from various sources both third party and first party and ensuring its availability for reporting in sql databases and looker this role requires a strong understanding of data infrastructure integration etl processes and looker

as the first member of the team the analyticsdata engineer will be working closely with the analytics lead in driving the data strategy and roadmap of the company

the ideal candidate will be enthusiastic wellorganized and motivated by creative problemsolving candidates should generally be interested in and passionate about the technologies poised to transform the way we live and be open to learning deeply about blockchain topics

responsibilities

integrate data from various third party and first party data sources including but not limited to google analytics youtube medium facebook twitter linkedin and individual spoke data
code fix and maintain mapreduce data transformation jobs
design build and launch new data extraction transformation and loading pipelines and processes in production
build sql scripts for processing and analysis of data
data analysis and data quality checks for completeness and accuracy
maintain reporting systems
define and manage sla for all data sets

requirements

3 years experience in the data warehouse space
3 years experience in custom etl design implementation and maintenance
3 years experience with schema design and dimensional data modeling
deep knowledge of blockchain technology
passion for ethereum and its potential
experience with snowplow postgres bigquery redshift looker and lookml
experience with data warehousing dimensional modeling and etl development
proven ability to work cross functionally
previous experience and successful trackrecord of learning new tools and technologies
working knowledge of aws components and services
strong programming shell scripting and deep sql skills
knowledge of mapreduce jobs and etl scripts
a keen eye for detecting data defects and anomalies
comfortable juggling multiple technologies and high priority tasks
you are a selfstarter who enjoys learning new technologies
ability to analyze data to identify deliverables gaps and inconsistencies
ability to manage and communicate data warehouse plans to internal clients

here are some of the perks of being part of a unique organization like consensys


the forefront of a revolution at consensys we fundamentally believe that a next generation of technologies presents the opportunity to create a more just and equitable society
a dynamic startup environment consensys is a thought leader in the blockchain space and we are absorbing a significant portion of the mindshare this is both exciting and challenging as we learn to scale our organization while adhering to the principles of decentralization
continuous learning youll be constantly exposed to new languages frameworks and ideas from your peers and as you work on different projects  challenging you to stay at the top of your game
deep technical challenges this entire ecosystem is about 10 years old ethereum itself is still a toddler there is much work to be done before these platforms can scale to the order of millions or billions of users consensys is building the technology platforms that can get us to those next thresholds of scale

",,NY,False,data_engineer
Data Engineer,"were seeking an experienced data engineer to join our growing data team you will team up with our data engineer to build scale and improve the core of our data stack in addition you will be working closely with our analytics team to productionalize statistical and machine learning models we are looking for someone whos excited to help us ask the right questions dig deep into the answers and build solid systems that address them

a little about us

the paperless post data team plays a crucial role in our products success we get to dive into advanced data work—from machine learning to visualization classifier creation to etl pipelines—that solve complex business problems and increase the functional capabilities of everyone throughout the company on the reporting side we help ensure that all teams have the information they need to make sound business decisions above all were a team that is excited about what we do

what youll do here


build efficient and reliable data infrastructure and tools
develop production code for realtime data processing etls and machine learning services
analyze the data we collect to generate important insights with our analytics team
deploy and monitor production systems

about you

as an ideal candidate you have a good blend of programming analysis and communication skills

this describes you


you are an expert in sql python andor javascript
you have an expert knowledge with aws data pipeline lambda redshift and best practices
you have experience with modern etl and data modeling technologies
you have a solid understanding of both relational and nosql database technologies
you have a strong understanding of data security and protection
you have great communication skills both written and verbal
you have the desire and willingness to take on new challenges and learn new things

this is a bonus


you have experience with hadoop  mapreduce or spark
you have experience working on and productionizing machine learning models
you have experience with realtime data processing
you have experience with database architecture

companywide we enjoy an amazing ecosystem of an even gender split and a healthy balance of engineers and designers because paperless post isnt supported by ad revenue we can focus our efforts on building and improving on the ideal version of our platform product content and partnerships for our users

we are proud that paperless post helped over 30 million people connect in the real world last year our product is global and we are committed to being a company where everyone belongs we encourage people of all backgrounds races genders and abilities to apply",,NY,False,data_engineer
Data Engineer,contractjob summaryfounded in 2007 intersources inc is an small business enterprise minority business enterprise  women owned small business certified company specializing in providing it consulting it staffing solutions and software solutions we have been recipients of various awards under fastest growing it consulting and software company  and excellence in technology services responsibilities and dutiesdata engineer you will focus on designing building and launching efficient and reliable data infrastructure to scale and compute for our businesshelp us build a world class data lakedata warehouse by building data pipelinesdesign and develop new systems and tools to enable folks to consume and understand data fasteruse your expert coding skills across a number of languages from python java c go etcwork across multiple teams in high visibility roles and own the solution endtoenddesign build and launch new data extraction transformation and loading processes in productionwork with data infrastructure to triage infra issues and drive to resolutionjob type contractlocationsan mateo ca preferred,,CA,False,data_engineer
Data Engineer,"semanticbits is looking for a data engineerwranger who is an effective technologists selfmotivated and able to source and develop data models to fuel the analytics developed by analysts and data scientists you will deliver data acquisition transformations cleansing conversion compression and loading of data into data and analytics models work in partnership with data scientists and and analysts to understand use cases data needs and outcome objectives you are a practitioner of advanced data modeling and optimization of data and analytics solutions at scale expert in data management data access big data traditional data marts etc advanced in programming python shell scripting java and sql advanced database modeling familiarity with analytic algorithms and applications like machine learning
semanticbits is a leading company specializing in the design and development of digital health services and the work we do is just as unique as the culture we’ve created we develop cuttingedge solutions to complex problems for commercial academic and government organizations the systems we develop are used in finding cures for deadly diseases improving the quality of healthcare delivered to millions of people and revolutionizing the healthcare industry on a nationwide scale there is a meaningful connection between our work and the real people who benefit from it and as such we create an environment in which new ideas and innovative strategies are encouraged we are an established company with the mindset of a startup and we feel confident that we offer an employment experience unlike any other and that we set our employees up for professional
success every day
requirements
bachelor’s degree in computer science or related and 2 to 4 years of professional experience
strong knowledge of computer science fundamentals objectoriented design and programming data structures algorithms databases sql and relational design networking
demonstrable expertise with python elasticsearch and spark wrangling of various data formats  csv xml json
experience with the following technologies is highly desirable r aws cloud computing apache nifi apache kafka kibana nodejs
experience with agile methodology using testdriven development
excellent command of written and spoken english
selfdriven problem solver
benefits
generous base salary
three weeks of pto
excellent health benefits program medical dental and vision
education and conference reimbursement
401k retirement plan we contribute 3 of base salary irrespective of employees contribution
100 paid shortterm and longterm disability
100 paid life insurance
flexible spending account fsa
casual working environment
flexible working hours",,,False,data_engineer
Data Engineer,"about reflektives engineering team

reflektive is seeking a data engineer to deliver our talent development platform to the worlds best places to work reflektive is a rapidly scaling company making this the best environment to take on ownership as well as learning how to grow a company

youll join a lean prolific team where everyone including you is active in the product defining and development process where deploying new features every 2 weeks is common youll know the customers were talking to and the needs of each one as a result you know where your initiative and drive can best make a difference and be recognized

our engineering team consists of developers from a wide array of backgrounds our data team primarily focuses on java sql and python our team is a tight knit friendly group of engineers that are dedicated to learning from and teaching to each other team members regularly contribute to and optimize our engineering practices and processes our team wants to make software engineering fun easy and fulfilling so weve come up with a set of values that we apply to our software every day simple flexible consistent predictable efficient and pragmatic
responsibilities
working on reflektives data  infrastructure projects
experience or demonstrated interest in big data technologies
enhance and further develop big data processing pipelines for data sources containing structured and unstructured data
monitor and optimize key infrastructure components such as databases ec2 clusters and other aspects of the stack
help promote best practices for big data development at reflektive
act as a bridge between the infrastructure and application engineering teams
provide infrastructure support with a focus on cloud based computing
build and support visualization and exploration capabilities around our data sets
work with the data extraction and data science engineers on normalization and analytical processes
work in an agile manner with business users and data scientists to understand and discover the potential business value of new and existing data sets and help productize those discoveries
help design and implement disaster recovery efforts
analyzes requirements and architecture specifications to create detailed design
research areas of interest to the team and help facilitate solutions
desired skills and experience
3 years of professional experience as a data engineer or a backend  full stack software engineer looking to move into data engineering
skills required java sql
great if candidate has experience in any of the following python ruby on rails postgressql redshift elasticsearch
startup experience
flexible team player
willingness to roll up your sleeves and get stuff done
willingness to learn and do whatever it takes to meet deadlines in a quick everchanging environment
in 30 days you will have deployed fixes to production and have an understanding of how data is consumedtransformedstored and the key infrastructure projects
in 60 days you will have taken on a deeper understanding of projects working independently or with team mates to implement key features
in 90 days owning your own project and working collaboratively with your peers",,CA,False,data_engineer
Data Engineer,"job responsibilities
translate complex functional and technical requirements into detailed design
design for now and future success
hadoop technical development and implementation
loading from disparate data sets by leveraging various big data technology
preprocessing using hive impala spark andor pig
design and implement data modeling
maintain security and data privacy in an environment secured using kerberos and ldap
highspeed querying using inmemory technologies
following and contributing best engineering practice for source control release management deployment etc
production support job schedulingmonitoring etl data quality data freshness reporting
job requirements
58 years of python or javaj2ee development experience
3 years of demonstrated technical proficiency with hadoop and big data projects
58 years of demonstrated experience and success in data modeling
fluent in writing shell scripts bash korn
writing highperformance reliable and maintainable code
ability to write mapreduce jobs
proven understanding and hands on experience with hadoop hive pig impala and spark
preferred
understanding and implementation of flume processes
good knowledge of database structures theories principles and practices
understand how to develop code in an environment secured using a local kdc and openldap
familiarity with and implementation knowledge of loading data using sqoop
knowledge and ability to implement workflowschedulers within oozie
experience working with aws components ec2 s3 sns sqs
analytical and problem solving skills applied to big data domain
lisnna",,CA,False,data_engineer
Data Engineer Intern (Summer 2019),"temporary internshipdata engineer intern summer 2019


position title data engineer – intern summer 2019
location chicago
department information technology
we are looking for a data engineer intern to join our team you will have the opportunity to be involved in all aspects of a performancedriven database infrastructure geared towards a fast paced trading environment on the technical front the database team touches every layer of the database stack from hardware to application layer so be ready to leverage your strengths while learning a lot to improve your weaknesses the team manages every aspect of the database environment from server hardware to arrays to sql development and administration on the business front this team works directly with traders other engineers and business stakeholders you will interact closely with both team members and stakeholders alike the ability to have a keen technical understanding but communicate in layman’s terms is important day to day tasks can vary between database design support tuning sql report writing scripting and anything else that could touch the database layer of the firm
required qualifications
major in cs mis engineering or an applied science30 gpa03 years of experienceexcellent problem solving skillsrising junior senior or graduate studentdatabase related coursework
key elements for the internship elaborate on these when applying
ms sql server experiencechashtag development skillsprogramming or scripting experience tsql preferredfinancial or trading industry experiencedatabase design and performance optimization experiencedatabase administration backupsrestores security hanetworking dns ad san raid
about wolverine
founded in 1994 the wolverine companies comprise a number of diversified financial institutions specializing in proprietary trading asset management order execution services and technology solutions we are recognized as a market leader in derivatives valuation trading and valueadded order execution across global equity options and futures markets with a focus on innovation achievement and integrity we take pride in serving the interests of both our clients and colleagues the wolverine companies are headquartered in chicago with offices in new york and san francisco and a proprietary trading affiliate office located in london
sponsorship is not available for this position






are you a returning applicant


previous applicants

email

password





if you do not remember your password click here",,IL,False,data_engineer
Data Engineer,"fox news is currently looking for a data engineer to join our digital team responsibilities will include building out tools and new data platforms that will drive the data driven decision process within the organization

a snapshot of your responsibilities
create and maintain new extract transmit and load etl processes to further the capabilities of our analytics platform
create programs that gather data from apis websites and other data warehouses
support and maintain a powerful and efficient data warehouse within the aws environment
run adhoc queries for stakeholders using an assortment of technology including redshift spark and athena
propose and design new methods and technologies to better leverage our data
support the data needs of business intelligence and data science teams
what you will need
sql expertise
fluency in an objectoriented language such as python java or c
experience with shell languages such as bash or powershell
understanding of relational and nonrelational data modeling
proficiency in creating etl processes for large scale data warehouses
excellent communication skills
nice to haves
indepth knowledge of hadoop and related technologies such as hive presto and spark
proficiency with the aws ecosystem including technologies such as dynamodb redshift s3 glue lambda athena and emr
experience with big data columnar formats such as orc and parquet
knowledge of adobe analytics and clickstream data feeds
machine learning
knowledge of data visualization tools such as tableau domo looker etc
please attach a resume to be considered applications without resumes will be considered incomplete and will not be reviewed



we are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin gender identity disability protected veteran status or any other characteristic protected by law we will consider for employment qualified applicants with criminal histories consistent with applicable law",,NY,False,data_engineer
Data Engineer,"viant’s engineering team is looking for a data engineer to join our irvine ca office the engineer will be involved in the full development lifecycle contributing to various viant product lines
responsibilities
writing complex sql queries
analyzing and tuning sql queries
writing etl and elt jobs using various tools and programming languages
designing developing testing debugging and deploying applications and reports using various technologies
importing and exporting large amounts of data in formats like csv json xml etc
need to be able to easily switch between different technologies
solving complex performance problems architectural challenges and production issues
working with product owners qa engineers and fellow engineers
following organization processes and procedures
adhoc duties as needed
qualifications
minimum bs in computer science mathematics or related field
strong foundation in computer science
experience with java python a plus
exposure to cloud based technologies like google cloud platform aws
experience with web services
experience with mysql oracle and other database technologies
ability to troubleshoot queries stored procedures functions packages and triggers
excellent problem solving critical thinking and communication skills
ability to learn newer technologies in a short period of time
good sense of humor and a team player
exposure or understanding of nosql technologies a plus
exposure to machine learning a plus
benefits
competitive salary and bonuses
paid benefits for the employees medical dental vision ltd life insuranceadd
paid parental leave
401k
summer “work from anywhere” fridays
wellness programs – info sessions and occasional chair massages
employee discounts – eg gym memberships wireless plans entertainment tickets
fully stocked kitchen
casual office atmosphere
commuter benefits program
ongoing education  training
company sponsored events  team building experiences
about viant

founded in 1999 viant technology llc is a leading global peoplebased advertising technology company enabling marketers to better plan execute and measure their digital media investments through our cloudbased platform built on a foundation of people instead of cookies the viant advertising cloud™ provides marketers with access to over 1 billion registered users globally one of the largest registered user databases in the world and infuses accuracy transparency reach and accountability into cross device advertising

viant owns and operates adelphic and myspace and is a member of the xumo joint venture
in 2016 viant became a subsidiary of time inc nysetime one of the world’s leading media companies with over 100 influential brands including people sports illustrated fortune and time in february 2018 meredith corporation nyse mdp meredithcom acquired time inc and all its subsidiary companies including viant creating a cross channel ecosystem of nearly 200 million unduplicated american consumers every month including 85 percent of us millennial women

lilf1",,CA,False,data_engineer
Data Engineer,responsibilitiesoptimize data both underlying data structure and delivery method for use by reporting platformswork with new nosql document and graph databaseslearn and assist with our extract transform and load etl process for bringing data into the warehouse in order to turn it into usable informationpartner with various users company wide to build a strong data driven culture through the use of information based decision makinghelp these users access and understand the data and metrics in the data warehousedeveloping appropriate new metrics to be used across the businessmaintaining documentationqualificationsaws environment experience3 years of python or node experiencecan construct complex sql queriesclickstream web analytics data management experienceindepth quality assurance expertisecomplex problem solving skillsrequires high proficiency in both written and verbal most communication involves technicalspecific terminology logical development of arguments or processes and requires clarity of expressionrequires high degree of independent judgment and problem solving of complex problemsdata auditing skills to verify data integrity and understand discrepanciesabout clearlinkclearlink’s team of 1700 employees is headquartered in salt lake city and has been creating marketing content services for fortune 500 companies for over 13 years at clearlink you will have opportunities to work with people who are as passionate as they are talented develop yourself and your skills and create valuable content and relationships every day we also like to reward our employeesup to 100 healthcare for your entire familyover two weeks paid time offpaid ski days wellness activities and team outingsfullystocked break room and gourmet coffeeawardwinning wellness program with free health coachingallexpense paid vacations for top employeeslocation salt lake cityjob type fulltime,,UT,False,data_engineer
RAD-Data Engineer,"job description
technical support tech ii – rad data engineer
the supply chain rad team seeks a data engineer to join our rad program management organization we are responsible for supporting amazon’s fulfillment and logistics infrastructure in a fastpaced and dynamic work environment to accomplish our goals we are interested in finding top candidates that are ready to take on challenges obsess over customers and lead change
in this role you will be a part of programs of significant scope and impact we are looking for a successful and outstanding mssql dba to help manage database support and operations of our mission critical systems the dba will be well versed in mssql data warehouse and integration technologies and will perform administration and engineering for multiple production databases the ideal candidate will have experience in the architecture design and implementation of large production systems with high transaction volumes the candidate will also be responsible for fastpaced complex distributed database environments supporting large databases and complex integrations successful candidates will have the ability to rapidly troubleshoot complex technical problems under pressure
preferred location is seattle wa but this position can be based out of any rad us amazon fulfillment center
basic qualifications
bachelor’s degree in computer science and 2 years of amazon experience5 year of experience as mssql dba in a high traffic transactional environmentstrong knowledge of systems architecture loosely coupled and distributed systemsday to day experience supporting highly scalable distributed service oriented systemsability to work cooperatively with software engineers and system administratorsexperience with system integrations etl data warehouse queries and stored procedurestwo years working experience on infor eam software package including software configuration dashboard development using cognos business objects or ssrs reporting toolsone full cycle of software implementation experience is requiredsuperior communication and analytical skills including strong ability to identify and solve ambiguous problemsstrong knowledge in project development methodology clear verbal and written communication skills and the ability to handle daily activities in a dynamic environment and drive deliverables
preferred qualifications
master’s degree in computer science with 5 years of industry experienceexperience with highvolume oltp and olap database systemsperformance tuning of mssql plsql sql processes and queriesstrong understanding of fundamental relational database design data warehouse and business intelligence best practices methodologies and terminologyexperience in distribution manufacturing logistics or other warehouse environmentsexperience in architecture design and implementation of production systems with high transaction volumes",,WA,False,data_engineer
Associate Data Engineer,"a pioneer in k– 12 education since 2000 amplify is leading the way in nextgeneration curriculum and assessment our captivating core and supplemental programs in ela math and science engage all students in rigorous learning and inspire them to think deeply creatively and for themselves our formative assessment products turn data into practical instructional support to help all students build a strong foundation in early reading and math all of our programs provide teachers with powerful tools that help them understand and respond to the needs of every student today amplify serves more than three million students in all 50 states for more information visit amplifycom 


as an engineer at amplify you will join a talented team tackling the toughest problems in education with the best ideas in technology – including user experience apis and services data analysis and deployment pipelines you’ll play an active role in imagining and improving product design and the classroom experience
we hire engineers “for the slope not the intercept” – we’re looking for intellectual ability flexibility and ability to learn and commitment to work together in tightknit teams

what you’ll do

our data team builds augments and maintains the infrastructure that empowers teams across amplify and our customers to make sense of and tell stories with their data we believe strongly in teaching our teammates to serve themselves within a safe reliable and agile environment you’ll be building data systems but also the sharingandlearning culture so that every team uses these tools to improve their own lives and those of our students and teachers
impress the toughest customers around – seventh graders – by
helping teams create fun compelling apps by leveraging millions of data points
make life better for passionate overworked teachers by
helping teachers understand their students by building reusable data pipelines
make life better for passionate overworked marketing and sales teams by
using rest apis for sourcingsending data to saas like salesforce hubspot
help school administrators build great schools by
respecting privacy and ensuring security while offering useful insights by making smart choices in tech stack database design and encryption
helping school principals understand how teachers are teaching and how students are learning by architecting data warehouse schemas and sql transforms with just the right ctes window functions and pivots
analyzing performance and squashing tricky bugs using tools like aws redshift matillion python sql aws cloudwatch aws sns

example projects you might work on
building welltested and optimized etl data pipelines for both full and delta extraction
collaborating with data scientists to store aggregate and calculate captured students’ work
contributing to leading industry data standards such as caliper analytics or xapi
improving our deployment and testing automation data pipelines

you must have
bs in computer science data science or equivalent
strong cs and data engineering fundamentals
proven fluency in sql and a development language such as python
strong communication skills in writing conversation and maybe silly gifs

extra credit for
ms in computer science data science or equivalent
2 years of professional software development or data engineering experience
understanding of etlelt pipelines and data warehousing design tooling and support
understanding of different data formatting json csv xml and data storage techniques 3nf eav model star schema data vault
experience with tools we use every day
storage aws storage services redshift redshift spectrum s3 glacier dynamodb parquet postgres
etlbi matillion looker
experience with tools we don’t use but should and the wisdom to know when to recommend them
proven passion and talent for teaching fellow engineers and nonengineers
proven passion for building and learning open source contributions pet projects selfeducation stack overflow
experience in education or edtech



amplify is an equal opportunity employer of minorities females protected veterans and individuals with disabilities

this position may be funded in whole or in part through american recovery  reinvestment act funds

amplify education inc is an everify participant",,NY,False,data_engineer
Data Engineer,"bittorrent offers a unique and compelling work environment we are proponents of the open internet and we serve one of the largest user demographics in history we take these responsibilities seriously and hire accordingly we work with only the brightest engineers and the most talented business people we can find everyone on our team is here to do meaningful work with broad reaching impact we have a fun yet challenging work environment that fosters diversity creativity and teamwork our team members receive industry leading salaries premium benefits and stateoftheart offices in san francisco’s soma district

data engineer
required skills
2 years datadevelopment experience
experience supporting and working with crossfunctional teams
proficiency in python
fluency in sql
experience with mapreduce and etl
nice to have skills
experience with aws toolsservices
git",,CA,False,data_engineer
Data Engineer,"this data engineer will join other extremely passionate engineers who share a common interest in distributed systems performance scale and solving problems with software and data our technologies power the insights for financial service and corporate giants
ideal candidates are those who are excited by big data challenges and enjoy using new technologies to make large datasets feel small
compensation includes a highly competitive salary bonus and equity

responsibilities
work closely with the data science and research team and execute on product goals
build fault tolerant secure data products to extract terabytes of disparate data through a unified scalable data extraction and reporting platform
assist with the troubleshooting of production support issues
enjoy the challenge of researching data issues to maintain quality in our large data sets
read relevant blogs and articles and grow as an engineer
requirements
3 years working as a data engineer
results driven with a strong desire to deliver insights to customers
willingness to meet time sensitive deadlines
fluent in python and sql
experience with aws data management stack athena rds redshift emr etc is a must
experience with spark and databricks is a plus
devops experience is a plus
ability to efficiently manipulate extremely large dataset
flexible and can adapt to the changing demands of a startup environment

company description
7park data transforms data to revolutionize business decisions
leveraging machine learning entity extraction and linking and predictive models we transform unstructured information into contextualized leading performance indicators for thousands of public and private companies our clients are the most sophisticated investment firms and fortune 500 corporations who depend on 7park data to guide benchmarking forecasting and product development
7park data offers the avenue suite a collection of dashboards providing clients and partners with on demand access to our report library commentary from domain experts and custom queries and visualizations
avenue io our developer site is a suite of apis sdks and tools for data scientists quantitative analysts and data owners who want access to cleansed mapped normalized data and userlevel panels to build their own models avenue io provides open source tools to quickly and easily build analytical products powered by our apis
7park data was founded in 2012 and is headquartered in new york city
for more information please visit www7parkdatacom",,NY,False,data_engineer
Data Engineer (Wilmington DE),120000  130000 a yearcontractlocation  wilmington deduration  6 months with possible contract to hiredescription should have good experience in working withsparkapache nifikylopython or scala or javacicd  devopsaws emr ec2 s3 etcunix  linuxjob types fulltime contractsalary 12000000 to 13000000 yearexperiences3 1 year preferredscala 1 year preferredaws 1 year preferredapache 1 year preferredjava 1 year preferred,125000.0,DE,False,data_engineer
Data Engineer / Data Scientist,"clora is looking for a data engineer to join our small growing dev team as a rapidly evolving company our priorities shift quickly and there is an everchanging set of technical challenges to tackle

our mission


clora is building a platform that organizes and provides access to the worlds life science expertise in order to accelerate the development of new therapies and fundamentally change how this industry works our technology helps innovative life science biotech  pharmaceutical  medical device companies find vet and engage with toptier life science experts on their most critical development priorities we make the process of finding the right expertise fast reliable and more costeffective

clora is already drastically reducing the time it takes to find the right talent from over two months down to just a few days and all at a third of the cost as we continue to scale clora will meaningfully reduce the time it takes for lifeimproving therapies to get into the hands of patients most in need

our investors to date include spark capital felicis ventures ludlow ventures notation capital v1vc the foundercto of hired and 99designs and early investors in classpass and zocdoc collectively our investors have backed twitter ginkgo bioworks wayfair box tumblr foursquare postmates warby parker and slack among others

our vision is only possible with the right team if you are scrappy entrepreneurial in spirit and eager to learn and grow read on

what youll do



improve and extend our data processing platform including
build and maintain data pipelines to clean and process platform data
tag and store platform information in a way that can allow us to easily filter and search based on our project demand
iterate and improve upon a recommender system facilitating the automated matching of expertise with requirements refining models learners and experiment with new approaches
take ownership of projects laying the foundation of great code yourself and helping others around you to code to those standards
work on new products as well on feature enhancements of existing products

stack  workflow



rails
react  bootstrap
postgresql rds and heroku
elasticsearch with searchkick
github  circleci  heroku for deployment
rollbar for error management
jira for project management

about you



you have a positive attitude and are an excellent communicator
you want to own the success of a feature beyond the pullrequest
youre used to a fastpaced environment that changes daily
you are really excited about making an impact in the life sciences
you can work seamlessly with a small but growing team happy to be working individually as a leader in implementation and direction or as a pair of helping hands
you have empathy for our users and be part of the creative process to develop new features and products

required



5 years development experience with some exposure to data processing pipelines
you have familiarity with or a strong interest in developing data science experience
ability to provide thought leadership on design and architecture of data platform
experience working closely with a variety of teams including product management and frontend engineers
experience working in a startup environment
experience working in a continuous development pipeline that uses jira github circleci and heroku to manage collaborative workflow and software releases or equivalent products
bs or higher in computer science or equivalent work experience

we accept all humans


we are committed to making clora an inclusive and diverse organization clora is an equal opportunity employer we do not discriminate based on race color ethnicity ancestry national origin religion sex gender gender identity gender expression sexual orientation age disability veteran status genetic information marital status or any legally protected status",,MA,False,data_engineer
SQL and Data Engineer,"at globant wwwglobantcom we strive daily to deliver powerful innovative software solutions for our clients through our unique digital journey approach our passion for technology reverberates in every area of our organization and drives our creativity working for us means being at the convergence of engineering design innovation and scale it means being part of a tightly knit and driven team whose work directly affects the products and bottom line of our clients

our bar is high but so are the results we achieve

we are seeking for a sql and data engineer to join the marketing solutions and sales team of one of the biggest and most innovative data companies in the market this position is the seed of a rapidly growing automation of many tasks using the top edge technologies before they are even in the market the position will also involve dealing with different teams to understand design and implement solutions to their problems and needs

responsibilities

work with stakeholders and a crossfunctional teams to understand requirements and business rules
understand the set of technologies available and already implemented solutions by other teams to adapt them
be aware of new internal and external technologies in order to suggest innovative solutions and analyze the possibilities they could bring
replace existing manual processes with automated and more reliable versions
create processes to extract and clean data into different databases
design and create etl pipelines to automate big data processes
create sql queries and other languages scripting to manipulate medium and large volumes of data
analyze and optimize queries and pipelines for internal and external reporting
understand the securities and compliance policies to execute proper implementations that protect the data and their users
lead the analysis and design of quality technical solutions
be part of a high performance engineering culture becoming the referent in data and a key player in the team

requirements


computer science studies or related technical field or equivalent combination of educationexperience
a minimum of 3 years of experience data manipulation
experience analyzing domain models for relational schemas data warehouses andor storage strategies
strong sql skills and data analysis
experience in tableau or similar data visualization platforms for reporting
proficient in at least one scripting language for automation purposes python bash among others
demonstrate ability to understand new datasets and data structures
proactive attitude to understand new business rules and think about the challenges they could bring proposing solutions
great problem solving and analytical skills
excellent verbal and written communication skills
ability to manage and develop multiple projects in parallel is a plus
familiarity with finance industry is a plus

we are interested in hardworking fastlearning talents and we have the knowhow and scale to help you make your own career path if you seek an entrepreneurial flexible and teamoriented culture come join us

we are ready",,CA,False,data_engineer
Data Engineer - Analytics,"the company
juuls mission is to improve the lives of the worlds one billion adult smokers by driving innovation to eliminate cigarettes juul is the number one usbased vapor product headquartered in san francisco and backed by leading technology investors including tiger global fidelity investments and tao invest llc juul labs is disrupting one of the worlds largest and oldest industries

were an exceptional team with backgrounds in technology healthcare cpg and biotech and were growing rapidly to deliver on our mission were actively looking to hire the worlds best scientists engineers designers product managers supply chain experts customer service and business professionals

role and responsibilities

partner with data scientists data engineers and business analysts to build configurable scalable and robust data processing infrastructure
work closely with our sales operations research and finance teams on data storage retrieval and analysis
develop new systems and tools to enable stakeholders to consume and understand data more intuitively
build manage and support data models

personal and professional qualifications

2 years of software engineering experience with focus on data analytics
proficiency in python and sql knowledge of google cloud bashshell and workflow tools eg luigi airflow is preferred
experience developing etl processes and workflows is desirable
exposure to relational eg mysql and nonrelational databases eg mongodb
comfortable working with bi tools eg looker tableau
knowledge of version control git and containers docker
proven critical thinking and analytical problemsolving skills
desire to learn new etl tools and frameworks
passionate about data and software engineering
able to work collaboratively in an agile environment

education

undergraduate degree in computer science engineering math or equivalent experience

juul labs perks  benefits

a place to grow your career well help you set big goals  and exceed them
people work with talented committed and supportive teammates
equity and performance bonuses every employee is a stakeholder in our success
boundless snacks and drinks
cell phone subsidy commuter benefits and discounts on juul products
excellent medical dental and vision benefits
location work in the heart of san francisco one of the worlds greatest cities

juul labs is proud to be an equal opportunity employer and is committed to creating a diverse and inclusive work environment for all employees and job applicants without regard to race color religion sex sexual orientation age gender identity or gender expression national origin disability or veteran status we will consider for employment qualified applicants with arrest and conviction records pursuant to the san francisco fair chance ordinance juul labs also complies with the employment eligibility verification requirements of the immigration and nationality act all applicants must have authorization to work for juul labs in the us

vapor juul work culture fast paced startup growth vape technology software hardware consumer electronics manufacturing design product disruptive revolutionary cutting edge app android ecommerce b2c san francisco bay area iot san jose los angeles
",,NY,False,data_engineer
Data Engineer,50000  100000 a yearcontracta successful data engineer will have the following·bs degree in computer science computer engineering or a related technical degree or an equivalent combination of education and experience·3 or more years of experience in apachespark with development experience inscala or pyspark·experience working in java  rest apis·development experience in python·strong knowledge of hadoop or other big data platforms·3 or more years of experience working within an agile software development life cyclepreferred qualifications·at least 3 years of experience using version control repositories such as svn or gitjob types fulltime contractsalary 5000000 to 10000000 year,75000.0,CO,False,data_engineer
Junior Data Engineer (2 yrs experience required),a junior data engineer will leverage a dynamic set of data management tools to profile select and target audiences for marketing efforts the role will assist in refining targeting strategies with our client engagement teams and delivering a data set to be ingested by one of our marketing platform or production processespeople with experience as a marketing data specialist data specialist would translate wellprimary responsibilities fulfill requirements on data projects within a predefined process while maintaining client budget and schedule and delivering the highest degree of accuracykeep track of all assigned action items and assigned projects to ensure they are completed in a timely mannerpartner with developers analysts and account executives to gather required materials and instructions necessary for completing data projects update and manage databases using client data sources process client results reports and prepare campaign files for productiondocument project procedures between agency team members client contacts and third party data partnersincorporate data from multiple sources using data software tools like microsoft excel access and sql server as well as other proprietary masterworks or third party software applicationsvalidate all data elements involved with client projects for content accuracy and procedural use including input data received from clients transformed data used for output and final output filestroubleshoot data errors and anomalies and provide recommended solutionsescalate anomalies and otherthananticipated results to project stakeholders as requiredposition requirementstechnical competencies excellent organizational skills and attention to detail plus the ability to multitask and negotiate prioritiesability to work at peak performance with limited direction and competing deadlinescommand of grammar and language sufficient to proofread professional documentsprevious experience in marketing production planning or nonprofit organizationsknowledge of database relationships and architectureexperience with ab testing and campaign segmentationproficiency with pythonproficiency in data management tools as appropriate to functions performed at masterworksrelational database management microsoft access and microsoft sql servercloudbased data lake technologies eg google big query or or amazon red shiftextract transform and load etl technologies with data hygiene practices toolbased sql scripting custom python and experience with matillion mulesoft or talend productsdata encryption and transfer technologies sftp or use of apisbehavioral competencies continuous learninginitiative and risk takingintegrityselfmasterycollaborationproblem solvinginnovation and changecommunicationdiversityresponsive to customer needsplanning and organizationresource maximizationquality resultsstewardshipwork experience 2 years of experience in related field marketing technology database managementeducational requirements bachelors degreejob type fulltime,,WA,False,data_engineer
Data Engineer,"instacart is building the best way for people anywhere in the world to shop for groceries since instacart started in 2012 weve launched sameday delivery in 200 us markets we are laser focused on delivering groceries from your favorite stores right to your door we now cover over 60 of us households and aim to have 80 coverage by the end 2018—thats 90 million households from a technology point of view the platform is complex rapidly scaling and processing millions of transactions in realtime all of the time our technology coupled with operational expertise enables instacart to deliver fresh groceries in as little as an hour this is a difficult problem to master and we are making it happen every day we solve incredibly hard problems to create an experience for our customers that is absolutely magical

the data engineering team at instacart is rapidly growing and you will have the opportunity to shape its direction and create large impact the team is looking for a motivated selfstarter with a drive to tackle a variety of data challenges at instacart

responsibilities


develop robust high performance batch and near realtime data pipelines
design develop and maintain data models for company wide data warehouses
work with modern data engineering infrastructure technologies eg snowflake airflow python
work in an agile collaborative environment

requirements


at least 2 years of relevant work experience post college
a high level of proficiency in one or more of the following domains
database design entity relationship modeling sql
python programming pandas scikit numpy
big data technologies eg hadoop spark
excellent written and verbal communication skills able to effectively collaborate with diverse teams
bsms in computer science engineering math other quantitative field or equivalent experience

benefits


talented and collaborative coworkers who will both push and support you
market competitive salary and equity
medical dental vision benefits
take what you need vacation and we really mean it
16 weeks maternity leave  8 weeks paternity leave so you can truly bond with your child
complimentary instacart express membership

resources


tech blog  httptechinstacartcom 
life at instacart  httpstwittercomlifeatinstacart 
team stories  httpsmediumcomlifeatinstacart 

",,CA,False,data_engineer
Data Engineer Migration & ETL,"5752 an hourcontractthis person will be responsible for migration of data from existing on prem systems into cloud data warehouse individual will be involved in all aspects of data migration including data analysis mapping etl development reconciliation testing and documentation  individual is accountable to estimate the work and ensure high quality deliverable ontime while adhering to policies and procedures of the group

responsibilities

projects and development
responsible for migrating data into cloud datawarehouse solution
individual will need to meet the requirements set by the business with a focus on data quality timeliness  group coding standards
work with other team members to ensure that all objectives and commitments are fulfilled in line with expectations agreements and standards
maintain consistency in processes and follow guidelines as laid out by team standards
monitor and report on progress on tasks assigned
understand and apply industry practices architectural standards and procedures relating to work assignments
translate business requirements and technical designs into welldeveloped solutions that meets business data and kpi goals
designing database queries views and functions for reporting and data analytics 
design and implement technology best practices guidelines and repeatable processes
optimize and refactor sql databases and database objects etl processes reporting and analytic solutions in support of business needs
evaluate and assess capabilities of new technologies and business intelligence tools as required
qualifications
strong experience data migrationintegration experience
bachelors degree in computer science information technology or related field
at least 5 years experience in data modeling development implementation and support of transactional databases and data warehouses preferably teradata
expert level experience in sql
experience with business intelligence reporting and analytical tools microstrategy tableau etc
experience working on cloud based platforms aws
data warehouse experience aws redshift snowflake computing
advanced expertise in performance monitoring and optimization
strong analytical critical thinking  problemsolving skills",,NJ,False,data_engineer
LE Data Engineer,"contractwho we are

fueled by a fundamental belief that having access to financial services creates opportunity paypal nasdaq pypl is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy our open digital payments platform gives paypal’s 244 million active account holders the confidence to connect and transact in new and powerful ways whether they are online on a mobile device in an app or in person through a combination of technological innovation and strategic partnerships paypal creates better ways to manage and move money and offers choice and flexibility when sending payments paying or getting paid available in more than 200 markets around the world the paypal platform including braintree venmo and xoom enables consumers and merchants to receive money in more than 100 currencies withdraw funds in 56 currencies and hold balances in their paypal accounts in 25 currencies
when applying for a job you are required to create an account if you have already created account  click sign in
creating an account will allow you to follow the progress of your applications

note
provide full legal first namefamily name
do capitalize first letter of first and last name example john smith
dont capitalize entire first andor last name example john smith
note use correct grammar for names with multiple cases example mcdonald or oconnell

provide full address details
resume is required
multiple attachments can be uploaded including resume and cover letter for each application


job description summary
data modeler lead  paypal enterprise solutions


about the enterprise solutions team


keeping the engine of the global economy strong and growing the enterprise solutions team a member of the paypal merchant organization is responsible for helping millions of paypal merchants manage and run their businesses on web and mobile we are responsible for building products that support paypal business customers from casual sellers to the world’s largest businesses we are currently working on building new enterprisegrade solutions to make our products even more dependable for largeenterprise customers putting ourselves in the best position to continue powering the world’s largest ecommerce and payments applications at a scale few companies can match

job description
we are looking for the best data engineer in the world who have a passion for developing enterprise scalable distributed and performance systems that require high availability to support missioncritical business tasks quality is at the forefront of everything our team does and we are looking for true passion for writing robust reusable and scalable
responsibilities

5 plus years experience in setting up etl solutions for large enterprises
experience on oltp and olap data modeling
experience in designing large oracle databases 500 tb with sharding
optimizing database index iot partitioning caching etc and query tuning for faster response time
assist development team on etl and db design and actively participate in code reviews
determines database structural requirements by analyzing upstream sources and downstream consumer needs
develops database solutions by designing proposed system defining database physical structure and functional capabilities
maintains application performance by periodically identifying reviewing and fine tuning those applications that cause database and etl performance issues
provides technical guidance to engineers whenever they deploy any newchanges to production in alignment with organizational data standards
works closely with enterprise data architects on new productpayment flows and determines the associated data contracts
play a key role in the data governance council that includes representation from upstream
partner with the data infrastructure team to provide leadership and guidance with enterprise data strategies
working knowledge on infrastructure  etl grid databases servers network and storage


subsidiary
paypal

travel percent
0

primary location
san jose california united states of america



additional locations


bachelors degree or equivalent




english
were a purposedriven company whose beliefs are the foundation for how we conduct business every day we hold ourselves to our one team behaviors which demand that we hold the highest ethical standards to empower an open and diverse workplace and strive to treat everyone who is touched by our business with dignity and respect our employees challenge the status quo ask questions and find solutions we want to break down barriers to financial empowerment join us as we change the way the world defines financial freedom


paypal provides equal employment opportunity eeo to all persons regardless of age color national origin citizenship status physical or mental disability race religion creed gender sex pregnancy sexual orientation gender identity andor expression genetic information marital status status with regard to public assistance veteran status or any other characteristic protected by federal state or local law in addition paypal will provide reasonable accommodations for qualified individuals with disabilities",,CA,False,data_engineer
Data Engineer,"as the data engineer youll be joining a team of passionate engineers designers and product managers together we answer business questions through data

blue bottle coffee is growing presenting us with exciting opportunities to solve interesting challenges and help create solutions to serve our production teams our retail teams and hq teams youll create impact that you can see and taste working on all parts of the data stack
you will
build maintain and troubleshoot etl pipelines for several data sources
build microservices to augment or supplant more involved etls
build automated testing performance evaluations monitoring tools and dashboards
work with and build apis fromfor other microservices and outside services
evaluate and when necessary rebuild existing etls
you are
constantly learning and eager to iterate hungry to build better software and are constantly finding better ways
a team player comfortable working as part of a group excited to share knowledge and welcome support
adaptable and versatile able to find compromises in situations where there is not one right answer
able to breakdown complex problems into solvable pieces of work
you have
production experience with data engineering
experience with cloud infrastructure
ability to model data and write sql
familiarity with testing a data application integration testing and processes that rely on cicd
familiarity with machine learning
a few benefits we offer
medical dental and vision coverage for all fulltime employees and their dependents starting on their first day of work
401k plan
paid time off and parental leave
annual conference budget
free drinks at any of our cafes and a complimentary bag of beans to take home each week
discounts on any blue bottle food items and merchandise
blue bottle is an equal opportunity employer we value an open mind dedication to work and a collaborative spirit we hire based on these qualities a job’s requirements our business’s needs and an applicant’s qualifications we do not tolerate discrimination or harassment of any kind—in the hiring process or in the workplace

we comply with the ada and consider reasonable accommodation measures that may be necessary for eligible applicantsemployees to perform essential functions if you have a disability or special need that requires accommodation please contact us at careersbluebottlecoffeecom

we may refuse to hire relatives of present employees if doing so could result in actual or potential problems in supervision security safety or morale or if doing so could create conflicts of interest

we will consider for employment qualified applicants with arrest and conviction records

we participate in everify we will provide the federal government with employees’ form i9 information to confirm authorization to work in the us we will only use everify once an employee has accepted a job offer and completed the form i9",,CA,False,data_engineer
Data Engineer ( Contract ),contractdata engineerresponsibilities leverage microsoft bi suites to provide actionable insights into customer acquisition and other key business performance metricsengineer a modern data pipeline to collect organize and process dataproduce clean reusable code that is unit tested code reviewed and adheres to code standardsrequired qualifications strong sql and data warehousing skillsstrong analytical skills and problemsolving capability3 years of experience in implementing bi solutions with ssasssisssrs1 years of experience in power biability to communicate and collaborate with peopleability to operate effectively and independently in a dynamic environmentpreferred qualifications experience in cosmosazure data lakeexperience in azure analysis serviceexperience in data security area rowbased security objectbased securityjob type contractexperiencepower bi 1 year requireddata warehouse 1 year preferredsql and ms bi stack ssas ssisssrs 3 years requiredinformation security 1 year preferredmicrosoft sql server 5 years requirededucationbachelors preferredwork authorizationunited states preferred,,WA,False,data_engineer
Data Engineer,"the data engineer position is responsible for the integration of enterprise data by developing testing and implementing packages and programs using microsoft’s ssis andor informatica’s power center in addition this position is responsible for building maintaining reference tables master data domains and data extracts that are needed to ensure the efficient and accurate processing of information within vidant health
typical tasks will include but are not limited to requirements gathering analysis software architecture and design software development testing implementation and documentation
responsibilities
analyzes designs build test and implement integration technology solutions that meet the specifications of a project or service request
effectively utilizes standard enterprise tools to develop or implement technical solutions
writes test cases and report results
identifies problems following problem management expectations and performs problem resolution
resolve most reported issues independently or escalates as needed to senior engineers
provides preventative maintenance troubleshooting and quickly resolves routine problems to ensure infrastructure and application stability
adheres to standards and best practices processes and deliverables in accordance with standards
participates in defining operational readiness requirements
follows testing best practices and standards
adheres to sla expectations
writes technical specifications for respective applications or infrastructure platforms
participates in creating prototypes or proofs of concepts for new infrastructure technology
remains current with respective technology capabilities
collaborates with project managers to resolve requirements gaps uncovered in design or within specifications or requirements
prepares technical documentation for platform service or infrastructure technical components
adheres to change and incident management standards and expectations
minimum requirements
bachelors degree in information technology or related field or relevant work experience required
4 years experience in an etl administration or etlapplication development environment experience working with project teams to design and implement new solutions
experience working in teamoriented collaborative environment
independently motivated to seek knowledge in areas pertaining to their current position exhibits proficient in either ssis or informatica etl tools
1 years applicable experience in the healthcare  health domain with good understanding of hipaa data privacy and security requirements
selfeducates and seeks knowledge from mentors  management of vh information services and other business leaders from vh
2 years of working with dimensional modeled data knowledge of data vault modeling techniques
expert level knowledge in writing sql code for queries stored procedures data cleansing and manipulation

other information
questions email jobsvidanthealthcom
general statement
it is the goal of vidant health and its entities to employ the most qualified individual who best matches the requirements for the vacant position
offers of employment are subject to successful completion of all preemployment screenings which may include an occupational health screening criminal record check education reference and licensure verification
we value diversity and are proud to be an equal opportunity employer decisions of employment are made based on business needs job requirements and applicant’s qualifications without regard to race color religion gender national origin disability status protected veteran status genetic information and testing family and medical leave sexual orientation gender identity or expression or any other status protected by law we prohibit retaliation against individuals who bring forth any complaint orally or in writing to the employer or against any individuals who assist or participate in the investigation of any complaint",,NC,False,data_engineer
Data Engineer,"spun out of mit in 2014 zylotech is a disruptive aipowered customer data analytics company located just 5 minutes walking from the kendall square t station we are ‘zylotechies’ big thinkers with a sense of fun who love working in an open environment full of startup perks

why youll love working here

zylotech is a fastgrowing company that rewards autonomy and creativity our team is hard working fast and collaborative and we encourage working on personal growth there will be many opportunities to work with other departments and youll be able to interact with some incredibly talented people

what you’ll do

1 explore client data analyze and implement etl process using open source data science platforms

2 write pythonspark scripts for model verification andor query database

3 analyze customer data back testing writing test cases for product layers executing test cases writing test plan conduct uat

4 monitor model performance and advising any necessary devops changes

5 build quick pocs  prototypes around data problems

what we seek
 a hustler we encourage hacking out creative ways to find and build simple and effective solutions to complex problems
 expertise in python spark
 experience in databases nosql and sql cloud databases
 experience in datawarehouse data analysis
 experience in etl tools and techniques
 flexible to learn and build solutions using frameworkstools across technologies

about zylotech

zylotech is a selflearning customer data platform that helps marketers create complete customer profiles for targeting revenue opportunities more effectively powered by automl the platform continuously unifies and enriches internal and external data and performs ongoing microsegmentation pattern discovery and recommendations all while integrating with a variety of marketing clouds for ondemand accessibility zylotech’s crossindustry clients have reported up to a 6x increase in customer lift for more information visit zylotechcom

zylotech is an equal employment opportunity employer and does not discriminate against any applicant because of race creed color age national origin ancestry religion gender sexual orientation disability genetic information veteran status military status application for military service or any other class protected by state or federal law

to all recruitment agencies zylotech does not accept agency resumes please do not forward resumes to our jobs alias zylotech employees or any other company location zylotech is not responsible for any fees related to unsolicited resumes unsolicited resumes received will be considered our property and will be processed accordingly

qualified applicants must be legally authorized for employment in the united states qualified applicants will not require employersponsored work authorization now or in the future for employment in the united states",,MA,False,data_engineer
"Data Engineer, In Our Backyards Campaign","reducing the use of jails
please note that we will be moving our headquarters to industry city in brooklyn ny next year
the vera institute of justice is working to build national momentum toward reversing mass incarceration everywhere in america it’s an ambitious goal—so we’re also building a skilled team of researchers who like big ideas and big challenges does that sound like you if so read on
in the last decade the geography of mass incarceration underwent a quiet dramatic shift as incarceration rates in america’s biggest cities leveled out and then declined rates in small cities and rural america continued to rise today thousands of often overlooked smaller cities towns and rural areas have the highest rates of incarceration and increasingly the most outsized jails this untold story calls for ending mass incarceration where it begins—in all of our backyards
to spark reform vera’s in our backyards project is advancing an ambitious research and communications agenda to inform the public dialogue and guide change to justice policy and practice our work is driven by the realization that if we do not respond to the shifting geography of incarceration the apparent national gains—driven by prison and jail population declines in large metropolitan areas—will be eroded by deepening problems in the small and rural communities across the country that actually comprise most of the population
responsibilities
the data engineer will work in close collaboration with the team to collect manage and analyze data relevant to the criminal justice system to visualize the results of these analyses and to report findings to our partners and the public data analysis data management and software development will be the primary focus
this position will join an interdisciplinary crossfunctional team that includes data scientists policy experts ethnographers and writers that span the research policy and communications functions at vera
what we need in you
experience assisting with research projects in an academic or professional setting our projects involve working with criminal justice system data to answer cuttingedge research questions handson experience with the research process and intimate familiarity with how to work on a research team are required
algorithmic reasoning skills many of the problems you will solve require devising a stepbystep procedure from a problem statement to a solution experience solving such problems is a must
proficiency in at least one programming language your duties will include creating or modifying code that retrieves maintains analyses and visualizes data from the criminal justice system experience in python matlab or r are preferred but no languagespecific experience is required
strength in data much of the work will involve collecting cleaning and maintaining large datasets experience working with and managing data are key
commitment to the missions of racial justice and ending mass incarceration you need to be fluent in the language of both and familiar with their relationship to communitypublic safety
you’re selfmotivated collaborative and look for how you can help without being told collaboration is a vera value – we thrive when we learn and build on each other’s ideas and are open to giving and receiving feedback what’s more it’s absolutely essential for the fastworking in our backyards team which is taking on big challenges and delving into an area of reform where so much is still unknown
qualifications
candidates must possess these minimum qualifications
demonstrated experience in dataset preparation and analysis
proficiency in at least one programming language
strong interest or experience in criminal justice and social justice for underserved populations
ability to work on multiple projects effectively and efficiently both independently and collaboratively
excellent oral and written communication skills
a commitment to a collegial and collaborative workplace
an excellent candidate will have some combination of the following
experience with database development
experience developing software
experience with statistical analysis using python matlab stata or r


salary based on experience and including excellent benefits vera believes in compensating its staff members at or above market
to apply
please submit cover letter and resume and if available a link to your github portfolio
no phone calls please only applicants selected for interviews will be contacted
online submission in pdf format for cover letter and resume is strongly preferred
however if necessary materials may be mailed or faxed to
attn people and culture
vera institute of justice
233 broadway 12th fl
new york ny 10279
fax 212 9419407
please use only one method of submission online mail or fax
vera is an equal opportunityaffirmative action employer all qualified applicants will be considered for employment without unlawful discrimination based on race color creed national origin sex age disability marital status sexual orientation military status prior record of arrest or conviction citizenship status or current employment status
vera works to advance justice particularly racial justice in an increasingly multicultural country and globally connected world we value diverse experiences including with regard to educational background and justice system contact and depend on a diverse staff to carry out our mission
for more information about vera please visit wwwveraorg
related
american jail the modern tragedy of mass incarceration",,NY,False,data_engineer
Data Engineer - 439,"job description

job id 439
position data engineer
location lombard il
type c2h

top 3
1mix of building and developing spark r and python
2 experience building data pipelines to the cloud their cloud technology is wherescape
3 understanding of data flows to and from the cloud
 must be selfdirected go getter developer mind set connect the dots get work done a data engineer who will take a ask and run with it

qualifications

null

additional information

all your information will be kept confidential according to eeo guidelines",,IL,False,data_engineer
Data Engineer,"about critigen
we develop innovative applications using the best technology out there our data and software engineers play a huge role in helping our clients make sense of complex data that make important things visible we are curious by nature and serve as valued consultants to our clients our developers enjoy the freedom to explore new tools and methods and apply them in a collaborative team environment
position overview
critigen is looking for data engineers who have a passion for map data we are building a team that will own a data pipeline to transform data from a variety of sources to high value services which provide a variety of mapbased functions task will include monitoring data streams evaluating issues analyzing patterns and developing algorithms and repeatable tools to automate and improve processes you will be a great team collaborator with excellent communication skills
key qualifications
bs ms in computer science or equivalent
2 years in either qa or release management role
strong written and verbal communicator
excellent problem solving and debugging skills
familiarity troubleshooting software and data issues using linux based environments
understanding of distributed computing
experience with apache airflow and spark
experience with nosql systems
pythonbash or similar language experience
ability to work in an agile environment
great work habits organizational skills and flexible enough to roll with changing priorities and tight deadlines
a strong sense of responsibility and an obsession with quality
preferred qualifications
familiar with openstreetmap osm or commercial map data
knowledge of directed acyclic graphs
experience with clis and scripting in linux based systems
experienced with source control tools such as github
critigen is an equal opportunity employer femaleminorityveteransdisabledsexual orientationgender identity",,WA,False,data_engineer
SQL Data Engineer,600  700 a daycontractit10130330sql data engineernew yorkup to 700 per day dependant on experience6 – 12month contractour client a cloud transformationtechnology consultancy with offices in the us uk emea are currently looking for an sql data engineer to join their growing team as a senior sql data engineer you will be playing an integral part in helping our client build an exciting sophisticated software tooling which will be placed within the marketplacejob objectives document design and concepts that will be utilized to help solve complex data architecture problemsworking with stakeholdersfast paced environmentexcellent understanding of solving complex problemsimplementing solutions into executable codesdeliver database solutionsdevelop and maintain databasesanalysis of datadesign and build strong and scalable solutions managing structured and unstructured data using traditional databasesconduct end to end analysis including data gathering etcprepare and perform data analysis and transformations to align data to business ruleswork through early stages of software life cycle to profile data and to conceptual logical and physical data model designsprovide gap analysisdeliver documentation including technical designs data flow erd’s and mapping documentsresponsibilities work with data owners designers creating technical specificationsapplication lifecycle analysis and definition system design implementation testing and deploymentliaising with the team’s applications architect to improve upon database and application designwork with our clients subject matter experts to obtain a greater understating of the business needs and goalsprovide technical expertise and capabilities in sql query writingwork closely with web development team in ongoing development and maintenance of databases applications or toolsare you a senior sql database engineer who would like to be considered for this exciting adventureare you an expert in sql querying writingable to solve complex problems and find solutionswe want to hear from youplease send your cv or call the team at talent analytixtalent analytix is acting as an employment agency in relation to this role due to the number of applications received please note that if you do not hear from us within 2 weeks we will not be proceeding with your applicationjob type contractsalary 60000 to 70000 dayexperiencesqldata 5 years requiredwork authorizationunited states required,,NY,False,data_engineer
Data Engineer – All Levels,"at datasync technologies our data engineering professionals touch every area of our company their insights drive our decisions and their innovations fuel projects when you join our team of data experts you’re helping datasync’s customers make better smarter and faster decisions every day see how you can help us solve some our customer’s most challenging data problems while you grow your skills and build your own future
job description
datasync technologies is seeking data engineers to support a mission critical program within the intelligence community
requirement
only candidates with active government security clearances and appropriate poly will be considered must be a us citizen
responsibilities will vary by specific data engineer role – data architect data scientist database engineer data governance to include the following
design and develop methods processes and systems to consolidate and analyze structured and unstructured data from diverse sources including “big data” sources
develop and use advanced software programs algorithms query techniques model complex business problems and automated processes to cleanse integrate and evaluate datasets
analyze the requirements and evaluate technologies for data science capabilities including one or more of the following natural language processing machine learning predictive modeling statistical analysis and hypothesis testing
develop information tools algorithms dashboards and queries to monitor and improve business performance maintain awareness of emerging analytics and bigdata technologies
designs implement and maintain standard data interfaces for data ingest including extracttransformload etl methodology and implementation apis restful web services data quality and data cleansing
provide data services data administration data management and “big data” support in clientserver virtual machine hadoop and cloud infrastructure environment andor migrations between these environments
database installation configuration and the upgrading of database server software and related products backup and recovery policies and procedures database implementation security optimization multidomain operation and performance management
hadoop cloud and other technologies associated with data storage processing management and use
the migrationtransition of database capability into cloud based technologies andor creation of interfaces between classic relational databases and key indexes to cloud based columnar databases and map reduce index capabilities
preferred qualifications all not required
databasesdata stores oracle mysql hive hbase and hdfs
frameworks hadoop rails javascript frameworks soawebservices jsp
indexing solr and lucine
developmentscripting languages java j2ee python ruby javascript mapreduce pig xml sql jaql html css xml bash ant and perl

what makes datasync technologies different
leadership training we provide employees with a variety of learning opportunities including access to exclusive classes professional growth training and more
feedback  mentoring we believe in talking—often so we have oneonone feedback sessions for every employee
community service we believe in helping the community where we work datasync and its employees donate time and services on a regular basis to local military charities we believe in helping both inside and outside of the office
social events we plan social events on a regular basis to help our employees relax and socialize so we get to know one another outside of our job titles
datasync is an eeo and affirmative action employer of femaleminoritiesveteransindividuals with disabilities
equal employment opportunity

all employment decisions shall be made without regard to age race creed color religion sex national origin ancestry disability status veteran status sexual orientation gender identity or expression genetic information marital status citizenship status or any other basis as protected by federal state or local law
information about equal employment opportunity eeo and employee polygraph act eppa provisions in addition to other federal labor laws can be found at httpwebappsdolgovdolfaqgodolfaqaspfaqid537
datasync is committed to providing veteran employment opportunities to our service men and women
wwwdatasynctechcom

wwwfacebookcomdatasynctechnologies

wwwtwittercomjobs at datasync datasyncjobs

wwwtwittercomdatasynctech

datasynctech on instagram

interested in joining our team  check out this youtube video

cj",,VA,False,data_engineer
Data Engineer,"overview
healthcare is an opportunity to utilize data assets including electronic medical records population health databases and clinical care models to have immediate and wide impact on peoples lives the data engineer is responsible for developing products to serve the analytic needs of the health system through the application of tools such as visualizations software development and statistical analyses driven by data resources

responsibilities
this position is expected to carry out sophisticated operations with data to procure transform and organize data that is required to develop insightful and actionable information they should therefore be capable of complex and creative problem solving with the ability to complete difficult projects that fulfill our outcomes based mission the ability to coalesce multiple sometimes divergent data sets to fulfill the requirements of data science and analytics is required creative solutions are encouraged and immersive experiences preferred

primary skills for this position include those requisite for developing the backend databases and data structures required for the development of analyses that use data to enable analyses information delivery and interaction with users successful candidates should have a good understanding of multiple data engineering programming languages such as sql including ssis hive hadoop spark or storm our shop is primarily python and so enough python to be dangerous couldnt hurt r is ok too domain knowledge in informatics or information modeling will be valuable
knowledge of information architecture as defined in the field of design as well as the field of data architecture is preferred to enable the candidate to construct integrated sets with complex data
ability to work with data science teams to assist in delivery of analytical outcomes and modelsability to develop maintain and test data systems and architectures especially with automationability to generate a quality work product in a timely manner while maintaining a strong attention to detailwork closely with business users and the analytics team to design data modelsutilize automation to create set processes for specific data ingestion transformation and access proceduresidentify and communicate new data needs effectively to the leadership teamsupport other members of the team with the ability to explain methodologies and assist in developmentbe a strong learner with the understanding of continuous professional and technical improvement of skills and techniques

qualifications
education
minimum bachelors computer science business statistics information sciences healthcare design engineering
preferred masters in healthcare computer science informatics analytics statistics engineering

requirements
healthcare experience preferred but not required
significant background with sql and expertise is required additional competency with any big data technologies and cloud platforms are a plus hive pig spark storm hadoop  aws azure cloudera
being conversant in data science languages r python scala are very useful

atlantic health system aims to deliver the highest quality and care combined the best experience for our patients and their families we are confident that you will find success within atlantic health system which has been named for the 8th year in a row to fortunes top 100 best us companies to work for list we believe youll find that our culture of collaboration and care exemplifies the value we place on our patients their families and our employees

atlantic health system aims to deliver the highest quality and care combined the best experience for our patients and their families we are confident that you will find success within atlantic health system which has been named for the 8th year in a row to fortunes top 100 best us companies to work for list we believe youll find that our culture of collaboration and care exemplifies the value we place on our patients their families and our employees

all qualified applicants will receive consideration for employment without regard to race national origin religion age color sex sexual orientation gender identity disability or protected veteran status",,NJ,False,data_engineer
Data Engineer,"job description

what do you do
artificial intelligence and machine learning are at the core of modern money mart you would be part of a new cuttingedge artificial intelligence and machine learning center of excellence tasked with developing innovative solutions for helping the business grow and become more efficient you get the gist – enjoy the experience of working on high impact silicon valley style projects while living in dallas or pa outside philadelphia you also get to learn about how big data is revolutionizing the world of consumer financial services

what do we need
you to have an amazing personality and communication style
that you are superorganized and are a problem solver
that you take pride in everything that you do and it shows
and most importantly that you have unquestionable integrity

why work for us
we invest in our employees and offer extensive training and development programs to set you up for future success
if we sound like a fit and you’re ready to start an exciting career with an organization that fosters employee growth apply today

job description
this position will be responsible for
manage the full lifecycle of assigned data projects from requirements to technical design platform data and automation routines to project deployment of the proposed lab solution
identify obtain understand and move data sets through the companys big data ecosystem
move large data sets from multiple sources and ingest this data into company environment
hands on data acquisition and integration using hadoop  aws cloud stack
perform detailed analysisdesign of functional and nonfunctional requirements and translate them to solutions
perform advanced data discovery profiling and assessment on required data
provide data subject matter expertise

qualifications

education
bs in computer science or related scientific fiel

experience
5 years of professional experience in a business environment
3 years of relevant experience in data engineering
preferred qualifications
masters degree in computer science or related technical field
710 yeas of technical business experience – etl experience
47 years of solid hadoop experience – scoop pig hive…
experience with sql hadoop unix scripting

skills
technical experience with big data visualization applications
ability to clearly articulate pros and cons of various technologies
ability to document use cases solutions and recommendations
strong communication and data presentation skills
the motivation to achieve results in a fastpaced environment
strong attention to detail
comfortable working in a fast paced highly collaborative dynamic work environment
additional information

benefits
medical  dental vision benefits available after 30 days of employment
company paid life insurance
paid holidays
pto 401k  tuition reimbursement
all your information will be kept confidential according to eeo guidelines",,TX,False,data_engineer
Data Engineer / (Business Intelligence),required experience skills and qualificationstitle data engineermorrisville ncfte full timewe are looking for a data engineer who will be part of our analytics practice and will be expected to actively work in a multidisciplinary fast paced environment this role requires a broad range of skills and the ability to step into different roles depending on the size and scope of the project its primary responsibility is the acquisition transformation loading and processing of datapreferred qualifications 5 years of related experience is requireda bs or masters degree in computer science or related technical discipline is requiredetl experience with data integration to support data marts extracts and reportingexperience connecting to varied data sourcesexcellent sql coding experience with performance optimization for data queriesunderstands different data models like normalized denormalied stars and snowflake models worked with transactional temporarl time series and structured and unstructured dataworked in big data environments cloud data stores different rdbms and olap solutionsexperience in cloudbased etl development processesexperience in deployment and maintenance of etl jobsis familiar with the principles and practices involved in development and maintenance of software solutions and architectures and in service deliveryhas strong technical background and remains evergreen with technology and industry developmentsjob type fulltimeexperiencebusiness intelligence 5 years requirededucationbachelors preferredwork authorizationunited states required,,NC,False,data_engineer
Data Engineer,"spotify is looking for a data engineer to join us you will build data driven solutions to bring music and digital media experiences to our 100 million active users and millions of artists either by working directly on product features publishing and insight tools for artists or by improving the quality of our data tools and large scale data infrastructure you will take on complex datarelated problems using some of the most diverse datasets available — user behaviors acoustical analysis revenue streams cultural and contextual data and other signals across our broad range of mobile and connected platforms above all your work will impact the way the world experiences music

what you’ll do
build largescale batch and realtime data pipelines with data processing frameworks like scalding scio storm spark and the google cloud platform
leverage best practices in continuous integration and delivery
help drive optimization testing and tooling to improve data quality
collaborate with other engineers ml experts and stakeholders taking learning and leadership opportunities that will arise every single day
work in cross functional agile teams to continuously experiment iterate and deliver on new product objectives
who you are
you know how to work with high volume heterogeneous data preferably with distributed systems such as hadoop bigtable and cassandra
you are knowledgeable about data modeling data access and data storage techniques
you care about agile software processes datadriven development reliability and responsible experimentation
you understand the value of collaboration within teams",,NY,False,data_engineer
Data Engineer (Machine Learning Focused),"at toyota research institute tri we’re working to build a future where everyone has the freedom to move engage and explore with a focus on reducing vehicle collisions injuries and fatalities join us in our mission to improve the quality of human life through advances in artificial intelligence automated driving robotics and materials science we’re dedicated to building a world of “mobility for all” where everyone regardless of age or ability can live in harmony with technology to enjoy a better life through innovations in ai we’ll…
develop vehicles incapable of causing a crash regardless of the actions of the driverdevelop technology for vehicles and robots to help people enjoy new levels of independence access and mobilitybring advanced mobility technology to market fasterdiscover new materials that will make drive batteries and hydrogen fuel cells smaller lighter less expensive and more powerful

our work is guided by a dedication to safety – in how we research develop and validate the performance of vehicle technology to benefit society as a subsidiary of toyota tri is fueled by a diverse and inclusive community of people who carry invaluable leadership experience and ideas from industryleading companies over half of our technical team carries phd degrees we’re continually searching for the world’s best talent ‒ people who are ready to define the new world of mobility with us

we strive to build a company that helps our people thrive achieve work life balance and bring their best selves to work at tri you will have the opportunity to enjoy the best of both worlds ‒ a fun start up environment with brilliant people who enjoy solving tough problems and the financial backing to successfully achieve our goals if you’re passionate about working with smart people to make cars safer enable the elderly to age in place or design alternative fuel sources tri is the place for you ‒ start your impossible with
about the machine learning  cloud platform team
the role of senior data engineer for machine learning ml infrastructure is at an exciting intersection between large scale deep learning and world scale data processing

ml as a member of the ml team you work alongside top research scientists in the field you are responsible for enabling cuttingedge deep learning to be applied to petabytescale and beyond volumes of sensory data including video lidar radar coming from our cars robots and other data collection platforms you interact closely with our cloud data team to design and deploy largescale distributed infrastructure for rapid experimentation training and inference you are passionate about applying cuttingedge machine learning to realworld problems in autonomous driving and robotics and about building the required frameworks and tools to do so

data as much code runs inside an autonomous car or robot even more code runs in the cloud services and pipelines that process data is what our machine learning mapping robotics and simulation teams build to implement their own initiatives the cloud data team is responsible for designing and implementing the set of services libraries tools and dashboards that make this possible we think about scale “consume petabytes of driving data” governance “explain through data that our car did the right thing” and crossplatform execution “deploy an imageprocessing service in aws or inside a robot” we are looking for engineers that can make this possible
responsibilities
maintain and continuously improve large scale iterative labeling experimentation training and deployment pipelines for modern deep learning on cameras lidars radars and other sensors
collaborate with other software engineers and research scientists to develop highperformance frameworks and tools for deploying and managing services and data pipelines from cloud storage to gpus
communicate scope and design new features to meet the needs of clients inside and outside of tri
developintegrate labeling tools and work with teams to provide groundtruth in support of machine learning and simulation
live and breathe the software practices that produce maintainable code including automated testing continuous integration code style conformity and code review
qualifications
bachelors degree in computer science or equivalent
strong communication skills team player good listener
strong python skills including scipy stack
experience with c is a plus
experience integrating with cloud apis especially aws
experience with highperformance computing gpus performance optimization
strong ability to write unit testable code
experience with data stores and related technologies for ingesting indexing and analyzing large amounts of time series and video data s3 parquet alluxio big data filesystems cloudera stack etc
experience with relational or nosql systems and integrations across different data stores
experience integrating with ci tools programmatically especially jenkins
experience with docker registries and container deployment services eg aws ecs kubernetes
experience with related tools and processes git continuous integration code reviews
experience with data transformation tools like opencv pandas etc
qualifications bonuses
experience working with machine learning especially computer vision deep learning a very big plus
experience building and growing image and video labeling pipelines
experience with software development on top of deep learning frameworks like pytorch preferred mxnet tensorflow
experience with big data pipeline a plus and pipeline orchestration frameworks such as spark airflow kafka",,CA,False,data_engineer
Data Engineer,the data engineer will lead the development of data warehousing solutions to power business intelligence at the hive they will synthesize business requirements for analytics operational and fundraising information creating and implementing solutions to integrate data from various enterprise systemsmissionthe united states association for unhcr usa for unhcr supports the un refugee agency’s humanitarian work to protect and assist refugees around the world the organization strives to meet the unmet needs of the world’s most vulnerable people building support and awareness in the united states for unhcr’s life‐saving programs established in 1989 by concerned american citizens usa for unhcr is a 501c3 notforprofit organization headquartered in washington dc with an office in new york nyessential duties and responsibilitieswrite code to build etl processes to integrate information from various enterprise it systemsability to perform api integrations on platforms such as salesforce marketing cloud we use postgres sql for our data stores and aws for hostingdesign new data structures add to and optimize existing data schemasability to analyze upstream and downstream effects of a change in existing data structures and planning for change managementunderstand key strategies and business processes of internal clients across the organization in order to provide the best solution to achieve their outcomesconduct analyses of business or technical user needs document requirements and design tailored data solutionsmonitor performance of etl processes and build in redundancies to avoid risk of an information outageprovide support and troubleshoot questions arising from report developers and business users of these data solutionstrack and document work done and communicate progress with business users in a timely mannerability to adapt andor modify processes in response to changing circumstanceswell versed in specific industry best practices and an ability to adapt them to u4u’s environmentability to work effectively across multiple complex projectsresearch and recommend innovative and automated approachesqualifications to perform this job successfully an individual must be able to perform each essential duty satisfactorily the requirements listed below are representative of the knowledge skill andor ability required reasonable accommodations may be made to enable individuals with disabilities to perform the essential functionseducation andor experiencebachelor’s degree in computer science information systems or related field required andor combined equivalent of education and experience master’s degree preferred5 years of experience as a business or technical professional in business intelligence data modeling or related fieldexperience in defining and documenting complex systems requirementsexperience with data integration building database objects using sql optimizing queries and writing stored procedures   5 yearsexperience in data warehouse methodology and data modeling  3 yearsexperience in extracting data from various apisstrong ability to analyze business requirements and recommend solutionsability and desire to mentor and train othersexperience in software development methodologiesexperience in writing sql queries coding in python and creating systems in the cloud computing space preferably awsexperience with crm’s preferably salesforceexperience with working on different file types for both structured and unstructured dataphysical demandsthe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this jobtasks involve some physical effort ie some standing and walking or frequent light lifting 510 lb minimal dexterity in the use of fingers limbs or body in the operation of office equipment may involve extended periods of time at a keyboardextended periods of sitting at a workstation or desk and manual dexterity to work efficiently on computer keyboard for data entry and composing of documentswork environment the work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job the tasks will generally be performed in a typical office environment may also involve travel to some locations within the company’s region of operations and select donor locationsdisability specificationsusa for unhcr will make reasonable accommodations in compliance with the americans with disabilities act of 1990job type fulltime,,NY,False,data_engineer
Associate Data Engineer,"the hartford’s data asset management organization is seeking entrylevel talent to build careers in data at locations that include hartford connecticut in this role associates will grow in the data engineering track providing development support on the hartford critical data assets associates will participate in the entire software development lifecycle process in support of information data projects and grow with emerging technologies and processes

overall knowledge

you must be a team player with a positive ‘can do’ attitude and possess the following qualities
interest in data analytics technology and problem solving
excellent communication analytical interpersonal and organization skills required
organizational and time management skills with the ability to adjust to changing priorities in a fastpaced environment
entrepreneurial mindset
responsibilities
partner with various parts of the organization to build a working knowledge of the organization business processes and its customers
learn and utilize tools such as informatica b2b plsql hadoop etcto develop data assets that support organizational decision making via prototyping data discovery profiling etc
leverage data mining and business intelligence tools to analyze large amounts of data identifying relationships and patterns within the data
solve a range of core business and technical questions through data analysis
work is guided by more senior members of the team
qualifications
qualifications
bachelors degree – we are seeking may 2019 graduates
a desired cumulative gpa of 30 or higher out of 40 scale or equivalent at the time of graduation
desired majors include but are not limited to computer science engineering it management information systems data analytics applied mathematics and business
desire candidates with prior data analysis andor data engineer competencies
understanding of current and emerging it products services processes and methodologies
prefer familiarity with big data technologies and concepts on a hadoop platform eg scoop hive pig nosql etc…
prefer working knowledge of etl process and experience with sql


equal opportunity employerfemalesminoritiesveteransdisabilitysexual orientationgender identity or expressionreligionage

higclg
job function
 data engineering
primary location
 united statesconnecticuthartford
schedule
 fulltime
job level
 entry level
education level
 bachelors degree ±16 years
job type
 standard
shift
 day job
employee status
 regular
overtime status
 exempt
travel
 no
job posting
 oct 4 2018 80909 pm
remote worker option  no",,CT,False,data_engineer
Data Engineer,"hi were nutscom

were changing the landscape of snacking on nuts dried fruit chocolate and more we planted our roots in newark new jersey during the great depression selling premium nuts on mulberry streets openair market weve come quite a long way since then taking our multigenerational family business online in 1999 even after 90 years we continue to pride ourselves in expertly sourcing the highest quality foods and treating our customers like family

whats our team like were driven collaborative and entrepreneurial energy and passion power our business and we look for candidates who share in that excitement to help us continue to build something special

the role

at nutscom we love our customers and we love data and while were happy to say that we have a lot of both we need help bringing it together managing it and making it useful  to us and to our customers this is where you come in were building our business on this foundation of data and youll make sure its a stable one

in partnership with an awesome analyst youll run everything from heavy crosschannel analysis of media interaction logs to optimize paid media to distilling purchase data down to understand our customer better you will help us think of innovative ways to make it even more enjoyable and valuable to shop with us

we have thousands of items a datadriven warehouse a robust order management system an exhaustive tagging footprint a growing number of media outlets and happy engaged customers if youre already imagining all the cool stuff well be able to build with that then we should talk

what youll do


collaborate with analysts marketers and department heads to define use cases solutions crossfunctional projects and priorities
maintain a holistic vision of the organization its data and its customers enough to recognize and even anticipate their data needs
define build and launch the solutions that make it all a reality
gather transform clean and secure data from many sophisticated stateoftheart sources and destinations
build pipelines that move the data to through and from all of the sources and also identifying how they should be connected in the first place
identify how the data will be used once its all built
respectfully and energetically express your thoughts and data philosophy to nontechnical smes backing up clear reasoning behind all tool  infrastructure decisionsproposals
architect create and build systematic solutions to tough problems such as the continuous data flow from networked sensors and the etl pipelines for all systems transactional and otherwise

what youll bring


bachelors degree
3 years of experience architecting traditional and big data solutions in sql and nosql databases ideally for ecommerce applications
2 years experience manipulating processing and extracting value from large disconnected datasets
1 years experience in dimensional data modeling and implementing these models in customer data platforms  crm systems
programming capabilities in common languages sql python java etc
handson experience architecting and implementing data infrastructure from scratch using platforms such as aws redshift alooma databricks etc
experience integrating multiple data sources and formats eg weblogs google analytics google adwords zendesk etc
experience working in an agile scrumbased environment
curiosity and creativity with sound judgment and high degree of both integrity and empathy
effective written and verbal communication of datadriven solutions across all levels of the organization

bonus points if youre


experienced in
mathematical modelingstatistical modeling
machine learning
data structure and algorithm optimization
knowledgeable or have direct experience using business intelligence reporting tools eg looker periscope etc

what we offer


a challenging role in a rapidly evolving business
competitive compensation benefits and 401k match
paid maternity adoption and paternity leave
an everevolving range of perks theyre employee feedbackdriven so were continuously improving
a casual work environment jeans and sneakers are aok
all the nutscom snacks your heart desires  a 40 phenomenal employee discount

eeo statement

braver brands is an affirmative action and equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity gender expression national origin age protected veteran or disabled status or genetic information",,NJ,False,data_engineer
Data Engineer,"overview
the data engineer will provide it support and development for data services at vistra and will ensure the timeliness quality and accuracy of the data and platforms that support the data management and etl functions


responsibilities
implement and maintain it data and etl platforms understand and deliver on the functional support and data needs of data management within vistra 
follow data policies standards guidelines and procedures in order to ensure data to support reporting and analysis is available responsive and achieving business outcomes and objectives
implement data and etl solutions or enhancements to improve overall vistra data architecture conduct research and make recommendations on new data management processes and innovations
work closely with vendors service providers the business and internal team to define and understand analytics needs in order to achieve key performance indicators and service level agreements for the benefit of vistra and its business objectives
translate business needs into functional requirements updatecreate documentation business process designs functional designs data architecture
participate in projects and agile teams make recommendations and implement changes to mitigate risks and optimize data platform performance

requirements
bachelors degree in mis computer science or a related field from an accredited collegeuniversity or equivalent
03 years of experience in data management or related practice such as data science
proven ability to collaborate on crossfunctional teams
• experience with open source hadoop and cloud highly desirable



job family
information technology


company
vistra corporate services company


locations
irving texas


texas
we are a company of people committed to exceeding customer expectations great people teamwork competitive spirit and effective communication if this describes you then you will have a good career here



if you currently work for vistra energy txu or luminant please apply via the internal career site",,TX,False,data_engineer
Data Engineer,contractspark data management6 years development on hadoopsparkdevelopment experience using microsoft sql server postgresql mysql or oraclelarge data sets experienceexposure to data hygiene routines and modelsdatabase design development and data modeling experiencejob type contractexperiencespark data management 6 years preferred,,IL,False,data_engineer
Big Data Engineer,"exabeam provides security intelligence and management solutions to help organizations of any
size protect their most valuable information the exabeam security intelligence platform
uniquely combines a data lake for unlimited data collection at a predictable price machine
learning for advanced analytics and automated incident response into an integrated set of
products the result is the first modern security intelligence solution that delivers where legacy
security information and event management siem vendors have failed

position overview

we are looking for a big data engineer to join our data lake engineering team data lake team is responsible for building the nextgen log management system that enables siem at scale some of the scale challenges we face are very unique in the industry we are looking for someone who is very passionate about distributed systems and high scalability
responsibilities
design  build highperformant reliable systems which scale effectively irrespective of the size of the customer
take pride in delivering a top quality product
work closely with engineers pm and customer support
constantly learn innovate and mentor other members in the team
be responsible for endtoend delivery of features and provide support after launch
we are a startup  wearing multiple hats is expected and encouraged
write clean elegant code that solves complex problems
participate in design  code reviews
qualifications
bs in computer science or related
experience in any of these is a big plus elasticsearch logstash kafka mongo hbase spark hadoop
experience in linux
experience in scala python desired
exabeam is built by seasoned security and enterprise it veterans from imperva arcsight and
sumo logic we are headquartered in san mateo california and are funded by norwest
venture partners aspect ventures icon ventures lightspeed venture partners cisco and
investor shlomo kramer follow us on facebook twitter and linkedin",,CA,False,data_engineer
Data Engineer,contractjob summaryclient is looking for a senior data engineer with 8 years of experience data engineer with skillsrequired experience skills and qualificationsface to face interview required8 years of experiencemust have spark scala hadoop  javajob type contractexperiencespark scala hadoop  java 1 year preferreddata engineer 8 years preferredlocationnew york ny preferred,,NY,False,data_engineer
Sr. Data Engineer,"job description
would you like to support increasing customer base and the revenue for amazon web services aws a marketleading cloud offering would you like to be part of a team focused on increasing awareness and adoption of the aws platform by analyzing customers behavior on and outside aws website do you want to empower aws marketing team make the datadriven decisions that further establish aws as the leader in the cloud computing world

as a business intelligence engineer at aws in seattle you will be working in a large extremely complex and dynamic data warehousing environment we are looking for someone with the uncanny ability to integrate multiple heterogeneous data sources like adobe site catalyst adobe target sales force adobe connect with aws central data warehouse and build efficient flexible and scalable data warehouse and reporting solutions the candidate should be enthusiastic about learning new technologies and be able to implement solutions using these technologies to empower internal customers and scale the existing platform you should have excellent business and communication skills and be able to work with business owners to develop and define key business questions then build the data sets that answer those questions you should be expert at designing implementing and operating stable scalable low cost solutions to flow data from production systems into the data warehouse and into enduser facing reporting applications above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth

roles and responsibilities
understanding business requirements and converting them to technical solutions
create etls to take data from various operational systems like adobe target adobe connect sales force and create a unified dimensional or star schema data model for analytics and reporting
support technical program manager research scientist and a growing virtual team aimed at analyzing usage data to derive new insights and fuel customer success
use business intelligence and visualization software eg obiee amazon quicksight etc to empower nontechnical internal customers to drive their own analytics and reporting
develop a deep understanding of aws’s vast data sources and know exactly how when and which data to use to solve particular business problems
monitor and maintain database security and database software
support the development of performance dashboards that encompass key metrics to be reviewed with senior leadership and sales management
work with business owners to build data sets that answer their specific business questions
manage numerous requests concurrently and strategically prioritizing when necessary
basic qualifications

bachelors degree in cs or related technical field and 5 years of experience in data warehousing or masters degree in computer scienceinformation systems and 3 years of experience in data warehousing
3 years of relevant experience with etl and business intelligence architectures
knowledge of sql
understanding of advanced data warehousing concepts and track record of applying these concepts on the job
experience building selfservice reporting solutions using business intelligence software eg obiee tableau amazon quicksight etc
preferred qualifications

experience with amazon redshift or other distributed computing technology
exceptional troubleshooting and problemsolving abilities
excellent written and verbal communications skills
demonstrated ability to work effectively across various internal organizations",,WA,False,data_engineer
Data Engineer – Legal & Licensing,"we are looking for a very motivated data engineer to build the framework of data reporting and analysis for our licensing partners – labels and publishers this is a great opportunity for a data engineer that has worked on the back end of things to gain more business context by working closer to the partners and business

what you’ll do

design build and maintain a “licensing specific” data infrastructure which captures all data points needed by the licensing external partners and by the internal licensing team
design build and maintain the standard reporting for licensing external partners major labels and publishers for examples top charts free trial conversion market share top search active users etc
partner with licensing data scientists to drive business insights on labels and publishers
partner with licensing data scientists and the broader licensing team to drive partners business reviews
design build and maintain adhoc solutions and data pipeline to gather relevant data across the sprawling data infrastructure of spotify
become the center of excellence for data collection data taxonomy and data filtering specific to licensing partners
drive automation of standard reporting and distribution wherever possible
who you are

you are selfdriven and have a good understanding of the business and communicate well with nondata colleagues
you are interested in being the glue between engineering and analysis and feel comfortable working in a business oriented team
you are innovative and able to come up with new solutions to very tricky problems
you are passionate about crafting clean code and have a steady foundation in coding
you know scala and python language
you have experience in developingbuilding data pipelines batch or streaming
you are familiar with etl extract transform and load
tools and infrastructure such as gcp google cloud platform is a plus as well as familiarity with amazon or azure cloud
at least 23 years of relevant experience ie software engineering working with data analysis data modeling data processing as well as
great role if you’re interested in making a change

questions or interested in learning more contact andrea silvestrini asilvestrinispotifycom",,NY,False,data_engineer
Data Engineer,"invision is the digital product design platform used to make the worlds best customer experiences we provide design tools and educational resources for teams to navigate every stage of the product design process from ideation to development today more 4 million people use invision to create a repeatable and streamlined design workflow rapidly design and prototype products before writing code and collaborate across their entire organization that includes more than 80 percent of the fortune 100 and organizations like airbnb amazon hbo netflix slack starbucks and uber who are now able to design better products faster

our team is in search of an awesome data engineer to help us change the way digital products are designed

about the team
invisions data science  engineering team helps the rest of the business to measure and analyze the impact of ongoing product changes this allows us to make datadriven decisions about what to build next and do more of what works less of what doesnt

building scaling and owning a highvolume data pipeline—from the frontend event code all the way back to the data warehouse—requires constant collaboration with the brightest people in the organization whether youre at a beach house in hawaii or a coffee shop on the east coast youll have the support of brilliant developers analysts and scientists at your fingertips to get you through and keep the workday challenging and fun

what youll do

supporting and scaling the pipeline that relays data from invisions production applications back to our warehouse this includes
writing operating and documenting analytics libraries for our production apps
replicating state and events from mysql mongodb and kafka using various third party tools
maintaining and extending scripts and components to consume raw event data into our warehouse
monitoring and tuning redshift
organizing our data warehouse to be a selfexplanatory selfdocumenting performant resource for product managers engineers and business analysts
working with our data scientists to tune and improve shared scripts for postprocessing raw data into clean easytoanalyze schemas
restructuring our warehouse to support increasingly sophisticated and more realtime analysis
investigating new technologies for incorporation into our architecture
helping engineers implement best practices for measuring the business impact of their features

what youll bring

1 years of experience designing implementing and operating production etl and data pipelines
full stack development experience especially writing apis andor libraries called by coworker teams
a track record of maintaining databases mysql redshift etc andor querying them performantly
a quality mentality you write automation do spot checks and get creative to make sure the data youve stored tells the true accurate story of what happened
excellent communication and collaboration skills with coworkers teams and stakeholders

about invision
invision offers an incredibly unique work environment the company employs a diverse team all over the world each invision team member is given the freedom and tools to do their best work from wherever they choose

the benefits we offer in the united states and canada include competitive health plans and a retirement plans some invisionwide benefits offered to all employees across the globe include a flexible vacation policy monthly coffee shop stipends annual allowances for books related to your profession and home office setup  wellness reimbursements invision is an international employer so some benefit offerings will vary from country to country

invision is proud to be an equal opportunity workplace we are committed to equal employment opportunity regardless of race color ancestry religion sex national origin sexual orientation age citizenship marital status disability gender identity or veteran status if you have a disability or special need that requires accommodation please let us know",,CA,False,data_engineer
Data Engineer Intern,"internshipthis is an opportunity for
a a gap year internship of one year no 6 months internships
or
b an endofstudies internship of one year followed by a potential job offer based on performance

you would be joining agilone in our engineering department starting summer 2018 in one of our offices in california sunnyvalesan francisco
responsibilities
design build install test and maintain a highly scalable data platform
ensure that said platform meets business requirements and industry practices
write queriesjobsfunctions to feed and enhance the pipeline
develop efficient testable and welldocumented code
recommend ways to improve data reliability efficiency and quality
integrate new technologies and software engineering tools into existing platform
qualifications
bachelors degree in engineering information technology computer science mathematics or similar technicalanalytical degree
proficient in sql data analysisexploration
intellectual curiosity along with excellent problemsolving and quantitative skills including the ability to disaggregate issues identify root causes and recommend solutions
selfmotivated and good sense of ownership  comfortable working with limited direction
nice to have
experience with distributed databases or sql engine on hadoop  hive sparksql impala etc
experience with sparkhadoop ecosystem
experience in query performance optimization involving large datasets
experience in java scala or similar language data visualizationreporting  eg tableau excel pivottables
olap design and implementation and knowledge of mdx
nosql databases hbase mongodb couchdb cassandra etc
experience extending hive userdefined functions
experience in data governance access retention etc
experience with data workflow management tools oozie airflow etc
experience with streaming data pipelines kafka spark kinesis etc
agilone the customer data platform provides enterprise consumer marketers the power to integrate customer data across digital physical and mobile channels deliver customer analytics with predictive insights and 360degree profiles and engage customers at every touch point in order to maximize lifetime value currently the agilone solution supports more than 150 brands worldwide

we leverage the latest technologies in big data machine learning and data quality management to deliver an enterprisegrade scalable and high performance tool for customers such as tumi lululemon lilly pulitzer and david’s tea agilone is funded by the best in the valley  sequoia capital tenaya and mayfield

this position does not fit your skillset or your career plans please check all our internship offers data scientist internsolutions consultant internjava engineer intern",,CA,False,data_engineer
Data Engineer,"the blavity family is seeking a top performing data engineer to join our organization
the ideal person has worked with a wide variety of languages such as python and sql a variety of raw data formats in this role you will work in a highly collaborative environment to help provide datadriven insights that enable better decisionmaking
what you’ll do at blavity
build realtime data capture and transformation functionality across all products
work with other engineers to enhance data models and improve data query efficiency
create complex data queries to facilitate ad hoc and exploratory analytics
act as inhouse data expert and make recommendations regarding standards quality and timeliness
what you have
35 years experience working with nosql databases like mongodb
35 years experience working with relational databases like mysql or postgres
a solid understanding of the cap theorem and how distributed systems work
23 years experience using tools for ad hoc data manipulation like r
experience working with both large and small data sets in the cloud
degree in computer science or a related field or a minimum of 3 year’s working as a data engineer
curiosity and the ability to stay organized and driven to better analyze data and identify deliverables
eagerness to tackle new problems in a data driven environment
thrives in a fastpaced startup environment
more about us…
we are a venturefunded technology and new media company we have assembled an amazing team of passionate highenergy  focused teamplayers who cultivate our community and advance our strategic direction blavity is changing the landscape of media representation by building the world’s largest digital community for millennials of color blavity was founded in 2014 around a simple idea enable millennials of color to tell their own stories
today we average 3 million monthly unique visitors generate 3050 million monthly social impressions and distribute our message across all major social media platforms we are based in downtown la with team members working across the world blavity inc includes the following brands blavitycom 21ninetycom shadowandactcom travelniolrcom and afrotechcom
what we have to offer
cool office environment and culture
medical dental vision plans
401k matching program
health savings accounts
discretionary vacation policy
gym membership",,GA,False,data_engineer
DATA ENGINEER,"transforming the future of healthcare isn’t something we take lightly it takes teams of the best and the brightest working together to make an impact

as one of the largest healthcare technology companies in the us we are a catalyst to accelerate the journey toward improved lives and healthier communities

here at change healthcare we’re using our influence to drive positive changes across the industry and we want motivated and passionate people like you to help us continue to bring new and innovative ideas to life


if you’re ready to embrace your passion and do what you love with a company that’s committed to supporting your future then you belong at change healthcare

pursue purpose champion innovation earn trust be agile include all

empower your future make a difference
the new data science group was formed to dramatically increase leverage of emdeon’s data assets to create material new revenue opportunities both within specific business areas and also across multiple lines of business with data and transactions from more than 1200 payers and 340000 providers emdeon is uniquely positioned to impact us healthcare


do you like working with data do you want to use data to influence product decisions for products being used by over a third of us healthcare if yes we want to talk to you our data engineering team works very closely with product managers data scientists and architects to figure out ways to acquire and maintain data to support new and existing data products in this role you will see a direct link between your work and company growth in this role you will work with some of the brightest minds in the industry and youll get an opportunity to solve some of the most challenging business problems in healthcare at a scale that few companies can match


this role has the opportunity to be based in either san mateo ca or nashville tn



responsibilities

 interface with data scientists engineers and product managers to understand data needs

 build data expertise and own data quality for allocated areas of ownership

 design build and launch new data models

 design build and launch new data extraction transformation and loading processes

 building key data sets to empower operational and exploratory analysis

 define and manage sla for all data sets in allocated areas of ownership

 work with data infrastructure to triage infra issues and drive to resolution

join our team today where we are creating a better coordinated increasingly collaborative and more efficient healthcare system",,CA,False,data_engineer
Data Engineer,"if youre someone who is passionate about data seeks out complex data problems and wants to help build a new and exciting platform you should consider joining our team as a data engineer iex is building a big data platform to tackle specialized data problems with highperformance cloud technology to help achieve our mission of creating fairer financial markets were currently looking for a strong data engineer who can develop creative and scalable solutions to marshal unstructured data this person will have the opportunity to play a key role on a brand new venture and work directly with the traders at the worlds largest hedge funds and asset managers

if youre up for working in a fastpaced environment and with a small and highlycollaborative fintech team changing wall street for the better – join us

about you

selfstarter with the capability of executing on projects independently
strong analytical and problemsolving skills
collaborative team player
strong communication skills to distill clear ideas to traders and nontechnical audiences

what youll do

work with complex financial data sets
design flexible applications to normalize unstructured data
validate data accuracy and map content to a proprietary database
work closely with our tech and analytics teams to solve new data problems
conduct selfdirected research to enhance product capabilities and generate new content and ideas for traders

your background

programming and database experience
demonstrated ability to efficiently manipulate large data sets
experience as a data engineer
experience normalizing complex data sets at scale
nice to haves
phd in computer science engineering or mathematics
python numpy and pandas programming experience
understanding of financial products and equities

here at iex we are dedicated to an inclusive workplace and culture we are an equal opportunity employer that does not discriminate on the basis of actual or perceived race color creed religion alienage or national origin ancestry citizenship status age disability or handicap sex marital status veteran status sexual orientation genetic information or any other characteristic protected by applicable federal state or local laws this policy not only complies with all applicable laws and protects workers rights but is vital to iexs overall mission and values",,NY,False,data_engineer
Visualization Data Engineer,"about copper
somewhere along the way crm got really hard to use we’re changing that copper was built with three basic principles in mind keep it simple show what matters and make it actionable

copper is the no1 crm for g suite that’s recommended by google it works instantly through a seamless integration with g suite has a beautiful user experience and is designed to help teams and businesses build longlasting relationships copper services more than 12000 paid businesses in more than 110 countries

what youll do
a newly formed data analytics team is looking for a data engineer  visualization to bolster its ranks as one of the cofounding member of this team you will work closely with gtm finance product and engineering teams to build copper’s’ next generation analytics stack


participate in development initiatives to design develop and implement visualization to turn event analytics raw application data and business systems into key business insights
create translate develop evolve and optimize data models
translate business requirements into technical requirements and design solutions to adhere to standards and build visualization to drive core business intelligence
participate in data model reviews with other team members and data validation
monitor daily data loads and take corrective action as needed
write complex and efficient queries to transform raw data sources into easily accessible models for supporting data visualization
be the sql expert  advise and train analysts and engineers inefficient schema and query design
collaborate with pms data analysts and architects to develop technical design specifications

what youll have

3  5 years of technical experience in the areas of data visualization
3 experience creating analytics solutions that improve business performance
experience with analytical tools for supporting data analysis reporting and visualization ie looker domo gooddata qlikview tableau r etc certification preferred
experienced with standard and mpp databases postgres redshift bigquery snowflake
familiarity with aws and gcp technologies
familiarity with unixlinux and scripted using either shell perl python etc
exceptional communication both written and verbal interpersonal skills and experience in presenting to business and technical teams including executive management
experience authoring technical documents and working with teams to drive reference implementation to production scale

brownie points

you have experience at a high growth company saas preferred
adhere to standards and build etlselts to drive core business intelligence
experience inventing data solutions not just implementing packaged software or maintaining mature systems

why copper

great team founded by successful veterans of yahoo zynga and ebay
huge market disrupting a massive growing 35 billion market for crms
funding raised 53m for our series c from toptier investors like norwest venture partners
our crm has been awarded g2crowd 1 in customer satisfaction summer rankings google best new tech partner of the year
impact a fun transparent and exciting startup culture that empowers its people to make a huge impact
goodies awesome benefits convenient soma location beautiful office catered breakfastlunchdinner team outings and more

",,CA,False,data_engineer
Data Engineer - Amazon Advertising,"job description
interested in using terabytes of data and machine learning

at amazon advertising we are developing stateoftheart largescale machine learning systems on terabytes of data in a system where multiple machine learning components interact on highspeed realtime data the challenge lies in understanding model behavior to diagnose performance issues we are looking for a talented data engineer who is passionate about building metrics and pipelines and has the growth goal of getting deep in quantitative algorithm analysis in this role you will work with scientists engineers and product managers on high impact initiatives in amazon’s display advertising
our team measurement and data science develops machine learning algorithms and high performance petabytescale distributed systems our innovative engineers and machine learning scientists sit at the intersection of two vast data sources ecommerce and advertising our systems process billions of ad impressions daily from across the internet to power all of amazon’s advertising reporting as well as algorithms for audience targeting real time ad ranking and bidding and automated campaign optimization

major responsibilities

it’s day one in amazon ads and you will play a leading role to build out our scientific infrastructure and create our research environment
you will be the primary owner of performance dashboards across multiple machine learning systems

you will dive deep into complex data issues in production and simulation

you will build tools for research experimentation and measurement
you will leverage petabyte scale data in strategic analysis for new monetization strategies products and business directions
together we will change the face of advertising and retail by allowing customers to discover and research products online and allow companies to understand and interact with their customers well be the dream team

basic qualifications
ms with 2 years of industry experience or bachelors with 5 years of experience in quantitative field cs ml mathematics statistics physics
3 years of experience with data querying languages eg sql scripting languages eg python or statisticalmathematical software eg r sas matlab
experience in creating data driven visualizations to describe an endtoend system
preferred qualifications
experience in processing filtering and presenting large quantities millions to billions of rows of data
demonstrable track record of dealing well with ambiguity prioritizing needs and delivering results in a dynamic environment
experience working with advertising retail or ecommerce data
2 years of experience with statistical analysis techniques including linear regressionleast squares experimental design hypothesis design confidence intervals ttest etc
amazon is an equal opportunityaffirmative action employer  minorityfemaledisabilityveterangender identitysexual orientation

madsjob",,WA,False,data_engineer
Data Engineer,"data engineer

who we are

murmuration is an organization dedicated to sustainable policy change in the us and we believe that the path to real change in america’s education system is through political activism and participation together with our partners we develop shared infrastructure and coordinated support for organizations on the ground to massively improve outcomes for all children we do this by working directly with local schools and organizations to amplify the voices of parents and families as key stakeholders in setting education policy

as part of our work murmuration has developed a technology product called “minsights” that seeks to aggregate data from a combination of sources including member data from partner organizations publicly available data consumer data voter file data and more the compiled data are then used to build a variety of analytic models and tools that enable murmuration’s partner organizations to activate expand and mobilize their supporter bases effectively for sustained political change

about the position

we are looking for an innovative data engineer to maintain and architect the data systems and pipelines to support our efforts the data engineer would work with our senior data engineer and use a variety of leading database technologies aws redshift mongodb and tools aws ec2 aws s3 python to process and store our existing data the role calls for expertise in managing aws resources and maintaining and expanding our pythonbased data ingestion pipelines there is also the opportunity to architect new data stores for our evergrowing data needs so a creative problem solving mindset is highly desirable
the data team is a highly collaborative friendly and hardworking 6 person group and we are looking for team members who embody those values the data engineer will report to the director of data

the data engineer will

help maintain and enhance our robust data warehouse that houses data from partners vendors and other data sources
manage and improve the data ingestion pipelines that service our data warehouse which are currently built in python
deploy and use aws resources like redshift and rds clusters and ec2 instances to support our work and manage the security around those resources through aws security groups and vpcs
collaborate with our data science team to help build out our data analytics automated pipeline in python

make recommendations and provide strategic support regarding ways to make data and database operations more efficient and effective across murmuration

candidate profile

murmuration attracts employees with distinctive and diverse backgrounds and accomplishments integrity creativity flexibility and drive are key attributes of competitive candidates
the ideal candidate will have
msc or higher in computer science or equivalent degree or 3 years experience in a data
engineering role
1 year experience managing large aws database resources either rds redshift or dynamodb
and the setup of vpcs and security groups to manage access to these resources
excellent sql skills with experience in building and interpreting complex queries
excellent python programming skills with a track record of welldesigned and maintainable code
experience in database design and structure with an emphasis on scalability
a strong desire to develop new and innovative ways to improve our data storage and processing

location

this position will be based in new york ny and may require some travel

compensation

the data engineer position is a fulltime salaried position with a comprehensive benefits package compensation for this position is commensurate with experience

an equalopportunity employer with a commitment to diversity

murmuration is proud to be an equal opportunity employer and as an organization committed to diversity and the perspective of all voices we consider applicants equally of race gender color sexual orientation religion marital status disability political affiliation and national origin we reasonably accommodate staff members andor applicants with disabilities provided they are otherwise able to perform the essential functions of the job",,NY,False,data_engineer
Data Science Engineer,"meet cargurus—the 1 visited online car shopping website in the us at cargurus were building the worlds most trusted and transparent automotive marketplace where its easy to find great deals from toprated dealers

founded in 2006 by langley steinert cofounder of tripadvisor cargurus is a technology company with a passion for data and its power to simplify every aspect of the car shopping experience using proprietary technology search algorithms and innovative data analytics we provide unbiased validation on pricing dealer reputation and vehicle history

were looking for a thoughtful technical and deeply collaborative data science engineer to work with our growing analytics engineering team this position will provide foundational framework for the data science team this includes building the infrastructure to allow the team to publish models into production developing python libraries to facilitate feature generation and providing the data science team with productbased datasets to train their models

what youll do

become a trusted advisor to the data science and analytics teams
turn complex data science algorithms and predictions into reliable productiongrade systems
create a platform to deploy said models at scale so that we can make the data science team as productive as possible
build python libraries to make it easy for data science to do feature engineering on our raw data
participate in creating the teams roadmap providing feedback on priority and business value
maintain and tune our data warehouse to support requirements from stakeholders and dependent systems
become an expert in our products and data models so that you can write performant sql queries to enable iterative analysis

who you are

3 years experience as a software engineer data engineer or related field
comfortable with using test infrastructure to validate code
team player who thrives in a collaborative environment
expert in sql with ability to optimize database and query performance
familiarity with olap databases such as redshift snowflake vertica or others
a natural detective with a keen interest in solving business problems with data driven methods
deeply focused on delivering value to stakeholders with a dataasaproduct mindset
passionate about creating production grade systems and data quality supporting what you build
experience in building statistical models a plus but not required

cargurus culture
at the core of our company culture is a spirit of innovation curiosity and collaboration true to our startup roots were nimble flexible and hardworking we have a great respect for testing and learning and a healthy aversion to scheduling meetings to discuss meetings lunch is catered daily gym membership is free foosball and ping pong are played often now a publiclytraded company were as committed as ever to cultivating the culture that got us here

in addition to the us cargurus operates sites in canada the uk and germany with other markets on the horizon our offices are located in cambridge ma detroit mi and dublin ireland if youd like to learn more please visit our careers page  httpscareerscarguruscom ",,MA,False,data_engineer
Quantitative Data Engineer,"we are looking for an outstanding engineer to join our investment team to build out our big data analytics pipeline

if selected the candidate will have significant responsibility in extracting signals from structured and unstructured data and in transforming them into tradeable insights

required
bs ms or phd in computer science statistics or related discipline

proficiency in python and analytic packages such as numpy pandas scikitlearn

proficiency in sql

preferred
experience in

processing big data with python using spark dask blaze
olap with aws redshift google bigquery
etl orchestration with apache airflow aws glue or google dataflow

",,NY,False,data_engineer
Data Engineer,"if you have what it takes to become part of the vistra energy family and would like to start a promising career with a global leader take a look at the exciting employment opportunities that are currently available and apply online


job description
overview
the data engineer will provide it support and development for data services at vistra and will ensure the timeliness quality and accuracy of the data and platforms that support the data management and etl functions


responsibilities
implement and maintain it data and etl platforms understand and deliver on the functional support and data needs of data management within vistra 
follow data policies standards guidelines and procedures in order to ensure data to support reporting and analysis is available responsive and achieving business outcomes and objectives
implement data and etl solutions or enhancements to improve overall vistra data architecture conduct research and make recommendations on new data management processes and innovations
work closely with vendors service providers the business and internal team to define and understand analytics needs in order to achieve key performance indicators and service level agreements for the benefit of vistra and its business objectives
translate business needs into functional requirements updatecreate documentation business process designs functional designs data architecture
participate in projects and agile teams make recommendations and implement changes to mitigate risks and optimize data platform performance

requirements
bachelors degree in mis computer science or a related field from an accredited collegeuniversity or equivalent
03 years of experience in data management or related practice such as data science
proven ability to collaborate on crossfunctional teams
• experience with open source hadoop and cloud highly desirable",,TX,False,data_engineer
Data Engineer,"contractposition data engineer 3 positions

location san jose ca

length of assignment 1 year contract

description

excellent technical expertise in plsql hive ql and python
experience with hive presto druid yaml configs apache airflow
experience in documenting data definitions metrics and dimensions in a businessfriendly language and also provide logical data models
good at conducting testing unit and uat as we change data pipelines
should be able to build new data pipeline etl with apache pipeline
candidates must have a linkedin profile

without this information you will not be considered

dynpro’s mission is to provide customers comprehensive solutions and services that will support and drive their business to success dynpro is committed to materializing ideas maximizing profits and optimizing operational efficiency for its clients dynpro is also dedicated to providing its consultants and employees with opportunities of growth and an overall enriching work experience",,CA,False,data_engineer
Software Engineer - Data,"about us

candid™ is helping people get the smiles they always wanted at prices they can afford by simplifying the process directtoconsumer and reducing costs by up to 65 less we can help more people feel confident and healthy we believe that high quality dental care should be affordable and accessible and were using teledentistry to facilitate the diagnosis and treatment of orthodontic patients our team includes startup veterans with experience across healthcare hospitality tech and finance at companies such as lyft squarespace wework blue apron and clover health

role

were building a bestinclass consumer  healthcare brand and are looking for a datadriven developer  scientist who has an interest in utilizing data to make an impact on our customer experience and growth in addition to the ability to execute on those ideas we are looking for a data engineer to join the candid™  httpcandidcocom  team to help build out our existing data pipelines as well as interpret the analytics and build reporting tools used by the whole business you will be responsible for owning much of the development of our pipelines data analysis and integration of thirdparty tools for our marketing operations and product teams you will partner with various teams across the business to help extract meaningful analysis from the data we have collected you will report directly to our vp of engineering

what youll do

write reports in sql
design and build etl pipelines
develop and maintain data products and infrastructure
compile data to show progress and guide highlevel decision making
help to design datadriven experiments across the business
think outside the box and maintain a flexible approach to problem solving

what youll need

3 years minimum experience as a data engineer or data scientist
fluency in two or more of python sql r go ruby scala
experience running data projects from start to finish
crossfunctional experience working with all teams throughout an organization
proven analytical skills
strong business instincts and fundamentals
experience in machine learning algorithms and processes a plus
experience with redshift redash looker a plus
experience in aws or other cloud providers a plus

pay  perks

equity in the business
medical and dental insurance
commuter benefits
easy access to work across the street from 4 5 6 l n q r w trains
a collaborative high energy work environment
you will grow a lot here youll be surrounded by employees with deep experience in their field who have a strong passion for doing great work and constantly learning

",,NY,False,data_engineer
Data Engineer,"position overview
the climate corporation’s mission is to help the world’s farmers sustainably increase their productivity with digital tools the data and analytics team is focused on creating competitive advantage for climate and our customers through novel data infrastructure metrics insights and data services we are a small but rapidly growing analysis and engineering team that builds and leverages stateoftheart analytics systems our work informs decisions and direction for our business while also impacting our products we are looking for a data engineer to not only build data pipelines to efficiently and reliably move data across systems but also to build the next generation of data tools to enable us to take full advantage of this data in this role your work will broadly influence the companys products data consumers and analysts we are looking for a candidate with knowledge of data warehousing and experience with etl tools

what you will do help design and build a multidimensional data warehouse
 build and maintain the core data model data pipelines core data metrics and data quality work directly with stakeholders across multiple functions science marketing sales risk finance product to define neesrequirements champion data warehousing best practices develop and build infrastructure in an aws cloud environment build data expertise and own data quality for the data pipelines design and develop new systems and tools to enable folks to consume and understand data faster provide expert advice and education in the usage and interpretation of data systems to end consumers of the data
basic qualifications bs or ba in computer science math economics engineering or other technical field 2 years of sql experience as applied to etl tools informatics kettle talend etc experience with relational databases or nosql infrastructure
preferred qualifications 2 years of experience with dimensional data modeling  schema design in data warehouses 2 years of scripting experience shell or python experience with massive scale relational databases mpp is a plus verticaredshiftteradata experience working in a cloud deployment such as aws is a plus excellent communication skills including the ability to identify and communicate data driven insights
what we offer
our teams are composed of industry experts top scientists and talented engineers the environment is extremely engaging and fastpaced with dozens of specialties coming together to provide the best possible products and experiences for our customers
we provide competitive salaries and some of the best perks in the industry including superb medical dental vision life disability benefits and a 401k matching program a stocked kitchen with a large assortment of snacks  drinks to get you through the day encouragement to get out of the office and into the field with agents and farmers to see firsthand how our products are being used we take part and offer various workshops conferences meetup groups techtalks and hackathons to encourage participation and growth in both community involvement and career development
we also hinge our cultural dna on these five values inspire one another innovate in all we do leave a mark on the world find the possible in the impossible be direct and transparent",,CA,False,data_engineer
Data Engineer,in order to be considered for this role you must apply at the following link httpstechnologyadviceapplytojobcomapplynfu93rfkhddataengineersourceindefthis isnt your typical data engineering role data here isnt just reporting its the core of our business leveraging both internal and external data sources we form the bedrock that powers our industryleading lead generation capabilities as technologyadvices data engineer on the business intelligence team the right candidate will be excited by the prospect of optimizing or even redesigning our companys data architecture to support our next generation of products and data initiativesthe core responsibilities of this role include prototyping internal data utilities to enhance and support various business units as the subject matter expert on all of the data resources we have available your unique perspective and capabilities will be invaluable for leveraging our data resources in new and innovative ways to drive value for the businessdevelop guidelines standards and processes to ensure the highest data quality and integrity in the data stores residing on the data repositorydesigning building and maintaining data models used by our bi platform seekwell and tableaubuilding and maintaining data integrations with thirdparty systemsidentifying and executing on opportunities for automating relevant data processesbuilding and maintaining etl processes and data dictionaries between our production systems and aws redshiftcollaborate with our software engineering team to ensure proper change management for etl processes and data modelsmusthaves for this roleproven professional experience withmanaging data with aws redshift thats the main playground for the data teamdesigning building and maintaining both new and existing data systems and solutionsunderstanding of etl processes and how they functionnicetohaves for this roleability to learn and work with python as needed while were not picky about your choice of language for any particular task we have production code running in python php bash awk and nodejs python is the way of the data world and experience with it would be beneficialthe perfect personality for this role be inquisitive and innovative the desire to say lets do this and the ability to do whats needed to follow througha sixth sense for detecting data defects anomalies and risksability to adapt and learn quickly is a fundamental necessityenjoy working in fastpaced collaborative agile environmentsplans and executes activities with generallydefined goals and minimal supervision we trust you to know your stuff and dont micromanage youminimal supervision doesnt mean minimal support  be comfortable and proactive asking questions and seeking additional help if needed to accomplish goalswants to understand the data not just the pipelines pushing it around can definitely perform some analytics and build some dashboards because you like to not just when you have toability to work independently while youll collaborate with and have the full support of our business intelligence and software engineering teams most projects will be worked on independentlyperks and benefits compensation is a combination of base salary plus quarterly profit sharing potential in addition to the opportunity to grow personally and professionally alongside a driven team we also offercomprehensive health insurance medical dental vision life and disability401k retirement plan with company matchunlimited paid time offweekly career development meetings for your first 60 daysbucket list benefit on each work anniversarygym membership reimbursementmonthly team outings and volunteer opportunitiesprofessional development opportunities and incentives book clubs monthly learning series leadership academy and morecatered lunches 4 days a weekcoffee soda snacks ping pong and beer on fridayswho we are technologyadvice is dedicated to educating advising and connecting buyers and sellers of business technology as a trusted resource in a variety of technology verticals the company helps buyers improve their businesses and vendors find their customers through unbiased research and crowdsourced product reviews technologyadvice provides the insight that buyers need to find the right technologyadditionally the company’s unique demand generation programs help vendors improve product awareness by placing matched solutions in front of qualified technology buyers technologyadvice is based in nashville tenn and was named to the inc 5000 list of america’s fastestgrowing private companies in 2014 2015 2016  2017preemployment screening requiredjob type fulltime,,TN,False,data_engineer
Data Engineer - STL,"description
team daugherty is hiring a data engineer to join us in st louis the ideal candidate for this position is a problem solver with the ability to utilize insights creativity and perspective to drive business success for our clients

as a data engineer you will have the opportunity to

contribute to the creation and maintenance of optimal data pipeline architectures
collaborate and work closely with team to build data platforms
maintain and manage hadoop clusters in development and production environments
assemble large complex data sets that meet functionalnonfunctional business requirements
work with team members and functional leads to understand existing data requirements and validation rules to support moving existing data warehouse workloads into a distributed data platform
create custom software components eg specialized udfs and analytics applications
employ a variety of languages and tools to marry systems together
recommend ways to improve data reliability efficiency and quality
implement  automate highperformance algorithms prototypes and predictive models
we are looking for someone with

1 years of experience in a similar role
proven experience working with aws technologies such as redshift rds s3 emr adp hive kinesis snssqs and quicksight
familiarity with python r shbash and jvmbased languages including scala and java
familiarity with hadoop family languages including pig and hive
familiarity with high performance data libraries including spark numpy and tensorflow
proven ability to pick up new languages and technologies quickly
intermediate level of sql programming and query performance tuning techniques for data integration and consumption using design for optimum performance against large data assets within an oltp olap and mpp architecture
knowledge of cloud and distributed systems principles including load balancing networks scaling and inmemory versus disk
experience building data pipelines to connect analytics stacks client data visualization tools and external data sources
exposure to streamprocessing and messaging such as storm sparkstreaming kafka and mq
understanding of devops and cicd toolset such as jenkins gitlab ci buildbot drone and bamboo
some experience with programming languages such as scala java r and python
we offer members of team daugherty

excellent health dental and vision insurance
revenue sharing and a 401k retirement savings plan
life disability and longterm care insurance
little to no travel
robust career development and training
do you think you’re a good fit for team daugherty apply now and find out why working here satisfies the smart the talented and the curious",,MO,False,data_engineer
Business Intelligence Data Engineer,"who is credible

we believe lifes changes create financial needs for people and that the traditional financial system often puts up unnecessary obstacles people celebrate major milestones like going to college getting married and buying a home and most of the time these milestones come with financial implications

at credible we have built a company with the mission of bringing transparency choice simple processes and savings to accessing credit for lifes important moments what you see is what you get we are committed to being upfront honest and clear about your options there are no mysteries no hidden fees and no secret clauses

credible is a fastgrowing australian securities exchange asx listed fintech company that has world class management has raised multiple rounds of funding is generating significant revenue and is disrupting the lending market and helping people save money and get out of debt faster

about the role

our business intelligence team is looking for a business intelligence data engineer who is passionate about data analytics and business strategy you will help the team learn more about our business teach others in the company about analytics and improve the use of our data youll be an integral part of providing datadriven insights that inform significant company decisions

you will

build data pipelines and pythonbased etl tools for getting processing and delivering data
partner with teams across the organization to understand their analytics needs and create dashboards and reporting that allow them to execute more effectively
work with business leaders to define key metrics and build reporting to monitor and understand performance along those metrics
conduct indepth data analyses that lead to actionable insights owning the entire process from ideation to execution to presentation of findings to stakeholders
develop data models in our data warehouse that enable performant intuitive analysis
become an expert on all aspects of credibles data and analytics infrastructure
be the driving force behind the adoption and effective use of our bi tool within every team at credible

education and experience

babs in a quantitative field
12 years of work experience as a data analyst data engineer or in a highly analytical role
experience writing sql queries and using a bi tool
experience with a scripting language preferably python for data processing and analysis a plus
experience using the command line and git
strong grasp of statistics and experience conducting rigorous data analyses
experience developing models and visualizations in looker a plus
experience at an ecommerce or fintech company a plus

personality and values

the capacity to juggle multiple priorities effectively within a fastpaced environment is critical
youre a highly motivated selfstarter with the ability to work efficiently with minimal supervision
anticipate business needs and think with a business owner mindset – think critically about analyses dont just complete them
passion for spreading the value of data throughout the company and communicating insights to a broad audience with varying levels of technical expertise

why you want to work at credible

we are a fast moving funloving seriously smart group of people who really care about impacting the lives of our customers we empower our employees to make decisions take risks drive our business and make changes when we dont get it right these are our values


exceed customer expectations we provide an exceptional experience to each and every customer that compels them to share it with others
take ownership we are trusted to make decisions that are in the best interests of our customers and our business we think and act like owners we care – and that makes all the difference
be curious we are curious ask questions seek to understand and try new things
do the right thing we earn trust by being transparent respectful and honest with each person with whom we interact
get results results fuel our excitement and we know how our personal accomplishments tie to the success of the company
be bold we are courageous and take risks that scare us our enthusiasm for experimenting is how we will find the next breakthrough

our benefits we offer competitive compensation generous benefits free food and a flexible vacation policy

but mainly you want to work at credible because you believe in our mission and want to have a major role in delivering on it we look forward to getting to know you

we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientationagemarital status veteran status or disability status pursuant to the san francisco fair chance ordinance we will consider for employment qualified applicants with arrest and conviction records",,CA,False,data_engineer
Data Engineer,"the department of biomedical informatics dbmi at columbia university is revolutionizing the clinical research enterprise with the help of information technology within the area of precision medicine we are building systems that implement harnessing genetic sequences to detect health conditions and save lives at dbmi we are building the infrastructure of the future to support and enable better research and dissemination we have an immediate opening for a talented and selfmotivated data engineer developer who can succeed in a collaborative work environment the ideal candidate will have experience with data pipelines and cloud environments the candidate will be responsible for data processing data exchangetransferload etl data visualization devops and software architecture the ideal candidate will have professional experience in a number of programming languages databases and development environments the candidate should be able to contribute in improving reliability and quality of data experience in clinical medicine clinical vocabulary and cloud development are not required but preferred the successful candidate will contribute to the development of open source solutions together with a community of international researchers

current available position is grantfunded

columbia universitys department of biomedical informatics is internationally recognized as one of the best programs of its kind our mission is to improve health for society by focusing on discovery and impact we develop new informatics methods enrich the biomedical knowledge base and enhance the health of the population employees of the department are passionate friendly and resourceful

minimum qualifications for grade
applicant must meet these minimum qualifications to be considered an applicant

bachelors degree in computer science biomedical informatics information science plus four years of related experience

additional positionspecific minimum qualifications
applicant must meet these minimum qualifications to be considered an applicant

great communication skills experience with one or more compiled programming languages eg java scala c c etc and one or more interpreted programming languages python javascript perl bash etc working knowledge of sql experience with big data nosql databases and health care data a plus

special instructions

preferred qualifications

essential functions

1 software and system design implementation and testing 75
2 application deployment and configuration 10
3 communicate with technical individuals at various grant sites 10
4 software requirements specification 5

additional essential functions limit to 3950 characters

the incumbent will work under the direction of the faculty member leading the project heshe will work closely with the projects team including the project manager current software developers and sponsoring project personnel

the incumbent must be organized and adhere to project deadlines

special indications

this position works with
hipaa compliance training required

yes

participation in medical surveillance required

no

what type of posting is this a waiver request

standard posting

requisition open date

09102018

requisition close date

open until filled

quick link

jobscolumbiaeduapplicantscentralquickfind171852",,NY,False,data_engineer
Data Engineer,"about 605
at 605 we are engineers analysts data scientists media experts marketing strategists and political operatives our team of data scientists pioneered the field of tv data analytics we offer unique independent audience measurement and analytics to build better marketing and programming initiatives within the media and entertainment industries
data engineers at 605 are responsible for onboarding qa and analyses of data sets into the 605 platforms this role will also interface with business and product owners to understand requirements and ensure that data sets are accurate timely and available to support the business needs responsibilities include
interpret data sets and define process and procedures to ensure data is received to spec and in a timely and accurate manner
identify and address issues with data sets
establish clear communications both across the data provider relationships as well as within 605
ensure appropriate procedures are in place to meet soc 3 compliance procedures
ensure excellent communication procedures are in place via dailymonthlyweekly reporting to advise status of data sets and that end users are informed of data status
work with business and product owners to develop procedures methods code to provide efficient tools and products to meet the needs of the end users
support all groups across 605 as needed to address questions regarding data quality status etl and other platform related questions and concerns that may arise
this role will oversee junior analysts to facilitate reporting and analytics
requirements
57 years in data processing and analytics industry
strong working knowledge of sql python and other database query related languages
strong working knowledge of cable ad sales inventory impression projections reach and frequency analytics a strong plus
bachelor degree or higher
excellent written and verbal communication skills to present to end users support teams technical teams as well as senior management as needed
preferred experience in application development “big data” analytics and ability to deliver customer focused products that are simple and easy for end users to interpret
benefits
comprehensive health and dental insurance for employees and their families
life insurance
401k with match eligible for match after one year
pretax flexible compensation plan for medical transit parking or dependent care expenses
paid time off
sick days—if you’re sick you stay home
a kitchen stocked with sodas snacks yogurt and other goodies
a tightknit startup community who likes to eat we celebrate everyone’s birthdays have frequent team lunches and do events in and out of the office
605 is an active participant in conferences
eeo statement

at 605 we’re just as passionate about diversity as we are about pioneering the field of tv data analytics we are committed to cultivating an environment of mutual respect and equal opportunity all hiring and advancement decisions are made on the basis of qualification merit and business need",,NY,False,data_engineer
Data Engineer,"collaborate with product teams data analysts and data scientists to design and build dataforward solutions build and deploy streaming and batch data pipelines capable of processing and storing petabytes of data quickly and reliably integrate with a variety of data metric providers ranging from advertising web analytics and consumer devices build and maintain dimensional data warehouses in support of business intelligence tools develop data catalogs and data validations to ensure clarity and correctness of key business metrics drive and maintain a culture of quality innovation and experimentation 13 years of experience developing in object orient python engineering bigdata solutions using technologies like emr s3 spark loading and querying cloudhosted databases such as redshift and snowflake building data pipelines using kafka spark flink or samza familiarity with binary data serialization formats such as parquet avro and thrift experience deploying data notebook and analytic environments such as jupyter and databricks knowledge of the python data ecosystem using pandas and numpy experience building and deploying ml pipelines training models feature development regression testing experience with graphbased data workflows using apache airflow bachelor’s degree in computer science or related field or equivalent work experience
disney streaming services is a place for the creative and the bold we’re seeking talent across disciplines to join our team whether new york city san francisco manchester or amsterdam we provide opportunities to elevate your career and transform an industry disney streaming services software engineers develop premium digital media products for major league baseball and our partners the products we build such as mlbtv nhltv hbo now and playstation vue are paving the way for the nextgeneration media and sport technologies disney streaming services engineering is headquartered in the chelsea area of new york ny with an office in the somo area of san francisco ca and team members based around the world if you are interested in joining disney streaming services in the pursuit of not only crafting new media products but enjoying the products you build we are interested in hearing from you at disney streaming services data is central to measuring all aspects of the business and critical to its operations and growth the data engineering team is responsible for collecting analyzing and distributing data using public cloud and open source technologies and offers transparency into customer behavior and business performance 573678",,NY,False,data_engineer
Data Engineer Intern,"internshipjoin a team recognized for leadership innovation and diversity
your time with honeywell could be spent in any of the following ways
extracting transforming and loading data in preparation for analysisengineering features incorporating domain expertise and statistical aggregationsdeveloping and evaluating statistical inference models based on those features solving a costumer’s problemdeploying analytic solutions to production platforms ready to be used in one of honeywell’s products or services
no matter which team you work on youll have the opportunity to participate in our intern project week  a week in which all interns come together to solve business problems it is a fun week and youll meet other interns who will be a great part of your network
our teams live by the ‘teach and learn’ mantra we value our more seasoned data scientists because they bring additional value to our company by using their years of experience to guide the next generation we also value you our young talent well assign you a mentor on day one so you can take advantage of this amazing learning opportunity we want you to finish your internship with a much better understanding of the data science field and honeywell we know youll be a better data scientist by the time this internship ends
25 administrative support to the engineering team

25 test data maintenance

25 communication support

25 system support and maintenance


you must have
be currently pursuing a bachelor’s or master’s degree in engineering computer science or related discipline at an accredited college or universityhave completed at least your first year of a college or universitybe able to participate in an internship prior to completing current degree program
we value
minimum 85 course average 37 gpabe familiar with one or more of the following programming languages python r matlab java or csome frameworks we use are jupyter rstudio flask opencpusome of the tools we use include git docker bamboo and moresome of the databases we use are hive opentsdb cosmodb and sqlinsatiable appetite for learning new technologiescommitted pursuit of innovative solutions
nonexempt how honeywell is connecting the world
includes
continued professional development
1st shift

additional information
job id hrd41023
category engineering
location 715 peachtree street ne atlanta ga 30308 usa
honeywell is an equal opportunity employer qualified applicants will be considered without regard to age race creed color national origin ancestry marital status affectional or sexual orientation gender identity or expression disability nationality sex or veteran status",,GA,False,data_engineer
"Data Engineer, Analytics (Instagram)","instagram is a global community of more than 1 billion which means jobs here offer countless ways to make an impact in a fast growing organization instagram was built to connect people to the people and interests they love our app has played a critical part in forming meaningful communities where people can connect with each other and share what matters most to them
do you like working with big data do you want to use data to influence product decisions for products being used by hundreds of millions of people every day if yes we want to talk to you our data warehouse team works very closely with product managers product analysts and internet marketers to figure out ways to acquire new users retain existing users and optimize user experience  all of this using massive amounts of data in this role you will see a direct link between your work company growth and user satisfaction you will be working with some of the brightest minds in the industry and youll get an opportunity to solve some of the most challenging business problems on the web and mobile internet at a scale that few companies can match


this is a full time position based in our office in menlo park
responsibilities

inform influence support and execute our product decisions and product launches

manage data warehouse plans for a product or a group of products

interface with engineers product managers and product analysts to understand data needs

partner with product and engineering teams to solve problems and identify trends and opportunities

build data expertise and own data quality for allocated areas of ownership

design build and launch new data extraction transformation and loading processes in production

support existing processes running in production

define and manage sla for all data sets in allocated areas of ownership

work with data infrastructure to triage infra issues and drive to resolution
minimum qualifications

bsba in technical field computer science or mathematics

4 years experience in the data warehouse space

4 years experience in custom etl design implementation and maintenance

4 years experience working with either a map reduce or an mpp system

4 years experience with schema design and dimensional data modeling

4 years experience in writing sql statements

ability to analyze data to identify deliverables gaps and inconsistencies

communication skills including the ability to identify and communicate data driven insights

ability in managing and communicating data warehouse plans to internal clients
preferred qualifications

4 years experience using python or java",,CA,False,data_engineer
"Data Engineer, Alexa Shopping","job description
at alexa shopping we strive to enable shopping in everyday life we allow customers to instantly order whatever they need by simply interacting with their smart devices such as echo or fire tv our services allow you to shop no matter where you are or what you are doing you can go from i want that to thats on the way in a matter of seconds we are seeking the industrys best to help us create new ways to interact search and shop you will have an impact on amazons new devices and the way shopping is done in the area of iot join us and youll be taking part in changing the future of everyday life

as a data engineer you will be working in one of the worlds largest and most complex data warehouse environments using latest set of toolsets we help product teams at vans build the future of shopping by providing metrics on new features and help them perform ab testing which will act as feedback loop for voice user experience our team is responsible for mission critical analytical reports and metrics that are viewed at the highest levels in the organization we are also working on near real time analytics using kinesis firehose and using the latest set of tools for data visualization and investing in big data technologies you should have deep expertise in the design creation management and business use of extremely large datasets you should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions you should be expert at designing implementing and operating stable scalable low cost solutions to flow data from production systems into the data warehouse and into enduser facing applications you should be able to work with business customers in a fast paced environment understanding the business requirements and implementing reporting solutions above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change
basic qualifications
4 years experience with various data analysis and visualization tools

experience in perl python or another scripting language command line usage

track record of diving into data to discover hidden patterns and of conducting errordeviation analysis

experience with various machine learning techniques and key parameters that affect their performance

strong personal interest in learning researching and creating new technologies with high commercial impact

ability to develop experimental and analytic plans for data modeling processes use of strong baselines ability to accurately determine cause and effect relations

understanding of relevant statistical measures such as confidence intervals significance of error measurements development and evaluation data sets etc
preferred qualifications
a track record of communicating well with software engineers and nontechnical leaders in speech technology
background in the fields of natural language processing or computational linguistics
excellent verbalwritten communication skills including an ability to effectively collaborate with research and technical teams and earn the trust and influence senior stakeholders
the motivation to achieve results in a fastpaced environment
experience with statistical modelling  machine learning
strong attention to detail
comfortable working in a fast paced highly collaborative dynamic work environment
ability to think creatively and solve problems",,WA,False,data_engineer
Data Engineer,"a data engineer at omnitech would qualify for multiple of the following labels including business intelligence consultant data warehouse consultant data acquisition etl consultant database administrator consultant master data management consultant data analyst data architect data scientist or many other labels currently being used at omnitech we don’t believe in labels and hierarchy we believe in helping people solve problems we are looking for an engineering caliber person that focuses on data and has a consulting type personality

we look for the following

a curious analytical mind with ability to understand business objectives ask insightful questions and be detailed in implementation
a track record of helping companies get value from data management and business intelligence
diverse understanding of industry tools software and techniques especially microsoft sql server platform and tools
a desire to mentor and be mentored
a history of working on multidisciplinary teams in a productive manner
professional image and demeanor with the ability to present oneself in a consultative confident and yet humble manner

desired skills the applicable candidate must possess a number of the following

strong tsql skills
sql server design and development experience
understanding of data profiling techniques
understanding of performance optimization data warehousing cube architecture
understanding of common data extraction techniques across a diverse set of sources including structured and nonstructured data
experience with data cleansing and conforming techniques
develop standards and best practices to ensure data standardization and consistency as required
strong experience with dimensional modeling star schema and kimball data warehouse methodologies
design and develop data warehousing solutions for clients across a variety of industries and business sizes utilizing microsoft’s sql

server platform

perform the role of subject matter expert for microsoft business intelligence technologies including sql server and analysis services
knowledge of multidimensional expression mdx and data analysis expressions dax languages
familiarity with managing dimensional attribute history through slowly changing dimension scd concepts
working knowledge of etl change detection solutions such as change data capture cdc
experience with big data technology a plus
understanding of sql server fasttrack andor parallel data warehouse
familiarity with storage technologies eg san nas etc a plus
translate business requirements and technical designs into welldeveloped solutions that meet client business goals
ability to explain the pros and cons of architectural decisions
evaluate and recommend new technologies as required
design and implement technology best practices guidelines and repeatable processes
provide technical assistance and cross training to other team members and clients
participate in the business intelligence community to promote the use of the microsoft bi platform and general data warehousing best practices
assist in presales scoping and requirements gathering process
ability to work closely with other project team members such as sales analysts project managers and software engineers

requirements

3 years data experience
a bachelor’s degree in engineering computer science physics mathematics or similar analytical degree
tsql sql server ssis ssrs ssas
desire for continuous learning and to pursue professional certifications
proven ability to consult and mentor others

personal characteristics

excellent communication presentation and interpersonal skills confident with customers
detail oriented wellorganized and excellent ability to multitask
energetic comfortable working in a fastpaced environment
hardworking and motivated able to take initiative and meet deadlines
comfortable working in a teambased environment
a handson attitude in a friendly work environment

contextual benefits

msdn premium and azure licensing as microsoft gold partner
opportunities for formal and informal training on new technologies
support for career and life goals and development
free soda coffee and other ingestible fuel to keep you going
onsite exercise room with equipment
company matching on the 401k plan
reimbursement for tuition and certification costs

qualified candidates must be legally authorized to be employed in the united states on a fulltime basis for any position omnitech will not sponsorship for employment visa status eg h1b or tn status for this position

if you are interested in being part of an exciting and growing company please apply if you have what it takes to support our organization then send your resume and salary requirements via email to careersomnitechinccom",,SD,False,data_engineer
Data Engineer I,"availity delivers revenue cycle and related business solutions for health care professionals who want to build healthy thriving organizations availity has the powerful tools actionable insights and expansive network reach that medical businesses need to get an edge in an industry constantly redefined by change


the data engineer aims to provide data in a readytouse form to enable a diverse set of business processes responsible for design build maintenance and production support of data processing pipelines and systems the data engineer will work closely with data analysts data scientists business and technical teams to deliver outcomes that are secure reliable faulttolerant scalable quality and efficient applying analytics eg machine learning and statistical models as needed the data engineer can also provide data analysis and extracts on large and complex data sets


key responsibilities
design build quality maintenance and production support of data processing pipelines and systems realtime and batch
design build quality maintenance and production support of restful apis
responsible for ensuring data processing pipelines and systems are secure reliable faulttolerant scalable accurate and efficient
perform data analysis and provide extracts on large and complex data sets
data wrangling
deliver automated functional tests on data processing pipelines and systems
full participation in the assigned agile team eg standups planning peer reviews etc
provide oncall support 24x7 may be rotational
collaborate within and outside assigned agile team
continuously seek opportunities to improve skillsets
proactively identify and communicate roadblocks evaluate and suggest alternatives
support multiple projects and accommodate frequent interruptions and changing priorities
the above cited duties and responsibilities describe the general nature and level of work performed by people assigned to the job they are not intended to be an exhaustive list of all the duties and responsibilities that an incumbent may be expected or asked to perform
education and experience
bachelors degree in information systems or computer science eg specialization machine learningartificial intelligence visualization databases and big data

skills and knowledge
must have experience with at least one compiled language java
must have experience building backend restful web services
must have experience with sql and relational database systems eg oracle sql server
must have experience with linux
familiarity with devops and microservices architecture concepts and tools
familiarity with common data science toolkits such as r and python
strong problemsolving capabilities and exhibits strong computer science fundamentals
experience working with agile and lean practices
excellent communication skills",,FL,False,data_engineer
Data Engineer & SND Analyst,"with our portfolio of global power brands such as oreo and belvita biscuits cadbury dairy milk and milka chocolate and trident gum were the worlds 1 in biscuits and candy and 2 in chocolate and gum were mondelēz international a snacking powerhouse with operations in more than 80 countries with approximately 90000 employees globally and our brands are marketed in around 165 countries
our purpose and vision is to create more moments of joy by building the best snacking company in the world
customer service  logistics
customer service  logistics csl is where youll integrate our endtoend demanddriven supply chain working from farm to shelf youll connect plants with customers to deliver bestinclass service in the most efficient way your goal will be to have the right products at the right time and with the right quantity and quality on the shelf
purpose of role
the analyst  data engineer will improve business results by supplying databases and interfaces that lead to models and analysis to solve various supply chain challenges the analyst  data engineer will be responsible for providing seamless digital highway solutions that are automated and repeatable to drive sc guru models ensuring integrity of data the role also supports the sc guru modeler and supply network design manager in running and analyzing models supporting 100mm to 9 billion in revenue 
main responsibilities

work with internal and external customers to obtain data needed for analysis and validate data for accuracy
design setup and maintain sql databases supporting supply network design studies
design setup and maintain data visualized reports  interface tableau  supplychaingurucomapp supporting supply network design studies
setup data process and governance ensuring predictability and accuracy
primary point of contact with isit and data owner to design setup and maintain the digital highway interface
communicate with internal and external customer with automatedcustom reports to understand the business model and obtain current state costs
coordinate with key stake holders and help in developing strategies assumptions and supply chain analysis deliverables
analysis of various manufacturing and distribution network alternatives
analyze alternatives to determine the cash cost and service impacts
kpis  dimensions
project  analysis excellence
capability building  knowledge
transfer
targets  dimensions
stakeholder confidence timely completion accurate analysis and detailed documentation
1 of revenue
building na snd knowledge  knowledge transfer to the broader isc team
key interfaces  stakeholders
external consultants
internal isc  finance  itis
key leadership  functional competencies
leadership competency

intellectual horsepower
problem solving
learning on the fly
problem solving
perseverance
functional competency
sequelalteryx
tableau
supply chain guru
sap bi bo
excel access
qualifications
career experiences required  role implications

minimum 1 year experience modeling in sql
sql server environment experience
bachelors degree
tableau alteryx excel access experience desirable
demonstrated examples in experience of applying analytical skills and problem solving skills
ability to deal with amibiguity and work under pressure
strong collaborative skills for crossfunctional and crosscountry studies
fluent in english with strong communication skills
mondelēz global llc is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability protected veteran status sexual orientation gender identity gender expression genetic information or any other characteristic protected by law applicants who require accommodation to participate in the job application process may contact 8479435460 for assistance
applicants must complete all required steps in the application process including providing a resumecv in order to be considered for this position",,NJ,False,data_engineer
Data Engineer,"description
viral launch is searching for a highly experienced business minded data engineer we are looking for someone who is very passionate about building high performing and scalable data infrastructure enabling data science research and analysis and helping data scientists to take machine learning models to production our data science team is based out of our indianapolis hq

why is this job important to viral launch
viral launch has established themselves as a market leader in a short amount of time by providing unrivaled value for our clients by harnessing powerful market data to drive new innovative products and services within the nation’s largest ecommerce marketplace

critical to viral launch and at the heart of its operations is data we consume create and store lots and lots of data this role is vital in bridging the gap between multiple sources of data and the internal consumers of data analysts systems data scientists etc you will work closely with engineering and data scientists to tackle problems and develop innovative tools to make our customers more profitable 

requirements

bscmsc in computer science or related field
4 years of a proven track record in a data engineering or related role
ability to take ownership of the design implementation and maintenance of scalable end to end data pipelines
ability to quickly evaluate and make tradeoff decisions on adopting emerging technologies
experience in architecting data management solutions and deep understanding of data management discipline
knowledge in big data engineering spark hadoop hive spark streaming kafka etc
proven ability to build and deploy scalable realtime data pipelines on leading cloud platforms
experience in developing and deploying tools and supporting rapid iteration of machine learning algorithms
experience architecting data platforms to support data science and analytics
extensive experience collaborating with data scientists in wrangling cleansing extracting and transforming data
excellent problemsolving skills
ability to interpret and analyze data is a must consequently mathematical inclination is a major plus
proficiency in one or more of the following languages python c java scala javascript
extensive knowledge of sql deep understanding of database full lifecycle designing and application development

no visa sponsorship is available for this position

why work with us

medicaldentalvisionlife benefits
simple ira with company match
potential to earn equity not guaranteed
flexible schedules and unlimited pto

please submit your resume portfolio and any additional materials if you have any relevant web links please be sure to include them

ready for launch 3…2…1…apply",,IN,False,data_engineer
Data Engineer,"about comfy

comfy is on a mission to create amazing workplace experiences we are a leading workplace app provider that connects people places and systems we started by solving the number one complaint in the office temperature and continue to expand to our product suite to give employees greater control over their workplace including room booking lighting and feedback we create amazing workplace experiences through a consumerfacing app for employees and solve real business problems for corporate real estate teams headquartered in oakland california with expertise in machine learning ux design and enterprise service comfy develops software solutions for everyone — from the people who operate the building to the people who fill it

about the role

comfy is looking for a data engineer to help build our nextgeneration analytics products having successfully deployed the first generation of our appwhich provided end users with an intuitive way to control the temperature within their building learning their preferences in the processwe are now well into the next generation which extends into a range of it ot and iot use cases including room booking access control wayfinding and visitor management simultaneously we are aggressively growing our user base with some of the largestever comfy deployments currently in flight

as the frontend app and our user base evolves we are seeing an increasing number of opportunities to leverage data within the comfy platform for both enhancing our existing customerfacing analytics product comfy insights as well as our internalfacing product analytics which informs how we manage the product in addition we are also looking at more aggressively embedding learning across our product so that comfy can better anticipate our end users needs across their entire day towards that end we are looking for a rising technical star who wants to shape and contribute to the foundation and platform upon which our analytics roadmap will be built

about you


youre willing to roll up your sleeves and do whatever it takes to succeed you love learning new things and no task is too boring or too challenging to undertake
you enjoy the fast pace and chaos of a startup environment and arent intimidated by the vast unknowns and lack of resources that startups deal with every day yes were still a startup culture
you love creative problemsolving and are comfortable working independently on your own or with a team you thrive on pairprogramming esp with data scientists and prefer rapidly iterating on prototypes to get something quick and dirty into the hands of our customers
youve worked before in software development teams and are comfortable with agile frameworksincluding sprint planning backlog grooming or managing a kanban board you have experience with jira git confluence and all that jazz
you are proactive about influencing future directions and arent shy about putting together documentation or proposals that may help evangelize your pointofview you realize that getting buyin from your peers is key to longerterm success

your skills and experience


you have a bachelors degree in computer science or equivalent and at least 2 years of work experience note that the primary focus of this role is around data infrastructure  engineering not algorithms or data science although you will have the opportunity to dabble in both
you have deep expertise in data platforms and are comfortable working with structured unstructured and streaming data whenever you see a new data stream youre eager to stand up a data lake andor a distributed systems environment so you can dive into all sorts of interesting analysis yourself our current infrastructure uses redis cassandra and postgres youve worked with at least a subset of those before
along those lines you know what it takes to stand up a big data environment from scratchbe it onprem or in the cloud whether its spinning up new vms and containers or diving into deployment across multiple clusters youre up to the task aws experience preferred
sql is second nature if you could youd have a full conversation in sql but you also love data visualization since a picture is worth a thousand words ideally you have prior experience working with d3js or similar
must be wellversed in python
youre wellversed in evaluating the tradeoffs associated with any analytics deploymentsperformance accuracy cost usability complexityand have the knowledge base to reason through these tradeoffs
you have some experience with machine learning and ml platforms and are keen to apply what you know in new environments

our benefits include


marketleading software application centered on improving the workplace experience comfy  
diverse quirky passionate and supportive team of coworkers
brand new bright airy office in sunny downtown oakland close to bart
takewhatyouneed vacation policy
competitive compensation
full medical dental and vision insurance
monthly wellness subsidy
independent startup culture with the backing of a global corporate powerhouse

our promise to you

we believe your work is an extension of yourself at comfy we hire many sorts of selves and thats what makes us exceptional we value diversity of thought always asking tough questions committing to solutions—and we do that best when we have and nurture every point of view we value you and we want to hear you learn from you and move forward together",,CA,False,data_engineer
Data Engineer - AWS,"contracthaving spearheaded best practices throughout the evolution of data from structured data warehouse methods to big data analytics caserta provides enterpriselevel innovative solutions for our clients to keep ahead of the technology curve and leverage their data to the fullest extent

data engineers will be responsible to help build the solutions along with team members for full data transformations as to the clients specifications the right candidate will have the ability to look beyond the requirements and has a true passion for how data works
principal duties and essential responsibilities
solid work history using big data applications with python
optimizing the performance of businesscritical queries and dealing with etl job related issues
building and migrating the complex etl pipelines from system to redshift
extracting and combining data from various heterogeneous data sources
experience using apache spark
aws experience
strong communication – ability to explain complex technical issues in nontechnical terms
knowledge of database structures theories principles and practices
experience with s3 datalakes ideal
caserta is an equal opportunity employer applicants will receive consideration for employment without regard to race color religion sex national origin sexual orientation gender identity disability or protected veteran status caserta fosters a collaborative environment for true technologists with a passion for creating innovative data solutions to solve the most complex problems businesses face today",,NY,False,data_engineer
Market Data Engineer,"employment permanentapply

start date immediately

location new york ny

openings 1


the market data engineering role consists of designing and supporting market data ticker plants globally competency in reuters trep bloomberg and direct feed infrastructures are required software development experience in c c or java is a big plus
this role has design engineering and support responsibilities the primary focus will be for our us based locations but will on occasion be asked to support international locations the candidate must be comfortable speaking directly with portfolio managers traders and other key personnel within the firm this engineer is responsible for ensuring that all of the firms market data ticker plants are functioning answering users technology questions and addressing problems as quickly as possible the function of the role will increase over time so some experience and the desire and ability to work in this space is a prerequisite

responsibilities
ensure the market direct ticker plants reuters bloomberg direct feeds are operational reliable and are maintained to specifications as designed
create innovative internal alternatives to commercial solutions if business needs require competitive distinction
provide basic api assistance to traders and internal technologists
assist in testing and evaluating of different market data solutions as directed by management
monitor the system for market data utilization and participate in capacity planning exercises

qualifications
experience with maintaining reuters bloomberg and direct feed market data ticker plants
creativity in recommending innovative approaches to capture distribution and usage of data software development experience in c c or java is a big plus
familiarity with basic reuters bloomberg exchange symbologies and content
working knowledge of network protocols
ability to interface and maintain excellent working relationships with traders other it staff and vendors
ability to maintain composure under pressure and to communicate effectively with business and it management regarding outages and problems",,NY,False,data_engineer
Data Engineer,"a better company

we believe homeownership is valuable heres why not only has homeownership historically been one of the most reliable ways to build wealth it also strengthens ties to community and contributes positively to overall wellbeing the way the mortgage industry operates today makes it harder and harder for people to consider homeownership  so we set out to change that the traditional mortgage process is designed to confuse riddled with unnecessary fees takes too much time and is built on a foundation of misaligned incentive structures its time americans had a better option

a better option is one that puts customers in control of the largest financial transaction of their lives its built with bestinclass technology supported by noncommissioned staff and offers affordable financing options that meet customers where they are

since 2016 weve already funded over 1b in loans raised 75m in capital and won the nerdwallet best online mortgage lender for customer service and were just getting started

trying to modernize a decades old industry isnt easy but it is supremely rewarding become part of a better team

a better opportunity

help us hack a thirteen trillion dollar industry by building a product that will allow more people than the status quo to own a home and build wealth rather than rent for life our tech team is small and you will be a big part of defining the technical direction and culture we encourage proposals for projects off the beaten path experimentation with different frameworks and libraries and doing as you see fit to solve problems we also offer abovemarket compensation and equity as well as full benefits

some projects you could be working on


work closely with our product team to understand funnel drop off and come up with product ideas
work closely with the marketing team to optimize our acquisition funnel
present conclusions to the executive team that can impact the strategic direction of the company
build a lead scoring model to help our customer support team prioritize
model the timelag of conversions  httpsgithubcombetterconvoys  using tensorflow and fun math like gamma distributions
design an experiment to understand the causal impact of an outbound phone call on conversion rates
build web scrapers to track price data for other mortgage lenders
migrate our data warehouse to redshift
work on our underwriting engine which turns out to be npcomplete and can be posed as a mixed integer programming problem
transcribe all our phone calls using speechtotext and figure out ways to optimize customer support

better technology


we do continuous deployment and we ship code 50100 times every day
the data stack is all in python 36
we use nodejs python and scala for services
postgres for the database
kubernetes for deployment and devops
aws for infrastructure leveraging ec2 s3 swf cloudfront route53 and much more

the team


the tech team is currently 19 engineers but growing quickly
erik bernhardsson  httpstwittercomfulhack  cto used to run the data team and the music recommendation team at spotify he is the open source author of a few popular projects like annoy  httpsgithubcomspotifyannoy  and luigi  httpsgithubcomspotifyluigi  and writes a blog  httperikberncom  about mostly data

",,NY,False,data_engineer
Data Engineer,"join tubi and reinvent the way consumers consume movies and tv with over 8500 active movies  tv shows our users are watching millions of hours of the worlds largest free catalog of premium content per month with backing from leading vc firms and content partners like mgm paramount and lionsgate we are disrupting the streaming media space

tubi is a datacentric company from product roadmap decisions to algorithms that power our services to what shows we license data and experimentation are at the center we are looking for engineers passionate about building scalable high throughput data infrastructure as well as tools to enable rapid iteration of machine learning algorithms

about the role
in this data engineering role you will work closely with product engineering teams and data scientists to tackle problems in personalization content discovery search advertising and content production some of the challenges you will take on will include streamlining feature engineering helping data scientists take machine learning models in production and enabling data science research and analysis even amongst nonscientists in the company

your background

bscmsc in computer science or related field
2 years of a proven track record in a data engineering or related role
ability to take ownership of the design implementation and maintenance of scalable end to end data pipelines
ability to quickly evaluate and make tradeoff decisions on adopting emerging technologies
strong knowledge of scala and apache spark 20
building realtime data pipelines using redshift s3 kinesis spark structured streaming akka streams and similar stacks on leading cloud platforms
experience with dag workflow schedulers like airflow
a passion for shipping production quality code with good test coverage using testing frameworks for testing spark code
excellent problem solving skills
ability to interpret and analyze data is a must consequently mathematical inclination is a major plus

benefits

a tightknit team of passionate people and a techfirst business
autonomy and endtoend ownership
in addition to vc funding tubi tv generates healthy revenue
we offer very competitive pay equity full medical dental  vision benefits catered lunch and dinner and gym subsidies
your choice of hardware
work with other fellow avod enthusiasts
opportunity for internal growth
open pto
pursuant to the san francisco fair chance ordinance we will consider for employment qualified applicants with arrest and conviction records we are an everify company

",,CA,False,data_engineer
Sr Data Engineer - Next Gen Analytics,"description
join the edabi team where your goal is to unlock the value of the vast treasure of data available – make it accessible through natural language interfaces and build novel big data solutions to create insights – your customer is business analystsusers
in this role you will be at the forefront of creating high performance real time streaming as well as data at rest analytics platforms you will derive satisfaction from deploying nontrivial scale solutions to solve business problems and create insights that were either downright impossible until now or took several days of effort
use your skills experience and talents to be a part of groundbreaking thinking and visionary goals you will be required to
understand how to build scalable real time streaming based big data systemshave developed and been a key influential member in a fully delivered data product
lead the architecture and design of several modules related to the backend of a search system a real time relevance engine a system that computes several complex functions on the data on the fly etcbe a handson developer and lead by example as a programmerprovide guidance and contribute to coding standardsprovide leadership in sprints cicd and the devops efforts

requirementsbs in computer science or related areas3 years of experience developing production grade softwareproficient in linux or related unix systemsexpert in one or more of c c java and python exposure to modern programming languages such as rust and go a huge plus
experience building and deploying large scale distributed systems
excellent written and verbal communication skills
qualifications",,CA,False,data_engineer
Data Engineer,"first republic is an ultrahightouch bank that provides extraordinary client service we believe that oneonone interactions build lasting relationships we move quickly to serve our clients’ needs so that their financial transactions are handled with ease and efficiency client trust and security are paramount in our line of business ultimately our goal is unsurpassed client satisfaction which will lead to personal referrals – our number one source of new business we recognize that our competitive advantage starts with our people and our culture at first republic we work hard and move quickly as a very coordinated team if you are looking for an opportunity to grow and contribute in a fun fastpaced environment first republic is the place for you we have exceptional people focused on providing extraordinary service
the data engineer will play a crucial role in our eagle lending group building the data infrastructure that will allow the team to conduct analyze and consult on business decisions eagle lending is leading the bank on how to leverage data and technology to acquire and engage the next generation of first republic clients the data engineer must be comfortable with a fast paced environment where heshe may need to shift responsibilities depending on business needs we’re looking for someone who is willing to roll up their sleeves to help build the foundation so that we can continue to create the reports and run analysis
responsibilities
build data pipelines that collect connect centralize and curate data from various internal and external data sources
manage and extend a reliable effective and scalable data infrastructure
work closely with analysts data scientists and product engineers to understand business needs and designmaintain scalable data models
partner with leadership and stakeholders to develop and execute various reporting packages and ad hoc requests
work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions
use predictive modeling to increase and optimize customer experiences revenue generation ad targeting and other business outcomes
qualifications
bs or ms in engineering computer science math physics statistics or related quantitative field
programming experience in one or more of the following java python r andor c c
strong sql skills ability to perform effective querying involving multiple tables and subqueries
advanced tableau coding skills with a track record of developing visualizations that drive and optimize business outcomes
strong r andor python preferred coding skills
experience and knowledge of statistical modeling techniques glm multiple regression logistic regression loglinear regression variable selection etc
understanding of and experience using analytical concepts and statistical techniques hypothesis development designing testsexperiments analyzing data drawing conclusions and developing actionable recommendations for business units
experience creating and using machine learning algorithms and statistics regression simulation scenario analysis modeling clustering decision trees neural networks etc
excellent written and verbal communication skills for coordinating across technical and nontechnical teams",,CA,False,data_engineer
Data Engineer,"job description
at marketdial were building software that enables our customers to make sophisticated multimillion dollar marketing pricing staffing and operational decisions through offline ab testing our customers are leaders in the retail grocery and cstore spaces we are an early stage startup with lots of room to grow

part of building this software is transferring and reshaping our clients’ data in the marketdial data ecosystem we’re looking for a developer that is looking to grow their big data skills and work closely with industryleading retail companies to develop creative analytical solutions this job includes managing the endtoend lifecycle of integrating client data into the marketdial app ensuring data accuracy a robust data architecture and automated etl process perfect data and a robust data pipeline is the lifeblood of our business

daily duties will include large file processing map reduce adhoc report generation development and maintenance of our automated etl code base and eating free food ultimately we’re looking for creative problem solvers to work in a caring fun and profitable environment

skills and qualifications
successful applicants will have some flavor of these skills 1 years experience

python must have at least 1 yr experience
sql
bigquery
data engineering and database layout skills
github or other version control tools
unix  shell
docker
luigi
apache spark
communication with people in both technical and nontechnical roles
dash of statistics the word standard deviation should treat you like a warm hug
business sense the ability to look at numbers and sense check if they look right or wrong is key to success in this role

here at marketdial we embrace and celebrate difference we believe that a diverse culture is essential to the benefit of our culture company and customers marketdial is proud to be an equal opportunity workplace and is an affirmative action employer we believe that in hiring the best talent a diversity of cultures ideas and perspectives will reflect the global diversity that our world is today we are committed to equal employment opportunity regardless of race color ancestry religion sex national origin sexual orientation age citizenship marital status disability gender identity or veteran status if you have a disability or need that requires accommodation please let us know at
erikamarketdialcom erikamarketdialcom
if you are interested and want to learn more about what marketdial does and what role you might be able to fit here please fill out an application below we look forward to getting to know you",,UT,False,data_engineer
Data Engineer,temporary contractlooking for suitable candidates for data engineering positions for our client in mclean vatechnology sparkpythonawsavailablity immediateexperience 3please apply with your latest profile and mention your employment statusthanksjob types fulltime temporary contractexperiencespark 1 year preferredaws 1 year preferredpython 1 year preferredwork authorizationunited states required,,VA,False,data_engineer
Biomedical Data Engineer - Health Technologies,"the health technologies team conceives and proves out innovative technology for apple’s future products and features in health
we are seeking a highly capable biomedical data engineer to join a multidisciplinary team successful candidates will be able to integrate with our research study leads data scientists and engineers to develop and support effective data analysis and machine learning workflows

key qualifications
experience with software engineering frameworks
excellent coding skills in python eg scipy pandas jupyter plotly c scripting and object oriented programming languages
experience with web development eg javascript html react d3 angularjs
experience with web service apis eg aws redcap xnat
experience designing and maintaining nonrelational databases eg mysql mongodb
experience with linux macos based development frameworks
experience with version control frameworks git virtualenv
experience contributing to open source projects eg using github
sense of design and appreciation for user experience are plusses
description
script and automate data ingestion and transformation pipelines with hooks for auditing qa and redaction
collaborate with team members to develop novel visualization and interactive front ends for navigating large volumes of data
process troubleshoot and clean incoming data from human studies
apply best practices for information security including safe harbor privacy principles for sensitive data
incorporate and comply with fda regulations as they pertain to electronic and clinical data and databases
work closely with team members and study staff to architect data management plans
implement and automate compliance and edit checks per data management specifications
collaborate with team members to architect data models and create tools to harmonize disparate data sources
create and populate databases with existing and incoming clinical data
translate data management requirements into computer hardware requirements
perform it administration of secure computing data stores and databases for structured and unstructured data
interest in data analysis data science and machine learning
experience with biomedical sensorsplatforms for measuring physiological signals in the health wellness andor fitness realms

education
bsmsphd in computer science biomedical engineering informatics statistics or equivalent with relevant 02 years industry experience in medical physiological health wellness andor fitness fields
bootcamp or selftaught data engineering  science skills are welcome

additional requirements
you will thrive in our fastpaced environment if you are highly organized and able to multitask
flexible thinking adaptability to change and comfort with ambiguity are hallmarks of successful people on our team
we look forward to witnessing your excellent communication and interpersonal skills during the interview process
apple is known for heterogeneous and cohesive teams a proven ability to work seamlessly with others is required to acclimate quickly to our culture
we highly value your analytical mind and problemsolving skills and expect a stellar attention to detail
you will let the customer experience guide your decision making you will design with apple’s culture and values inclusion for all and privacy as fundamental requirements",,CA,False,data_engineer
Software Engineer - Big Data,"we are looking for an exceptional data engineer to help build a stateoftheart data platform that scales with the rapidly growing ecosystem at jet

about the role

 we are looking for a creative resourceful problem solver who is comfortable working both independently and collaboratively this person would take on the following responsibilities

design implement and manage a data platform that supports realtime ingestion lowlatency reads and ml workflows
implement reusable apis for stream processing and data transformation
gather and process data at scale across all business domains
evangelize an extremely high standard of code quality system reliability and performance
influence crossfunctional architecture across the organization
about you
you have at least 2 years of working experience in a productdriven engineering environment
you have worked with highvolume highvelocity data ideally using technologies like kafka spark and cassandra
you know how to write microservices in java or scala or are willing to learn
you are interested in learning more about functional programming
you have experience building and deploying services in a cloud environment
you prioritize building maintainable scalable operationally sound services",,NJ,False,data_engineer
Data Engineer,"company description
quartet is a pioneering technology company connecting physical and mental care to improve people’s health and quality of life we are building a collaborative technology platform that brings together physicians mental health providers and insurance companies to effectively improve patient outcomes and drive down healthcare costs our datadriven platform identifies highneed patients and facilitates access to personalized care backed by 92mm in venture funding from top investors like gv formerly google ventures and oak hcft quartet is headquartered in nyc and is currently operating in several markets across the us  pennsylvania massachusetts louisiana washington northern california and new jersey

mission
were creating a platform to improve outcomes for patients with mental health and chronic medical conditions we do this in many ways from identifying patients at risk and routing them to the right specialists to creating a feedback loop between the primary care physicians and behavioral health specialists so they can collaborate on each patient’s treatment these patients are often lost in our healthcare system and dont get the right care at the right time we want to fix that

outcomes
we are looking for a data engineer that will work on ingesting transforming and organizing disparate sources of healthcare data from our partners and internal teams into canonical data models for application and data science insights our data platform team works to not only clean standardize and load external data sources into our platform but also generates key base features from that data to be utilized by downstream systems and internal customers — from the backend api to data science teams this role will also work to vend tooling and automation to support our growing data needs and allow data integration team members working with customers to self service data prior to it being ingested and distributed to the rest of quartet you are passionate about data and will collaborate with and learn from other engineers data scientists and clinicians
responsibilities
develop and maintain tools and systems to ingest transform and distribute numerous application streams as canonical data models and features
implement and vend data ingestion transformation and feature generation tools to data science ml and partner services teams
work with subject matter experts and product managers in architecting models to improve reliability and interpretability of data for analytical and business needs
understanding quartet business objectives and design services that couple business logic with reusable components for future expansion
monitoring performance and advising any necessary infrastructure changes
leverage best practices in testing continuous integration and delivery
build a world class scalable health data ingestion pipeline
drive down the time to insight by improving the accessibility and organization of data
competencies
must haves
experience with integration of data from multiple heterogeneous data sources
experience developing in python and spark scala and java a plusexperience working in distributed systems
experience with sql and data modeling
experience standing up and maintaining infrastructure at all levels of the stackinterest in solving realworld healthcare problems
a great sense of humor and an ability to add to our dynamic culture
a desire to work on a highlycollaborative missiondriven team

nice to haves
ideal candidate has 5 years of engineering experience
experience with hl7 and other healthcare data exchange standards a big plus
experience with aws experience with apache airflow
benefits and perks of working at quartet include
medical dental vision and life insurance
enhanced mental health benefits
paid membership to one medical
pretax health transit and dependent care flexible spending accounts
feefree 401k program
unlimited vacation and sick leave and competitive family leave policy
amazing office with stocked kitchen and regular company gatherings
working with some of the most talented and missiondriven minds in the industry


employee benefits for quartet include unlimited vacation volunteer opportunities catered lunches snacks team events and outings full medical dental  vision coverage generous parental leave commuter benefits 15 free therapy sessions  unlimited copay reimbursements for mental healthcare 401k espp gym benefits
want to know what quartet life is like click here to meet our team
quartet is committed to building a diverse team and fostering an inclusive culture and is proud to be an equal opportunity employer we embrace and encourage our employees differences in race religion color national origin gender family status sexual orientation gender identity gender expression age veteran status disability pregnancy medical conditions and other characteristics headhunters and recruitment agencies may not submit resumescvs through this web site or directly to managers quartet does not accept unsolicited headhunter and agency resumes quartet will not pay fees to any thirdparty agency or company that does not have a signed agreement with quartet
please note",,NY,False,data_engineer
Data Engineer,"summary

the data engineer will lead the development of data warehousing solutions to power business intelligence at the hive they will synthesize business requirements for analytics operational and fundraising information creating and implementing solutions to integrate data from various enterprise systems

essential duties and responsibilities
 write code to build etl processes to integrate information from various enterprise it systems ability to perform api integrations on platforms such as salesforce marketing cloud we use postgres sql for our data stores and aws for hosting design new data structures add to and optimize existing data schemas ability to analyze upstream and downstream effects of a change in existing data structures and planning for change management understand key strategies and business processes of internal clients across the organization in order to provide the best solution to achieve their outcomes conduct analyses of business or technical user needs document requirements and design tailored data solutions monitor performance of etl processes and build in redundancies to avoid risk of an information outage provide support and troubleshoot questions arising from report developers and business users of these data solutions track and document work done and communicate progress with business users in a timely manner ability to adapt andor modify processes in response to changing circumstances well versed in specific industry best practices and an ability to adapt them to u4u’s environment ability to work effectively across multiple complex projects research and recommend innovative and automated approaches

qualifications
to perform this job successfully an individual must be able to perform each essential duty satisfactorily the requirements listed below are representative of the knowledge skill andor ability required reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions

education andor experience bachelor’s degree in computer science information systems or related field required andor combined equivalent of education and experience master’s degree preferred 5 years of experience as a business or technical professional in business intelligence data modeling or related field experience in defining and documenting complex systems requirements experience with data integration building database objects using sql optimizing queries and writing stored procedures  5 years experience in data warehouse methodology and data modeling 3 years experience in extracting data from various apis strong ability to analyze business requirements and recommend solutions ability and desire to mentor and train others experience in software development methodologies experience in writing sql queries coding in python and creating systems in the cloud computing space preferably aws experience with crm’s preferably salesforce experience with working on different file types for both structured and unstructured data

physical demands
the physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job
 tasks involve some physical effort ie some standing and walking or frequent light lifting 510 lb minimal dexterity in the use of fingers limbs or body in the operation of office equipment may involve extended periods of time at a keyboard extended periods of sitting at a workstation or desk and manual dexterity to work efficiently on computer keyboard for data entry and composing of documents

work environment

the work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job the tasks will generally be performed in a typical office environment may also involve travel to some locations within the company’s region of operations and select donor locations

disability specifications

usa for unhcr will make reasonable accommodations in compliance with the americans with disabilities act of 1990",,NY,False,data_engineer
Data Engineer,"if you love clean data we want to hear from you we are looking for a data engineer who will help take the company’s data reporting and infrastructure to the next level you will work with the executive product marketing sales sales engineering finance and customer success teams every day—in short your work will have an impact on the whole company you will be our second data engineer and will be critical in shaping our data foundation

you will contribute to a variety of projects that range from designing robust and fully automated etl processes to building tools for improving companywide productivity with data you have a passion for designing implementing and operating stable scalable and efficient solutions to flow data from production systems into the data warehouse

we know new analytics technologies are emerging every single day and we are excited about the impact they will have – we hope you share our enthusiasm

what youll do
collaborate with engineers to extract transform and load etl data from a wide variety of inhouse and 3rd party data sources
ensure we have data consistency on both production and analytical databases you will own the integrity of our data from endtoend and the company will make high impact decisions based on this data
build a data warehouse to provide timely data to multiple third party applications salesforce marketo etc
design and build tools that make our data pipelines and surfacing more reliable and easier to use
work closely with backend engineers to roll out new tools and features
triage identify and fix scaling challenges
collaborate with internal data customers to gather requirements
help develop our data engineering function in areas of data architecture business intuition and insight
who you are
you have at least 2 years of experience with at least one relational database—mysql postgres oracle or other
you have experience with sql and data warehousing using a relational database
you are experienced with largescale data pipelines and etl tooling
you have previous coding experience our etl process is in ruby and we use python for some data analysis
you can maintain confidentiality of sensitive customer data
bonus points
you are experienced with eda exploratory data analysis and data visualization we use tableau
you have used amazon redshift
you can manipulate data using python pandas numpy scikitlearn etc
you have previously worked in business intelligence analytics or finance
about hellosign
we believe that the way business gets done today is broken that’s why we’re dedicated to simplifying work for everyone  from small startups to large enterprise companies millions of individuals and over 75000 companies worldwide trust the hellosign platform – which includes esignature digital workflow and efax solutions – to automate and manage their most important business transactions
with a sharp focus on user experience and a lust for innovation hellosign is on a mission to simplify work

life at hellosign

we are centrally located in downtown san francisco near bart the transbay terminal and the ferry building just over 100 employees we are growing the company deliberately with a keen eye towards maintaining a culture that values lifestyle fun and continuous improvement we were awarded the hirepalooza culture award for lifestyle in 2015 and the healthy mothers workplace bronze award in 2016 and 2017 this year we won sf business times best places to work award for small employers we continue to maintain an overwhelmingly positive presence on glassdoor and the muse

we have raving fans who love what we make • were userfocused and productdriven • were always evolving with an eye towards improvement • were committed to building a product people want • we thrive on collaboration and learning from each other • we have a supportive familial atmosphere • we work in an open airy creative space • we laugh a lot • we love dogs • and well never forget your birthday

hellosign is an equal opportunity employer committed to hiring a diverse team of qualified individuals • hellosign conducts background checks pursuant to the san francisco fair chance ordinance hellosign will consider for employment qualified applicants with arrest and conviction records • hellosign participates in everify",,CA,False,data_engineer
Data Engineer,"univision is seeking a solutionsoriented data engineer to join the media intelligence team the ideal candidate will not only possess great communication skills but will also be equally at home writing code and solving complex problems in a fast paced creative environment this role focuses on transforming large datasets into meaningful insights that will ultimately inform business decisions across an array of marketing channels including digital social media email tv radio and outofhome this individual must be a strategic and creative thinker a selfstarter and a collaborator who’s willing to share ideas and proactively discover opportunities for marketing efficiencies and increased roi

job responsibilities
the data engineer will be responsible for developing and implementing databases data collection systems data analytics and other strategies to identify opportunities in the performance of media campaigns in addition the role will inventory all sources of data to maximize data analytics opportunities further responsibilities include
conduct analysis on key initiatives using internal and external data and understand key drivers of the business
analyze effectiveness of marketing spend per campaign
interpret data analyze results using statistical techniques and provide ongoing reports
develop and implement databases data collection systems data analytics and other strategies that optimize statistical efficiency and quality
acquire data from primary or secondary data sources and maintain databasesdata systems
manage relationship with data and analytics vendors as well as internal counterparts on other teams
manage ingestion of daily reporting from various media channels and platforms
audit and “clean” current data sets and redefine reporting processes and workflow for sharing information
identify analyze and interpret trends or patterns in performance data and recommend optimization opportunities in realtime for improved marketing performance andor cost efficiencies
project manage quarterly and endofcampaign reporting to present data and learnings to key stakeholders
advance the data and analytics capabilities of univision by researching exploring and onboarding future tools
minimum qualifications
desired experience
candidates must be comfortable with manipulating transforming and analyzing complex data from varying sources we are actively looking for professionals with experience in the following enterprise information management disciplines

data warehousing
data warehouse design and architecture
dimensional modeling
data integrationdata services

analytics and reporting
dashboards
ad hoc and guided analytics  olap
predictive analytics
data visualization

data governance
design and initiation of data governance process
metadata management
master data management
data auditing and security
data architecture organization and practices

required education  skills
bs in mathematics computer science information management or data science preferred
2 – 5 years of proven experience as a data engineer or similar role working with complex data sets
technical expertise regarding data models database design data mining and segmentation techniques
strong knowledge of and experience with reporting suites domo and tableau preferred databases sql etc programming xml javascript and etl frameworks
knowledge of statistics and experience using statistical packages for analyzing datasets excel spss sas etc
strong analytical skills with the ability to collect organize analyze and disseminate significant amounts of information with attention to detail and accuracy
ability to manage multiple priorities under tight deadlines
strong analytical strategic thinking and problemsolving skills
strong skills in developing powerpoint presentations and communicating performance data to senior leadership
excellent verbal and written communications skills",,FL,False,data_engineer
Data Engineer,"we are seeking a detailoriented imagery data engineer to join our team helping to maintain an imagery data platform that support model training in this particular role you will work with large amount of imagery data coming from different perception sensors
responsibilities
responsible for the maintenance of dl training data pipelines
keep track of the progress of image data inhouse labeling
responsible for data customization to meet various demands from deep learning team
manage the tasks and progress of labeling to support model training
requirements
strong familiarity of python
2 year  experience in programming in python mysql
good knowledge of web service webgl and react
experience with data pipelines is a plus
experience with c is a strong plus
experience of mldl project is a plus
excellent communication skills and team player
bsms in computer science or related technical discipline",,CA,False,data_engineer
Data Engineer,"commissionworking in a team to build a new enterprise platform that will consolidate enterprise datasets and handle data integration and transfer between enterprise systems
developing components that comply with standards and where required developing key integration touchpoints for interoperability
working closely with the lead data engineer
provide recommendations and evaluations of new designs and solutions
work in technologies in which you are unfamiliar and learning it as you go
solve advanced programming problems with minimal supervision
provide technical expertise to peers on the team
requirements
key required areas of experience
4 years working with largescale enterprise database warehouses
experience working with azure blobs events azuresql and other azure technologies
experience with data analytics and data modeling
experience with aspera tibco data virtualization formerly cisco composite
experience with integration platforms like snaplogic iib biztalk
must have strong etl experience with tools like informatica ssis
not required but a plus if you know…
experience with nosql azure’s implementation of it is a double plus
experience with elastic search
a computer science degree or background
benefits
about the company
clearlyagile is one of the fastest growing agile companies in the tampa bay area we foster career growth and are focused on having fun and delivering quality products and services to our clients with 15 paid holidays off per year including the entire week of thanksgiving and christmas plus 15 days of paid time off medical vision and dental benefits that start on your first day and we contribute 250 towards your medical 401k paid training certifications and very competitive pay  commission plans clearlyagile strives to listen to and invest in its most important asset…its people
our mission transform our customer’s businesses using agile methodologies and principles to help them succeed in a flexible collaborative selforganizing and fastpaced environment

our values we hire fire and reward based on our core values
produce the best quality of work possible
be a team player
invest in yourself
be a professional
be a leader
we are an equal opportunity employer and committed to a diverse workforce
to learn more about us visit our website",,FL,False,data_engineer
Big Data Engineer,90000  140000 a yearhiplease have a look at the job description below and let me know if you would be interested if so please revert with your updated resume and expected salaryjob description title big data engineerlocation irving tx and tampa flduration fulltimepermanenthandson experience as big data engineer  data analyst with experience on big data hadoop echo systems hdfs hive map reduce sqoop sparkextensively worked on spark and hive for performing data analysisimplemented business functionality using spark core and spark sqltransforming the hive jobs into spark sqldeveloping new jobs using spark and evaluating their performancehaving good experience in writing hive queriesworked on spark core numeric rdds pair rdds data frames and caching for developing spark applicationsexcellent programming skills in object oriented programming core java java ee 8  jsp jdbcworking knowledge in web services soap and restgood knowledge  skills in java multithreading collections etcforward details to adamatklaxontechdotcomjob type fulltimesalary 9000000 to 14000000 yearexperiencehadoop 1 year preferredspark 1 year preferredsql 1 year preferredhive 1 year preferredjava 1 year preferred,115000.0,FL,False,data_engineer
Data Engineer/SQL Developer,"job description

our leading retail sportswear client is looking for a data engineersql developer please note this is strictly a w2 position only and we cannot do c2c
job duties
develop and support data solutions in support of supply chain planning reporting and analytics requirements
engage with product owner technology lead report developers product analysts and business partners to understand capability requirements and develop data solutions based on product backlog priorities

qualifications

3 years of experience with data engineering with emphasis on data analytics and reportingstrong experience with sql and relational database engineering oracle sql server teradata— expertlevel sql abilitiesexperience developing with scripting languages such as shell and pythonexperience developing with the aws emr managed service leveraging tools such as sparkexperience with agile delivery methodologies– scrum safe extreme programmingexperience working with sourcecode management tools such as github and jenkinsability to partner with business and technology team members to understand business requirements and translate those into valueadd technology solutions
additional preferences are
experience developing solutions in snowflakeexperience with workload automation tools such as airflow autosysexperience building solutions with data visualization and reporting tools tableau cognosknowledge of supply chain planning business processes and objectives
additional information

to apply
aroghia group provides top market compensation h1b transfers green card processing and a great company culture please provide your resume linkedin profile address and phone number when applying
aroghia group has established a solid reputation in the marketplace by providing our employees with outstanding opportunities for personal and professional growth some additional benefits include but are not limited to
we are a preferred it vendor for topnotch companies in a wide range of industries across the us
aroghia offers various compensation structures hourly salary based on qualifications and market demand
we provide continuous training and development to ensure our team remains at the forefront of technological advancements
open positions httparoghiacomcareers",,OR,False,data_engineer
Data Engineer II,"under moderate supervision the data engineer ii accepts and validates all student level data for assigned projects in order to ensure data integrity combines several sources of data used for reporting test results the data engineer ii also provides input and support into internal products and systems that affect data in the company this position follows established protocols and standards when performing tasks and work outside of standard processes and procedures must be approved by department manager additional responsibilities include the following
validate and accept student level data including student demographic and test data from various sources and provided in various formats
perform cleanup activities to data per specifications created
perform documentation of data processing specifications to ensure common understanding of processes and procedures used on a project
participate in project meetings in order to ensure data integrity issues are discussed and resolved
develop code and process to support validation cleanup transformation and delivery of student data
provide data support to internal products and systems
provide input into the development of internal products and systems
develop appropriate quality assurance steps to be implemented on projects to ensure data accuracy
provide support to team members on projects as needed


qualifications
bachelor’s degree and three 3 to five 5 years of experience in sql development or an equivalent combination of education and experience
comprehensive knowledge of microsoft sql server
sql programming of complex views stored procedures functions and scripts
strong understanding of the fundamentals of developing userfacing reports and forms
experience with visual studio and c preferred
knowledge of microsoft office",,NH,False,data_engineer
Big Data Engineer,50  95 an hourtemporary contractbig data engineerextensive experience of working in scala a mustjob overviewwe are looking for a savvy data engineer to join our growing team of analytics experts the hire will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for cross functional teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up the data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our company’s data architecture to support our next generation of products and data initiativesqualificationsadvanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databasesexperience building and optimizing ‘big data’ data pipelines architectures and data setsexperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementbuild processes supporting data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsexperience with big data tools hadoop spark kafka etcextensive experience of working in scala a mustexperience with relational sqlexperience with aws cloud services ec2experience with objectorientedobject function scripting languages java scalaunderstanding data science algos regression deep learnig methods will be a big plusjob types temporary contractsalary 5000 to 9500 hourexperiencehadoop 2 years requiredjava 1 year requiredbig data 3 years requiredspark 1 year requiredscala 3 years requiredsql 5 years requiredlocationwashington dc required,,MD,False,data_engineer
Data Engineer,"blizzard entertainment games don’t just begin with game ideas nor do they end once those games are released a lot more goes into the creation of an epic game than the work of developers and more than you can ever imagine goes into continuing to build and hone and perfect the most epic gaming experience in the years after our games are in the hands of gamers worldwide
blizzard entertainment is looking for a data engineer to join our global insights team to partner with our respective analytics teams with technical leadership and vision innovation and agility with big data at scale and to develop a deep and rich subject matter expertise with the data most important to the franchise
in this role you will be responsible for providing accurate timely reliable and ultimately useful data to the analytics group this mandate involves everything from the discovery access and integration of source data into the ecosystem to guaranteeing its health and robustness within that ecosystem to modeling and presenting that data in a manner that allows stakeholders within the ecosystem to perform their duties effectively you will have a delicate balance in this role you work most closely with the other members of your group and translate their needs into agile highlycustomized implementations for franchisespecific data at the same time though you work just as closely with the core data team both to ensure that your group does not introduce problematic deviations from core data and that the core data infrastructure itself is supporting your group’s evolving needs you are just as closely tied to the tools and technology team to ensure that your franchisespecific system usage is “playing nice playing fair” within the greater analytical data ecosystem you are one step closer to the business needs of the stakeholders and act as the primary technical resource for the franchise analytics team your priority is to ensure that the analytics groups can provide bestinclass analyses insights and recommendations in the most timely and effective manner possible
our ideal candidate is the druid of the analytics space a powerful technologist whose dedication to the craft allows him or her to morph into whatever form necessary to get the job done while retaining the flexibility to see the bigger picture and respond accordingly the ideal candidate uses the speed agility and targeted onpoint damage of cat form to meet the quickshifting highimpact immediate needs of his or her franchise group before morphing seamlessly into a bear form responsible for tanking the ongoing operational needs of the group as a whole a shift to moonkin allows for the pushandpull flow of ideas between blizzard analytics and core and the final shift to tree provides the stability and integration between the franchise group and the other users approaches policies and procedures of the overall analytical data ecosystem
responsibilities
design develop implement and evolve franchisespecific data pipelines
troubleshoot any performance system or data related issues and work to ensure data consistency and integrity
work with the franchise team as technical lead and primary technical resource
plan and coordinate franchisespecific technical projects
innovate in a more agile environment and summarize ideasapproaches to the core data team for validation and potential integration into core data infrastructure
ensure no deviation from core data
act as a primary technical liaison between the blizzard analytics teams and the core data  tools and technology teams

requirements
2 years working in a large analytical data ecosystem
strong technical understanding of data modeling design architecture principles and techniques to take business requirements from concept to implementation
very strong knowledge of relational databases mpps sql with an emphasis on teradata fundamentals
very strong experience with the hadoop ecosystem including hdfs mapreduce spark hivepig et al
strong verbal and written communication skills across both technical and nontechnical audiences
knowledge of python java linux architecture and scripting
extensive background extracting and transforming complex data sets etl process design and administration
experience with database design and star schema data warehouse theory
passionate video gamer and indepth knowledge of blizzard entertainment games products and services

blizzard entertainment is a global company committed to growing our employees along with the business we offer generous benefits and perks with an eye on providing true work  life balance we’ve worked hard to foster an intensely collaborative and creative environment a diverse and inclusive employee culture and training and opportunity for professional growth our people are everything our core values are real and our mission has never changed we are dedicated to creating the most epic entertainment experiences…ever join us",,CA,False,data_engineer
Data Engineer,"about skillz
today people spend more time playing video games than they do playing all physical sports and esports are poised to become bigger than the nfl nba mlb and nhl combined skillz provides the technology that powers an esports industry forecast to exceed as much as 40 billion in revenue by 2020

as the esports provider for over 8000 game developers skillz enables any mobile game to be turned into a competitive esport that can also be broadcast on major streaming sites like twitch and youtube we do this by integrating our unique layer of code directly into a mobile app which activates our endtoend tournament administration and other important features like player matching anticheating mechanisms customer support and a builtin loyalty program using our patented technology stack weve already hosted more than 500 million tournaments for 15 million players around the world

skillz has raised over 53 million in funding from sources including telstra liberty global and the owners of the new england patriots milwaukee bucks new york mets and sacramento kings in our quest to make gaming better for players and developers were looking for savvy driven and enthusiastic teammates to help us build the future of sports if youre excited about defining a multibillion dollar industry building an awesome product or working with cuttingedge technology skillz just might be for you

our culture
we are true believers in electronic sports so dont be surprised if you see us playing mobile games at our desks or in the kitchen at skillz this type of behavior is encouraged you can also catch us at our weekly game nights playing anything from super mario kart to codenames over dinner while discussing new technologies or brainstorming ideas to improve our business

not a gamer dont worry about it every skillzian brings a unique perspective to the team and we bond over plenty of activities that dont involve games were working to build a truly groundbreaking company and we want topnotch people to join us in that mission as the creators and leaders of a new marketplace we work with a do whatever it takes mentality and frankly we get the job done

our team is comprised of passionate intelligent and creative individuals who consistently seek out new challenges and knowledge we embrace outofthebox strategies to propel our business forward and foster a culture where every persons voice is heard our team comes from diverse backgrounds and our leaders have a strong history of funding and building successful enterprises if youre up for the challenge wed love to meet you

who were looking for
youre ready to take the next step in your data engineering career  to a fastmoving successful company building out their nextgeneration streaming analytics infrastructure you love data consistency and integrity you consider yourself scrappy and a technologist passionate about data infrastructure with your attention to detail and insistence on doing things correctly you know you can make a big impact on a small team youre an excellent communicator and know that you grow faster from being able to mentor others

what youll do

maintain current data infrastructure ensuring that the wider organization can analyze millions of tournaments a day
prototype emerging technologies so that skillz can get the benefit of cutting edge technology
provide infrastructure expertise to data consumers evangelize data engineering principles and enable others to selfhelp
develop instrumentation for analytics and alerting collect and report on meaningful data to improve costs reliability and performance
detect analyze and fix faults with data infrastructure components propose design changes that eliminate weaknesses and obstacles to scaling reliably

your skillz

2 years of experience with python
1 years of experience with sql
independent and resourceful able to assess plan and execute in unfamiliar conditions
able to reprioritize on the fly and respond to adhoc events
excellent analytical and problem solving skills
experience working and improving the etl process
understanding of optimization methodologies

bonus

2 years industry experience
familiarity with aws data products data pipelines dms s3 etc

",,CA,False,data_engineer
Data Engineer,"data engineer data science  palo alto

are you a coding ninja with an appetite for healthcare innovation would you like to help us reinvent the way parents use technology to monitor and improve the health of their young children

we are looking for a software developer with solid foundational knowledge in machine learning proven record of building clean scalable software in the real world and an overflowing passion to make a difference

you should have

team spirit and enthusiasm
flexibility versatility and resourcefulness needed to thrive in at a fastpaced startup
strong foundation in software development
3 years of market experience applying software development specifically to data science and machine learning projects
degree in computer science software engineering or a related field

your responsibilities

own and manage the deployment of ml models into our production backend in a reliable seamless and qualitycontrolled way
identify and abstract common datascience experimentation use cases and implement into modular frameworks accessible via clean well defined apis
own and manage site traffic and user analytics including data pipelining integrating multiple third party analytics platforms dashboard design and implementation

",,CA,False,data_engineer
Data Engineer,"cross river is actively looking to expand our business intelligence and data analysis team
a suitable candidate for this position will have the experience in data warehouse development architecture and handson physical and logical database designing the candidate will have experience working on projects in a collaborative setting composed of crossfunctional teams
a candidate for this position must have a deep passion for data analytics technologies as well as analytical and dimensional modeling the candidate must be extensively familiar with data warehousing and have the skill to draft analyze and debug sql queries
job responsibilities include
design and develop systems for maintenance of business data warehouse etl processes and business intelligence
work closely with other departments and teams to create and implement solutions that balance data needs across the company
establishes the documentation of reports develops and maintains technical specification documentation for all reports and processes
any other duties delegated by director of data analytics and data science
qualifications
3 years of data analysis experience
experience with creating sps functions views sql jobs
experience with sql server management studio
experience with tableau a plus
coding experience would be a plus preferably python
extremely detail oriented with excellent communication skills
excellent problem solving and troubleshooting skills
bs or ms in computer science or related technical field",,NJ,False,data_engineer
Data Engineer,110000  120000 a yearthe enterprise data architect is a thought leader sitting in the enterprise architecture organization partnering with both business and it stakeholders to define and execute an enterprise data strategy and architecture that supports our federal customers mission needs our customer is transforming its applications and data layers to better control the acquisition validation quality and distribution of data across multiple mission critical applications data warehouses and external partners the enterprise data architect will set the overall vision strategy and data architecture as well as direct future initiatives that build components of architecture ensuring convergence towards the defined future state this leadership role will also set the direction for technology including tools for data acquisition reporting analytics data discovery and visualizationresponsibilitiesdevelop maintain and evangelize data architecture guiding principles policies best practices reference architecture and standardsdefine and maintain target data architectures and master data management strategies in alignment with business and technology objectivesleader of data transformation efforts from legacy to new and alternative technologiesprovide thought leadership for it’s data security data integration data services and api effortscollaborate with various business operations applications and data and analytics groups to define establish and run a process that ensures adherence to enterprise data standards and architecture principlesadvocate for and champion efforts to close gaps between asis and tobe architecturesmonitor compliance of development work against established standards and principles and work to resolve issues through appropriate formal and informal channelswork closely with other architects and it managers and developers so that they understand and support data architecture prioritiesreview and analyze existing systems and make recommendations for improvementscreate governance policy for the enterprise data modelplay a lead role in selecting and implementing technologies supporting mdm data discovery data quality analytics and bi tools and champion related process changesprovide general guidance to teams on data architecture topicsrepresent data architecture concerns in design implementation and deployment reviewsanalyze proposed business solutions to understand and document data requirements and partner with solution architects to define required data architecture elementsrequirementsbachelor’s degree in information technology computer science data management or related filed with an emphasis on data and databases required but a master’s preferred equivalent extensive relevant work experience will be considered8 years of experience requiredadvanced knowledge of applying togaf methodology or similar ea framework to the document data architecturestrong working knowledge of application development processesadvanced knowledge of data management data integration and database development technologies and processesadvanced knowledge of cloudbased data strategies nosql sql data warehouse etl business intelligence and analytics toolsability to translate complex technical terminology concepts and issues in terms understandable to technical and nontechnical management and staffstrong interpersonal skills to resolve problems in a professional manner lead working groups negotiate and create consensusadvanced database development skills and experience requiredintermediate knowledge of uml and objectoriented design requiredexcellent oral and written communication skills requiredjob type fulltimesalary 11000000 to 12000000 year,115000.0,VA,False,data_engineer
Data Engineer,contractjob title data engineerlocation whitehouse station njduration 12 monthsvisa h1b gc or uscinterested people please keep in touch with me on 7324121384ideal candidate for this role is someone with a strong background in computer programming statistics and data science who is eager to tackle problems with large complex datasets using the latest python r andor pyspark you are a selfstarter who will take ownership of your projects and deliver highquality datadriven analytics solutions you are adept at solving diverse business problems by utilizing a variety of different tools strategies algorithms and programming languages specific responsibilities are as follows utilize the data engineering skills within and outside of the developing client information ecosystem for discovery analytics and data managementwork with data science team to deploy machine learning modelsyou will be using data wrangling techniques converting one raw form into another including data visualization data aggregation training a statistical model etcwork with various relational and nonrelational data sources with the target being azure based sql data warehouse  cosmos db repositoriesclean unify and organize messy and complex data sets for easy access and analysiscreate different levels of abstractions of data depending on analytics needshands on data preparation activities using the azure technology stack especially azure databricks is highly desiredimplement discovery solutions for high speed data ingestionwork closely with the data science team to perform complex analytics and data preparation taskswork with the sr data engineers on the team to develop apissourcing data from multiple applications profiling cleansing and conforming to create master data sets for analytics useutilize state of the art methods for data manning especially unstructured dataexperience with complex data parsing big data parser and natural language processing nlp transforms on azure a plusdesign solutions for managing highly complex business rules within the azure ecosystemperformance tune data loadsskills required  · mid to advanced level knowledge of python and pyspark is an absolute must · knowledge of azure hadooop 20 ecosystems hdfs mapreduce hive pig sqoop mahout spark etc a mustexperience with web scraping frameworks scrapy or beautiful soup or similarextensive experience working with data apis working with restful endpoints andor soapsignificant programming experience with above technologies as well as java r and python on linux a mustknowledge of any commercial distribution like hortonworks cloudera mapr etc a mustexcellent working knowledge of relational databases mysql oracle etcexperience with complex data parsing big data parser a must should have worked on xml json and other custom complex data parsing formatsnatural language processing nlp skills with experience in apache solr python a plusknowledge of highspeed data ingestion realtime data collection and streaming is a plusqualificationsexperiencebachelors in computer science or related educational background35 years of solid experience in big data technologies a must microsoft azure certifications a huge plusdata visualization tool experience a plusjob type contractexperiencebigdata 1 year requiredpython 1 year requiredpig 1 year preferredpyspark 1 year requiredhive 1 year preferred,,NJ,False,data_engineer
Predictions and Extensions Data Engineer - Apple Maps,"how should you decide when to leave for your next appointment how will you find a parking structure closest to your destination
our team builds solutions which seek to answer these and many other important questions we are the maps predictions and extensions team and we are seeking a teammember to help us innovate and craft the next generation of the maps experience we support apples ios macos tvos and watchos solutions join us to build a new experience that will surprise and delight millions of travelers for every single trip they take

key qualifications
objectoriented programming and design experience
strong skills in objectivec andor c
deep understanding of multithreaded programming
experience with decision support and analysis techniques
real passion for product quality and attention to detail
experience translating complex functional and technical requirements into deliverable solutions
ability to blend multiple concepts together into a cohesive and scalable design
strong overall systems knowledge is desired
description
on our team you will be responsible for building frameworks which make apple products more personalized and intelligent you will work closely with designers and engineers across our company to ideate and craft new features which will positively improve our customers navigation experience
in this role you will collaborate with many other apple team members working on internal and public apis used by 3rd parties to meet these demands you will use your ios or macos development skills to contribute to the bestpossible application performance solutions possible using a variety of tools and techniques along with your aptitude for building userfriendly interfaces you will develop and support various maps frameworks and solutions on multiple platforms ios macos watchos and tvos understanding and developing shared codebases between different operating systems will be a comfortable concept for you

education
bs or ms in any engineering or science field or equivalent experience will be considered

additional requirements
while not required exposure or knowledge of one or more of the following skillsets would be beneficial
 interest in maps or location related technologies
 experience with machine learning technologies or advanced data analysis
 systems programming experience frameworkslibrariesdaemons
 knowledge of applied research techniques
 published an app for consumers or have written production code for a device
apple is an equal opportunity employer that is committed to inclusion and diversity we also take affirmative action to offer employment and advancement opportunities to all applicants including minorities women protected veterans and individuals with disabilities apple will not discriminate or retaliate against applicants who inquire about disclose or discuss their compensation or that of other applicants",,CA,False,data_engineer
Data Engineer,"the data engineer will collect and manage the data we receive from the field including casinos

job responsibilities



builds and maintains etl systems
collects and reviews the data from native american tribes and makes changes to the data as needed
gathers cleans imports and manages our performance data
enhances data collection procedures to include information that is relevant for building analytic systems
munges the data from a lot of data sources including processing cleansing and verifying the integrity of data used for analysis
builds a roadmap for the tools and processes we will use to manage our data as it grows exponentially
integrates new sources of data such as competitive geographic weather and calendar data
20 travel is expected in this role

qualifications



bs in computer science or equivalent degree
solid knowledge of statistics including familiarity with statistical tests distributions maximum likelihood estimators etc
proficiency in using sql
previous etl and data integration experience
experience with python or other scripting language
comfortable in a windows environment
excellent organizational and communication skills must be detail oriented
occasional travel to various locations as needed
excellent skills in articulating ideas and information to clients in a clear manner
high ethical standards and integrity
team player with highperformance standards

preferred qualifications



13 years of experience as a data engineer
strong customer servicesupport experience via phone email and inperson

",,VA,False,data_engineer
Data Engineer,"dialpad is the cloud based phone system that powers voice video and messages all from a single platform with a beautifully intuitive interface that works on your existing devices your phone system is finally as adaptable as your team

who we are
at dialpad were a team of doers a team that thinks outside the box and when that doesnt work we reinvent it we dont settle for the status quo and neither do the things we build led by the same minds behind google voice we build products that get businesses talking—whether its across the hall street or country

with 120 million in funding from iconiq capital google ventures andreessen horowitz scale ventures and other top vc’s dialpad attracts top engineers from companies like microsoft and google and every member of our team plays an essential role in creating dynamic products that doesn’t just combine design and mobility but works with you wherever productivity may strike

about the role
were looking for data engineers who are eager to embrace broad aspects of data engineering from bare metal to data model you’ll work directly with our data science and backend engineering teams to build infrastructure and manage the overall performance and reliability of our systems you’ll design software to process search analyze and store data for applications that are continually growing in scale while continually optimizing for security and speed interested in the science of conversations data apis and scaling a system that supports realtime voice transcription  analysis let’s meet

environment


languages python
batch and stream processing with beam data bricks dataflow kinesis bigtable
data warehousing bigquery google storage
experience building and managing efforts in both batch and streaming data processing pipelines with technology like beam spark etc
rdbms nosql shared storage etls queuing systems pubsub message buses
operations cloud providers ie gcloud aws etc docker orchestration systems salt puppet ansible etc cicd systems circleci jenkins etc
also linux gi

required


strong fundamentals in computer science and software engineering
your experience with the tools we use is nice your skill with lots of tools is better
you arent afraid to switch between building longterm stable systems and scrappy demos when needed
you measure  monitor everything you build to ensure that it remains stable
you work well on on siloed as well as collaborative projects
you want to work at a startup this means things are going to change quickly and you’re comfortable with that
you’re committed to personal and professional growth both inside and outside of the workplace through code reviews conferences and exploration

about us
joining our team means collaborating with people that aren’t just passionate about their work but about argentine tango musicals sushi burritos comic books  you name it because if you’re going to redefine the status quo you need a group of people hungry to do more to see more and be more than where they started

there is no idea too crazy and no task too small — we work together to make things we’re proud of

compensation  equity

teamwork makes the dream work we recognize that our dedicated team members are what make our success that’s why we offer competitive salaries in addition to stock options

healthcare

an apple a day keeps the doctor away  and it doesn’t hurt that we offer 100 paid medical dental and vision plans for you and your dependents

reimbursements

we offer a monthly stipend to help cover your cell phone home internet and even gym membership costs

education

we believe in your future as much as you do thats why we offer a yearly stipend for continued learning and education expenses

office meals

bon appetit enjoy catered lunches free snacks  drinks both health and unhealthy  no judgment

location location location

san francisco san ramon austin raleigh vancouver kitchener tokyo new york from coast to coast our offices are nestled in active and growing downtown areas

dialpad is an equal opportunity employer we believe in creating a community of inclusion and an environment free from discrimination or harassment",,CA,False,data_engineer
Data Engineer,"meet cargurus—the 1 visited online car shopping website in the us at cargurus were building the worlds most trusted and transparent automotive marketplace where its easy to find great deals from toprated dealers

founded in 2006 by langley steinert cofounder of tripadvisor cargurus is a technology company with a passion for data and its power to simplify every aspect of the car shopping experience using proprietary technology search algorithms and innovative data analytics we provide unbiased validation on pricing dealer reputation and vehicle history

cargurus is looking to hire a highly motivated data engineer to help shape our growing data infrastructure you will work closely with analysts in all areas of the organization becoming the expert in crafting data assets pipelines and reporting tools youll be a founding member of this team and will be a key participant in its growth this role is key to helping cargurus become an insightdriven organization by democratizing our data assets

what youll do

create and promote the cargurus data dictionary a key component of our data analytics strategy the data dictionary contains the definitions of our core entities measures and metrics
become a trusted advisor to product marketing finance and other areas of the business to define and provide data critical to strategy
maintain and expand etl and reporting tools
participate in the design of our overall data collection strategy including technology data pipelines and visualizations
build a scalable data insight platform that makes every decision data driven

who you are

24 years experience as a software engineer data engineer or related field
significant software engineering skills preferably in python ruby or similar
familiarity with linuxunix shell scripting
comfortable with using test infrastructure to validate code
ambitious team player who thrives in a collaborative environment
expert in sql with ability to optimize database and query performance
familiarity with redshift snowflake bigquery or other largescale databases a plus
familiarity with nosql environments a plus
detective with keen interest in solving business problems with data

cargurus culture
at the core of our company culture is a spirit of innovation curiosity and collaboration true to our startup roots were nimble flexible and hardworking we have a great respect for testing and learning and a healthy aversion to scheduling meetings to discuss meetings lunch is catered daily gym membership is free foosball and ping pong are played often now a publiclytraded company were as committed as ever to cultivating the culture that got us here

in addition to the us cargurus operates sites in canada the uk and germany with other markets on the horizon our offices are located in cambridge ma detroit mi and dublin ireland if youd like to learn more please visit our careers page  httpscareerscarguruscom ",,MA,False,data_engineer
Data Engineer,"analytics division philadelphia pa or remote  full time

our data engineer will be a datadriven expert but also strategic that can deliver insightful and actionable insights from complex datasets the data engineer will provide data  analytical support to all elite sem divisions our analytics team is helping big brand ecommerce optimize their marketing stack

essential functions

collaborate with division leads to design implement and deliver insightful analytic solutions for clients
build out api integrations for ingesting vendor data
build out etl pipelines to push data to reporting and other systems
prepare customer facing reporting including working with account managers to determine correct metricsdimensions

core competencies

strategic agility  sees ahead can anticipate future consequences and trends broad knowledge and perspective
problem solving  uses rigorous logic and methods to solve difficult problems with effective solutions
innovation management  brings creative ideas to market facilitates effective brainstorming helps the creative process
customer focus  dedicated to meeting and exceeding expectations to customers establishes and maintains effective relationships with customers
business acumen  knows how businesses work knowledgeable in currentfuture policies practices trends technology etc
process management  excellent at figuring out the processes to get things done understands efficient work flows
learning on the fly  learns quickly when facing new problems relentless learner open to change improves enjoys challenges and finding solutions

requirements

13 years of professional software development experience
1 years working with big data sets
experience with a host of tools including google analytics adobe analytics google tag manager and tag auditing tools such as observepoint
strong experience using postgressql and version control with git
basic experience using python javascript and linux
advanced ms excel skills required
strong statistical and modelling ability

preferred requirements

etl experience api integration and marketingadtech domain knowledge

about elite sem elite sem is an awardwinning digital marketing agency founded on search focused on holistic performancedriven digital marketing elite expertise spans paid search seo shopping  feed display advertising paid social conversion rate optimization cro and insight  analytics elite brings a unique business model to the market that ties account performance to account managers and rewards our teams for continuous performance and satisfied clients with a share of company profits elite sem survives and thrives by the mantra great lives for great people – this includes employees clients partners vendors fans and everyone that crosses our paths our core values – love what you do circle of education attitude of gratitude and strive for greatness – help foster this goal each and every day

disclaimer this description has been designed to indicate the general nature and level of work performed by employees within this position the actual duties responsibilities and qualifications may vary based on assignment or group elite sem is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color gender sexual orientation gender identity or expression religion national origin marital status age disability veteran status genetic information or any other protected status

flsa classification exempt

working conditions working indoors sitting at a computer for extended periods of time lifting no more than 10 pounds",,PA,False,data_engineer
Data Engineer,60  65 an hourcontractjob summarythis person will be responsible for migration of data from existing on perm systems into cloud data warehouse individual will be involved in all aspects of data migration includingdata analysis mapping etl development reconciliation testing and documentation responsibilities and dutiesresponsible for migrating data into cloud data warehouse solutionindividual will need to meet the requirements set by the business with a focus on data quality timeliness  group coding standardswork with other team members to ensure that all objectives and commitments are fulfilled in line with expectations agreements and standardsmaintain consistency in processes and follow guidelines as laid out by team standardsmonitor and report on progress on tasks assignedunderstand and apply industry practices architectural standards and procedures relating to work assignmentstranslate business requirements and technical designs into welldeveloped solutions that meets business data and kpi goalsdesigning database queries views and functions for reporting and data analytics design and implement technology best practices guidelines and repeatable processesoptimize and refactor sql databases and database objects etl processes reporting and analytic solutions in support of business needsevaluate and assess capabilities of new technologies and business intelligence tools as requiredrequired experience skills and qualificationsstrong experience data migrationintegration experiencebachelor’s degree in computer science information technology or related fieldat least 5 years experience in data modeling development implementation and support of transactional databases and data warehouses preferably teradataexpert level experience in sqlexperience with business intelligence reporting and analytical tools microstrategy tableau etcexperience working on cloud based platforms awsdata warehouse experience aws redshift snowflake computingadvanced expertise in performance monitoring and optimizationstrong analytical critical thinking  problemsolving skillsjob type contractsalary 6000 to 6500 hourexperiencedata modeling development implementation 5 years preferrededucationbachelors preferred,,NJ,False,data_engineer
Senior Big Data Engineer,contractthis is one of the super urgent position prefer local candidatesrole senior big data engineerduration long term contractlocation nyc nyskill set  spark impala scalajava hadoopjob type contract,,NY,False,data_engineer
Data Engineer,required experience skills and qualificationstitle  data engineerlocation morrisville nctype fulltimepreferred qualifications  5 years of related experience is required a bs or masters degree in computer science or related technical discipline is required etl experience with data integration to support data marts extracts and reporting experience connecting to varied data sources excellent sql coding experience with performance optimization for data queries understands different data models like normalized denormalied stars and snowflake models worked with transactional temporarl time series and structured and unstructured data worked in big data environments cloud data stores different rdbms and olap solutions experience in cloudbased etl development processes experience in deployment and maintenance of etl jobs is familiar with the principles and practices involved in development and maintenance of software solutions and architectures and in service delivery has strong technical background and remains evergreen with technology and industry developmentsjob type fulltimeeducationbachelors preferredwork authorizationunited states required,,NC,False,data_engineer
Data Engineer,"duties and responsibilities
as a member of crossfunctional project teams work with partners to build data services suitable for data analysis machine learning and visualization
develop analysis programs and visualization code based on specifications from data scientists
assist in data management and metadata capture
train users on systems and provide basic support
prepare technical reports and make presentations to project teams leadership and other stakeholders


education and experience
ms 2 years’ experience or bs 3 years’ experience in physics mathematics statistics biology engineering bioinformatics computer science or a related field
strong computer science database and programming background


technical skills
handson experience in developing and implementing data services and data analysis pipelines
programming in python  r
database design querying and performance optimization
api development workflow management
experience with visualization tools is desired
experience with cluster and queue management systems is a plus
web site development is a plus
software development skills functional vs object oriented design version control modular design


desired key competencies
ability to understand and execute on the company’s mission and values
maintain a high degree of ethical standard and trustworthiness
capable of fostering change in an organization
deals with conflict in a direct positive manner
ability to think and adapt to a rapidly changing environment
able to reach rational conclusions through complex processing of information
fosters innovation through creative solutions
successful at communicating in both oral and written forms
fosters constructive dialogue and feelings toward the company coworkers and tasks being managed
well organized and capable of clear communication through technology ie outlook powerpoint and other programs used to create and distribute reports and key information
effective organization and implementation of group projects
uptodate knowledge on industry current events
maintain a high degree of accuracy and attention to detail
energized by accomplishments and excellence in the workplace
capable of high performance in independent work as well as in team setting
understanding eukaryotic and prokaryotic biological systems including molecular and cellular biology
ability to effectively communicate complex data and analysis to audiences with diverse technical backgrounds
effectively portrays analysis conclusions in a graphical andor interactive format
eoe mfdv",,CA,False,data_engineer
"Data Engineer, Various Data Engineering Teams","the new york times is seeking inventive and motivated data engineers at all levels of experience to join the data engineering group in this role you will build critical data infrastructure that surfaces data and insights across the company

about us
our data engineering teams are at the intersection of business analytics data warehousing and software engineering as maxime beauchemin wrote in “ the rise of data engineering ” etl and data modeling have evolved and the changes are about distributed systems stream processing and computation at scale they’re about working with data using the same practices that guide software engineering at large

a strong data foundation is essential for the new york times and we’re responsible for it we use our data infrastructure to power analytics and data products and to deliver relevant experiences to our customers in realtime we enable our company to validate strategic decisions make smarter choices and react to the fast changing world

we are part of a new york based technology organization with a remotefriendly workplace that includes engineers around the world we value transparency and openness learning community and continuous improvement check out the times open blog  which is written by engineers and other technical team members and follow nytdevs on twitter to see what we’re up to

about the job
we focus on the software engineering related to data replication storage centralized computation and data api’s we provide customers and partners with data tools shared frameworks and data services these are the foundational core of our group which enables ourselves and others to work with data from a common underpinning our tools and services enable our group to scale and avoid blocking others

we reduce data redundancy by creating systems and datasets that serve as sources of record we enable discovery and governance of our data we support key business goals like growing our digital subscriber base understanding how our customers use our products and retaining our print subscribers

as a data engineer you will
run and support a production enterprise data platform
design and develop data models
work with languages like java python go bash and sql
build batch and streaming data pipelines with tools such as spark airflow and cloudbased data services like google’s bigquery dataproc and pubsub
develop processes for automating testing and deploying your work

about you
to thrive in this role you are excited about data and motivated to learn new technologies you are comfortable collaborating with engineers from other teams product owners business teams and data analysts and data scientists you are own and shape your technical domain area and move the related business goals forward you are eager to resolve upstream data issues at the source instead of applying workarounds you analyze and test changes to our data architectures and processes and determine what the possible downstream effects and potential impacts to data consumers will be

benefits and perks
make an impact by supporting our original independent and deeply reported journalism
we provide competitive health dental vision and life insurance for employees and their families
we support responsible retirement planning with a generous 401k company match
we offer a competitive parentalleave policy
we are committed to career development supported by a formal mentoring program and 8000 annual tuition reimbursement
we have frequent panel discussions and talks by a wide variety of news makers and industry leaders
join a community committed to the richness of diversity experiences and talents in the world we cover supported by a variety of employee resource groups

lihk1

the new york times is committed to a diverse and inclusive workforce one that reflects the varied global community we serve our journalism and the products we build in the service of that journalism greatly benefit from a range of perspectives which can only come from diversity of all types across our ranks at all levels of the organization achieving true diversity and inclusion is the right thing to do it is also the smart thing for our business so we strongly encourage women veterans people with disabilities people of color and gender nonconforming candidates to apply

the new york times company is an equal opportunity employer and does not discriminate on the basis of an individuals sex age race color creed national origin alienage religion marital status pregnancy sexual orientation or affectional preference gender identity and expression disability genetic trait or predisposition carrier status citizenship veteran or military status and other personal characteristics protected by law all applications will receive consideration for employment without regard to legally protected characteristics",,NY,False,data_engineer
Data Engineer,"job description

minimum qualifications

bachelors degree in computer science software engineering or other technical degree
3 years experience developing business critical big data solutions including datamodeling data architecture data platform development and optimization for same
3 years architecting  building business intelligence olap solutions using sql or similar
familiarity in one or more scripting languages eg python and unix
self starter who can meet critical deadlines in a fast paced environment with little direction and guidance

preferred qualifications

advanced degree in a technical field
experience working with webscale databases and building scalable data pipelines capable of aggregating and processing millions of events per day on cloud platforms
experience with implementing crm domain usecases sales marketing customers

keyskills  must have

data analytics
sql
unix

keyskills  nice to have

python
crm

",,CA,False,data_engineer
Data Engineer,"servicetitan is looking for a data engineer to join our data team strong candidates will have solid command of the sql etl operations and ssis packages in addition to very strong analytical and critical thinking skills the most critical portion of the role is deconstructing and reinterpreting databases from other software to translate them into our database it also includes support of existing and development of new automated import methods the candidate will work closely with cross departmental resources to ensure on time delivery of transferred data for customers adoption of servicetitan

our data engineers receive projects and deadlines from several departments the ability to own tasks clearly communicate requirements delays completion and prioritize a constantly shifting schedule of deadlines is paramount

this work is highly critical to successfully building our company it is the lynchpin of the sales and onboarding process data concerns are a blocker for most of our customers so delivering high quality highly accurate transfers is absolutely crucial and greatly appreciated by both our customers and our company

what youll do


map data from various legacy databases into the servicetitan platform subsequently developing sql scripts that will extract the information efficiently and accurately
develop automated scripts to validate legacy database values and identify previously unmapped fields prior to loading them into the servicetitan platform
receive and incorporate feedback from customers and internal stakeholders on data import quality into previously developed extraction scripts
identify opportunities to leverage information from legacy databases into the implementation process to avoid inquiring for additional information from customers
given the experimental nature of this job we will require very tight compliance when it comes to data  we need to focus on learning
establish quality working relationships with internal stakeholders
contribute material input to gonogocontinue decisions upon test completion

what youll need


25 years of experience with sql server 2008201220142016
advanced knowledge and experience in tsql complex etl tools and operations and ssis
expert level understanding of database and data model concepts
vertical saas experience is highly desirable
results and solution oriented  we want to know how we can win not why we cant
ability to work independently and cross functionally

about servicetitan

servicetitan is a mobile cloudbased software platform that helps home services companies streamline operations improve customer service and grow their business servicetitans endtoend solution for the multibillion dollar residential home services industry includes crm intelligent dispatch custom reporting marketing automation mobile solution for field techs and accounting integration with intacct and quickbooks servicetitan brings a fully operational modern saas infrastructure to an industry traditionally underserved by software servicetitan is the preferred software for hundreds of the worlds most successful plumbing hvac and electrical companies for more information about servicetitan visit wwwservicetitancom  httpwwwservicetitancom 

los angeles business journal best places to work 2018
inc 5000 best workplaces 2018
inc 5000 americas fastest growing companies 2018
mogul top 1000 companies worldwide for millennial women 2018
glassdoorbattery ventures cloud computing companies 2018
forbes next billion dollar startup 2017",,CA,False,data_engineer
"Big Data Engineer, Apple Media Products Analytics","the itunes store is looking for a topnotch big data engineer to develop an analytics infrastructure that will generate insights into customer experiences on products such as the itunes store app store and ibookstore our products reach hundreds of millions of customers around the world and have revolutionized how people interact with their music movies tv shows apps books and podcasts

key qualifications
language java or scala
working knowledge on the following distributed data processing platforms
required spark hadoop
great if you also know hbase kafka java map reduce
algorithms you will be working on developing new algorithms to process large scale data efficiently we expect you to know
basic computer science algorithms and data structures
distributed algorithms to process and mine data eg map reduce algorithm
great but not required if you also know about how to develop graph data classification and clustering algorithms in distributed environment
good debugging critical thinking and communication skills
knowledge in engineering machine learning feature engineering systems is a plus
able to gather crossfunctional requirements and translate them into practical engineering tasks
5 years of programming experience
description
the itunes store analytics team is responsible for collecting analyzing and reporting on customer experience data from this data we generate insights into how customers interact with our products and use these insights to drive improvements to userfacing features
you will be working on a small team and will be responsible for processing large amounts of data and developing platforms to process analyze and mine that data to extract intelligence prepare data for visualization adhoc exploration reporting and further analysis we are looking for a wellrounded data engineer who has good design sense
the ideal candidate pays close attention to details  caring about the quality of the input data as well as how the processed data is ultimately interpreted and used you are also a team player  ready to contribute during design sessions and able to give and receive constructive code reviews your curiosity drives you to explore new technologies and apply creative solutions to problems

educationbs degree in computer science or a related field

additional requirements
• build large scale data processing mining and analysis projects and features ensuring robust  maintainable solutions are implemented with special attention to data quality performance and usability details
• effectively demonstrate feature prototypes to executives
• develop advocate for and build consensus on coding best practices
• ability to effectively work with cross functional teams to understand requirements and identify design and engineering impacts
• experience with architecting big data and analytical applications that scale to petabytes highly preferred",,CA,False,data_engineer
Data Engineer,"
role description


in this role you will build very large scalable platforms using cutting edge data technologies this is not a maintain existing platform or make minor tweaks to current code base kind of role we are effectively building from the ground up and plan to leverage the most recent big data technologies if you enjoy building new things without being constrained by technical debt this is the job for you

this position is open in the following offices san francisco ca mountain view ca


responsibilities



you will help define company data assets data model spark sparksql and hivesql jobs to populate data models
you will help definedesign data integrations data quality frameworks and designevaluate open sourcevendor tools for data lineage
you will work closely with dropbox business units and engineering teams to develop strategy for long term data platform architecture


requirements



bs or ms degree in computer science or a related technical field
4 years of python or java development experience
4 years of sql experience nosql experience is a plus
4 years of experience with schema design and dimensional data modeling
ability in managing and communicating data warehouse plans to internal clients
experience designing building and maintaining data processing systems
experience working with either a map reduce or a mpp system on any sizescale


benefits and perks



100 company paid individual medical dental  vision insurance coverage
401k  company match
market competitive total compensation package
free dropbox space for your friends and family
wellness reimbursement
generous vacation policy
10 company paid holidays
volunteer time off
company sponsored tech talks technology and other relevant professional topics

",,CA,False,data_engineer
Analytics Data Engineer,"job description
the marketplace tech platform team is looking for a talented analytics engineer to help buildenhance the platforms that manage amazons global marketplace business you will play a key role in driving business insights about our businesses and how they interact you will transform data into actionable information and make it readily accessible to worldwide stakeholders

as an amazon data engineer you will be working with one of the worlds largest and most complex data processing environments you will need expertise in the design creation management and business use of extremely large 100tb datasets you must have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions you must be able to work with business customers in understanding the business requirements and implementing reporting solutions above all you should be passionate about working with huge data sets to answer challenging business changing questions as a global scale
basic qualifications
bachelors degree in computer science engineering mathematics or a related technical discipline
3 years of industry experience in data engineering business intelligence data science or related field with a track record of manipulating processing and extracting value from large datasets
3 years in using olap technologies and bi analytics
demonstrated strength in data modeling etl development and data warehousing
experience using business intelligence reporting tools tableau business objects cognos etc
knowledge of data management fundamentals and data storage principles
knowledge of distributed systems as it pertains to data storage and computing
proficient in one scripting languages eg python
preferred qualifications
experience writing machine learning algorithms
experience using big data technologies hadoop hive hbase spark etc
experience working with aws big data technologies redshift s3 emr
familiarity with statistical models and data mining algorithms
proven success in communicating with users other technical teams and senior management to collect requirements describe data modeling decisions and data engineering strategy",,MI,False,data_engineer
Big Data Engineer,"short description

about capgemini
a global leader in consulting technology services and digital transformation capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud digital and platforms building on its strong 50year heritage and deep industryspecific expertise capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations capgemini is driven by the conviction that the business value of technology comes from and through people it is a multicultural company of 200000 team members in over 40 countries the group reported 2017 global revenues of eur 128 billion
visit us at wwwcapgeminicom people matter results count
job title big data engineer
job type full time
we are looking for a data engineer to design and develop consumercentric low latency analytic applications leveraging big data technologies for our enterprise data lake initiative
essential responsibilities
design and develop cutting edge analytic applications leveraging big data technologies hadoop nosql and inmemory data grids
build automation of deployment and configuration using open source frameworks
act as the subject matter expert for big data platforms and technologies
work across it teams to ensure code quality performance and scalability of deployed data products
perform other duties andor special projects as assigned
qualificationsrequirements
bachelors degree with minimum 2 years of it experience in a quantitative field such as engineering computer science statistics econometrics or in lieu of degree a high school diplomaged and 5 years of experience in quantitative field with programming javaj2ee and data services
disclaimer capgemini america inc and its us affiliates are eeoaa employers capgemini conducts all employmentrelated activities without regard to race religion color national origin age sex marital status sexual orientation gender identityexpression disability citizenship status genetics or status as a vietnamera special disabled and other covered veteran status click the following link for more information on your rights as an applicant httpwwwcapgeminicomresourcesequal",,,False,data_engineer
Data Engineer,"our vision is to bring more innovation efficiency and equality of opportunity to the world by creating an open financial system our first step on that journey is making digital currency accessible and approachable for everyone to achieve that it is critical to have timely and reliable access to all of our data from user clicks on our website down to blockchain transactions
as a data platform engineer you will build our next generation data platform and accompanying services our data pipelines are growing rapidly currently processing several terabytes of data from production databases and external providers to our data warehouse we build foundational selfservice systems that allow end users to create etl flows and consume data in batch and streaming fashion for machine learning fraud prevention ab testing and analytics purposes
responsibilities
data ingestion pipeline build our next generation streaming ingestion pipeline for scale 10x data speed 1 minute of lag and ease of use 1 hour to add a new source read from a variety of upstream systems mongodb postgres dynamodb mysql api in both batch and streaming fashion tail mongodb’s oplog and postgres’ wal today we do this with apache airflow hadoop spark and a pure kotlin service
selfservice transformation engine build and maintain our selfservice tooling that allows anybody at coinbase to transform complex json and create dimensional models specific challenges are supporting type 2 slowly changing dimensions endtoend testability validationmonitoringalerting and efficient execution today we do this with apache airflow
anomaly detection build a comprehensive anomaly detection service that allows anybody at coinbase to quickly set up notifications in order to detect process breakage
security build a security layer that authorizes data access at the rowcolumn level build a logging and auditing system in order to surface suspicious data access patterns
requirements
exhibit our core cultural values positive energy clear communication efficient execution continuous learning
experience building data backend systems at scale with paralleldistributed compute
experience building microservices
experience with python andor javascala
knowledge of sql
a dataoriented mindset
preferred not required
computer science or related engineering degree
deep knowledge of apache airflow spark hadoop hive kafkakinesis
what to send
a resume that describes scalable systems you’ve built",,CA,False,data_engineer
Data Engineer,"expedia

we are looking for talented software engineers to join our data services development team your experience matters but more meaningful to us is what you can do going forward if you are technically talented and have the tenacity to build upon your current skill set then we want to talk to you if you have both a willingness and dream to work in a dynamic environment and is able to apply agile methodologies in daytoday activities and is a selfmotivated developer who mentors and shares knowledge

experience in
hands on experience working on hadoop for 3 years or more
deep understanding of the internals of core hadoop components  yarn hdfs sparx and mapreduce
good knowledge of sql nosql and etl concepts
good handson knowledge of python shell or any similar scripting language
hands on experience on hive oozie pig and data modeling

duties and responsibilities
translates technical specifications into code for new or improvement projects for internal clients
elevates code into the development test and production environments on schedule provides follow up production support submits change control requests and documents
participates in design code and test inspections throughout life cycle to identify issues
participates in systems analysis activities including system requirements analysis and definition eg prototyping and logical and physical design
writes the systemtechnical portion of assigned work including the version description document assists technical team members with the systemtechnical portion of their work egsystems testers test plans
aligns with it policies and procedures especially those for quality and productivity standards that enable the team to meet established achievements
participates in special projects and performs other duties as assigned

qualifications
undergraduate degree in a related field or the equivalent combination of training and experience
strong analysis analytical skills and social skills


lims1

expedia is committed to creating an inclusive work environment with a diverse workforce all qualified applicants will receive consideration for employment without regard to race color religion gender gender identity or expression sexual orientation national origin genetics disability age or veteran status this employer participates in everify the employer will provide the social security administration ssa and if necessary the department of homeland security dhs with information from each new employees i9 to confirm work authorization",,WA,False,data_engineer
Data Engineer II,"data engineer
the data services team is seeking a data engineer with a passion for creating data products to help create more engaging personalized experiences for users across conde nast’s properties you will have the opportunity to build both product features and internal data tools all while working with a diverse group of datasets – web events ad streams content and context models etc you will also get to work with the newest data technologies available above all you will influence how users interact with conde nast’s industryleading journalism
primary responsibilities

develop and maintain scalable data pipelines with a focus on writing clean faulttolerant code
maintain various data stores and distributed systems such as hive and presto
optimize data structures for efficient querying of those systems
collaborate with internal and external data sources to ensure integrations are accurate scalable and maintainable
collaborate with data science team on implementing machine learning algorithms to facilitate audience intelligence and crossbrand personalization initiatives
collaborate with business intelligenceanalytics teams on data mart optimizations query tuning and database designs
execute proof of concepts to assess strategic opportunities and future data extraction and integration capabilities
define data models publish metadata and best practice querying standards
required skills

2 years data engineering andor software development experience preferably with experience using a scripting language such as python or java
fluency in sql any variant
experience with hadoop and related technologies hive presto spark
exceptional analytical quantitative problemsolving and critical thinking skills
have a collaborative work style with strong desire to work in dynamic fast paced environment that requires flexibility and ability to manage multiple priorities
desirable skills

experience with workflow  etl tools and schedulers eg luigi airfow
experience with aws tools especially emr s3 lambda
experience with gcp tools eg bigquery dataflow pubsub
experience with apache beam",,NY,False,data_engineer
Data Engineer Internship - Summer 2019,"temporary internshipoverview
at sentry we realize that getting valuable handson experience is important for you and your career we don’t offer just an internship we offer a whole experience built to give talented students like you a head start for your career from rewarding work in your business area to professional development trainings all the way to paid volunteer time and diverse social events we make sure our internship program fits all of your needs
what youll do
our data engineering internship offers opportunities to work handson with some of sentrys most significant data assets you will gain valuable reallife experience working with sentry’s developers and architects to create systems to transform data into structures that facilitate critical business processes present information for indepth analysis and drive advanced predictive analytics you will get firsthand exposure to the entire data development lifecycle and find out what it takes to build successful largescale data ecosystems
in addition you’ll
design code test and debug while maintaining programsparticipate in prototyping solutions preparing test scripts and conducting tests and for data replication extraction loading cleansing and data modeling for data repositoriesutilize and adhere to sentry’s solution development life cycle sdlc project management methodologyadhere to sentry information technology standards and proceduresbecome technically proficient in programming languages software and other technological areas
what it takes
in order to be eligible for this elite opportunity you must meet the following criteria
pursuing an undergraduate degree in computer science computer engineering mis or a related fieldobtain a minimum inmajor gpa of 30graduating in fall of 2019 or spring of 2020ability to work in a team atmospheresentry does not offer employment in this position to holders of f1 j1 and h1 visas for the purpose of obtaining practical experience
what youll receive
sentrys excellent benefits package is designed to meet todays most important needs benefits for fulltime sentry insurance employees include
competitive compensation
group medical dental vision and life
401 k plan with a dollarfordollar match on your first eight percent
comprehensive paid training
generous paidtime off plan
pretax dependent care and health expense reimbursement accounts
how you’ll apply
sentry insurance has an online employment application in order to complete it you need to apply for a specific position we ask that you apply for one position at a time with us so if you are interested in several positions please determine the position in which you are most interested and apply for that position first if you are not selected for your first choice we invite you to apply for the next job in which you are interested
if this is the first time you have applied for a position at sentry you will be asked to register returning applicants will only need to provide their email address and password

who you’ll want to contact
hannah krueger at 7153466281
hannahkruegersentrycom
about sentry
sentry insurance is one of the largest and strongest mutual insurance companies in the united states holding an a superior rating from am best the company and its subsidiaries sell property and casualty insurance life insurance annuities and retirement programs for business and individuals throughout the country headquartered in stevens point wisconsin sentry employs more than 4000 associates in 41 states a complete list of underwriting companies can be found at wwwsentrycom
equal employment opportunity
it is our policy that there be no discrimination in employment based on race color national origin religion sex disability age marital status or sexual orientation",,WI,False,data_engineer
Data Engineer,"about revolutionparts
revolutionparts is a rapidlygrowing 50 employee saas company based in sunny arizona we’re a tech company dedicated to modernizing the auto industry with a revolutionary ecommerce platform that’s already helped hundreds of dealerships nationwide sell auto parts online

we’re seeking talented individuals who can adapt to a fastpaced environment join our team to work with a downtoearth group of people who stick to our core values and genuinely care about providing a quality experience to customers and employees alike

about the role
revolutionparts is looking for a talented data engineer with passion and drive for customer success and to help evolve our technology to support our next phase of growth your primary focus will be on improving customer business outcomes through optimization and automation of data operations strong verbal and written communications as well as troubleshooting skills are critical for success in this role youll be joining a team of professionals that are dedicated to providing cutting edge ecommerce solutions to the auto parts industry

if you want a clearcut role with the same tasks for years this is not for you if you like to think big and want to help drive how we leverage data at the company we need you

what you’ll do

creates processes to streamline data loading process increasing performance reducing effort and increasing data quality
communicates with customers and internal team to discuss any issues with received data and helps them identify and fix data issues
understand existing data environment variations of implementation and develop effective triage mechanisms and tools
establish baselines for key metrics and drives improvement of those metrics
analyze data trends to identify issues
work with team to ensure data for all brands is accurate and uptodate
oversee data processing
create and maintain supporting documentation related to the management of the parts data and catalog
track and manage projects using scrum framework

what you need

bachelors in computer science or computer engineering or related field
5 years experience building queries creating reports running data infrastructure
understand what is involved in processing structured data from ingestion to production
understanding of databases relational or not sql
have an in depth knowledge of aces and pies data standards
understand how structured data sells more parts
understand how to improve ecommerce conversion through data
architecture decision making  realtime batch queuebased processing
must like the dynamic and fastpaced nature of a smaller team working in a company doubling in size each year
gsd  get stuff done

why you’ll like working here

top salary and stock options
medical dental and 401k retirement plan
rewards for highperformers opportunity for bonuses
opportunity for career advancement
collaborative team environment that values multiple perspectives and fresh thinking
flexible hours and pto
casual dress code
free food catered lunch every friday  fully stocked fridge and snacks
drinks on us with team happy hours and beer fridge
gym reimbursement

",,AZ,False,data_engineer
Data Engineer,"under armour is the chosen brand of this generation of athletes and the athletes of tomorrow were about performance  in training and on game day in blistering heat and bitter cold whatever the conditions whatever the sport under armour delivers the advantage athletes have come to demand
that demand has created an environment of growth an environment where building a great team is vital an environment where doing whatever it takes is the baseline and going above and beyond to protect the brand is commonplace
the worlds hungriest athletes live by a code a pledge to themselves and everyone else protect this house i will our goal is to build a great team will you…protect this house

summary
under armour is searching for a committed talented and highenergy data engineer iii and technical lead to join a resultsoriented team this position provides the opportunity to grow into a technology expert leading the development of new capabilities in etl extract transform load data applications and data cleansing the role will include extracting data developing integration and load programs enhancing existing development and unit testing

essential duties and responsibilities
to perform this job successfully an individual must be able to perform each essential duty satisfactorily the requirements listed below are representative of the knowledge skill andor ability required reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions
collaborate with appropriate data owners to identify and map data from the source environment to target data environment this data may include sap and nonsap data sources technical development activities including
develop data extraction programs
develop interfaces between ua systems and thirdparty systems
write code or use specialized development tools to create enhance or customize software components
test developed programs and integration of data from various sources
ensure that development adheres to organizational architecture guidelines
identify data quality gaps and work with data owners to develop solutions and close gaps

ongoing service delivery including
documentation and ownership of relevant change control requests including evaluation test implementation and verification
coordinate and conduct application testing new support packages releases functionality and customizing in close cooperation with the technology team
engage system owners to filter size and prioritize business requests and drive towards appropriate decision points
contribute to development policies standards and conventions
collaborate with peers to enable quality service for business community project schedules and support it performance metrics
maintain expert knowledge of development tools technologies and related delivery methods
establish consistent technical architecture

education andor experience
bachelors degree stem science technology engineering math
at least 5 years of experience with assorted data management tools etl data quality etc
at least 5 years of experience with industry standard relational database systems ms sql server oracle etc
experience using sap data services
experience with sap software systems both master and transactional data
experience with job scheduling tools such as controlm
at under armour we are committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and teammates without regard to race color religion sex pregnancy including childbirth lactation and related medical conditions national origin age physical and mental disability marital status sexual orientation gender identity gender expression genetic information including characteristics and testing military and veteran status and any other characteristic protected by applicable law under armour believes that diversity and inclusion among our teammates is critical to our success as a global company and we seek to recruit develop and retain the most talented people from a diverse candidate pool",,MD,False,data_engineer
Data Engineer,"overview
software and data engineer
at hospital for special surgery our clinicians and scientists collaborate to deliver the most innovative care our specialized focus on orthopedics and rheumatology enables us to help patients get back to what they need and love to do reliably and efficiently our patients are overwhelmingly satisfied with the care they receive at our facilities when you join us you will become part of this legacy of commitment to the most cuttingedge research and coordinated care
the software and data engineer will be responsible for the implementation security and maintenance of the data analytics platform the ideal candidate must be passionate about the field of analytics and well versed in all aspects of an enterprisewide analytics architecture the software and data engineer will work closely with the interface team and infrastructure and server team the engineer support and collaborate with our data engineers researchers report writers and data analysts

responsibilities
implement secure and maintain the advanced data analytics platform
implement secure and maintain the frontend interface to platform
design implement and automate data flows to and from the platform
work with partners and vendors on data integration projects
create data models for analytics applications
assist in the data warehouse etl design and implementation
assist in resolution of production issues and root cause analyses
technical qualifications and experience
3 years with python analytics platform python notebooks and data science libraries
3 years’ experience with etl tools ssis preferred informatica talend
3 years’ experience with restful apis and web services json and xml
3 years’ experience with rdms databases sql server postgres oracle
strong expertise in sql scripting required
strong expertise in python scripting required
experience integrating large datasets many 100gbs to several terabytes required
experience with linux and windows server operating systems required
strong expertise in a programming language such as javascala or c a big plus
experience with web front scripting such javascript html and css a big plus
experience supporting researchers in bioinformatics a big plus
experience with statistics machine learning and deploying predictive models a big plus r python matlab spark
experience with sas administration and sas language a plus
experience with public cloud a plus aws google cloud azure
experience with big data technology a plus hadoop spark aws emr hive etc
experience in healthcare a plus
elements of success
passionate about data
enjoy learning and exploring new technologies
problem solver and critical thinker
team player committed to improving quality and service and maintaining a spirit of cooperation and respect
education and certifications
master’s degree or bachelor’s in computer science
other requirements
lijl1",,NY,False,data_engineer
Data Engineer,"
global problems global impact


flexports mission is to make global trade easy for everyone we are remaking a trillion dollar industry that touches every person on earth which means solving some of the global communitys most complex challenges we are looking for makers who love learning are passionate about collaborating and desire to build solutions with a global impact

reliable and scaleable data pipelines and data warehouse are integral in allowing us to fulfill our mission of fixing the user experience in global trade at flexport youll provide data for products that are at the forefront of reshaping the entire logistics  supply chain industries youll work alongside selfstarters interested in solving realworld problems and streamlining the inefficiencies in the complex global trade industry

youll have the opportunity to reshape an industry by creating the new operating system for global trade started in 2013 with a total addressable market of 1 trillion weve raised 304m from investors that include google ventures first round capital bloomberg beta y combinator and more


what youll do



develop resilient pipelines from a variety of data sources both internal and external
implement comprehensive testing and continuous integration frameworks for schema data and functional processespipelines
design the scheduling framework airflow to automatically recognize and setup object dependencies for robust and timely data delivery
be part of a closeknit data engineering team that ships new code every day


what youll need



5 years experience developing data frameworks using python
5 years of using sql for data manipulation in a fastpaced work environment
experience with airflow is strongly preferred
data warehousing development and fundamentals preferred
passion for businessoriented data development


what youll get



the opportunity to shape data engineering at agile startup
meaningful equity in a startup growing their business 20 every month
feature ownership  design implement and own significant portions of data infrastructure


our stack


our pipelines are built using python and sql glued with bash data warehouse is a combination of postgres and redshift all of our infrastructure is based on aws our bi data is only 15 minutes behind production servers


culture  values



learn more at wwwkeyvaluescomflexport  httpswwwkeyvaluescomflexport 

",,CA,False,data_engineer
Data Engineer - Spark,"what if you could have it all a smart and passionate team to work with innovative games to work on and an environment thats collaborative and transparent join us at tilting point as a data engineer in new york city

as part of this team you will work on the collecting storing processing and analyzing huge sets of data the primary focus will be to oversee the construction and maintenance of our data pipeline etl processes and data warehouse our senior data engineer will also be responsible for data quality and understanding the data needs our various internal departments in order to anticipate and scale our systems

your future at tpm


develop an aws cloud platform that will support big data processing and analytics
work with data analysts product managers and customer service to help define technology needs for the logging processing storage and presentation of data in a manner that delivers business value
liaise with third parties for data integration and validation
implementing maintaining and improving etlddl processes
monitoring performance and costs and advising any necessary infrastructure changes
working with the various internal teams to deliver various analytical needs by building both large systematic reports and small custom pieces
become a tilting point key holder of data quality

your xp  skills

need to have

2 years of experience in architecting building and maintaining software platforms and largescale data infrastructures in a commercial or open source environment
prior experience using and building on apache spark  databricks
must have expertise in at least 2 of the following go pythonr sql javac
experience with integration of data from multiple data sources knowledge of various etl techniques and frameworks
comfortable with aws cloud s3 ec2 emr redshift etc

nice to have

knowledge of existing third party video game analytics services is a plus
ability to collaborate with colleagues across different disciplineslocations
strong written and oral communication skills and ability to work with creative partners
love for video games
experience in a freetoplay mobile game company a plus

choose tilting point for


prominent role in making tech decisions that will shape the company and industry
involvement in a large range of mobile game titles
work with great people on great games that reach millions of people each month
excellent location with a rooftop patio in midtown nyc
free snack and beverages
robust perks  benefits

 httpswwwglassdoorcomreviewstiltingpointreviewse1370330htm 


direct applicants only  no agenciesheadhunters please

tilting point provides equal employment opportunity to all individuals regardless of their race color creed religion gender age sexual orientation national origin disability veteran status or any other characteristic protected by state federal or local law discrimination of any type will not be tolerated this policy applies to all terms and conditions of employment including recruiting hiring promotion termination time off and compensation",,NY,False,data_engineer
Search Engine Data Engineer,"job description

as a search engine data engineer on our team you will be working on developing maintaining testing and optimizing the search engine that powers the merchant cloud platform you will have to participate in various automated search related activities likemaintenance of an elasticsearch cluster in the cloud update versions monitor performance etcoptimize cluster configuration and usageplanning allocating recovering and migrating shardscluster recovery and georeplicationschema creation optimization and maintenancecreating monitoring and constantly improving metrics to track quality of search resultsdevelop and maintain the etl procedure that ingests data in elasticsearchdeveloping identical search capabilities in multiple languages english japanese and others to be added over timesupporting our support engineers with elasticsearch logstash and kibana
requirements
2 years of experience with elasticsearch or related technologies like solr or luceneexperience in developing and maintaining a search engine serviceexperience in developing and maintaining search related data modelsexperience in data manipulation for elasticsearch ingestionexperience in working with different deployment environmentsan open mind desire to learn the best languagetechnology to solve a given problemautonomous and responsible organized and structured in initiatives and workdetailoriented and able to keep a global vision of the issues and their solutionsproficient with linux

qualifications

bs in computer science or related technical field or equivalent practical experience5 years of industry experience
preferred qualifications
knowledge and experience in performing search query expansionknowledge and experience in search ranking optimizationknowledge and experience in using elasticsearch for autocompletion tasksknowledge of and experience with the elastic stack
additional information

all your information will be kept confidential according to eeo guidelines",,CA,False,data_engineer
Principal Data Engineer - Personalization,"description
join us as a principal data engineer  personalization
as a principal data engineer you’ll have the opportunity to design and architect high quality flexible manageable and performant systems and services you’ll architect solutions that will capture manage process and serve small as well as some of the largest data sets in retail technology the principal data engineer works with business partners to provide technical solutions for business problems in a fast paced environment responsibilities will include analyzing designing programing debugging modifying software for existing and new products used in distributed largescale analytics solutions for target
we’re looking for a highly motivated engineering professional who will partner with technical product owners and management at one end as well as lead and motivate highly skilled scrum dev teams on the other – while having fun along the way
key responsibilities
lead decisionmaking process for selection of software products and architecture solutions
develop software systems using test driven development employing continuous integration practices
mentor and partner with engineers to develop software that meets business needs
follow agile methodology for software development and technical documentation
innovate constantly and keep systems up to date with current technologies
requirements
ms or phd degree in computer science or area of study related to data sciences and data mining
10 years of experience in developing software applications at scale
3 years of experience with big data technologies  spark druid hive and apex
proficient in applicationsoftware architecture definition business process modeling etc
advanced understand applicationsoftware development and design
collaborative personality able to engage in interactive discussions with the rest of the team
inquisitive on big data technology as well as stay current on new ideas and tools – constant learner
qualifications",,CA,False,data_engineer
Data Engineer,"roadbotics is a vc backed company based in pittsburgh pa that monitors and manages our world’s roadways by identifying and rating a wide array of important roadway features and conditions including cracks potholes signage and other characteristics our ai technology was spun out of the carnegie mellon university robotics institute with the explicit goal of providing efficient and costeffective roadway transparency to those responsible for roadway infrastructure our technology turns any smartphone and car into a sophisticated mobile sensor
with our product we attach a smartphone to a dash mount in a car windshield giving the phone’s camera a full view of the road ahead the data is uploaded to our aidriven cloud platform to be analyzed using our proprietary deep learning technology the video data along with the smartphone’s other sensor capabilities allow us to precisely calculate a wide variety of vital and established roadway metrics and conditions the roadbotics roadway web platform provides a mapbased visualization giving roadway managers a comprehensive status of their roads
go to googlfpzu3s and googlitqpgj for some news on our company learn more at roadboticscom and visit demoroadboticscom to see the live demo
the data engineering role will be responsible for the design implementation and improvements to roadbotics data systems and pipelines this involves data ingestion pipelines from smartphones in the field deployed all over the world data storage and manipulation for future access as well as apis and analyticsready database developments
the roadbotics video and geospatial data must be analyzed queried and delivered to a the internal data science operations engineering divisions as well as external customers in a variety of formats and with varying reliability requirements this role involves managing these pipelines and data warehouses to ensure successful access and control of that data
positions responsibilities
design development and management of data pipelines and data storage systems
clear communication with company divisions to understand data requirements and deploying apis and tools for efficient retrieval and utilization of that information
developing and executing a clear data infrastructure plan for the roadbotics data systems
working closely with other engineering teams to develop robust and reliable tools
supporting the roadbotics data science effort by efficiently developing data pipelines by delivering high quality and analyticsready data sets
requirements include
35 years of job experience in a software or database development role
must be fluent in python
must be proficient and have working experience with algorithms and distributed design challenges and data structures
must be proficient and have working experience with api design
must be proficient and have working experience with modern scalable databases their design challenges and implementations
must be proficient and have working experience with development and deployment related technologies git docker
must be proficient and have working experience with a modern cloud environment gcp aws or azure  preferrably gcp
must be knowledge of modern batch and streaming pipeline systems apache beam dataflow etc
must be proficient and knowledge of database schemas in both sql and schemaless based database architectures
must be proficient with modern object stores google storage s3 etc
successful candidates will also
have experience with data science and data science related practices
have knowledge and experience working with geospatial data and techniques
be very comfortable learning and using new techniques
have an ambition towards strong personal growth as our company continues to rapidly grow we are looking for future leaders who can take ownership and get things done
have superb communication skills we are a small startup company working in a novel market we need people who understand complex business needs and can translate them into working solutions
be able to clearly articulate problems and their solutions before they become critical
be biased toward action and have strong initiative and personal drive
this is a fulltime position in our pittsburgh pa offices",,PA,False,data_engineer
Data Engineer,"who we are
cityblock health is a new type of healthcare company  httpswwwcityblockcom  operating out of brooklyn and backed by alphabets sidewalk labs along with some of the top healthcare investors in the country

our mission is to radically improve the health of urban communities one block at a time importantly our solutions are designed specifically for medicaid and lowerincome medicare beneficiaries and we bring the capability to deliver care in the home and neighborhood with our fieldbased teams

in close collaboration with communitybased organizations and leading commercial partners we are reorganizing the health system to focus on what matters to our members we deliver personalized primary care behavioral health and social services through a network of neighborhood hubs with deep communitybased partnerships and worldclass technology

we partner with payers and atrisk providers accepting capitated financial risk to care for their most vulnerable high and rising risk members additionally we invest in strategic partnerships with communitybased and social services organizations in some instances bringing them into the value equation through subcapitation and performancebased compensation

over the next year well grow quickly including entering new markets each with their own commercial relationships and fieldbased teams this role will be a key contributor to the success of our business

the role
we are looking for a data engineer to help build and maintain the data infrastructure that backs commons—our digital care management platform commons enables our clinical teams to engage with patients collect structured data about medical behavioral and social needs and develop personalized care plans that drive good health commons will allow our care operations to scale to eventually support hundreds of thousands of patients in cities across the country

as one of our first data engineers you will help build mixer—our data pipeline you will work closely and crossfunctionally with your peers from the product data and clinical teams to collect and structure data—both from primary and 3rd party data sources— analyze that data and make it useful in promoting the medical and social wellbeing of our patients through automation and decisionsupport capabilities

mixer involves a collection of services that run on google cloud platform including pubsub dataflow via scio  httpsgithubcomspotifyscio  datastore and bigquery these services are provided by scala ruby and elixir

if youre inspired by such a challenge and are an amazing teammate wed love to hear from you

you will

be responsible for the integrity and accuracy of data in our systems
focus on building our data pipeline ie the backend features and related data infrastructure that will store clean and transform data—making it useful to our application and reporting layers
develop secure integrations into the data systems of various community and health system partners eg ehrs hies adt feeds claimspreauth feeds predictive analytics as well as data sets from government services and communitybased organizations
design our data pipeline to scale up to handle integrations across hundredsthousands of partners
write clean welltested code that will stand the test of time
participate in creating and maintaining strict compliance data privacy and security measures
help recruit highly capable engineers to the team from diverse backgrounds
learn continuously via mentorship and on your own to upgrade your skills and thinking as an engineer
collaborate with clinicians and social workers to understand the challenges that they face and develop solutions to drive better care for patients

youd be a good fit if

you are excited at the prospect making messy data useful
you have done data engineering work like this before in healthcare
you enjoy doing whatever it takes to execute on complex projects with little guidance
you have 3 years experience writing production code
you have worked in fastmoving startup environments before
you enjoy taking initiative
you have a processoriented mindset and ability to execute
you have a passion for doing missionoriented work

nice to have

experience with the technologies in our stack
experience deploying models created by data scientists
familiarity with bi tools eg looker tableau etc
experience building userfacing features
previous exposure to clinical operations andor working with physicians

nice to have really means nice to have its completely possible that you dont have any of these and are still a great fit for the team

you should include these in your application

a resume andor linkedin profile
a cover letter including a one paragraph summary of a technical project youre most proud to have built and what was hard about it optionally include links to publicfacing documentation about the project such as a github repo or blog post if available

cityblock values diversity as a core tenet of the work we do and populations we serve we are an equal opportunity employer indiscriminate of race religion ethnicity national origin citizenship gender gender identity sexual orientation age veteran status disability genetic information or any other protected characteristic",,NY,False,data_engineer
"Intern, Data Engineer / Data Sciences Developer","internshipintern  data engineer  data sciences developer 
job number
 043033 
hours per week  40
description
 summer 2019 paid internship

zions bancorporation is currently accepting resumes for our data engineer internship position the intern will have the opportunity to
work with other developers and data scientists to code proofofconcept projects on large scale data sets
assist in developing data processing and system integration applications
assist in constructing web based user interfaces and visualizations
document design decisions code and work flows
assist in designing developing and testing etl applications consistent with application architecture guidelines
qualifications
preferred candidate will be pursuing a degree in computer science software engineering or computer engineering
strong analytical organizational and problem solving skills
ability to elicit gather and analyze user requirements
ability to work independently and provide updates to management
requires strong interpersonal skills
must be able to meet deadlines
technical knowledge in the following is preferred
programming languages including r tcl java ruby and python
sql and nosql data stores and solutions
knowledge of big data technologies eg apache hadoop spark
work locations
 utahsalt lake cityzions bancorporation  hdqtrs
business operations
sep 12 2018",,UT,False,data_engineer
Senior Data Engineer,"about aaptiv

aaptiv is the fastest growing mobile fitness product on the market with a community of nearly 200000 members and is backed by leading venture capital firms and top companies including the amazon alexa fund and disney

with a mission to empower everyone to live a healthier life aaptiv has transformed the way people exercise and train through its innovative audio fitness classes every aaptiv class combines the guiding voice of an expert aaptiv trainer with motivating music by top artists in every genre aaptiv members have unlimited ondemand access to over 2500 classes and structured programs across every type of exercise and a wide variety of activities including running strengthtraining yoga indoor cycling meditation and more

want to join team aaptiv were looking for team members who are passionate about building a worldclass fitness experience there are over 80 million americans who value fitness  and we believe every one of them should be an aaptiv user

about the role

we’re looking for a senior data engineer to help us design data access patterns optimize integrations and solve data problems at aaptiv we thrive on building data driven solutions to help our members find workouts that best fit their lifestyles to pursue their wellness goals

in this role you’ll be working with a team of data engineers tasked with data integrations explorations and enabling stakeholders to find actionable data in a timely manner you will spend majority of your time working in the code whether that’s building new data pipeline yourself pairing with team members or reviewing pull requests the remaining time will be spent mentoring other software engineers to apply best practices in schema design optimize data access patterns and enforce data standards you will coordinate and execute online schema changes debug production issues and perform root cause analysis should things not work as expected

in addition you will work collaboratively with other data engineers cross functional teams analysts and stakeholders and your input will have a large impact on how our product is built you will thrive to explore new and better ways to do things last but not least you will ensure the team is delivering high quality codes with test coverage streamline deployment process and respond to incidents as appropriate candidates at this level should be comfortable in all of those facets

what you’ll do


provide technical guidance in designing data warehouse architecture schemas and pipelines that accurately represent our business model and store data efficiently to enable fast application access and easy reporting
enforce data precision implement guidelines and support software engineers in creating software that access and store data in the most optimal way while generating reliable data
coordinate with software engineers to deploy online schema changes with minimal customer impact
work closely with product managers other data engineers and analysts to identify data gaps brainstorm ideas break down projects and estimate how long they will take
part of a team that’s responsible for developing of all data products ensuring we are shipping only high quality codes that are tested thoroughly and monitored appropriately
be a champion of engineering best practices within your team we want to build highquality software that’s easy to understand easy to change and works the way it’s supposed to

who you are


6 years of experience building data solutions or software as an engineer
you’ve administered data warehouse in production environment
you’ve previously held a more senior engineering position for longer than a year
expert in sql data modeling
expert in data warehouse performance analysis and optimizations
strong python programming skills
experience in creating custom data integration tools to extractloadtransform data
experience in building data products with unit and integration tests
experience with both sql and nosql datastores mongodb
experience using aws services rds ec2 data pipeline lambda is a plus
you keep up to date with advances in data solutions and selectively choose new tools and approaches when appropriate to be more effective

",,NY,False,data_engineer
Senior Data Engineer,about vydiavydia vydiacom is a fast growing inc 500 technology company that has built a premiere platform for the exploding video content industry our solutions empower music creators to easily distribute manage and optimize their video and audio content through one centralized platform the company is viewed as one of the leaders in the space as evidenced by strategic partnerships and integrations with vevo youtube facebook spotify apple dailymotion and several more the vision of the company is to disrupt the entertainment industry through automation data and artificial intelligence that helps both creators and the next generation of music distribution vydia is constantly evolving and has attracted more than 200000 musicians influencers and brands worldwide the company has recently completed series a financing poising it to continue the exponential growth it has achieved since its inceptionsummary vydia’s data engineering  data science efforts are an integral part of our success through our data we nurture our artists creators partners and internal users with insights to help them engage their audienceour extractloadtransform workflows promote quick analysis and richer complex investigations all at once and our data warehouse supports both data science and analytics of all the terabytes of data we gather onethird is wellstructured with the remaining being mostly semistructured and some wholly unstructured and it currently doubles every 53 monthsthe role as a sr data engineer you will own vydia’s multitude of data pipelines you will design and implement our elt workflows which originate at partner apis and conclude in the warehouse you will work closely with our data science bi and product teams in figuring out current and future needsas a leader on the data team your responsibilities will include ensuring the availability and timely delivery of data companywidemodeling new data sets and crafting all new elt workflows and pipelineslead the orchestration of the workflows and contribute strongly to infrastructure decisionsimproving on and monitoring of existing pipelines and oversight of our elt workflowmaintaining a single version of truth for our data and working with others to implement continuous integration ci data quality testsmentoring and guiding your junior colleagues and leading with vision and with respect to the company’s data strategytechnologies while we are not married to any tool or technology we also look for those intimately familiar with python and have previous experience using airflow docker and kuberneteswe use aws s3  ec2 extensively our current dw is on redshift and our app relies mostly on postgres we use looker inhouse for bi and product engineers work mostly in ruby and python while our data scientists work in rabout you we want to learn more about you if you feel like you are the right fit for this role let us knowin our mind being a perfect fit means that you have the necessary hard skills and expertise and the complimentary soft skillsyou are a python pro and have regularly used aws or google cloud platform to manage data and move it between applicationsdo you love apis when you encounter a new one do you study it inside and out and learn every corner of it as though you designed it yourselfworking with deeplynested complex json is a fun day at the office for youyou can articulate the merits and pitfalls of the different approaches in designing a pipelineyou are passionate about data quality control and know how and where to anticipate potential errorsworking “in the cloud” is not a point of distinction for you it is a givenyou understand what it means to work at a tech startup hopefully this is what excites you more than anything else about working hereyou intuitively know how to extract value and insights from datayou love the idea of building the data scene in nj and being a leader in this communityyou have orchestrated workflows using airflow and are familiar with the challenges and how to overcome themcritically youre a person who thinks in data you relate the real world to data and viceversa you understand that data is not the end goal but a vehicle to help get us where we are going and you see your role as the person most critical in making that happenreasons to work with us as an inc 500 fastest growing company in america vydia offers huge opportunities to grow with the companyvydia was named a best place to work in nj by njbiz in 2017 due to its collaborative fastpaced and fun thriving environmentfull medicaldentalvision packagegenerous vacation policy work hard and take time when you need itteam breakfast every monday and a wellstocked kitchen full of snacksan onsite gym facility and team yoga on thursdaysopen creative workspace located inside the historic site of nj innovation bell worksleadership identified as the 2017 tech innovator of the year and highlighted by entrepreneur magazine as builder of one of the most entrepreneurial companies in americawe are an equal opportunity employer and value diversity at our company we do not discriminate based on race religion color national origin gender sexual orientation age marital status veteran status or disability statusjob type fulltimeexperiencekubernetes 1 year requireddocker 1 year requiredpython 5 years requiredaws or gcp 5 years requiredlocationholmdel nj requiredwork authorizationunited states required,,NJ,False,data_engineer
Data Engineer,"gathering the business requirements analyzing business requirements and defining functional specifications analyzing existing applications consisting of multiple batch programs in sas and developing the code in python and spark designing rules and workflow processing using python and spark frame work identifying and developing automated batch packages participating in the deployment of the applications into existing systems and databases documenting modifications and enhancements made to the applications systems and databases as required by the project

educational and experience requirements 
must require at least a bachelor’s degree in electrical engineering or related field of study
location edison nj

cv to i5tech address 3 ethel rd suite306 edison nj 08817 or
email careersi5techinccom",,NJ,False,data_engineer
Data Engineer,contractdata warehouse engineerlocation seattle wajob type contractvisas us citizen green card holder h1bno optcpt candidatescurrent state of migration project o has a tsql database which houses several sql views that contain business logic creating calculated metricsdimensionso qlikview data mover files source data from these views and store data in qvds for consumption by our qlik dashboardso migrating from tsql to the snowflake engine necessitating rewrite of all sql views into snowflakes syntax and revision of qlikview data mover script fileso scope of transition work is approximately 110 sql views and 50 qvdmsrequired skills o strong capabilities in sql scripting language  best practiceso familiar with sql database navigation with tools like ssmso familiar with qlik scripting languagepreferred skills o prior experience with tsql scriptingo prior experience with snowflakes scripting languagejob responsibilities o review sql views and develop candidate scripts in snowflake scripting languageo identifytroubleshoot view dependencies if encounteredo update qlikview data mover load scripts to reference new field names and sources in snowflakeo querytest data from snowflake to ensure output of resultsjob type contractexperiencetsql 3 years preferredsnowflake 1 year preferreddata warehouse 5 years preferredetl 3 years preferredqlikview 2 years preferredsql 3 years preferred,,WA,False,data_engineer
Data Engineer,"job summary

at revinate we are revolutionizing the hotel experience for both operators and guests by unlocking the power of data intelligently and intuitively to drive revenue the data engineering  analytics team is the nucleus that drives the innovation and advancement of the companys core mission and vision for the hospitality industry we are looking for an experienced data engineer to join our team in san francisco the data engineer will be integral in building maintaining monitoring and improving our data pipelines and analytics platform at scale we are committed to delivering highly available scalable faulttolerant and performanceefficient data solutions the ideal candidate will be a handson expert in architecting a data ecosystem that can fulfill the data needs of our internal and external customers in real time you will be required to design and develop code scripts and data tools that process large volumes of structured and unstructured data from multiple disparate data sources our engineers work in a collaborative environment and learn from the best among each other

job responsibilities


architect develop and own key components of the data platform including the deployment and maintenance of complex etls scripts and custom code
adhere to disciplined best practices to produce reusable maintainable efficient and welldocumented code on time every time
analyzetroubleshoot existing issues and bottlenecks in the system and propose technically creative solutions and implement to completion
evangelize data products across the organization to enhance visibility and transparency
communicate timelines and status across teams effectively using productivity metrics

qualifications


masters or higher degree in engineering or computer science disciplines background in economics mathematics or statistics will be a plus
7 years of handson industry experience using big data tools like spark kafka and related
working experience with nosql and distributed databases cassandra hive google bigquery or similar
hands on experience with rest apis and functional programming tools scala or similar
aws cloud experience with ec2 s3 vpc rds etc in a big data environment
deep understanding of mapreduce methodologies and tools
data warehouse architecture and modeling experience
experience with administering and optimizing business intelligencedata visualization tools looker tableau r studio or similar
self starter and motivated individual who is able to think objectively about abstract concepts and willing to question the status quo to make the necessary improvements

nice to have


scripting languages like python nodejs or similar
knowledge of source control and automated deployment tools github jenkins etc
implementation of monitoring and auditing processes
experience working on agile teams in a startup setting
experience developing machine learning algorithms is a plus

about revinate

revinate enables hoteliers to transform their guest data into revenue with revinate marketing and revinate guest feedback hoteliers are empowered to make smarter decisions resulting in increased direct revenue and guest engagement the company is backed by leading silicon valley investors including benchmark capital tenaya capital and sozo ventures headquartered in san francisco with regional offices in amsterdam and singapore revinate counts tens of thousands of the worlds leading hotels as customers

to learn more please visit wwwrevinatecom  httpwwwrevinatecom 

we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,CA,False,data_engineer
Data Engineer,company overview we provide services to help healthcare institutions in southeastern portion of the united states mitivate successfully manages the complexities of finance care evaluation and patient conditions mitivates data analysis tools evaluate patient data claims data  clinicallygenerated data to identify clinical variations and financial inconsistencies in short our goal is to provide revolutionary analytical services to help the healthcare ecosystem become more efficient mitivate provides automated technology services to the many manual tasks currently produced today to provide our clients a faster service in a streamlined mannerjob overview as a data engineer you have a passion for the value and capability of data and information at mitivate we are looking for a savvy data engineer to join team of analytics experts the hire will be responsible forproviding technical expertise on data storage data mining and data cleansing the ideal candidate is an experienced data engineer that is selfdirected and comfortable supporting the data needs of multiple teams systems and products because we work on the cutting edge of a lot of technologies we need someone who is a creative problem solver resourceful in getting things done and productive working independently or collaboratively this person would also take on the following responsibilitiesgather and process raw data at scale including writing scripts web scraping calling apis etcidentify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etcwork closely with our engineering team to integrate your amazing innovations and algorithms into our production systemsprocess unstructured data into a form suitable for analysis – and then do the analysis support business decisions with ad hoc analysis as neededstrong knowledge of and experience with statistics potentially other advanced math as well programming experience ideally in python or javadevelop tools that provide customers with unprecedented transparency into their operationswrite sql queries to support product implementationsrequired skills providing technical expertise on data storage data mining and data cleansingsupporting initiatives for data integrity and normalizationloading cleaning and manipulating data from multiple sources including internal external and third partiesaccessing and analyzing rich healthcare data to generate insights and make proactive recommendationsformulating success metrics for optimizing healthcare resources and patient experience creating visualization to monitor themjob type fulltimeexperiencedata mining 3 years preferredpython 3 years requiredsql 3 years preferredjava 3 years preferredlibrary outreach 2 years preferrededucationbachelors requiredlocationatlanta ga 30309 preferred,,GA,False,data_engineer
Data Engineer,"were reimagining sports and technology
draftkings is bringing sports fans closer to the games they love and becoming an essential part of their experience in the process an industry pioneer since our founding in 2012 we believe we can continue to define what it means to be a tech company in sports entertainment we love what we do and we think you will too

love data we do too
as a data engineer youll be a creative contributor to our data analysis and scalability processes and you will use your experience to provide key insights that help us make smarter decisions analytical thinking drives our business and when you join our team youll not only solve new problems every day youll see your data solutions immediately improve our users experience

what youll do as a data engineer

youll build tools to provide actionable insights into key business metrics
care about agility like you care about scalability we roll out products very quickly and priority management is key
design processes that support data transformation and structures metadata dependency and workload management
you will also focus on performance analysis optimization and tuning
have the opportunity to see your personal work make an immediate impact on influential products

what skills you will use

ideally you have experience in aspects of business intelligence and data engineering including data warehousing delivery and operations
the ability to build and optimize data pipelines transformations architectures and data sets
a deep knowledge of a variety of data engines like sql server mysql and redshift
youll also have a solid understanding of dimensional modeling
experience working in aws emr and spark is a big plus

who are we a good fit for
we love working with talented people but more than that we seek out compassionate coworkers with a collaborative spirit our work moves quickly and were great at coming together to find creative solutions to some of techs most interesting problems if that sounds good to you join us

apply now
were proud to believe that your gender race nationality religion sexual orientation status as a protected veteran or status as an individual with a disability should have nothing to do with our hiring practices well never discriminate against anyones background or creed if youre good at what you do we want you to do it at draftkings",,MA,False,data_engineer
Data Engineer,"we are umg the universal music group we are the world’s leading music company in everything we do we are committed to artistry innovation and entrepreneurship we own and operate a broad array of businesses engaged in recorded music music publishing merchandising and audiovisual content in more than 60 countries we identify and develop recording artists and songwriters and we produce distribute and promote the most critically acclaimed and commercially successful music to delight and entertain fans around the world
we have opportunities for data engineers to join our growing tech team at universal’s offices and contribute to the development of our innovative approach to finding new and impactful insights to grow umg’s business
we have moved all of our data and analytics to google cloud platform gcp as a data engineer you will be responsible for designing and implementing new gcpbased data solutions – new data processing data sets and systems to support various advanced analytics needs this involves working with the existing engineering team data scientists analysts and the business to understand requirements and data needs and definitions all the while thinking creatively about what data can be best exploited to solve a wide array of business problems you will create data flows to integrate with multiple external sources using apis database connections and flat files you will liaise with members of the wider universal data  analytics teams to ensure alignment with existing systems and consistency with internal standards and best practice
job functions
build understanding of data sources and downstream systems
liaise with key stakeholders to understand requirements business definitions and the potential value of different data
design and document and implement suitable solutions for loading piping and exposing data from multiple sources
design and build wellengineered data systems to support analytical needs using google cloud platform cloud dataflow bigquery bigtable are musts
assure accuracy of data processing and outputs through consistently high software development skills adherence to best practice thorough testing and peer reviews
habitually approach problem solving with creativity and resourcefulness carefully evaluate risks and determine correct courses of action when completing tasks
job requirements
skillsabilities
expertise using cloudbased systems and services to acquire and deliver data via apis and flat files
demonstrable handson professional software development skills using java python is a plus
excellent verbal and written communications skills with the ability to clearly present ideas concepts and solutions
demonstrated willingness and ability to effectively work with various team members when gathering requirements delivering solutions and eliciting suggestions and feedback
extremely quick learner both in terms of new technical skills and acquiring domain knowledge
experience
demonstrable professional experience designing building and maintaining data systems and processes using cloudbased platforms google bigquery and cloud dataflow extremely desirable airflow is a big plus including experience working in unixlinux operating systems and tools
extensive handon experience working with data using sql
education
bachelor’s degree in computer science or closely related discipline
universal music group is an equal opportunity employer
disclaimer
this job description only provides an overview of job responsibilities that are subject to change",,CA,False,data_engineer
Data Engineer,"upstart is a fastgrowing and profitable company revolutionizing how people access credit we use data science and automation to make smarter lending decisions and help borrowers access credit easier and faster join our engineering community as a data engineer and help upstart build infrastructure to move and analyze large volumes of data our success depends on our ability to efficiently make sense of data and as a data engineer at upstart youll be responsible for architecting systems to move store transform and analyze large amounts of data including financial and business data youll have an outsized impact on the productivity of the entire engineering and data science team and directly contribute to upstarts core competitive advantage

here is more about what youll be doing

build data pipelines that collect connect centralize and curate data from various internal and external data sources
manage and extend a reliable effective and scalable data infrastructure
partner with data scientists and other business stakeholders to meet their data requirements
implement systems for monitoring data quality and consistency
productionize machine learning models that power our data products and integrate with our loan origination platform
help the data science team apply and generalize statistical and econometric models on large datasets
identify inefficiencies optimize processes and data flows and make recommendations for improvements

requirements

3 years of experience as data engineer or software engineer
proficiency in python or java
experience with streaming kafka etl for service oriented architectures
ability to collaborate crossfunctionally and communicate effectively
ability to bring new ideas and promote process improvement

",,CA,False,data_engineer
Data Engineer,"data engineer

centerfield develops intelligent big data driven marketing and sales technology utilizing real time biddable media rtb automated call routing and customized scripting our proprietary platform dugout combined with our 1500 person sales and retention center delivers new customers at scale to many of the leading brands worldwide
we’re looking for highly motivated rock star data engineers with 12 years of professional experience you will help design maintain support and improve company etl processes you must have practical experience working with large data sets in the website lead generation  search engine marketing saas or cloud computing domains
skillsattributes required
1 years working in a data engineer or bi engineer or data warehousing engineer role
handson experience with etl tool like talend or ssis or informatica
strong experience with sql
some experience in performance tuning techniques
strong sense of ownership
proactive team player with good communication skills
analytical mindset
skillsattributes desired
experience building reports and with data visualization
handson experience with tableau
handson experience with talend
experience with data services in aws is a plus
why centerfield
competitive salary and profit sharing bonus
401k match
take a break when you need it – unlimited pto
award winning culture  unprecedented team spirit
fully stocked break rooms with drinks snacks
toro the bull dog mascot and everyone’s friend
paid volunteer days",,CA,False,data_engineer
Data Scientist/ Data Engineer Intern,"internshipwant to work for a company where your everyday projects can meaningfully change or save people’s lives where you have the support and cuttingedge resources you need to be creative and challenge the norm are you looking for an enriching internship with an adaptive and innovative technology company located in the heart of san diego’s booming tech hub
we are looking for passionate data science data engineering interns with fresh ideas and strong technical skills to join us as we solve the emerging big data challenges in the healthcare industry
this 1012 week paid internship will offer you the opportunity to work alongside industry pioneers and healthcare experts to develop a sophisticated distributed and scalable healthcare data and machine learning infrastructure
your experience at clinicomp will expose you to the foundational concepts of healthcare data science and give you a bird’seye view of the latest developments in the industry on a daytoday basis you will be leveraging open source technologies such as pytorch tensorflow keras kafka elasticsearch spark etc to analyze a large volume of real world clinical data and discover new actionable intelligence used to save lives around the world
about clinicomp
clinicomp intl is a global provider of electronic hardware software and support solutions that has maintained an unrivaled track record of performance and reliability in complex high acuity hospital environments for decades this integrated offering guarantees a seamless transparent patient record viewingcharting across all patient environments distinct sites and time clinicomp has managed over 600 million real world patient records and provided virtually zero down time since 1983
we are a san diego based company made up of inspired people that form a team as strong as each of its individuals we design develop and implement cuttingedge technology that contributes to fundamental advancements in computer science as technology advances we adapt and evolve so that we remain at the forefront of our industry and continue to provide unrivaled performance and reliability
we strive to find selfmotivated team players problemsolvers who thrive in a fastpaced agile environment who love innovative technology as much as creating it if you’re smart creative ambitious and always looking for ways to improve we’d like to talk with you
requirements
minimum qualifications
currently enrolled in a master’s or phd degree program in computer science or related field with an expected graduation date between december 2019 and june 2021
strong background in one of the following computer scienceengineering aimachine learning or bioinformatics
extensive knowledge and experience with cnn and rnn grultsm cc and python
ability to think outside the box and present new ideas to enhance and improve current processes
must be available to work 40 hours a week for 3 months during summer 2019 mayseptember
preferred qualifications
industry experience in designing and developing professional software
demonstrated progressive interest and development in areas such as neural information processing systems computer vision and pattern recognition knowledge discovery and data mining or a related field through publications andor research projects
experience with cudamiopen
excellent communication and interpersonal skills
clinicomp intl is an equal opportunity employer all applicants will be considered for employment without attention to race color religion sex sexual orientation gender identity national origin veteran or disability status we comply with the americans with disabilities act and consider reasonable accommodation measures that may be necessary for eligible applicantsemployees to perform essential functions eeoaamfveterandisabled",,CA,False,data_engineer
Associate Data Engineer,"company overview
niche helps people find where they belong every month millions of people use niche to choose where to live work and go to school we have indepth reviews rankings and statistics on every college k12 school and neighborhood in the us and millions of monthly website visitors located in pittsburgh were quickly becoming one of the largest websites in the us
job summary
we are looking for a highly motivated data engineer we want someone who loves designing database solutions this person will utilize their skill set to improve upon sql database flows build processes to work with back end applications and make maintaining our databases easier
responsibilities
create and maintain sql stored procedures triggers and functions to support tech requirements
design data infrastructure that can be utilize by data analysts back end engineers and nontech employees
organize data in a way that optimizes querying
work collaboratively with team members to improve upon existing practices
write technical documentation


required qualifications
13 years relevant experience
bachelor’s degree in information technology computer science or related field
strong knowledge of sql andor postgresql databases
strong programming skills including complex sql programming stored procedures and performance tuning
experience designing database solutions to move and transform information to different teams and services
hard worker who wants to learn and grow with the position and company
passionate about all things data
ability to work independently in a fast paced environment and handle multiple projects concurrently


preferred qualifications
experience with geospatial and boundary data
basic knowledge of r
basic understanding of etl processes
experience building a data warehouse

princpals only no recruiters or agencies please
niche will only employ those who are legally authorized to work in the united states without sponsorship now or in the future for this opening
benefits and perks
this is a full time salaried position with competitive compensation and benefits including 20 paid days off per year paid parental leave stock options simple ira and a comprehensive health plan including vision and dental provided at no cost to the employee niche is committed to the local community and offers three paid volunteering days per year we’ve also been ranked as one of the best places to work in southwestern pa by the pittsburgh business times eoe",,PA,False,data_engineer
Data Engineer,"peeriq is transforming the way lending and securitization markets work meeting the needs across the credit funding cycle  from loan purchasing to financing to securitization  we work with industry leaders to unlock capital at scale we aim to bridge the gap between originators and the capital markets so that investors can invest with confidence our employees come from the technology and financial sectors combining the best of both to change the game of consumer credit
peeriq is looking to hire a software engineer passionate about data datadriven insights and building products designed to improve financial services and transform capital markets you will be at the forefront of green field development in delivering our data and analytics platform working closely with our product research and capital markets teams on businessdriven development
the ideal candidate is a selfstarting engineer who enjoys working with data analysis transformations analytics with experience in multiple back end front end and visualization technologies
previous successful candidates for this role even if lacking financial product experience have shown themselves to be passionate developers through projects they have built from scratch for work and personal satisfaction
responsibilities
work closely with insightsanalytics to build highly configurable scalable robust data processing infrastructure and applications
implement and productionize data pipelines and automation to support product and business needs
work closely with our product data research and capital markets leads on data retrieval and analysis as well as prototyping and iterative development
qualifications
bs in computer science engineering math or equivalent experience
24 years of software engineering experience with focus on data analytics
proficiency in python and knowledge of rest api frameworks flask django a plus workflow tools airflow
experience in other languages java scala go r is preferred
strong relational and distributed database experience familiarity with sql is critical
experience developing and building distributed and scalable etl processes and workflows
experience with automated build and continuous integration testing tools jenkins or similar and continuous deployment tools kubernetes or similar
proven critical thinking and analytical problemsolving skills
desire to learn more about the consumer credit ecosystem and how capital markets affect everyday consumers
bonus qualifications
experience with big data spark presto hive and stream technologies kafka mq
familiar with linux bash dockerizing applications
financial services experience",,NY,False,data_engineer
Business Intelligence Engineer,"job description
we are looking for a talented business intelligence engineer bie who is passionate about using data to drive critical business decisions for amazon studios as a bi engineer working on the amazon studios analytics team you will be developing and supporting the analytic technologies to give our internal customers flexible and structured access to data that is timely accurate and actionable moreover you will partner with senior leaders throughout the organization to drive insights and measurable results

the ideal candidate will not only be passionate about working with big data sets but also be comfortable developing key analytical frameworks in addition this person will have strong business acumen experience in developing reporting and analytical infrastructures exemplary communication skills an ability to work effectively with cross functional teams and an ability to work in a fast paced and everchanging environment
basic qualifications
babs in computer science engineering statistics mathematics or related fielddemonstrated strength in sql data modeling etl development and data warehousingexperience with aws technologies including redshift rds s3 emr23 years of relevant work experience in a role requiring application of analytic skills to integrate data into operationalbusiness planningadvanced skills in excel as well as any data visualization tools like tableau or similar bi tools familiarity with tableau preferredadvanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management as requiredbe selfdriven and show ability to deliver on ambiguous projects with incomplete or dirty dataan ability and interest in working in a fastpaced and rapidlychanging environment
preferred qualifications
mba or master’s degree in computer science engineering statistics mathematics or related fieldexperience working in very large data warehouse environmentsexperience with python andor r23 years of experience in a data engineer or bie role with a technology companyexperience conducting large scale data analysis to support business decision makingstrong verbalwritten communication and data presentation skills including an ability to effectively communicate with both business and technical teams
amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,CA,False,data_engineer
Big Data Engineer,contractjob summaryposition big data engineerlocation dallas txduration long term it can be 1 or 2 yearsinterview  in person or skype after phonevisa h1b usc gc gcead onlyneed 10 years exp profiles onlyresponsibilities and dutiesdesign engineer and build data platform solutions using big data technologiesestablish and communicate fit for purpose analytical platforms for business prototypeslead innovation by exploring investigating recommending benchmarking and implementingdatacentric technologies for the platformbe a proactive coding engineer interfacing with vendorsqualifications and skillsminimum 6  years of solid development experience on hadoop javascalaminimum 2 years of solid experience on scala spark kafka hive etcexperience on system integrationexperience on linux and big data frameworksshould have working knowledge of mysql etcprior experience with cloudera is an added advantagejob type contract,,TX,False,data_engineer
Data Engineer,"overview

bny mellon asset management north america mellon capital managementamna mcm a top tier global multiasset investment manager is seeking a talented experienced individual to lead the design implementation and maintenance of data and model technology infrastructure of the asset allocation aa investment team

the aa team utilizes several proprietary multiasset strategies based on fundamentalsbased principles and quantitative investment models amna has provided a wide variety of asset allocation and multiasset solutions to investors since 1983

responsibilities
design build and maintain the data infrastructure used by the aa investment team and serve as a liaison between researchers portfolio managers and developers

make use of etl knowledge to design tools for robust data managementdevelop api for accessing data for use by business users ie researchers and portfolio managerscontribute to the codebase for investment modelsmake recommendations for innovative or creative approaches for data management as neededassist in the design and development of enterprise data standards and best practicesparticipate in the evaluation and implementation of vendor application software and tools
qualifications
requirements

5 years experience as a data engineer data scientist software engineer or similarexperience with overall data architecture and infrastructure or similarexperience successfully managing large projects to completiondevelopment experience with matlab r or python in a datascience or research settingexperience with relational database design ms sql server or similarexperience building etl pipelines and knowledge of etl best practicesdemonstrated ability to work with multidisciplinary teams portfolio management research information technology teamsavailability to work during market hours
nice to have

experience working in investment management andor quantitative financeknowledgeexperience with financial data provider api’s bloomberg  datastream

knowledgeexperience with the following technologies

dockerjavamicrosoft net suitepentahonosql mongodbcloud and distributed computing


for over 230 years the people of bny mellon have been at the forefront of finance expanding the financial markets while supporting investors throughout the investment lifecycle bny mellon can act as a single point of contact for clients looking to create trade hold manage service distribute or restructure investments  safeguards nearly onefifth of the worlds financial assets bny mellon remains one of the safest most trusted and admired companies every day our employees make their mark by helping clients better manage and service their financial assets around the world whether providing financial services for institutions corporations or individual investors clients count on the people of bny mellon across time zones and in 35 countries and more than 100 markets its the collective ambition innovative thinking and exceptionally focused client service paired with a commitment to doing what is right that continues to set us apart make your mark bnymelloncomcareers

as one of the worlds leading investment management organizations and one of the top us wealth managers bny mellon investment management combines agility insight and scale to create and deliver strategies and solutions to address our clients needs encompassing bny mellons investment management firms wealth management organization and global distribution teams we draw on deep expertise to collaborate with clients and tailor our best ideas and resources to meet their specific needs we pride ourselves on providing dedicated service through our network of global professionals who have a deep understanding of local requirements with our extensive experience in anticipating and responding to the investment and financial needs of the worlds governments pension plan sponsors corporations foundations endowments advisors intermediaries individuals and families and family offices bny mellon investment management is dedicated to helping clients reach their goals

bny mellon is an equal employment opportunityaffirmative action employer
minoritiesfemalesindividuals with disabilitiesprotected veterans

primary location united statescaliforniasan francisco
internal jobcode 45144
job asset management
organization na investment boutiqueshr13428
requisition number 1809765",,CA,False,data_engineer
"Data Engineer, Building 8","facebooks mission is to give people the power to build community and bring the world closer together through our family of apps and services were building a different kind of company that connects billions of people around the world gives them ways to share what matters most to them and helps bring people closer together whether were creating new products or helping a small business expand its reach people at facebook are builders at heart our global teams are constantly iterating solving problems and working together to empower people around the world to build community and connect in meaningful ways together we can help people build stronger communities — were just getting started
building 8 brings together worldclass experts to develop and ship groundbreaking products at the intersection of hardware software and content we have a clear mandate to deliver products at scale that define new categories and advance facebooks mission of connecting the world

our analytics team works closely with product managers product analysts and marketers to acquire and retain users and optimize the user experience — all while using massive amounts of data in this role you will see a direct link between your work company growth and user satisfaction you will be working with some of the brightest minds in the industry and youll get an opportunity to solve some of the most challenging business problems at a scale that few companies can match

this is a fulltime position based in our office in menlo park

responsibilities

inform influence support and execute our product decisions and product launches

manage data warehouse plans for a product or a group of products

interface with engineers product managers and product analysts to understand data needs

partner with product and engineering teams to solve problems and identify trends and opportunities

build data expertise and own data quality for allocated areas of ownership

design build and launch new data extraction transformation and loading processes in production

support existing processes running in production

define and manage sla for all data sets in allocated areas of ownership

work with data infrastructure to triage infra issues and drive to resolution
minimum qualifications

bsba in a technical field computer science or mathematics

4 years experience in the data warehouse space

4 years experience in custom etl design implementation and maintenance

4 years experience working with either a mapreduce or an mpp system

4 years experience with schema design and dimensional data modeling

4 years experience in writing sql statements

experience analyzing data to identify deliverables gaps and inconsistencies

communication experience including experience identifying and communicating data driven insights

experience managing and communicating data warehouse plans to internal clients
preferred qualifications

4 years experience using python or java",,CA,False,data_engineer
Big Data Engineer,"work with business owners and development teams to define develop and support datadriven applications and product prototypes
gather data insights related to user behavior product usage audience segmentation social media quality of services and media consumption to drive business decisions
working with predictive analysts and data scientists build scalable prototypes of machine learning algorithms build production quality codes manage and maintain the code base
work with product management and internal stakeholders to help dictate the requirements and technical design of fandango data services and related intelligence tools
develop bi applications including transactional systems mobile application development of bi productsservices including android ios andor cross platform
contribute to every phase of the bi product development life cycle design development testing iteration deployment support and maintenance
other duties as assigned
qualificationsrequirements
masters degree in cs mis statistics machine learning applied mathematics data mining or a related field
3 years of overall professional experience proven track record working on distributed scalable serviceoriented platforms proven ability to deliver high quality production ready code
handson experience with hadoop ecosystems hive pig spark etc
handson experience in developing complex talend etl processes for integration between systems enterprise application and business analytics big data  hadoop using talend tools
handson experience in programming languages python java scala etc
experience in data extraction datadriven statistical modeling analysis and supervised learning using modeling languages such as r stata matlab etc
experience in using cloud services such as amazon web services microsoft ibm and google cloud
experience with machine learningdeep learning apis frameworks and ai tools
experience with bi reporting tools tableau microstrategy sap businessobjects ssrs etc
expert understanding of the agile software development life cycle
excellent knowledge and expertise with sql and relationalmultidimensional databases
understanding of data warehousing concepts
strong customer service and communication skills verbal and written to effectively interact with a diverse team of people across business and engineering
must maintain regular and acceptable attendance at such level as is determined at the company’s sole discretion
must be available and willing to work extended hours during crunch times per day including occasional weekends and holidays
desired characteristics
willingness to dig into technical conceptsdetails
proactive to improve products and business processes
aws certifications
naturally inquisitive and selflearner
a team player
stay on top of the latest innovations in data and technologies
subbusinessfilm fandango
career level
experienced
citybeverly hills
stateprovince
california
countryunited states
about us
at fandango we love movies from showtimes and ticketing to engaging content and innovations in movie going we strive to deliver the perfect movie going experience—anytime anywhere and to be the goto destination for moviegoers we think it’s all about collaboration anyone can build a website or app but it takes a special group across many disciplines to create an experience that can live across multiple platforms and connected devices thanks to an exceptional team we’re working hard to make fandango a little bit better every day our 30 million and growing online and mobile monthly visitors can now buy movie tickets at over 25000 screens nationwide and stay for exclusive trailers our awardwinning original video series movie reviews celebrity interviews and more so if you’re looking to inspire be inspired and work at the intersection of entertainment and technology look no further than fandango visit fandangocomcareers for a behindthescenes look at fandango and follow us on linkedin for the latest news and updates fandango is an nbcuniversal company
notices
nbcuniversal’s policy is to provide equal employment opportunities to all applicants and employees without regard to race color religion creed gender gender identity or expression age national origin or ancestry citizenship disability sexual orientation marital status pregnancy veteran status membership in the uniformed services genetic information or any other basis protected by applicable law nbcuniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements including the city of los angeles fair chance initiative for hiring ordinance where applicable",,CA,False,data_engineer
Data Engineer,"as a member of the data engineering team you will be required to leverage strong data engineering experience with cutting edge technologies in the nosql hadoop ecosystem and data lakewarehouse spaces to support and enable a true data driven company the ideal candidate will have a track record of developing data pipelines to extract transform and aggregate data that can scale to petabytes elastically with low latency and high availability

qualifications


a background in computer science engineering mathematics or appropriate industry experience
experience building complex data pipelines for data integration from enterprise wide applicationssystems into centralised big data lakeswarehouses
advanced experience and understanding of distributed database technologiesconcepts
experience integrating with big data platforms including spark and kafka
strong analytical competencies with the ability to turn requests from business intelligence and data analyst personnel into efficient and scalable data transformations
a proficient python programmer
experience processing data at scale with a concrete understanding of the tradeoffs and challenges of a variety of implementations
experience building and enforcing strong data quality guarantees and anomaly detection into data pipelines

nice to haves


experience with aws internals and their suite of product offerings
knowledge of database internals transactions clustering sharding and replication
knowledge of optimised data storage and serialisation formats
fundamental data science knowledge and experience

what we expect from you


you are a data visionary that believes in the power and potential of being data driven
be willing to share your expertise and mentor less experienced engineers
able to work quickly and independently within a fast pace agile team
exhibit strong ownership of all aspects of assigned projects tasks issues and code
possess a natural tendency to analyze and optimize platform scalability and efficiency
continually seek to improve your skills and keep abreast of industry trends
able to evaluate and experiment with emerging technological trends and apply them to new and existing projects as well as certify their usage for wider adoption throughout mongodb
can adapt to new different or changing business requirements able to distill complex problems into concrete technical requirements and are comfortable identifying alternatives and making timely decisions

",,NY,False,data_engineer
Data Engineer,100000  140000 a yearoptomi in partnership with the global technology team for a leading global asset management and financial services company is seeking a data engineer for their baltimore md location to play a key role in helping build the future of financial servicesthe data engineer will be joining a brandnew team that will help establish and build new capabilities for the organization’s research data science machine learning and business analytics efforts the goal is to transform large amounts of structured and unstructured data such as text time series and events into machinereadable knowledge fueling applications and the buysell investment decisionmaking process for portfolio managers analysts and quants and traderswhat the right professional will enjoyhelp establish best practices in big data technologies and data warehouse to collect and analyze large volumes of data advancing the state of the art in efficiency optimization predictive analytics and bi selfreporting toolsjoin an emerging technical team of data engineers delivering a wide array of big data and selfservice reporting solutions that use cutting edge technologieshelp guide the organization in efficient data and resource management best practices with cloud based big data data warehouse and reporting platforms and servicesapply today if your background includes you have a bachelor’s degree in computer science or related field and have 3 years of relevant work experience in business intelligence data engineering data warehousing or a similar fieldyou remain active in learning emerging practices and technologies in the bidw and data science spaceyou are comfortable and confident in your knowledge of multiple database programming languages and your knowledge of relational and columnar databasesyou have experience integrating data from multiple data sources and have processed large amounts of unstructured datayou have experience with aws big data components apache spark hadoop presto etc and continuous integration tools teamcity octopus jenkins etc is desired but not requiredjob responsibilities provide significant contributions to the growth of our data infrastructuredesign develop test and deploy business intelligence solutionsdesign and document data structuresmodels and data flowsinteract with various business units and technical teams to gather requirementsreview optimize and document current etl processesensure data quality completeness and accuracycollaborate with team members in code reviews discovering better practices and patterns and continuous improvementsjob type fulltimesalary 10000000 to 14000000 yearlicenseus citizen or green card preferred,120000.0,MD,False,data_engineer
Principal Data Engineer,"description
join us as a principal data engineer
join target’s data science  engineering team in sunnyvale as a principal data engineer – data architect here we employ cutting edge technologies to help target meaningfully engage with guests and make intelligent business decisions using huge data sets our data engineers partner closely with data scientists continuously innovating to harness valuable insights from data generated you’ll work in an environment that provides the freedom and agility of a startup with the security and vast resources of a large established company
as a principal data engineer you’ll get the chance to design and architect high quality flexible manageable and performant systems and services you will architect solutions that will capture manage process and serve small to large data at scale this role allows you to work with business partners to provide technical solutions for business problems on a large scale in a fast moving retail data industry responsibilities will include analyzing designing programing debugging modifying software for existing and new proprietary data products used in distributed large scale analytics solutions
we’re looking for a highly motivated engineering professional who will partner with lead technical product owners and management at one end as well as lead and motivate scrum development teams on the other
key responsibilities
lead decisionmaking process for selection of software products and architecture solutions
develop software systems using test driven development employing continuous integration practices
mentor and partner with engineers to develop software that meets business needs
follow agile methodology for software development and technical documentation
innovate constantly and keep systems up to date with current technologies
requirements
ms or phd degree in computer science or equivalent experience in data architecture
10 years of experience in developing software applications
3 years of experience working on big data products  preferred experience with hadoop spark hive druid etc
proficient in applicationsoftware architecture definition business process modeling etc
extensive understand of applicationsoftware development and design
collaborative personality – ability to engage in interactive discussions with diverse engineering teams
stays current and up to date on big data technology and trends
experience mentoring and developing skillsets of data engineers

qualifications",,CA,False,data_engineer
Data Engineer,"who we are
omazes mission is to transform lives by leveraging the power of storytelling and technology our model democratizes traditional auctiongiving by offering people everywhere the chance to have a onceinalifetime experience for as little as a 10 donation to continue raising money for hundreds of nonprofits around the world were growing our team of smart dedicated and passionate world changers thats where you come in

who were seeking
omazes engineering team is looking for a data engineer to help us grow in 2018 and beyond we have a unique product passionate customers and global reach we need a great engineer to help us marshall and wrangle data if you are comfortable working with sql spark redshift parquet python scala big data and aws we want to talk to you

key responsibilities

work on our existing data pipeline which is sql bash python spark scala s3 redshift and cron
develop our new data pipeline using things like alooma sql s3 redshift
help consolidate our media spend across social networks ad networks affiliates into a holistic dashboard this may require api integration work with third party companies or working with companies like funnelio
help manage and administer our data warehouse
support business intelligence and database administration
etl performance optimization
build aggregates

our ideal candidate

you have 5 years of professional software experience have worked with several programming languages and deep knowledge of at least one objectoriented language
you do or would enjoy working in bash golang python andor scala
youre comfortable working with ad spend data from facebook instagram twitter ad networks and affiliates
you have experience building and managing data pipelines and with writing etl jobs
you have designed and implemented optimized scalable data warehouses
you are great at query optimization and have dba experience
you have experience with cloud infrastructure
you have experience working with data marts and the star scheme
youre familiar with tableau looker or microstrategy
you take your work seriously but not yourself

to apply
tell us a little bit about yourself and why you would be an ideal fit",,CA,False,data_engineer
Data Engineer-Data Scientist,"are you a data engineerdata scientist with a solid data experience who is seeking a new challenge our downtown seattle client would like to meet you you will be working with a small team currently migrating data into aws your daytoday focus will be on programming you are ideal for this team if you have experience working with hadoop and related technologies sql aws database engineering experience and programming experience ready to learn more

expectations


you excel working as part of a team
you enjoy opportunities to participate in standups and other sprint meetings
you are passionate about solving the toughest challenges
you are comfortable working with hadoop related technology databases and cloud platforms
you are good at rapidly rationalizing and transforming data into useful form and delivering their results via clean maintainable code
you have experience working with engineer and analyst teams to rapidly deliver insights in an iterative agile development environment
you enjoy working in a fastpaced collaborative team environment contributing to the highperformance team culture

requirements


degree in in engineering computer science or a related field
3 years of experience in the development of data engineering for nonacademic problems
5 years of experience data engineering for real world problems using hadoop and related technologies spark hive etc
experience developing software within the full software development lifecycle from design through release
experience at a large company with complex business models working directly with internal customers and facilitating or mediating across functions
knowledge of fundamental cs concepts eg algorithms and data structures
expertise in programming python and java
experience with hadoop and related technologies for distributed scalable storage and processing
expertise in sql

thank you for considering quardev when you join quardev consulting team you join a team of industry veterans with a combined experience of over 30 years who are dedicated to creating a positive work environment that attracts and retains consultants through a combination of employee satisfaction working conditions and company culture team members enjoy w2 employment benefits competitive salary birthday off paid affordable health vision and dental insurance 401k and fridge access at our corporate office we pride ourselves on being a great place to work and strive to ensure our team members enjoy coming to work each day

for more information and new job opportunities visit wwwquardevcom

to check out our employee reviews on glassdoor click here",,WA,False,data_engineer
Senior Big Data Engineer @Apple Inc.,50  65 an hourcontractjob descriptiontranslate complex functional and technical requirements into detailed designarchitect data pipeline using spark airflow  beamproficiency in spark for technical development and implementationload disparate data sets by leveraging kafka consumersability to utilize hive spark cassandra mesos pysparkcontribute and adhere to the best engineering practices for source control release management deployment etcparticipate and facilitate in production support job schedulingmonitoringperform machine learningsupervised  unsupervised natural language and statistical analysis methods such as classification collaborative filtering association rulesqualificationsbs and ms in mathematics computer science or engineering6 years of python java scala6 years of demonstrated technical proficiency with spark big data projects and experience in data modelingwriting highperformance and reliable codes spark scripts and implement kafka and flume topicsprocessesgood knowledge of database structures theories principles and practicesanalytical and problem solving skills applying to big data domainunderstanding and experience of utilizing hadoop pig hive and spark elastic search etcgood aptitude in multithreading and concurrency conceptsjob type contractsalary 5000 to 6500 hourexperiencespark 2 years preferredcassandra 2 years preferredmesos 1 year preferredlocationsunnyvale ca preferred,,CA,False,data_engineer
Data Engineer,"homelight is changing the face of real estate one homeowner at a time we empower consumers to use real agent performance data to make a more informed choice on the biggest financial decision of their lives our proprietary machine learning algorithms analyze over 30 million transactions from 2 million agents to determine the best agents to meet clients specific home buying or selling needs

we are backed by some of the most well known investors in silicon valley such as menlo and google ventures and help consumers sell billions of dollars in homes annually we are expanding our lean versatile engineering team by hiring a data engineer

what youll do here
we are building a data engineering team to tackle homelights diverse data challenges you will develop and operate our data pipeline which collects processes and distributes data to a suite of homelight products and teams you will provide data to both our algorithms and internal users refining our product and identifying new markets some projects you will work on


execute on requests to pull analyze interpret and visualize data
partner with team leads to build out and iterate on team and individual performance metrics
participate in our data release process and partner with team leads to iterate on and improve existing data pipelines
design and develop systems that ingest and transform our data streams using the latest tools
setup and integrate new cutting edge databases and data warehouses develop new data schemas and figure out new innovative ways of storing and representing our data
research architect build and test robust highly available and massively scalable systems software and services

you have


3 years of data engineering experience
experience writing and executing complex sql queries
experience building data pipelines and etl design implementation and maintenance
experience with aws or other iaas or paas provider
ability to produce highquality software through unit  functional testing
experience with development in one or more of the following python r scala sql
experience with data processing frameworks and data warehouses such as hadoop spark redshift
scrumagile software development process

bonus points for

real estate experience
experience with periscope looker tableau and other bi tools
experience with building data pipelines
experience with machine learning

the perks



medical vision dental and paternitymaternity benefits
401k
commuter benefits
flexible time off policy
catered lunches and snacks
corporate gym membership
company events happy hours bowling bocce league etc

",,CA,False,data_engineer
Data Engineer,70000  90000 a yearhelp data scientists and analytics modelers prepare poor quality data so it can be used in analytics modelsenable access to internal and external data sources and making sure data is available for those who need itgive input to it for the design and implementation of data management andor architecture solutionsset up and ongoing operational support of etl environments including development test and productiondesign implement and deploy data loaders to load data into hadoopnosqlassist in pulling filtering tagging joining parsing and normalizing data sets for usework with the business analyst data governance team data steward to resolve data quality issues create analytical datasets from large data sources multiterabytehadoop through the development of highlyefficient reusable codedata engineers in the big data platform  hadoop spark scala java python with hands on experience in supporting analytical projectscloud  aws google or microsoft experience is requiredjob type fulltimesalary 7000000 to 9000000 yearexperiencehadoop 2 years requirednosql 2 years requireddata analysis 5 years preferredgoogle cloud 1 year preferredaws 1 year preferredspark 1 year preferredscala 1 year preferredpython 1 year requiredjava 1 year requiredazure 1 year preferrededucationbachelors preferredwork authorizationunited states preferred,80000.0,MA,False,data_engineer
Big Data Engineer,contractjob summarygreetings from infotechspectrum we have an immediate requirement for big data engineer please share suitable profilestitle big data engineerduration 12 monthslocation phoenix azjob detailsperfect in bigdata  hadoop conceptsshould have knowledge of big data tools hivesqooppigshould have experience working with apache sparkknowledge of big data ecosystemshould have experience in optimizing hadoop etl jobsvery good in advanced sql queries join group by partition by indexing etcshould have knowledge and exposure to nosql databasesable to explore and analyze datasets with tools like excelgood to have knowledge in banking domain and risk management systemexcellent communication analytical and interpersonal skillsjob type contractwork authorizationunited states required,,AZ,False,data_engineer
Data Engineer,160000 a yearposition overviewredefine how washington workswhen government is at its best diverse ideas are at work the same is true of bloomberg government our ability to innovate and serve our clients means diversity and inclusion are essential if you’re eager to join a multidimensional team that celebrates and leverages difference if you have the vision to see how information can transform “business as usual” and if you are hungry to createto build a service transforming how things get done—then stop reading this and join our teamwho thrives hereindividuals who embrace hard work act with urgency and collaborate without reserve thrive at bloomberg government you are on the front lines of revolutionizing the information services industry in washingtonas high as our expectations will be of you yours must be higher if you are dogged innovative and interested in work that contributes to causes greater than yourself you belong at bloomberg governmentbloomberg bna also provides legal tax and compliance professionals with critical information practical guidance and workflow solutions we leverage leading technology and a global network of experts to deliver a unique combination of news and authoritative analysis comprehensive research solutions innovative practice tools and proprietary business data and analytics bloomberg bna is an affiliate of bloomberg lp the global business financial information and news leaderwe are looking for an experienced web application architect to be responsible for business analysis application design development integration and delivery and application maintenance and support individuals in this position must be a selfdirected professional who will also bring leadership skills and quickly learn new technologies and programming languageshiring requirementsjob detailsjob profilejob profileweb application architect project supervisor bgov bbnajob families for job profilesjob families for job profilesemptyworker subtypeworker subtyperegularworker typeworker typeemployeetime typetime typefull timecompensation gradecompensation gradem04primary locationprimary locationwashington  1101 k street nw bbnaprimary job posting locationprimary job posting locationwashington  1101 k street nw bbnaadditional locationsadditional locationsemptyadditional job posting locationsadditional job posting locationsemptyscheduled weekly hoursscheduled weekly hours375work shiftwork shiftemptyrecruiting start daterecruiting start date08272018target hire datetarget hire date08272018target end datetarget end dateemptyadditional informationunion membership from job profileunion membership from job profileemptyallowed unions from job profileallowed unions from job profileemptyjob descriptionjob descriptionprimary responsibilitiesproposes develops and supports worldclass customer facing web applications using a range of technologiesparticipates in the analysis of system and business requirements to provide handson solutions to meet or exceed our customers’ expectationsdelivers highquality code by defining and deploying best practices in unit testing and regression and testing frameworksperforms integration and testing of software components across an entire team as neededserves as the scrum master for a crossdisciplinary team on an as needed basisresponsible for the delivery of discreet products and components marshalling resources across a matrixed organizationcommunicates with the product management and development teams to raise issues and identify potential barriers in a timely fashionparticipates in usercentered research through client focus groups interviews usage analysis and rapid prototypingresponsible for protecting our customers and brand by writing securebydesign codeleads supervises mentors and trains other team members in order to develop a strong bestinclass development benchdirects the work of and provides technical guidance to less experienced staffparticipates in recruiting hiring onboarding and performance management of new team membersparticipates in special projects and performs other duties as assignedjob requirements demonstrated commitment to high quality user facing and back end code that is usable maintainable and well thought outstrong track record of establishing best practices in software architecture and developmentexperience developing applications using soa service oriented architecture interfaces and architectures such as reststrong record of project execution and completion with experience using scrum and agile development practicesexcels at working with multidisciplinary teams to develop great user experiencesability to work with and mentor other developers and lead by example to develop highly proficient and productive teamsmust be a selfdirected and highly motivated individual who embraces modification of their work based on customer feedback and other business factorsworks closely with designers and other developers in a tightly knit agile teamability to work both independently and collaboratively across team and organizational boundariesdisplays enthusiasm for the challenge of pushing the limits of the web platform to deliver disruptive innovative solutions to the world that will delight our customersmust be focused on frontloading quality into the development process ensuring that quality tests are not failingfamiliarity with new and emerging technologies across the full stackfamiliarity with web application security topics such as saml ad and sslexcellent written verbal and interpersonal communication skills including the ability to interact with all levels of employees and customers throughout the organizationability to travel as required to meet with stakeholderswillingness to maintain a flexible work scheduleeducation and experiencebachelor’s degree in computer science or a related discipline or equivalent experience master’s degree preferreda minimum of 5 years’ experience as a software engineer or architect for web applicationsminimum 3 years’ experience developing web applications in a complex multiplatform distributed environment with object oriented languages ruby on rails java etcexperience using a variety of languages and technologies to develop web solutionsexperience working in an iterative or agile development environment preferably scrumjob type fulltimesalary 16000000 yearexperiencejava 5 years requirededucationbachelors preferred,160000.0,DC,False,data_engineer
Data Engineer,"job code 4777
grade k
stanford graduate school of business
residing in silicon valley the heart of innovation stanford gsb has built a global reputation based on its immersive and innovative management programs we provide students a transformative leadership experience push the boundaries of knowledge with faculty research and offer a portfolio of entrepreneurial and nondegree programs that deliver global impact like no other we strive to change lives change organizations and change the world
the data insights team at the stanford gsb supports the school’s etl api and analytics needs we’re looking to add a strong handson database engineer to the team the ideal candidate must have extensive handson experience an all relevant tech and tools experience in dealing with business level conversations and interactions juggling multiple and shifting priorities in building environmentappropriate practical solutions that appropriately balance between competing pulls of the immediate and future since the team is distributed across time zones ability to collaborate across the distributed work environment is crucial
responsible for development of complex technical analysis and design new programming modifications scheduling tuning testing and maintenance of systems in support of new and existing business intelligencebi and other projects
your primary responsibilities include
architect design implement and maintain secure scalable bi data stores for structured and unstructured data for all domains of the school’s business  operations learning admissions crm etc
collaborate with integration engineers to build etl processes for ingesting data into bi stores and do data prep for bi dashboards
provide complex analysis conceptualize design implement and develop solutions for critical bi components
plan and implement standards definecode conformed global and reusable objects perform complex database design data modeling edw and programming and streamline the systems
consult with client groups to assess user needs and understand business processes convert requirements into technical solutions
contribute to data analysis design and development of new and ongoing business intelligence bi projects involving complex edw structures or on oltp systems
collaborate closely with internal and external teams to understand and apply changesmodifications impacting data warehouse
monitor industry for emerging technologies and trends provide appropriate recommendations to team and leadership
provide technical mentoring to other team members as appropriate
be flexible to completing any other additional assigned duties

to be successful in this position you will bring
bachelor’s degree and seven years of relevant experience in computer science or engineering or combination of education and relevant experience
mastery in sql skills and ability to support sql based etl processes
mastery in business intelligence and data warehousing concepts and methodologies
expertise on databases data acquisition etl strategies and tools and technologies like informatica talend etc
expert in data modeling data from heterogeneous oltp sources into appropriate bi stores  structured warehouses and data lakes
experienced in designing physical and reporting data models for seamless crossfunctional and crosssystems data reporting
experienced in building robust and reusable data prep processes to support bi analysts
experience working with standard sdlc processes
experience in one or more programming platforms like r python etc a strong plus
experience in relevant components of aws and gcp a strong plus
experience in machine learning a plus
selfmotivated demonstrable quick learner of new technologies andor processes experienced in working with distributed teams across time zonesconsistent with its obligations under the law the university will provide reasonable accommodation to any employee with a disability who requires accommodation to perform the essential functions of his or her job

why stanford is for you
stanford’s dedicated 16000 staff come from diverse educational and career backgrounds we are a collaborative environment that thrives on innovation and continuous improvement at stanford we seek talent committed to excellence driven to impact the future of our legacy and improve lives on a global sphere we provide competitive salaries excellent health care and retirement plans and a generous vacation policy including additional time off during our winter closure our generous perks align with what matters to you
 freedom to grow take advantage of career development programs tuition reimbursement or audit a course join a ted talk film screening or listen to a renowned author or leader discuss global issues
a caring culture we understand the importance of your personal and family time and provide you access to wellness programs childcare resources parent education and consultation elder care and caregiving support
a healthier you we make wellness a priority by providing access to worldclass exercise facilities climb our rock wall or participate in one of hundreds of health or fitness classes
discovery and fun visit campus gardens trails and museums
enviable resources we offer free commuter programs and ridesharing incentives enjoy discounts for computers cell phones recreation travel entertainment and more
we pride ourselves in being a culture that encourages and empowers you

how to apply
we invite you to apply for this position by clicking on the “apply for job” button to be considered please submit a cover letter and résumé along with your online application",,CA,False,data_engineer
Data Engineer,"we at flywire are looking for a smart analytical thinker whos excited to empower datadriven decision making at an exciting and fastgrowing organization as our data engineer you will work within the data analytics team to ensure that our organization has access to reliable accurate and timely data to be used in various reporting business intelligence and analytical solutions great data aptitude is a must for this role but were also looking for someone thats willing to work across flywire teams to understand real business problems and design solutions that will ultimately provide insights into the performance of the company improve process efficiencies and contribute to our companys ability to provide a worldclass crossborder payment solution

key responsibilities

own the maintenance and ongoing development of flywires analytical data infrastructure
develop productiongrade data pipelines and etl processes to support analytics projects business intelligence reporting and machinelearning solutions
continuously identify and implement data process improvements eg optimize data delivery redesign for scalability implement testing and alerting systems to assure data quality etc
own maintenance of documentation and data dictionaries for various internal data sources

minimum qualification criteria

bs in computer science mathematics or related field
5 years of experience of data engineering database administration or related work
experience with awsamazon redshift andor google cloud platform is required
experience in building data extraction and manipulation scripts in python
general understanding of the broader data landscape trends and emerging technologies
hunger and excitement for learning new tools and techniques
excellent problemsolving skills you may not know the solution to all the problems youll face but you have the ability to research available technologiesstrategies and figure out a solution or a path forward
strong communication skills you can make even the most complex data and technical problems easy to comprehend

preferred criteria

experience in business intelligence development tableau looker etc
demonstrated ability of building streaming data applications
practical understanding of classification regression and other statistical methods
familiarity with apache spark
proficiency with spanish

flywire is an equal opportunity employer",,MA,False,data_engineer
Sr Data Engineer,"collaborate with product teams data analysts and data scientists to design and build dataforward solutions build and deploy streaming and batch data pipelines capable of processing and storing petabytes of data quickly and reliably integrate with a variety of data metric providers ranging from advertising web analytics and consumer devices build and maintain dimensional data warehouses in support of business intelligence tools develop data catalogs and data validations to ensure clarity and correctness of key business metrics drive and maintain a culture of quality innovation and experimentation 35 years of experience developing in object orient python engineering bigdata solutions using technologies like emr s3 spark loading and querying cloudhosted databases such as redshift and snowflake building data pipelines using kafka spark flink or samza familiarity with binary data serialization formats such as parquet avro and thrift experience deploying data notebook and analytic environments such as jupyter and databricks knowledge of the python data ecosystem using pandas and numpy experience building and deploying ml pipelines training models feature development regression testing experience with graphbased data workflows using apache airflow bachelor’s degree in computer science or related field or equivalent work disney streaming services is a place for the creative and the bold we’re seeking talent across disciplines to join our team whether new york city san francisco manchester or amsterdam we provide opportunities to elevate your career and transform an industry disney streaming services software engineers develop premium digital media products for major league baseball and our partners

the products we build such as mlbtv nhltv hbo now and playstation vue are paving the way for the nextgeneration media and sport technologies bamtech engineering is headquartered in the chelsea area of new york ny with an office in the somo area of san francisco ca and team members based around the world if you are interested in joining disney streaming services in the pursuit of not only crafting new media products but enjoying the products you build we are interested in hearing from you at disney streaming services data is central to measuring all aspects of the business and critical to its operations and growth

the data engineering team is responsible for collecting analyzing and distributing data using public cloud and open source technologies and offers transparency into customer behavior and business performance 600905",,NY,False,data_engineer
Lead Data Engineer,lead data engineerharmony labs is on a mission to understand media influence at scale and to experiment with using media to support an open resilient democratic society our community of researchers practitioners and industry partners is building basic knowledge and applied solutions to help get ahead of pressing media systems challenges like business models that favor engagement over accuracy partisan polarization and information wars fought with manipulated media we are currently seeking a lead data engineer to help us build out our data warehouse and add new sources to it from our accelerator programthe lead data engineer will take on the following roles and responsibilitiesarchitect and implement reliable etl pipelineswork with myriad sources to automate ingestion processes across internal and externalsystemsbuild alarms and health metrics to maintain high data availabilitydesign and create data schemas and models that can scalefacilitate the growth of the engineering team at harmonyqualifications and requirementscs degree or related work experiencefamiliarity with cloud database architectureexperience designing and implementing systems using pythonfamiliarity with schemas tables structures relational and nonrelational databasearchitecturestrong experience in improving performance of queries and data jobs and scaling thesystem for exponential growth in dataexperience leading small teams and working with stakeholders to design and build systemshow to applyplease submit your cover letter resume and salary requirementscompensationsalary is commensurate with experience there is an excellent benefits plan including unlimited paid time off for sick leave and vacation medical dental and vision plans pretax flexible spending accounts and transit program and 401k as part of our dedication to the diversity of our workforce harmony labs is committed to equal employment opportunity without regard for race color national origin ethnicity gender protected veteran status disability sexual orientation gender identity or religionabout harmony labsharmony labs is on a mission to understand media influence at scale and to experiment with using media to support an open resilient democratic society through the sharing of data knowledge and other resources were enabling networks of researchers practitioners and partners to rapidly generate and refine hypotheses about how media and society interact to align around ideal outcomes and to test outcomesoptimized interventions together we’re building basic knowledge and applied solutions to help get ahead of pressing media systems challenges like business models that favor engagement over accuracy partisan polarization and information wars fought with manipulated mediaharmony labs is new york city based 501c3 that has evolved from nearly a decade of research and prototyping in partnership with andor funded by leading organizations like google the ford foundation the corporation for public broadcasting mtv and columbia universityjob type fulltimeexperiencepython 1 year preferrededucationbachelors preferredlocationnew york ny 10036 preferred,,NY,False,data_engineer
Data Engineer,55000 a yearposition data engineerlocation cincinnati ohio usaduration fulltimesalary starting at 55000  yearbenefits competitive benefits packageabout sphaericai sphaericai is an up and coming leader in developing and implementing ai solutions for corporate clients and funded startups we are currently working with clients in the insurance healthcare and marketing industries and are looking to move into additional verticals as we continue to grow current solutions we offer includemlai model building and deployment in flexible and scalable cloud environmentsweb application development for process automation and ai interactioncloudbased data engineeringtechnical consultingthis is a great opportunity to join a small but growing company and quickly become a part of the leadership teamposition summary as a data engineer for sphaericai you will be entrusted with significant responsibility the primary function of this role will be as lead data engineer for a sophisticated cloudbased data collection platform this includes working with apache airflow to ensure that data pipelines are functioning properly innovating and implementing improvements and taking lead on recommendations in addition you will be responsible for supporting our data science services that could include model deployment and some frontend web app developmentwe are looking for a candidate who can grow into a leadership role with our companyresponsibilities managing workflows in apache airflowbuilding data pipelines to collect and store data in the cloudreworking existing backend infrastructure to optimize performancedeploying of mlai models in the cloudbuilding and deploying uis for mlai modelsinteract with clients regarding work productsrequirements ability to adapt to new programing languages or software products quicklyproven programming experience preferred but not required python java sql airflow etcknowledge of and experience with the software development lifecyclefamiliarity with cloud environmentsfamiliarity with data warehousingfamiliarity with big data tools hadoop apache spark mongodb etcoptional requirements experience with dashboarding and data visualizationstrong quantitative and problemsolving skills exposure to math statistics engineering or physicsbenefits of working with sphaericaiteam members working with sphaericai will be entrusted with significant responsibility and room for growth we love innovative thinking and working at the highest standard while maintaining a relaxed environment in which we actively help each other learn and share best practices that we discoverspecific benefits includework on industryleading ai projectsparticipate in the entire project lifecycle from ideation to deploymentinvolvement in ai conferencesopportunity to work with a growing startup which is set to expand significantly in the next 5 yearslook us up website sphaericailinkedin httpswwwlinkedincomcompanysphaericjob type fulltimesalary 5500000 yeareducationmasters preferredlocationcincinnati oh required,55000.0,OH,False,data_engineer
Data Engineer Intern,"internshipdata engineer intern  00051473
description
do you want to help analyze data and do the analysis needed to contribute to solving our nation’s most critical problems do you want to be mentored by engineers and scientists that are experts in their fields do you want to join over 300 other interns for a summer full of learning networking and fun

mitre’s people are committed to tackling our nations toughest challenges we are different from most technology companies we are a notforprofit corporation chartered to work for the public interest with no commercial conflicts to influence what we do the rd centers we operate for the government create lasting impact in fields as diverse as cybersecurity healthcare aviation defense and enterprise transformation were making a difference every day—working for a safer healthier and more secure nation and world

our workplace reflects our values we want you to come as an intern and then join us upon completing your degree so that you can experience the gratifying work our competitive benefits exceptional professional development opportunities and a culture of innovation that embraces diversity inclusion flexibility collaboration and career growth

the mitre corporation is seeking a data engineer intern to come join our team our data engineering  biometrics department applies machine learning computer vision and biometrics capability to provide mitreunique value across multiple sponsors and driving multiple research initiatives and efforts across mitre or in collaboration with academy industry and sponsors
key function what do mitre data analytics  operations research  statistics  math interns do
mitre’s data analytics operations research  statistics  math interns help strengthen our sponsor’s effectiveness by using data analytics statistical analysis and modeling and simulations methods to drive analyticallydefensible decisions they apply advanced analytical and mathematical techniques to solve complex decision problems—those with multiple alternatives that require quantitative analysis to confidently select the best one analysts use high performance computing cloud computing big data analytics and data visualization tools and techniques to improve system designs to assist in making difficult policy and acquisition decisions to maximize operational effectiveness and efficiency and to achieve the highest quality engineering solutions

qualifications
what does an ideal data science  operations research  statistics  math intern or new grad have

demonstrated understanding of how to retrieve data from databases and other systems and tools using queries exporting capabilities and other effective methods

understanding of or experience with statistical software and data visualization tools such as r spss sas ms access python visual basic unix shell scripting andor sasjmp

proficiency in one or more of the followingjava python xml html c objective c database design  development including sql

ongoing excellence in academic performance

high level desire to help their nation solve its most critical problems

exhibits the characteristics of a continuous learner

additional information

70 of mitre’s fulltime jobs require us government security clearances therefore many internships and full time positions require that the candidates be clearable which requires us citizenship mitre does not provide sponsorship for those that need it currently or in the future

many of our jobs welcome those students who have an interdisciplinary approach to problem solving

primary location united statesvirginiamclean
work locations washington 22102
job student
this requisition requires a clearance of none
travel no
job posting oct 16 2018 23402 pm",,VA,False,data_engineer
Data Scientist,80000  140000 a yearflowcommand is hiring a lead data scientist for our san francisco office we are a sensor company that aims to accurately capture the behavior of high throughput fluid systems with this information we can help optimize allocations while reducing spills and theft this technology could change the way the oil and gas industry water municipalities and anyone dealing with high volume fluid operate our sensors send ultrasonic data directly to our server via cellularsatellite we then use a mix of physics equations signal processing and anomaly detection to determine the behavior of fluid volume and speed in pipesas the first data engineer at flowcommand you will work closely with our small team split across houston san francisco and mexico city you’ll leverage our remotely controllable flowloop test facility in houston to generate training data from our sensors as the owner of this process you will be building the foundational models and algorithms that our future suite of products will run onresponsibilities increase accuracy of our measurementsincrease the accuracy of our confidence in our measurementscollaborate with engineers to build models that enable a fundamentally new sensor technologyunderstand source and leverage tangentialcontextual datasetsincrease the usecases of our products by identifying correlations with tangentialcontextual datasetsrequirementsexperience building production grade machine learning modelsexperience building models with limited training datastrong written and verbal communication skillsexpert knowledge and demonstrable experience with python and sqlteam oriented and able to take an idea from conception to launchpreferencesdegree in statistics or computer science with a machine learning focusnoteif you have a very strong theoretical knowledge of building these models from a phd or something similar but no experience you should still apply for considerationflowcommand is proud to be an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion gender gender identity or expression sexual orientation national origin genetics disability age or veteran statusjob type fulltimesalary 8000000 to 14000000 yearexperiencedata science 1 year requirededucationbachelors preferredlocationsan francisco bay area ca requiredwork authorizationunited states required,110000.0,CA,False,data_engineer
Data Engineer,70000  90000 a yearbig data geek needed at awhawh a 24year old software engineering firm in dublin ohio has partnered with snowflake to take data to the cloud we’re looking for a data engineer to work with nextgen data technologies to architect and deploy clients your primary role will be to support data integration processes that move enterprise data lakes into the snowflake cloudwwwawhnetwwwsnowflakecomyour skills will includebachelor’s degreeminimum 3 years of experience configuring managing and troubleshooting postgresql or sql server or oracle or redshift2 years experience as an ssis etl developer in ms sql server or with using etlelt tools such as pentaho talend business objects or informaticadata stageminimum 3 years of experience with database backup and recovery including implementing disaster recovery standardsminimum 2 years of experience in an agile development environment with experience with version one and jiraminimum 2 years of experience developing in sql python r ruby c c java ansible or chefexperience with hadoop spark tableau and other big data technologiesat least 3 years of experience with database design optimization and tuningas a data engineer you will have the ability to grasp new technologies quickly break down complex data issues quickly and resolve them your goal will be to work with a crossfunctional team of client and internal resources to drive design and deployment from a client’s data lake into a snowflake data warehouse solution you’ll be an expert at grasping multitier multiplatform frameworks and have handson experience in the design development and maintenance of relational databases for data storage and data miningjob type fulltimesalary 7000000 to 9000000 yeareducationbachelors preferred,80000.0,OH,False,data_engineer
Data Engineer,"caseys general stores corporate headquarters in ankeny ia is currently seeking a data engineer to join our business intelligence  analytics team as a data engineer youll be responsible for identifying data sources dimensional modeling of warehouse tables extract transform and load etl process and working with other team members to troubleshoot and maintain the data warehouse

specific responsibilities will include

designs solutions that conform to the established data warehouse standards
evaluates existing data assets and understands how to extract and model the source data to a star or snowflake schema
develops data warehouse table architecture that adheres to kimball best practices andor specific needs of the teams bi tools
builds extract transform and load processes to extract data from a variety of source systems using sql server integration services and transact sql
provides thorough testing of all data warehouse objects and etl processes
expands and maintains etl and data warehouse architecture documentation
documents best practices for data modeling and integrations
required

bachelors degree in computer science management information systems data analytics or related discipline or equivalent related experience
25 years experience in related role
advanced sql skills and experience experience writing macros and stored procedures
possess a thorough and practical understanding of application design development and environment
knowledge of physical and logical database design
preferred

ssis informatica or other data integration tool experience
ability to extend etl process using c python scala sql or similar programming language
experience with multiple database platforms such as sql server ms aps microsoft analytics platform system teradata oracle and hadoop
experience with reporting tools including microstrategy bi publisher obiee oracle business intelligence enterprise edition powerbi and business objects",,IA,False,data_engineer
Data Engineer - Deep Learning,"overview
we are looking for a data engineer to work with a team of quantitative researchers in sig’s philadelphia office this group will utilize machine learning techniques to capitalize on trading opportunities for our equities futures and options products this team will be responsible for spearheading the application of deep learning to our daily trading activity

in this role you will collaborate with other researchers developers and traders to improve existing proprietary strategies and develop new trading algorithms that analyze and optimize our performance in capital markets you will use your software development and data mining skills to build data sets data quality metrics and automation tools to enhance our research and system development

this work will be challenging fastpaced and competitive your interest and drive to apply cuttingedge machine learning techniques to large financial data sets will enable this team to expand quantitative research at sig

what were looking for
advanced degree in computer science statistics machine learning applied mathematics or related field
strong object oriented programming skills
interest in applying machine learningdeep learning theories in a professional research environment
visa sponsorship is available for this position

we don’t post salary ranges externally so any salary estimate you see listed here was not provided by sig and may not be accurate

sig is not accepting unsolicited resumes from search firms all resumes submitted by search firms to any employee at sig viaemail the internet or directly without a valid written search agreement will be deemed the sole property of sig and no fee will be paid in the event the candidate is hired by sig",,PA,False,data_engineer
Data Engineer,"120000  160000 a yearas an integral part of our technology team you will work on our data platform including cloud databases and etl pipelines you will enable our groundbreaking natural language platform helping us develop scale and deploy our applications in a variety of contexts you’ll wear many hats touch many parts of our system and have a significant impact on our products
do you love organizing data in ways that enable creative applications
the kinds of problems you’ll be working on include
leveraging existing open source technologies like kafka hadoop druid spark rdbms and other tools
indexing and summarizing large datasets enabling high performance analytics
optimizing database queries
scaling cloud databases and data processing pipelines
developing data driven apis for machine learning and application developers
when applying please tell us about your real world large scale data platform experience
qualifications
bs ms phd in computer science engineering or related discipline or 3 years equivalent technology experience
3 years of software development python java or equivalent
familiar with complex database management replication and backup
design and operation of robust distributed systems
expertise with writing efficient complex database queries
secure cloud development experience on aws gcp or equivalent
use engineering best practices – deliver high code quality automated testing and build reusable components
authorized to work in the united states
salary range 120k – 160k
company benefits
flexible leave policy
health care insurance
dental  vision insurance
life insurance
shortterm  longterm disability insurance
health care fsa
transit  parking fsa
free lunch at sf office
flexible work hours
holiday time off",140000.0,CA,False,data_engineer
Big Data Engineer,"nordstrom data and services technology is at the core of nordstrom technology and is pivotal to the nordstrom customer experience the team designs develops and maintains software applications and services that support all of data engineering and analytics business needs across multiple channels this opportunity also provides various avenues to collaborate and influence several other platforms within nordstrom technology and have a companywide impact – both business and engineering

join the nordstrom cloud data pipeline team we believe that with our talented engineers smart technology and passionate customers we can deliver the best retail experience on the web we’re looking for a cloud and data savvy engineer to help us maintain and improve our data pipelines that deliver data from source systems to a data lake in the cloud help us solve complex problems with data and automation while ruthlessly pursuing incremental wins that scale our systems to the next level of sustained performance while we don’t expect someone to know everything we expect a great candidate is someone that is willing to learn new technologies where they lack knowledge we value collaboration innovation and passion for delivery while sustaining work life balance

a day in the life
you will help us maintain and improve the data pipelines that acquire data from various data sources such as transaction customer vendor inventory and land that data in the cloud to be used by various internal customers that vary from supply chain to data scientists you will be working with various types of data sources that range from oracle to elasticsearch and using technologies such as kafka nifi spark aws and more this work enables the business to be more agile in decisions and serving the customer

you own this if you…
proficient in java and objectoriented programming
basic knowledge of relational databases
basic knowledge of aws
kafka experience a plus
spark experience a plus
nifi experience a plus
oracle goldengate experience a plus

we’ve got you covered…

our employees are our most important asset and that’s reflected in our benefits we listen to what’s most important and continue to evolve our offering to support both our employees and their families

beyond strong health retirement and time off benefits nordstrom is proud to offer
commuter benefits
100 paid parental leave
charitable giving and volunteer match
merchandise discount
nordstrom stock purchase plan

a few more important points

the job posting highlights the most critical responsibilities and requirements of the job it’s not allinclusive there may be additional duties responsibilities and qualifications for this job

nordstrom will consider qualified applicants with criminal histories in a manner consistent with all legal requirements

applicants with disabilities who require assistance or accommodation should contact the nearest nordstrom location which can be identified at wwwnordstromcom 
© 2018 nordstrom inc  nordstrom careers privacy policy

current nordstrom employees to apply log into workday click the careers button and then click find jobs",,WA,False,data_engineer
Data Engineer,"the data engineer acts as a subject matter expert of the data repositories available within the organization by obtaining an indepth understanding of each source systemthese engineers are primarily focused on the creation management and availability of structured analytics requires the ability to conduct data mining and analytics structuring

minimum qualifications
bachelor’s degree required emphasis in information science mathematics business management or related discipline preferred
5 years in healthcare analyticsinformatics and report development experience
3 years’ experience with analytics in data warehouse environment to include etl ssis ssrs api coding and programming knowledge
3 experience with visualization tools qlik tableau powerpivot",,MT,False,data_engineer
004: Data Engineer,"84000  126000 a yeardo you know etl do you know it really well are you interested in working with some of the hottest new etl tools like wherescape and alteryx are you looking for a new challenge in a very cool company

we’re helping a very forwardthinking financial institution locate the person who can make sure the right data is in the right places at the right time you’ll be the key data manipulation resource and will report directly to the manager of bi  dw your efforts will directly affect the success of the company

is this you if so please submit your resume and fill out our questionnaire asap

the work the data engineer will work on implementing complex data projects with a focus on collecting parsing managing analyzing large sets of data to turn information into insights using multiple platforms in this role you’ll identify where needed data exists whether it be inside or outside of the organization you’ll then be responsible for designing and building rock solid etl applications to access and deliver that data to key business intelligence systems and analytic users you’ll work hand in hand with business contacts and bi developers to determine what they need and then deliver on those needs to accomplish this you’ll have to harness some of today’s hottest etl technologies including wherescape and alteryx

in this role the right person will have an unusual opportunity to make a huge impact on a cool growing company

location silicon valley in the country you’ll be working in a beautiful brand new headquarters in brighton michigan brighton is a centrallylocated town that’s also only 20 minutes from ann arbor home to the university of michigan 30 minutes from lansing home to michigan state university and 50 minutes from detroit a rapidly evolving technology hub

the company recently built their new headquarters building around open workspaces and the latest technologies in terms of location this job has it all a beautiful work environment access to major metropolitan centers and the ability to easily get back to nature when you want

mode this is a permanent role

required applicants must be very strong in
etl tools and techniques
sql

desired in addition it would be great if you had some background in
sql server and tsql
data architecture
bi tools
wherescape
alteryx
cloud database architecture especially azure
big data  nosql data stores
the financial services  credit union industry

compensation this organization is not afraid to invest in technology and the skills necessary to harness that technology thus the right candidate for this role will earn a base salary of between 84000 and 126000 as well as a generous benefits package

interested if youre interested and have the skills wed love to hear from you please answer our questionnaire and submit your resume right away thanks
us citizens and all those authorized to permanently work for any employer in the us are encouraged to apply we are unable to provide visa sponsorship at this time

note dataspace performs background and drug screens on accepted candidates prior to their employment or contract start dates",105000.0,MI,False,data_engineer
012 Senior Data Engineer - Hadoop & Spark,"65  70 an hourcontractour client one of the largest health insurers in the country has asked us to provide them with a superstrong data engineer to work with their data scientists to provide critical data from hadoop and sql data sources

is this you if so please submit your resume and fill out our questionnaire asap

the work the work includes manipulating data in big data sources and then extracting it in datasciencefriendly forms the chosen consultant will be working on a highly skilled team with some of the latest nosql big data and data science technologies as a senior data engineer you’ll also be responsible for mentoring lessexperienced staff

location this client is located in the heart of detroit michigan in case you haven’t heard the detroit area is experiencing a new renaissance of technology food arts and culture building on its storied history as the “motor city” detroit is now reinventing itself as a home for a vibrant community of wellfunded startups with all the amenities demanded by a sharp urban crowd with its constant offering of music and theatre performances several of the nation’s best known museums a trio of new sports arenas and distinct neighborhoods of every flavor the detroit region truly has something for everyone

mode contract or contract to hire

duration the chosen consultant will be required for at least six months and likely longer

required applicants must be very strong in the following
hadoop and tools in the hadoop ecosystem
spark
automation scripts batch scripts apache oozie 

desired in addition it would be great if you had some background in
﻿ python and pyspark
etl processes

compensation 65  70  hr including all expenses

interested if youre interested and have the skills wed love to hear from you please answer our questionnaire and submit your resume right away thanks

note dataspace performs background and drug screens on accepted candidates prior to their employment or contract start dates

note our client requires that we work only with direct w2 employees of our contracting partners contracting firms do not submit resumes for candidates who are not your own direct employees",,MI,False,data_engineer
Data Engineer - Solutions,"dv01 is a data management reporting and analytics platform that brings transparency and insight to lending markets making them more efficient for institutional investors and safer for the world in a nutshell were doing our part to prevent a repeat of 2008

as the technological hub between lenders and capital markets dv01 provides all parties with unprecedented data transparency insight and analytics to date dv01 has offered institutional investors insight into 15 billion of securitizations and more than 64 billion of consumer small business real estate auto and student loans from the largest online lenders including lendingclub prosper and sofi

you will


be at the heart of dv01 you will operate as the bridge between the engineering and finance teams contributing to a variety of integral processes that drive dv01 on a daily basis every new dataset that gets integrated within dv01 will have your fingerprints all over it

be an owner of dv01s most valuable asset youll own the business logic in our data pipeline encapsulating all the knowledge weve accumulated across hundreds of datasets the output from the pipeline powers all of dv01s customer offerings and is critical to the success of our business

be customerfacing you will have direct exposure to highlevel contacts at hedge funds banks and asset originators providing valuable insights to help them answer complex questions

work with stateoftheart technology youll work with popular modern and exciting open source technologies like apache spark the skills you develop here will serve you well beyond dv01

qualifications


a wellrounded engineer you have 2 years of professional programming experience with apache spark scala java r or python you are able to write thoughtout code while accounting for resource and performance constraints and are also capable of performing adhoc data investigations with sql

interest and experience in both engineering and finance youre looking to grow your skills in both disciplines and are excited about the synergies between finance and technology

knowledgeable about consumer credit you understand how investors evaluate loan portfolios and the complexities of amortization prepay and default you strive to further your knowledge in the credit market

excited about big data you should have 2 years of professional engineering experience working with large datasets with exposure to large datasets related to loan products an added plus you enjoy working with data from expressing complex business logic as scalable data processing logic to configuring and debugging intricate big data pipelines you love the intricate details of a thorough investigation but also stay aware of the bigger picture while operating across multiple threads of work

undergraduate or graduate degree in finance math or engineering note that were not anti dropouts if youre a superstar

dv01 is an equal opportunity employer and all qualified applicants and employees will receive consideration for employment opportunities without regard to race color religion creed sex sexual orientation gender identity or expression age national origin or ancestry citizenship veteran status membership in the uniformed services disability genetic information or any other basis protected by applicable law",,NY,False,data_engineer
Data Engineer,"the global digital acquisition organization within mobile  web engineering is looking for talented data engineers to join our platform excellence engineering group we build the core capabilities that power the digital acquisition software platform and enable the journey of a prospective customer of american express

in this role you will use your extensive knowledge of database systems and data processing paradigms to modernize and globalize the data layer of our digital acquisition platform you will create perform and scalable data pipelines and processing software that integrate with our enterprise data warehouse and reporting and analytics systems

job locations new york sf bay area phoenix remote okay

if you were to join our team these are the kinds of things youd do

collaborate with software architects to design the next generation of the global digital acquisition platforms data layer
work in a crossfunctional team with other engineers to design build test and deploy software components enabling data layer capabilities
develop frameworks and approaches for measuring and testing performance and correctness of data layer components and systems
review colleagues code with an eye toward performance reliability and maintainability
help our production support team address issues encountered in production and fix defects when discovered
continuously learn about new technologies and help keep the entire group abreast of industry developments and evolving best practices
mentor other engineers and be mentored in turn
qualifications
requirements for this position

7 years of software development experience in multiple project environments
strong fundamentals and production experience with multiple programming languages including java and at least one scripting language such as python or ruby
deep understanding of and strong opinions on data programming concepts and architectural patterns
handson experience building data pipelines and etl systems using tools such as hadoop spark and nifi
handson experience with software engineering practices like source code control code review and continuous integration and delivery
working knowledge of unix system and shell programming
also critical to your success

familiarity with and desire to work using agile methodologies and practices such as scrumkanban iterations user stories and development flows using continuous delivery and automated testing
a drive to stay uptodate with the latest web architecture technology including language innovations containerization storage technology and runtime problem solving
the ability to see and to understand the larger context in which your team works and to craft solutions within that context
adaptability to changes in product requirements organizational structures and business conditions
a strong belief in your personal responsibility for ensuring quality craftsmanship
an open collaborative spirit
bonus points

strong computer science fundamentals
experience with domaindriven design ddd
experience in a fastpaced startup environment
why american express
talk to our people and you’ll find out what we’re really all about open creative risktaking collaborative and innovative are just some of the expressions you’ll hear it’s our culture that makes american express an outstanding place to work and a big part of why we regularly win best workplace awards all over the world if you’re ready to take on a challenge and make an impact you owe it to yourself to launch or grow your career here
employment eligibility to work with american express in the us is required as the company will not pursue visa sponsorship for these positions
reqid 18008463
schedule fulltimeparttime fulltime
date posted sep 27 2018 34027 pm",,NY,False,data_engineer
Data Engineer,"peerstreet is an awardwinning andreessenhorowitz backed platform focused on democratizing access to real estate debt what were working on at peerstreet will ultimately change mortgage finance peerstreet is a leading online platform for investing in real estate backed loans wwwpeerstreetcom

peerstreet is strongly datadriven data is the foundation of our operational processes ranging from loan underwriting lender acquisition loan servicing to product decision making having access to highquality data internal and external allows us to continuously optimize our operations and maintain great insights into how we can continue to improve product on both sides of the marketplace

we are looking for a highly talented data engineer with a strong technical background and one who is passionate about engineering elegant solutions to data problems and creating an environment that allows users to dive deep into financial and user data with cuttingedge analytics and data insights you will have a huge impact on defining and implementing peerstreet data strategy your daytoday will involve close collaboration with engineering product and business organizations

responsibilities

work closely with product managers engineers and business stakeholders to become a source data expert
develop and optimize etl processes to meet the growing business needs
define technical requirements and data architecture for the underlying data warehouse
collaborate with subject matter experts across different business units to design implement and deliver insightful analytic solutions
improve and maintain data access for our bi tools periscope tableau
automate data quality monitoring and improve auditing capabilities
analyze trends and work with development teams to develop a longrange plan designed to resolve problems and prevent them from recurrence

basic qualifications

bachelors degree or greater technical or science degree preferred
3 years of backend or data engineering experience
knowledge of data warehousing concepts
experience with scalable architectures and large data processing
expert understanding of sql rdbms and data modeling for scalability and performance
experience in etl data mining and using databases in a business environment with largescale and complex datasets
experience with aws services eg ec2 rds dms redshift etc
experience with linux and shell scripting
experience with etl orchestration tools such as airflow pentaho etc
proficiency in a leading programming language ruby python java etc
systemlevel dba functions including configuring replication automating backups performance tuning etc
excellent communication ability

bonus points

experience with bi systems periscope tableau etc
experience with dimensional data modeling
experience with terraform
experience with ror or salesforce
experience or deep knowledge in finance

we offer a competitive salary  equity medical flexible vacation and an awesome team",,CA,False,data_engineer
Data Engineer,"who we are
our data management team at gradient ai is building an industry leading data pipeline and infrastructure for data science from modeling and transforming distributed client data stores to providing highperformance cloud infrastructure to building client facing business insights and analytics our data management team is at the core of the data at gradient ai
what you’ll do
you will shape and realize the vision of our data insights you will learn new technologies and tools and expand your competence in multiple engineering areas examples of the kind of work you might do include developing tools to extract and process client data from distributed sources transform large amounts of data to provide the building blocks for our data science or scale our data pipelines to do all this work you will collaborate with machine learning researchers software engineers and project managers on the team
who you are
you are a multitalented engineer excited about taking a highlevel problem and designing and owning the details of implementing the solution you are independent and creative with tools such as python sql or aws if you are an engineer excited about data systems engineering or the power of cloud computing this could be the job for you you probably have
working knowledge of sql or experience with nonrelational databases
experience with highlevel programming languages ideally python
experience with predictive analytics algorithms or machine learning
desire to learn new skills and tools eg redshift spark tableau etc
requirements
experience with software engineering best practices
bachelor’s degree or higher in computer science or related field
an aptitude for systems software design",,MA,False,data_engineer
ML / NLP / Large Data Engineer,"as a mlnlplarge data engineer you will be responsible for building and improving ml models modeling  experimentation frameworks and building out technical core of agentiq you will be given opportunity to drive positive technology improvements and develop state of the art nlpml applications
responsibilities
build and improve nlpml models at hearth of agentiq product
build and improve infrastructure to support nlpml modeling experimentation and deployment
take ownership of nlpml trainer tools and data processing pipelines
brainstorm and prototype algorithmic improvements
develop customer specific and general machine intelligence
contribute to deployingmonitoringdebugging models in production
take ownership of nlpml trainer tools and data processing pipelines
collaborate with platform teams on developing new tools and features needed for nlpml development and deployment
create and maintain documentation
provide internal training on applicable topics

requirements
passion for improving mlnlp models and making them more robust and scalable
thrive in a diverse dynamic environment that leverages multiple tools and languages
the ability to communicate effectively with thoughtfulness and maturity
make technology decisions that are best for the business of agent iq
experience building large productionquality nlp speech or deep learning systems
strong software engineering and interpersonal skills
ability and desire to quickly pick up on new topics and techniques
ability to take an idea from conception and prototyping to deployment in production
masters degree or equivalent in mlnlp or related field

our environment
awsgcp hosted infrastructure
linux
python
tensorflow
nodejs
docker
perks
competitive salary  equity
full medicaldentalvision benefits
unlimited pto policy
tons of snacks in the office and allyoucandrink coffee
convenient office within a 3 minute walk from bartmuni underground
google apps dropbox drive slack mac or pc everything
agent iq swag
commuter benefits
great teammates
perks
full medicaldentalvision benefits for 3 monthstons of snacks in the office
weekly team lunches happy hours tons of snacks in the office and allyoucandrink caffeinated drinksconvenient office within a 3 minute walk from bartmuni underground
powerful apple productsagent iq swag",,CA,False,data_engineer
Sr. Data Engineer,"title senior data engineer
reports to vp – analytics and data science
location ny office

overview we are looking for a savvy data engineer to join our growing team of analytics and data science experts they will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for the analytics and data science teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up the data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our company’s data architecture to support our next generation of products and data initiatives

primary responsibilities include but are not limited to
create and maintain optimal data pipeline and predictive modelling architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and aws ‘big data’ technologies
build analytics tools and processes that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics
work with stakeholders including the it product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
create data tools for analytics and data scientist team members that assist them in building and optimizing models
work with data and analytics experts to strive for greater functionality in our data systems
qualifications for senior data engineer
advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
experience building and optimizing ‘big data’ data pipelines architectures and data sets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
strong analytic skills related to working with unstructured datasets
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores
experience building and support data modelling infrastructure and processes
strong project management and organizational skills
experience supporting and working with crossfunctional teams in a dynamic environment

education  experience requirements
we are looking for a candidate with 4 to 6 years of experience in a data engineer role who has attained a graduate degree in computer science statistics informatics information systems or another quantitative field they should also have experience using the following softwaretools
experience with objectorientedobject function scripting languages python java c scala etc
experienced on aws tools redshift hive glue and rds
experience building data pipelines etl elt type applications on aws
experience with big data tools hadoop spark kafka etc
experience with relational sql and nosql databases including postgres and cassandra
experience with machine learning data pipeline and workflow management tools azkaban luigi airflow etc
experience with streamprocessing systems storm sparkstreaming etc
familiarity with r modeling language and predictive modeling concepts
strongly motivated to be a player in a team which is constantly working to improve themselves through discovering new analytics techniques and software tools to improve the quality of our work
strong verbal and written communication skills
adaptability and the capability of multitasking and strong time management
thrive in a fast‐paced entrepreneurial environment comprised of high achievers and high stakeholder expectations
ability to work in a team environment and dynamically align to changing business conditions
ability and willingness to travel and work long hours and weekends if necessary to meet stakeholder demands

jcrew group inc is an equal employment opportunity eeo employer
we are committed to affirmatively providing equal opportunity to all associates and qualified applicants without regard to race color ancestry national origin religion sex marital status age sexual orientation gender identity or expression legally protected physical or mental disability or any other basis protected under applicable law",,NY,False,data_engineer
"Data Engineer, Business Intelligence","as a data engineer for business intelligence at compass you will be responsible for helping to build the datadriven decisionmaking culture throughout the organization youll work as part of a rapidly growing team in a fastpaced environment you will be responsible for managing largescale business systems initiatives that impact multiple functions and teams across the organization in this high impact role you will have an opportunity to work with emerging technologies while driving business intelligence solutions endtoend business requirements workflow instrumentation data modeling etl metadata reporting and dashboarding you are someone who loves data understands enterprise information systems and has a strong business sense
at compass you will
design develop and implement the infrastructure that elevates datadriven decisionmaking for our proprietary real estate technology
work with the enterprise business systems that facilitate the end to end experience of real estate transactions
work with company stakeholders and product and engineering teams to define analytics requirements
deliver flexible and scalable solutions from endtoend harvesting processlevel data and transforming it into normalized data marts from which operational and process metrics and analysis can be reliably generated
what were looking for
bachelors degree in computer science information systems or related field
3 years of sql development experience
3 years of data modeling etl and data warehousing experience
familiarity with etl tools such as informatica pentaho talend etc
expertise in modern oo language eg java c c objective c
3 years or python scripting experience
familiar with aws as a platform
strong business communication skills
experience with aws technologies such as redshift rds emr etc
comfortable in a linux environment
capable of data processing and transference outside of etl tools or databases custom scripts to pull and load from apis or files
experience writing software requirements
familiar with enterprise networking
at compass our mission is to help everyone find their place in the world this means we continually celebrate the diverse community different individuals cultivate as an equal opportunity employer we stay true to our mission by ensuring that our place can be anyones place",,NY,False,data_engineer
Senior Data Engineer,"senior data engineer kyc entity exchange

new york ny  usa

posted 20181005  requisition no 71150

as the know your customer kyc industry evolves at a rapid pace we are responding by building innovative and bestinclass enterprise software solutions that enable our clients to gain a competitive edge in their industry our products entity exchange and entity intelligence provide our clients’ ways to optimize workflows satisfy kyc regulatory laws receive proactive notifications and ultimately reduce the friction of doing business

as an engineer on the team you will be contributing to our client’s entity exchange a centralized secure platform to enable trading counterparties to manage and share client data and documents the product accelerates the onboarding process between brokers hedge funds and corporations while letting each party maintain control of their information

in our dynamic and collaborative environment you will design and build application services that are flexible scalable and easy to maintain you will also help figure out the right solutions for our clients’ needs if you are passionate about helping us build these solutions we want to hear from you

we’ll trust you to

design architect and develop application data solutions that solve business problems in innovate ways
design and develop robust fault tolerant ways to store and access data
collaborate within an agile multidisciplinary fastmoving team
advocate for high quality welltested solutions
take ownership and drive technical solutions from inception to production release

need to have

35 years proven experience with technical architecturedesign and implementation of enterprise scale software projects
experience in writing software in 1 or more languages ideally python
strong technical problem solving skills good ability to troubleshoot and debug
experience in data modelling data engineering software design etl
experience with relational and nosql databases including schema design transactions and performance tuning
experience using orms for applicationdatabase integration sql alchemy django hibernate or other
experience designing applications that employ encryption when data is stored
experience with software best practices including automated testing continuous integration and documentation
ba bs ms phd in computer science engineering or related technology field

we’d love to see

experience building asynchronous services and message queues rabbit mq celery
experience building and defining api interfaces and building restful services using oas 30
experience with designing software for and deploying to private clouds

",,NY,False,data_engineer
Data Engineer,"if you are an active vivint employee please apply through workday by searching find jobs
job description
job summary
as a data engineer on our data engineering team you will be responsible for developing the core service that provides data to the entire enterprise you will be responsible for building the processes that support the ingestion and consumption of data at vivint working closely with our data ops and business analytics teams you will design build and maintain a data warehouse platform that provides timely accurate and reliable data to thousands of users your role will be critical in defining the appropriate architecture and processes needed to build a data warehouse that is flexible agile reliable responsive and scalable
job responsibilities
help build and maintain an enterprise data warehouse platform with its associated data pipelines and data architecture requirements
responsible for designing building and maintaining robust highperforming etl processes
implement best practices and innovative etl solutions to provide timely accurate  reliable data
evaluate recommend and implement proper tools  technology to achieve a high performing data warehouse platform servicing thousands of users and a broad set of use cases
build cross functional relationships with data analytic teams and business leaders to understand their requirements and data needs
develop data products for delivery via web and mobile technologies
required skills
must have a passion for data and helping the business turn data into information and action
3 years of data warehousing architecture  design experience
3 years of etl  data pipeline development experience
ability to initiate drive and manage projects with competing priorities
ability to communicate effectively with business leaders it leadership and engineers
expert in sql databases and etl development processes  tools cloud mpp like snowflake or redshift
proficiency in one or more scripting languages python php perl net etc
familiarity with one or more web technologies javascript nodejs angular etc
bonus skills
experience with big data technologies hdfs hadoop spark elastic search etc
experience with tableau or similar data visualization tool
experience with aws or azure data product offerings and platform
experience with machine learning technologies r sparkml azureml etc
minimum qualifications
babs or higher in computer science information systems math or other technical field
master’s degree preferred",,UT,False,data_engineer
Data Engineer,"about us
lark is the worlds largest ai healthcare provider servicing more than a million patients suffering from or at risk of chronic disease with ai nurses we’re on a mission to improve people’s health and happiness through our digital health coach we are the only ai nurse ever to become fully medically reimbursed to 100 replace a live nurse because we achieved equivalent health outcomes to live healthcare professionals  which allows for infinitely scalable healthcare since launch lark has continued to receive awards and accolades for both our product and our leadership

✦apples top 10 apps in the world
✧ business insider s most innovative companies in the world along with uber and snapchat
✦ biz journal ’s 100 women of influence

we are looking for a talented data engineer to join our growing team in mountain view ca where youll be building our next generation data pipelines

 open to temp contractors for immediate fill 

about the role

what youll do

build our next generation data pipelines into a fast and efficient bigdata system
youll be the first fully dedicated data engineer on the team and will be able to call the shots on strategy

what youll need

a love of data and the makeorbreak effect it has on startups
default to coding efficient systems from large databases both rdbms and nosql
familiarity with the following key technologies or similar  spark
yarn
kafka
python
aws

join us
our team works with cutting edge tools and technology related to artificial intelligence and machine learning we are using nlp to process millions of meals and accelerometer data to compute activity and sleep amounts from users phones our chat ai is the most sophisticated digital health engagement tool in the world join us and make it even better

lark is an equal opportunity employer lark does not discriminate on the basis of race religion color sex gender identity sexual orientation age nondisqualifying physical or mental disability national origin veteran status or any other basis covered by appropriate law all employment is decided on the basis of qualifications merit and business need",,CA,False,data_engineer
Data Engineer,"who you are
getty images is looking for a data engineer who enjoys working across the entire lifecycle of machine learning projects and takes pride in deploying highquality ml and data workflows
the mission of the data science team at getty images inc is to leverage internal and thirdparty data to inform other groups on how to interact with its customer base we achieve this goal by 1 building automated solutions that apply bestinclass machine learning and engineering practices and 2 continuous interactions with stakeholders to identify critical needs that deliver results relevant to the business
as a data engineer on the data science team you will have endtoend autonomy and ownership of your projects and will work closely with other business units to develop creative solutions to a variety of problems

your next challenge
you will join a team of highlycollaborative and curious data scientists and data analysts that are comfortable working with a diverse set of tools and willing to take initiative on their ideas as a member of the team you will have the chance to define the technical architecture that serves as the foundation for upstream analytical projects and accelerate the delivery of a robust portfolio of data science models
your primary goal will be to catalyze the development and deployment of fullstack machine learning pipelines you will have the opportunity to continuously develop and ship code in our production environment and will be empowered to implement a variety of datacentric architectures that support critical operational initiatives
you will also interact with the entirety of getty images inc technology stack and collaborate with data infrastructure platform and cloud engineers to design and build a productionlevel data ecosystem that aligns with business function requirements and capable of handling largescale structured and unstructured data you will also have the opportunity to continuously evaluate and provide guidance on the use of new technologies
we value learning and development and you will be given every opportunity to work on projects that excite you you will get to lead and innovate as a thoughtleader within getty images and will sit at the intersection of engineering marketing and leadership to inform influence support and execute on our decisions

what youll need
you have prior experience working as a data engineer preferably in a product or customerfocused organization
you are extremely comfortable working with python and have a working knowledge of cloud services and tools as well as standard engineering tools such as git linux and sql
you have experience building streaming and batch data pipelines and are comfortable working within a largescale distributed environment with open source tools such as hadoop hive airflow and spark
you can independently execute on a project from ideation to delivery to stakeholders and can proactively interact with other engineers at getty images to access necessary resources or data
you understand or have interest learning about the realworld advantages and drawbacks of various machine learning techniques and have applied those to a variety of datasets
nice to have
a ms or phd in computer science statistics economicseconometrics natural science or any other equivalent quantitative project is preferred if you are selftaught and believe you are a good fit for this role or have significant work experience we would love to hear from you as well
previous experience in an analytical role or experience working with teams of data scientists and data analysts
experience having managed or contributed to the use of business intelligence platforms

limm1

who we are

getty images is the most trusted and esteemed source of visual content with over 200 million assets available through its industryleading sites wwwgettyimagescom and wwwistockphotocom the getty images website serves creative business and media customers in almost every country in the world and is the first place people turn to discover purchase and share powerful content from the worlds best photographers and videographers getty images works with over 200000 contributors and hundreds of image partners to provide comprehensive coverage of more than 160000 news sport and entertainment events impactful creative imagery to communicate any commercial concept and the worlds deepest digital archive of historic photography
for company news and announcements visit our press room find istock on facebook twitter instagram and linkedin or download the istock app where you can easily search save and share superior images to create standout visual communications

getty images is an equal opportunity employer and strongly supports diversity in the workplace",,NY,False,data_engineer
Data Engineer,100000  130000 a yearmusthavesat least 5 years of data engineering or related experiencesql  relational databaseexperience with data warehousesour client is looking to add an experienced data engineer to their technology team in philadelphia the ideal candidate will be adept at problem solving interested in pursuing new ideas and will play a key role in the strategic initiatives of an innovative global investor responsibilities include gathering requirements building out a data warehouse establishing and maintaining data integrations developing data governance best practices and optimizing data flowthey are looking for candidates that are passionate about building and optimizing data systems the data engineer will collaborate with developers data scientists and technology products they will also support nontechnical colleagues in the collection and use of structured and unstructured data they must be selfdirected and comfortable supporting multiple projects and teams this hire will contribute to data transparency across the organization driving operational efficiency and providing decision makers with actionable insightsjob description project management – gather project requirements establish timelines track progress and manage to milestone achievementsmodeling – determine the most appropriate schema for storing structured and unstructured data extract transform load – apply business logic to move data from one system to another and validate data qualityintegration – determine the optimal methods for collecting and incorporating new data into data warehousesgovernance – establish and educate the organization on data governance standardsstrategic reporting – collaborate with colleagues to scope out new data requests and methods to extract and present data from various data sourcesautomation  implement internal process improvements with an aim to automate manual processes and optimize data deliverynecessary qualifications 5 years experience in data engineering preferably in financial servicesbabs in a related field eg computer science mathematics engineeringmust have experience with objectoriented programming languages and agile software developmentmust have proficient technical skills in sql and relational databases exposure to data integration tools and experience building and consuming apismust have experience building a data warehouse in a professional environmentexposure to statistical data analysis tools eg r and data visualization tools eg tableau is a plusmust have proficient communication skills be proactive and be able to comfortably lead projects independently that include crossfunctional collaborationnicetohavesagile software developmentsalary range100000 – 130000performance bonus1015signing bonusnonebenefitsmedical insdental insvision inslife insretirementequitymore informationrelocationnonereports tostrategic technology teamremote workup to 20 of the timetraveltravel not requiredvisavisa sponsorship not supportedjob type fulltimesalary 10000000 to 13000000 yearexperiencetableau and r 1 year preferreddata engineering 5 years requiredsql 1 year preferredsoftware development 3 years preferrededucationbachelors requiredwork authorizationunited states required,115000.0,PA,False,data_engineer
Big Data Engineer,95000 a yeartitle big data engineerlocation dearborn mitype full timesalary 95000benefits5 years of experience in a data engineer roleadvanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databasesproficiency building and optimizing ‘big data’ data pipelines architectures and data setsbackground performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementbuild processes supporting data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsworking knowledge of message queuing stream processing and highly scalable ‘big data’ data storesexperience supporting and working with crossfunctional teams in a dynamic environmentknowledge and skillsstrong analytic skills related to working with structured and unstructured datasetsproject management and organizational skillsexperience with relational sql and nosql databasesknowledge of data pipeline and workflow management tools ie knime dataflow dataprep airflow etcfamiliar with objectorientedobject function scripting languages ie python java c scala etcfamiliar with big data tools examples include hadoop bigquery kafka etcjob type fulltimesalary 9500000 yearexperiencedataflow 3 years preferrednosql database 2 years preferredquery authoring sql 3 years preferreddata engineer 5 years preferredbigdata 4 years preferredmetadata 2 years preferrededucationhigh school preferred,95000.0,MI,False,data_engineer
Data Engineer,"animoto is looking for a datadriven software engineer with a focus on analytics and data warehousing you are highly analytical ask the right questions and are a true selfstarter you will be the “reality expert” for animoto helping leadership across functions translate their products and questions into actionable metrics analysis reports and recommendations

in the role of data engineer you will be responsible for architecting designing and developing animotocom’s data infrastructure to support the wide variety of application and analytical needs we want someone smart quick and creative an engineer who will dig deep into the system and find various ways to improve it who has not only an understanding of how web technologies work today but where they are going in the future
why animoto wants you
you love having a big impact and high visibility
you are exceptionally detailoriented
you’re a great debugger and like finding and solving mysteries
you are customer focused and eager to work with stakeholders to deliver value
excellent analytical skills to deliver meaningful and impactdriven insights using big data
the day to day
design and implement data systems
design and implement dimensional data models and systems that scale
partner with product engineering and analysts to explore structured and unstructured data to leverage business insights
what we’re looking for
bachelors degree in cs or equivalent work experience
solid experience in languages like ruby or python
strong experience with sql
experience with splunk or other elasticsearch tools
familiarity with etl and bi concepts
bonus points
comfortable with aws redshift athena etc
comfortable working in application code when needed
familiarity with looker
why youll want to work at animoto
be a part of a thriving engineering team that includes opportunities to collaborate with teams across the organization including product and design
learn and grow within a role that is important to you we encourage exploration and the chance to work on interesting projects that challenge you professionally
you resonate with our company’s mission and value teamwork
we have an inclusive and quirky culture here ask us about our values humbletude betterfication and oomphosity
great benefits we offer competitive salary bonus equity 100 paid medical dental and vision for you and your dependents and paid time off to name a few
at animoto we help our customers communicate who they are what they do and what they love through video our users are connected by the desire to use video to share what matters most to them but come from all walks of life and are passionate about all sorts of different things we’re proud to help them share these passions
similarly we embrace the differences of our team members and actively seek diversity of beliefs backgrounds education and all the other things that make us unique we strive to create a space where employees can bring their true selves to work every day by doing so we’re building an inclusive culture where we can continue innovating for our customers we too are united in the belief that our voices are even more powerful when using video to communicate and we aim to have a workplace that reflects the variety of our users animoto is proud to be an equal opportunity workplace and affirmative action employer",,NY,False,data_engineer
Data Engineer,"summary
the data engineer is responsible for developing systems to acquire analyze and gain actionable insight from data that promotes the splcs mission preparing and implementing quantitative and qualitative models for analysis collaborating with attorney and policy subject matter experts through the process of developing and using these systems and models using data to lift up and tell stories to support litigation and policy transformation and working closely with a variety of internal and external partners and stakeholders to these ends

strong analytical and reasoning skills that result in clear robust flexible architectures proven ability to drive complex design and development efforts in an agile environment

primary job functions
under the supervision of the big data manager the data engineer will


implement their knowledge of cloud serverless and hybridcloud technologies
provide oversight of data collection and analysis synthesis of data and study outcome reports and quality assurance and auditing of data in an azure environment
find import transform validate andor model data with the purpose of understanding or drawing conclusions from the data
in collaboration with key splc staff develop the necessary data and analysis to assist in the dissemination of information on successful and promising approaches lessons learned and other policy priorities to local and regional government bodies partners and other stakeholders
participate with the splc data team in the process of data governance quality and integrity and manage the implementation of related policies
create and maintain detailed uptodate system documentation
comply with all federal and state lobbying and ethical rules and requirements

qualifications –

education and related work experience

a bachelors degree and at least four 4 years of relevant experience are required advanced degree in statistics data science public policy andor other relevant field is required except in unusual circumstances to be evaluated on a casebycase basis
strong research and analytical skills applied to public policy issues including an ability to synthesize and summarize large amounts of information and to focus quickly on the essence of an issue
strong knowledge of microsoft azure sql server azure sql database cosmosdb services logic flow
demonstrated experience in indicator selection quantitative and qualitative data collection and analysis and multiple data stores g sql  nosql on premise hybrid and cloud
strong knowledge of data analysis languages eg python r etc
demonstrated experience in data collection tools and mitigation for measurement errors as to ensure data reliability
demonstrated experience in solo and collaborative development of data triangulation presentations and reportwriting
demonstrated experience with capturing analyzing and visualizing data from research studies assessments and evaluations
demonstrated experience communicating clearly and concisely orally visually and in writing
demonstrated experience assisting with or conducting briefings with internal and external partners and other stakeholders when necessary

knowledge skills and abilities

ability to be an sme in multiple projects all of which have competing deadlines and require cooperation of various people inside and outside the organization
ability to organize data and communicate to all levels of the organization and external partners and stakeholders at all levels of expertise
initiative vision and a commitment to social justice
excellent and consistent attention to detail and the ability to prioritize and meet deadlines
willingness to travel amount of required travel varies depending on splc needs
willingness to work variedflexible hours depending on splc needs and

other special considerations
this job is performed under general office conditions and is not subject to any strenuous physical demands or dangerous conditions

disclaimer
the statements herein are intended to describe the general nature and level of work being performed by the employee in this position these statements are not intended to be construed as an exhaustive list of all responsibilities duties and skills required of a person in this position

an equalopportunity employer with a commitment to diversity

southern poverty law center splc is proud to be an equal opportunity employer and as an organization committed to diversity and the perspective of all voices we consider applicants equally of race gender gender identity color sexual orientation religion marital status disability political affiliation national origin or prior record of arrest or conviction",,,False,data_engineer
Data Engineer,"the mis data engineering team is responsible for designing and developing the enterprise database architecture data warehouse and reports on the wmis space in am our primary focus includes data lakes automated data analysis devops and continuous integration of data visualization as well as reporting software individuals on this team are selfdriven excited to learn new technologies and interested in solving challenging problems

the main role will be to use different types of data gathered from our existing financial technologies to generate reports and test existingpoc software to diagnose different failures in addition to measuring success we work with crossfunctional teams of software engineers qavalidation designers and infrastructure technicians with the recent adoption of a data lake this composition may change to be dominated by hive sql on hadoop shell python scripts and a scala programs on this team we act as responsible engineers for assigned products maintain highest standards of excellence never settling for the status quo and dive deep into clients issues and find efficient solutions

skills
high degree of accuracy along with attention to detail excellent oral and written communication skills strong interpersonal skills
partner with nontechnical stakeholders to understand their analytical needs help frame the problem by asking the right questions document and prioritize requirements clearly communicate results of complex technical work high standards for code quality maintainability testing and performance
knowledge of sql nosql hive
experience with unix shell scripting
experience with git version control
proficiency in one or more of the following cc java scala python
experience with all aspects of the software development life cycle sdlc in a professional team environment including requirements collection solution design implementation code reviews testing and operational support
large data analysis and visualization experience


preferred background
strong understanding of experience with distributed horizontally scalable systems such as hadoop or spark
message queues such as kafka
experience with qlik",,NJ,False,data_engineer
"Engineer, Data Engineering & Apps","comcast brings together the best in media and technology we drive innovation to create the worlds best entertainment and online experiences as a fortune 50 leader we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines we are at the forefront of change and move at an amazing pace thanks to our remarkable people who bring cuttingedge products and services to life for millions of customers every day if you share in our passion for teamwork our vision to revolutionize industries and our goal to lead the future in media and technology we want you to fastforward your career at comcast
comcast shapes the future at the intersection of media and technology we create worldclass experiences that people love and trust and drive innovation that builds value we bring millions tv internet entertainment sports and news communications and home management theme parks television and movies comcast brings to life the best of whats to comesummary are you a data engineer that loves working with very large data sets are you skilled in using sql hive or python to integrate large data sets into meaningful assets that can be used by the business for analytics if you answered yes to any of the questions above please read onthe comcast enterprise business intelligence team needs data engineers to help us architect and build robust data solutions that can be used by the data science  analytics teams as well as analysts throughout the business the role requires you to collaborate with both technical and nontechnical folks so unfortunately you wont be able to speak techie all the time however you will be involved in a variety of projects allowing you to grow your knowledge and skills beyond what you thought was possiblewe spend a lot of time and effort architecting building and automating our solutions so hopefully its no surprise that we take data quality very seriously well ask you to use your jedi engineering skills on data quality efforts from time to time its fun and a great way to learn our datawhat you will be doing  transforming large complex data into business assets that serve both the enterprise business intelligence team and analysts throughout the organization providing appropriate data for a given analysis this would require you to work with data modelersanalysts to understand the business problems they are trying to solve and create or augment data assets to feed their analysis explore and recommend innovative solutions to complex problems how cool is that ensure our data assets meet our data quality standards its important have fun in a fast paced energetic environmentwhat you need  2 years of relevant employment experience teradata experience preferred were looking for power users not administrators strong sql we mean really strong we want you to be excited about sql scripts that are hundreds of lines experience transforming large datasets into consumable assets for selfservice analytics and reporting experience designing implementing and supporting data marts must be familiar with linux systems including basic shell scripting design develop and maintain data aggregation summarization jobs ie automation experience with devops processes and principles you need to be flexible to changing priorities and comfortable in a fast paced dynamic environment knowledge of amdocs andor csg billing systems a plus good generalist experience is a plus ideally working with all layers in the technology stack if youre good in various technologies we should talkwhat you get  an opportunity to work with an excellent and exciting engineering team a fantastic work environment an awesome boss and mentor work on challenging projects learn new stuff competitive salary comprehensive benefits package early exposure to new comcast products and serviceswhat are you waiting for interviews are occurring immediately dont miss out on this incredible opportunity
comcast is an eoeveteransdisabledlgbt employer",,PA,False,data_engineer
Senior Data Engineer,60  80 an hourcontractjob title sr data engineerlocation atlanta gaduration 12 monthsi94 required for h1bsskill sets required sparkawspythongood sqlsnowflake schema preferredgood database backgroundenglish proficiency spokenwrittenjob type contractsalary 6000 to 8000 hourexperiencespark 4 years preferredaws 5 years preferredpython 4 years preferredsql 4 years preferredwork authorizationunited states required,,GA,False,data_engineer
Big Data Engineer,"contractoverview
c009 big data engineer
location harrisburg pa
position type contract
length of project 8 weeks

description
this position will be working with data scientists helping with migrating structured and unstructured data sets into hadoop using sqoop hive and other etl technologies will work with the hadoop development team on data design and data acquisition process
will be reporting to project engagement manager and will be responsible for data design data wrangling and data security on hadoop and s3aws cloud the project is related to risk prediction across various government entities based on both structured and unstructured data with emphasis on text analytics nlp natural language processing

experience with the following is required
working with big data including the following
data design
data acquisition process
data wrangling
data security
hadoop
sqoop
hive
hortonworks
etl technologies
awsazure cloud
text analytics and nlp natural language processing",,PA,False,data_engineer
Data Engineer 2/BI Engineer 2,contractwe are looking for a data engineerpowerbi sql for our client in redmond prefer local candidates its a 18 months contract role or long term contractresponsibilitiesanalyze data and help prepare dashboards that provide better insights of service usagework on and execute existing infrastructuredo reverse engineering to understand existing power bi charts and help prepare new reports by computing data through sql queriesqualificationsbachelors degree in computer science or related field or equivalent level of practical experience3 years of big datarelated software engineering experiencehigh usage of kusto queriesstrong sql querying knowledge with power bi experience is a mustmust be able to ramp up quicklycompany benefits visagreen card sponsorsick leaveptoholiday401kabout csi interfusionchinasoft international limited csi hkse 00354 founded in 2000 is an industry leader in globalized software and information technology services with branches in 28 cities across china and 18 cities around the world csi draws upon its complete ecology of industrial resources and provides multifield technological services such as cloud computing big data and etc to help clients tackle challenges and accomplish digital transformation the main business of csi includes consulting solutions and technological services targeting major clients and industries online and offline operation of internet software crowdsourcing services centered on the selfowned its cloud platform “joint force” it education and training system composed of etc the offline training center eec the experience center and zker the online study communityjob type contractexperiencepower bi 3 years requiredsql 3 years requirededucationbachelors required,,WA,False,data_engineer
Data Engineer,"data engineer permanent job in new york city big data background with experience in relational databases sql nosql hadoop preferably someone with an analytics or digital advertising background and some project management or leadership

duties

create technical product roadmap with input from the delivery team stakeholders and leadership
develop and code the data management services
analyze and report results and adjust the overall engineering strategy accordingly with engineering leadership

required

java
scala and spark
docker and images running on dcms
apache spark for data ingestion
kafka for streaming apps or nosql dbs like casandra or postgress
510 years of software development experience as a developer or manager
12 years of experience as a development manager including direct reports
25 years of experience with digital advertising technologies
oo design data structure and algorithm design skills
fluency in at least 1 of the following programming languages c c ruby r sas mapr python
25 years of experience with both relational database design sql nonrelational nosql big data realtime technologies
scalable computing mechanisms such as hadoop and amazon elastic mapreduce
web application development and associated skills rest http web services
bachelor¹s degree in computer science or related field

",,NY,False,data_engineer
Data Engineer,"about inmarket


the most sophisticated companies in the world such as procter and gamble and walmart rely on inmarket to engage with consumers and create proven roi the most trusted news publications such as wall street journal forbes and business insider utilize inmarkets first party data to understand how consumer behavior is evolving and what it means for global brands these brands rely on inmarkets third party verified data which is both iab certified and nai compliant

our competition has raised over 400 million dollars from vcs weve raised 2mm and are thriving after 8 years of growth how did inmarket become the leader in digital advertising and consumer insights by finding the best people in the world

founded in 2010 in venice ca by awardwinning tech entrepreneurs inmarket strives to embody the team mindset needed to thrive in the modern digital workplace  including all the quirks and creativity of our venice roots we are a high energy fast paced company and a place where entrepreneurial selfstarters thrive knowing teammates have all the bases wellcovered with offices in venice chicago new york city and bentonville inmarket is a growing company who has kept the spirit culture and focus of an explosive tech startup we are always in search of top talent like yours to join our family

about you


you are a good peep who has a blast going above and beyond to tackle daring challenges despite adversity you somehow find a way to make stuff happen and are agile in a world of accelerating changes you creatively brainstorm yet are datadriven in your decision making

job description

at inmarket our number one priority is our customers and reaching them at the precise moment the data scientist at inmarket combines deep data analysis and research of our rich user data to present a compelling vision around user retention user behavior and preferences across the vast ecosystem of product offerings and content

we are looking for data scientists who are passionate about using data to drive strategy and product recommendations and is able to develop successful algorithms to help understand the customer you will be engaged with senior leaders to design wellconstructed analyses and work crossfunctionally with analysts product managers and engineers to effectively deliver actionable results you will work on a variety of domains such as data science lead cuttingedge analytical solution development pipeline and contribute to external research via attending conferences and collaborations you will support data and insight needs across a wide range of functions and activities to help us better understand our data with cuttingedge analyses and interactive visualizations the ideal candidate has a proven track record of analyzing large datasets to identify meaningful information and insights and creating valuable products out of data

your day to day


create statistics via data mining in a variety of areas including customer analysis and user behavior
invent and fast iterate on novel solutions to challenging data related problems
develop scalable and efficient methods for largescale data analyses and model development
collaborate with developers program managers and product managers in an open creative environment
coaching and providing research and system guidance to a team of other researchers on a variety of areas including data analysis

required qualifications


bachelors degree preferably in statistics or related quantitative field eg computer science econometrics mathematics physics operations
masters degree technicalscientificanalytical field preferred but not required
3 years related experience such as analyzing data andor building analytical models in a professional setting
ability to draw conclusions from data and recommend actions
demonstrated selfdirection
hunger to continue learning and developing as a data scientist willingness to help further build the team including contributing ideas establishing best practices following trends and attending conferences
perform statistical and other data analysis to inform decision making and drive content creation
the ability to present results in a clear and concise manner to nontechnical teams
an appreciation and understanding of good design in both software ui and slideshow presentations

perks


competitive salary depending on experience
opportunity to work for one of leading mobile startups in the us
equity appreciation grants
comprehensive benefits to include medical dental vision supplemental benefits and a flexible spending account fsa which includes transit  medical coverage
paid maternity and paternity leave
company matched 401k plan
unlimited pto
continuing education and learning program
matching charitable contributions program
weekly catered lunches
fully stocked kitchen
free shared bike membership breeze citi divvy and hudson
dog friendly offices with zerogravity massage chairs
and more

",,CA,False,data_engineer
Data Engineer,"vividcortex is a groundbreaking database monitoring platform that gives developers and dbas deep visibility into the database our solution is delivered as softwareasaservice and helps our customers see and analyze the work their databases are doing in unprecedented detail it addresses critical issues in measuring and managing todays large distributed diverse storage tiers composed of multiple different clustered products all working together vividcortex is headquartered in charlottesville virginia with a soontocome office in the arlington va area and remote team members in the us and abroad

we have a fastgrowing customer base of wellknown companies and a tremendous reputation in our market for delivering a highquality innovative solution for database performance problems that are common in thousands of enterprises
about the role

vividcortex is looking for an experienced data engineer to architect and build our nextgeneration internal data platform for large scale data processing you are at the intersection of data engineering and product and run the strategy and tactics of how we store and process massive amounts of performance metrics and other data we measure from our customers database servers

our platform is written in go and hosted on the aws cloud it uses kafka redis and mysql for data storage and analysis we are a devops organization building a 12factor microservices application we practice small fast cycles of rapid improvement and full exposure to the entire infrastructure but we dont take anything to extremes

the position offers excellent benefits a competitive base salary and the opportunity for equity diversity is important to us and we welcome and encourage applicants from all walks of life and all backgrounds

remote candidates will be considered depending on location and time zone alignment with periodic travel to a vividcortex office
responsibilities
work with others to define and propose for approval a modern data platform design strategy and matching architecture and technology choices to support it with the goals of providing a highly scalable economical observable and operable data platform for storing and processing very large amounts of data within tight performance tolerances
perform highlevel strategy and handson infrastructure development for the vividcortex data platform developing and deploying new data management services both in our existing data center infrastructure and in aws
collaborate with engineering management to drive data systems design deployment strategies scalability infrastructure efficiency monitoring and security
discover define document and design scalable backend storage and robust data pipelines for different types of data streams
write code tests and deployment manifests and artifacts using circleci git and github pull requests issues etc collaborate with other engineers on code review and approval
measure and improve the code and system performance and availability as it runs in production
support product management in prioritizing and coordinating work on changes to our data platform and serve as a lead on userfocused technical requirements and analysis of the platform
help provide customer support and youll pitch in with other departments such as sales as needed
rotate through oncall duty
understand and enact our security posture and practices
continually seek to understand and improve performance reliability resilience scalability and automation our goal is that systems should scale linearly with our customer growth and the effort of maintaining the systems should scale sublinearly
contribute to a culture of blameless learning responsibility and accountability
manage your workload collaborating and working independently as needed keeping management appropriately informed of progress and issues
preferred qualifications
you are collaborative selfmotivated and experienced in the general development deployment and operation of modern apipowered web applications using continuous delivery and git in a unixlinux environment
you have experience resolving highly complex data infrastructure design and maintenance issues with at least 4 years of datafocused design and development experience
experience building systems for both structured and unstructured data
you are hungry for more accountability and ownership and for your work to matter to users
you’re curious with a measured excitement about new technologies
aws infrastructure development experience
saas multitenant application experience
ablility to understand and translate customer needs into leadingedge technology
experience with linux system administration and enterprise security
mastery of relational database technologies such as mysql
a bachelor’s degree in computer science another engineering discipline or equivalent experience",,,False,data_engineer
Data Engineer,"about accion
accion usaccionorg is a nationwide nonprofit community lender dedicated to helping entrepreneurs generate income build assets create jobs and achieve financial success through business ownership our network serves small businesses in communities across the us and is made up of four certified community development financial institutions cdfis and a us network office globally for more than 50 years accion has helped over 90 partners serve the financial needs of tens of millions of people in 40 countries

accion serving arizona colorado nevada new mexico and texas is looking for a data engineer to join our operations team either at our albuquerque headquarters or remotely within one of the states in our region arizona colorado nevada new mexico and texas accion is embarking on a threeyear project to overhaul our technology infrastructure and implement a stateoftheart lending platform it will be the only endtoend lending platform in our industry and is fully owned and operated by accion allowing it to be customized to meet our and our customers’ needs this will have a transformational effect on accion our clients and the sector of lenders supporting underserved entrepreneurs as our data engineer you’ll be an integral part of this transformation helping us create a datacentered culture we need to make datainformed decisions learn about our values
what you’ll be doing
you’ll work closely with our technology operations and engineering teams to understand business needs and designmaintain scalable data models
you’ll make databacked recommendations to the executive team to help inform business decisions and answer complex questions
you’ll own the design build maintenance quality and expansion of a data warehouse and support and scale the pipeline that relays data from accion’s lending platform back to the warehouse
over time you’ll act as a product manager determining project timelines goals and deliverables for updates to our lending platform
skills and experience
must have a passion for accion’s mission and a strong commitment to accion’s culture of exceptional customer service excellence and accountability
knowledge of etl processes and applications
experience in the financial services industry and familiarity with the lending process strongly preferred
advanced skills in sqljavaruby preferred
bachelor’s degree in computer science engineering applied mathematics or related quantitative discipline plus four years’ relevant experience preferred


accion offers an excellent total compensation package including competitive base salary the opportunity for exciting incentive pay health and dental coverage retirement benefits and generous paid time off",,NV,False,data_engineer
Hadoop Data Engineer,"arthur lawrence is urgently looking for hadoop data engineer for our client in hayward ca kindly review project details and respond back at your earliest

must have

6 to 8 years of experience as hadoop data engineer
experienced in hadoop distributions
experienced with hadoop map reduce yarn and hive
experienced in nosql hbase apache or mongodb
experienced with big data ecosystem


nice to have

relevant certifications


for further details please contact adam at 8325624613 or email at adamarthurlawrencenet",,CA,False,data_engineer
Data Engineer,"over 20 trillion worth of goods—the items we use wear and consume every day—flow through increasingly complex global supply chains annually alloy is a supply chain synchronization platform that connects manufacturers suppliers logistics providers distributors and retailers giving businesses endtoend visibility with fast and actionable insights our customers—companies the make move and sell products—use alloy to get the right products to the right place at the right time with greater agility efficiency and effectiveness than ever before we work with companies of all sizes in many industries ranging from fortune 100 enterprises to fastgrowing innovative manufacturers

we are early stage well funded by leading vcs and growing fast our small team studied at top institutions including mit stanford waterloo caltech eth zurich carnegie mellon and harvard and has diverse backgrounds and experience in analytics largescale enterprise software retail and financial technology there are many challenging problems to solve in this complex industry and a huge opportunity for modern software to make the global supply chain operate more effectively

about the role

as a data engineer at alloy you will oversee and expand our entire data integration layer allowing alloy to seamlessly communicate with a wide variety of companies across the supply chain this includes retailers distributors logistics operators and ecommerce platforms

about you

you thrive in a small team where you can build technology from the ground up you love to pick up new tech master it quickly and do something creative with it

you don’t shy away from even the most challenging problems and relentlessly strive for better solutions you are selfmotivated and enjoy working with others towards a common objective when you know a better way you voice your opinion building software is the means to an end—you want to change the way an entire industry operates
what youll do
build automate and maintain integrations with retailerdistributor portals ecommerce platforms logistics providers erp platforms manufacturers and other relevant data sources
build and improve internal libraries to streamline data integration across multiple sources including web scrapers edi files rest apis and flat files
be the internal expert on how each player in the supply chain shares and interpret data maintain internal alloy logic to automate the interpretation of data across channels through the unified alloy data model
what were looking for
strong knowledge of python and sql especially in data wrangling and etl applications
familiarity with java is a plus
experience in interpreting and manipulating supply chainrelated datasets pointofsale logisticsedi product master
working knowledge of selenium and other webscraping tools
our stack
google cloud platform
postgres redis
python modern java react",,CA,False,data_engineer
Sr. Data Engineer (REMOTE),"contractsenior data engineer remote
apply directly to creposasyrinxcom

our engineers dont just make things they make things possible we are looking for someone that is ready to solve the most challenging and pressing engineering problems for our clients join our engineering team that builds massively scalable software and systems architect low latency infrastructure solutions proactively guards against cyber threats and leverage machine learning alongside financial engineering to continuously turn data into action

what we look for
we are working with a global investment company that is building solutions in risk management big data mobile and more we are looking for creative collaborators who evolve adapt to change and thrive in a fast paced environment

technologies
spark hadoop sqlpython must be able to code in pythonfamiliarity with awstableau nice to have

this is a 12 month remote contract",,,False,data_engineer
Intermediate Data Engineer - Nike Technology,"design and build reusable components frameworks and libraries at scale to support analytics products
design and implement product features in collaboration with business and technology stakeholders
identify and solve issues concerning data management to improve data quality
clean prepare and optimize data at scale for ingestion and consumption
support the implementation of new data management projects and restructure of the current data architecture
implement automated workflows and routines using workflow scheduling tools
understand and use continuous integration testdriven development and production deployment frameworks
participate in reviews of design code test plans and dataset implementation performed by other data engineers in support of maintaining data engineering standards
analyze and profile data for the purpose of designing scalable solutions
troubleshoot data issues and perform root cause analysis to proactively resolve product and operational issues

qualifications
bachelors degree in computer science information systems or related field or equivalent work experience
2 years of experience with data engineering with emphasis on analytics and reporting
experience with relational sql
experience with scripting languages such as shell python
knowledge of workflow scheduler systems such as airflow oozie or aws data pipeline
experience developing on hadoop ecosystem with tools like pig hive sqoop and spark is preferred
knowledge of file formats including json parquet and avro
experience developing solution within aws services framework emr ec2 rds lambda etc is preferred
experience with source control tools such as github and related dev process
willing to learn new skills and technologies
has a passion for data solutions
strong understanding of data structures and algorithms
strong understanding of solution and technical design
has a strong problem solving and analytical mindset
able to influence and communicate effectively both verbally and written with team members and business stakeholders
able to quickly pick up new programming languages technologies and frameworks",,OR,False,data_engineer
Software Data Engineer- Maps Software,"apples map service team builds necessary infrastructure which are the foundation for many customer facing maps services for our millions of awesome customers this is an exciting role for someone who loves realtime huge data processing pipeline we bring our new ideas to the table and we are excited to create solutions for the apple maps developer communities were looking for a talented and passionate person to join this amazing team if you feel this is you wed love to hear from you

key qualifications
you have experience with architecting designing and developing bigdata processing pipelines
you possess proficiency in mapreduce development and experience with hadoop and spark data processing technologies required
significant experience with distributed kevvalue store
build instrumentation experience
performance metrics reporting
strong core java programming experience
description
you will architect design and build bigdata frameworks that automate the creation of spatial a data warehouse these data services enable maps developers to build new features at greater speed we are part of a larger maps organization which strives to provide foundation services for developers as daily activities in this role you will
works quickly to deploy necessary spatial data solutions as requested
recommend best practices of architectural and design performance for distributed data systems
provide infrastructure and service team members solutions for efficient dataprocessing and data delivery
build a geospatial index using realtime feeds which many teams can access

education
bsms or anyone with relevant industry experience will be considered

additional requirements
nice to have but not necessary apache kafka and geo spatial database experience python and scala programming background",,CA,False,data_engineer
Python Data Engineer,"about aqr capital management


aqr is a global investment firm built at the intersection of financial theory and practical application we strive to deliver concrete longterm results by looking past market noise to identify and isolate the factors that matter most and by developing ideas that stand up to rigorous testing by putting theory into practice we have become a leader in alternative strategies and an innovator in traditional portfolio management since 1998

at aqr our employees share a common spirit of academic excellence intellectual honesty and an unwavering commitment to seeking the truth were determined to know what makes financial markets tick – and well ask every question and challenge every assumption we recognize and respect the power of collaboration and believe transparency and openness to new ideas leads to innovation

the team
the python data engineer will work hand in hand with the product management teams playing a key role in aqrs portfolio management

the two primary objectives portfolio monitoring and client communication

you will build tools to aid in many stages of the investment process including new business presentations new account onboarding performance monitoring and analysis and portfolio review meetings with clients product management teams are ultimately responsible for the accuracy and delivery of information to clients and are expected to do so in a professional poised and consultative manner as a result the teams interact closely with the rest of the firm including research portfolio management trading business development legal compliance risk and marketing through this collaboration product management teams have indepth knowledge of the strategies they cover and are expected to be inhouse experts of their respective products they are integral part of initiatives to create and sell new products run competitor analyses and produce market commentary as needed

your role
portfolio monitoring

analyze portfolio exposures and performance using existing tools and drive the development of new tools for monitoring
conduct portfolio analysis and present results to product and portfolio teams in a logical comprehensive manner
be familiar with funds investment parameters and review these on a regular basis
additional department specific tasks such as oversee funds onboarding including launch and postlaunch analysis and build maintain and present competitor analysis reports

client communication

prepare review materials on quarterly and yearly performance
create review and approve presentations used by business development
complete bespoke portfolio analysis to answer client queries
develop tools to enhance and streamline data used in client portfolio reviews

sample projects

buildout tools for and run returnsbased style analysis using multivariate regression
create a dashboard of tactical asset allocation views for client use
analyze the impact of a surprise currency devaluation on portfolio returns and risk

skills  requirements

2 years of working with or analyzing data
2 years of working experience in finance
2 years of programming experience
proven track record and portfolio of successful work

experience with the following

python pandas numpy scipy or any other programming languages
experience with tableau preferably or any other bi tool
strong knowledge of sql with advanced analytic functions
experience with consuming and building apis
ability to design database schemas
excellent problem solving and communication skills
knowledge of visualization best practices is a plus
strong coding skills with knowledge of software design patterns
experience in an agile environment is a plus
masters degree or bachelors degree with equivalent experience in computer science data science statistics or equivalent quantitative field

aqr is an equal opportunity employer eeovetdisability",,CT,False,data_engineer
ASSOCIATE DATA ENGINEER,"about the role

associate data engineers at bluelabs have a passion for problem solving at the intersection of data and engineering whether it’s architecting a new data processing pipeline building out internal tooling scaling our modeling work or feature engineering collaboratively with data scientists the associate data engineer works closely with both the data science and engineering teams across a widevariety of bluelabs’ work they have strong technical skills and are also creative thinkers who are always looking to innovate and deliver value to our clients they aren’t afraid of messy data and are comfortable working in a fast paced productionoriented environment
duties and responsibilities
scope design and implement data pipelines and processes
developdeploy data visualizations and internal tools to facilitate data analysis and reporting
collaborate with data science to support and optimize bluelabs’ modeling work
strives to support team excellence by documenting processes and evangelizing new approaches
you probably have
an undergraduate degree in computer science or a quantitative field or significant personal programming experience
proficient understanding of a general programming language such as python ruby or java
proficient understanding of a statistical programming language such as r python or julia
the ability to effectively communicate technical concepts to a nontechnical audience both in writing and verbally
you may also have
the ability to manipulate data with sql
experience working with messy data or building etl data pipelines
experience creating informative and engaging data visualizations using industry leading tools
the ability to create user interfaces for new products using frameworks such as shiny or django
we know that the best candidate may not fit neatly into the boxes we define here so if this sounds like a place you want to work even if youre not confident you perfectly match our posting we still encourage you to apply we welcome diverse outofthebox thinking and we strive to provide an ecosystem for innovation and development if you want more information about who we are as a team check out our facebook page twitter or instagram

about bluelabs

bluelabs was formed in early 2013 by senior members of the obama for america analytics team we help organizations personalize their engagements with individuals optimize communications and achieve their strategic goals our team includes more than 40 data scientists engineers and strategists from diverse backgrounds who share a passion for using data to solve the world’s greatest social and analytical challenges through our work we’ve directly and measurably improved the health and financial security of millions of americans

since 2013 we’ve served more than 300 organizations run more than 1000 randomized experiments built hundreds of models generated over 6 billion touch points reached virtually every contactable person in the united states and driven significant improvements in some of the highestprofile private sector advocacy and government programs around the world along the way we’ve developed some of the most innovative tools available in media optimization reporting and influencer outreach

our clients range from political campaigns to advocacy groups unions government agencies and international groups as well as global companies in the automotive travel consumer packaged goods entertainment healthcare media telecom and other industries

bluelabs is headquartered in washington dc and has offices in new york city
equal opportunity and diversity policy

bluelabs believes a diverse inclusive staff makes us a stronger team and more impactful partner for our clients we’re committed to a diverse team and qualified people of all races ethnicities cultures ages sex genders sexual orientations gender identities and expressions languages social class marital status religions veterans status and disabilities are strongly encouraged to apply",,DC,False,data_engineer
Data Engineer,contractjob summaryhellohope you are doing wellmy name is kumar from softcom systems inci am aggressively recruiting for one of the positions “data engineer” for location “new york city “with one of our direct client please have a look at the job description below and if interested feel free to call me at 6097599004 or revert to this email with your updated resumeposition data engineer location new york cityduration long term contractskill data engineer with spark scala hadoop  java skillswith regardssoftcom systems inc your trusted technology partneroffice 6097599004 fax 6097519077475 wall street princeton nj08540under bill s1618 title iii passed by the 105th us congress this mail cannot be considered as spam as long as we include contact information and a remove link for removal from our mailing list in order to not be in the recipientslist for this mail please revert to us with remove either in the subject or in the mail bodypplease dont print this email unless you really need tojob type contractexperiencedata engineer 4 years preferred,,NY,False,data_engineer
Data Engineer - MSBI Developer,87000  131000 a year indeed est contractdata engineer  downtown dallas txthis is a data engineer role   bachelors degree   812 years of experience   advanced sql skills  adept at queries report writing and presenting findings   expertise in data analysis data profiling and sql tuning   expertise in translating business requirements to project design development and execution   strong analytical skills with the ability to collect organize analyze and disseminate significant amounts of information with attention to detail and accuracy   ability to clearly communicate capabilities opportunities and recommendations to both technical and nontechnical audiences   experience working in data warehouse etl  bi platforms and have a good understanding of related development activities and challenges   strong knowledge of and experience with reporting databases sql etc programming  etl frameworks   experience in understanding the source data from various platforms and mapping them into entity relationship modeler for data integration and reporting   has deep understanding of data architecture  data modeling best practices and guidelines for different data and analytic platformsresponsibilities interpret and analyze data from various source systems to support data integration and data reporting needs within cbre   identify analyze and interpret trends or patterns in complex data sets   work with team leads to prioritize business and information needs   prepare highlevel etl mapping specifications   develop complex code data scripts primarily sql for etl   data quality control metrics   troubleshoot  determine best resolution for data issues and anomalies   manage exploratory data analysis to support database and dashboard development as well as advanced analytics efforts   may assist in development of software technical documentationjob type contract,109000.0,TX,False,data_engineer
Quantitative Data Engineer,"this position is part of our data technology team and will help implement enhance and manage our quantitative models primary responsibilities include researching designing coding testing and deploying projects while working in a fastpaced environment and improving proprietary data repository and financial data platforms the quantitative data engineer will work closely with quantitative research and portfolio management professionals to implement new ideas the successful candidate must possess strong knowledge of financial equity data eg compustat bloomberg thomson reuters have solid coding skills in sql python and c and experience working with large datasets msphd degree in computer science or related field required


we are seeking a quantitative data engineer to design and implement our proprietary quantitative investment systems you will be a key player in the technology team and will research design code test and deploy projects while working in a fastpaced environment

responsibilities include
implement enhance and manage quantitative models
design and improve proprietary data repository and financial data platforms
automate and support the extract transform and load etl processes from various market data vendors
develop and manage reporting and performance analytics platforms



requirements include
msphd in computer science engineering statistics or related discipline with excellent academic credentials
strong knowledge of financial equity data a plus with experience in bloomberg thomson reuters compustat and capiq data
broad knowledge of database concepts with proficiency in sql and stored procedures preferably with microsoft sql server
2 years of solid coding experience in python c c
experience in processing large and complex datasets
an advanced knowledge of math and statistics
for immediate and confidential consideration please email your cover letter and resume to careersjlemcom please indicate the position for which you are applying

equal opportunity employer",,NJ,False,data_engineer
Telematics Data Engineer,"rfa engineering wwwrfameccom is seeking several growth oriented entry level to experienced candidates to be part of our engineering team at our customers facility in dubuque iowa you will work with our experienced engineering staff ato provide highly engineered data solutions for offroad equipment using state of the art engineering tools


our customers facility is a worldclass manufacturing center these are full time positions that are indefinite in duration with opportunity for professional growth and direct hire by our customer


telematics data engineer


job duties for these positions are associated with integrating telematics data collection in offroad machinery
collaboration with various departments to assist the integration of machine telematics into their projects
analyzing machine telematics data for custom information reporting
developing and testing telematics data accuracy to provide high quality information to internal engineering teams
developing and documenting requirements for telematics data to be collected from offroad machinery
telematics data generation and summary from various sources to support custom projects


requirements
bsee computer science or mechanical design or related degree with experience

a proven mechanical aptitude through employment personal experience or education including machinery operation maintenance repair metal fabrication and other “hands on experience

candidates must have excellent communication teamwork and analytical skills

previous design experience or knowledge of offroad mobile equipment is a plus

high level of attention to detail and accuracy

travel minimum to none
desired attributes
design experience or exposure to offroad mobile equipment

ability to communicate clearly and interact with multiple engineering groups

work autonomously with minimal direction while supporting a team atmosphere
about rfa engineering


rfa engineering has provided machine design and engineering services to industry leading customers since 1943 our primary focus is engineering of off highway equipment including agricultural and construction equipment engine and drive train development consumer recreational industrial and special machines


rfa engineering is domestically owned and operated exclusively by engineers who have spent their careers in the industry our engineering staff is located both at our engineering center in minneapolis and at numerous customer sites throughout the us


why work for rfa
we offer
health and dental insurance programs
company paid life and longterm disability insurances
retirement savings account 401k
flexible spending plan for medical expenses and dependent care
paid time off pto
employee assistance program eap
education assistance
equal opportunity and veteran friendly",,IA,False,data_engineer
Data Engineer,"about the company

the name thousandeyes was born from two big ideas the power to see things not ordinarily possible and the ability to collect insights from a multitude of vantage points as organizations rely more on cloud services and the internet the network has become a black box they cant understand thousandeyes gives organizations visibility into the now borderless network arming them with an accurate understanding of how the network impacts their applications users and customers thousandeyes is used by some of the worlds largest and fastest growing brands including all of the top 5 global software companies 5 of the top 6 us banks and 45 of the fortune 500 thousandeyes is backed by sequoia capital sutter hill ventures tenaya capital google ventures and salesforce ventures with headquarters in san francisco ca

about the position

we are looking for a data engineer superhero who will take the analytics teams data infrastructure to the next level you will work directly with our data infrastructure datasets and analytics tools that are used by the product marketing sales sales engineering finance and customer success teams every day

you will contribute to a variety of exciting projects that range from designing robust and fully automated etl processes to building tools for improving companywide productivity with data you have a passion for designing implementing and operating stable scalable and efficient solutions to flow data from production systems into the data warehouse you are also a selfstarter who is comfortable with ambiguity pays close attention to detail and has the ability to work in a fastpaced environment

in short you will play a critical role in shaping our analytics foundation on the analytics team we know new analytics technologies are emerging every day and we are excited about the impact they will have – we hope you share our enthusiasm

required skills

bsms with quantitative focus eg economics computer science mathematics physics statistics or equivalent practical experience

2 years experience designing implementing and maintaining production grade etl processes and data pipelines

2 years experience operating databases eg redshift mysql mongodb and advanced query authoring

2 years of dimensional data modeling  schema design in data warehouses development experience in at least one scripting language eg python javascript

knowledge of industrial grade data architectures and reporting tools eg chartio tableau

an eye for automation and instrumentation in all datarelated aspects work experience in an interdisciplinarycrossfunctional field

preferred skills

working experience in saas companies

experience performing quantitative analysis and using data visualization tools to deliver dashboards at scale

strong crossfunctional and interpersonal skills with demonstrated ability to communicate technical content to general audiences",,CA,False,data_engineer
Data Engineer,"automattic is the company behind wordpresscom jetpack woocommerce and more we are looking for a fullstack data engineer

you’ll work with business leads analysts data scientists and fellow engineers to build datapowered products that empower better decision making you’re committed to data quality you’ll understand how to manage a cluster to deliver performance and reliability you’ll evaluate and help to craft technology choices and you’ll implement systems that tackle business use cases

what we’re looking for

handson production experience with the hadoop family of big data technologies hive impala hbase etc
collaboration with business partners to craft and iterate on solutions that extract value from data
experience with spark python and java
strong analytical skills and a fervor for data integrity and accessibility
the curiosity and determination to understand and improve data flows
we’re serious about growing diversity in the tech industry we want to build automattic as an environment where people love their work and show respect and empathy to those with whom we interact diversity typically includes but is not limited to differences in race gender sexual orientation gender identity or expression political and religious affiliation socioeconomic background cultural background geographic location disabilities and abilities relationship status veteran status and age to work on diversity means that we welcome these differences and strive to increase the visibility of traditionally underrepresented groups read more about our dedication to diversity and inclusion

how to apply
does this sound interesting if yes please send a short email to jobs  this domain telling us about yourself and attach a résumé let us know what you can contribute to the team include the title of the position you’re applying for and your name in the subject

proofread make sure you spell and capitalize wordpress and automattic correctly we are lucky to receive hundreds of applications for every position so try to make your application stand out if you apply for multiple positions or send multiple emails there will be one reply

if you’re reading this on a site other than automatticcom please ensure you visit automatticcomworkwithus for the latest details on applying
please answer the following questions in your cover letter applications without these questions answered will not be considered

tell us some details about an interesting data problem you’ve worked on what made it interesting
include a link to a recent favorite blog post or paper about working with lots of data
what questions do you have for us",,CA,False,data_engineer
Data Engineer,"data engineer


position title data engineer
location chicago
department information technology
we are looking for a data engineer to join our team you will have the opportunity to be involved in all aspects of a performancedriven database infrastructure geared towards a fast paced trading environment on the technical front the database team touches every layer of the database stack from hardware to application layer so be ready to leverage your strengths while learning a lot to improve your weaknesses the team manages every aspect of the database environment from server hardware to arrays to sql development and administration on the business front this team works directly with traders other engineers and business stakeholders you will interact closely with both team members and stakeholders alike the ability to have a keen technical understanding but communicate in layman’s terms is important day to day tasks can vary between database design support tuning sql report writing scripting and anything else that could touch the database layer of the firm
required qualifications
bachelor’s degree in an applied science30 gpa03 years of experienceexcellent problem solving skillsefficient tsql and ansisql coding abilityprevious work or internship experience
recommended qualifications
financialtrading industry experiencesql server experiencechashtag development skillsproblem solving skillsdatabase design normalizationknowledge of database operations backupsrestores security haability to connect business problems with technological solutionsdatabase performance tuningindexingknowledge of networkingdnsad san raid
about wolverine
founded in 1994 the wolverine companies comprise a number of diversified financial institutions specializing in proprietary trading asset management order execution services and technology solutions we are recognized as a market leader in derivatives valuation trading and valueadded order execution across global equity options and futures markets with a focus on innovation achievement and integrity we take pride in serving the interests of both our clients and colleagues the wolverine companies are headquartered in chicago with offices in new york and san francisco and a proprietary trading affiliate office located in london
visa sponsorship is not available






are you a returning applicant


previous applicants

email

password





if you do not remember your password click here",,IL,False,data_engineer
Big Data Engineer/Analytics Developer,"this position is for a role in tedra department tedra trade enrichment data reporting  allocations is part of the institutional securities technology ist division it is responsible for maintaining distributing and reporting on trading revenue risk and reference data client product and pricing as the authoritative source of key data sets we are at the forefront of database technology and are heavily involved in data engineering data science data visualization and machine learning efforts across the firmthis position is for a data engineer role in the analytical databases team our team designs develops and manages a variety of data containers etl tools real time and batch driven systems our technology domain spans relational nosql data lakes and ultra low latency worlds we are experts in advanced data engineering when you join our team you will be exposed to all the latest data technology in fintech development will utilize an agile methodology which is based on scrum time boxing daily scrum meetings retrospectives etc and xp continuous integration refactoring unit testing etc best practices candidates must therefore be able to work collaboratively demonstrate good ownership and be able to work well in teams work will include designing enhancing and developing databases across different database environments the job will involve considering all aspects of the project life cycle and includes proofofconcept evaluations coding designing testing implementing deploying and continued support of project releases as well as oncall level 2 support collaboration with the firms engineering teams is expected we are a team of highly technical individuals who manage a large number of databases that include big data volumes we deliver multiple projects for multiple business areas in parallel the business owners and subject matter experts are globally distributed making strong communication skills important to the position the candidate will be expected to work closely with our it partners in analyzing and delivering on business requirements

35 years of experience in database managementengineering role  knowledge of relational or nosql databases  any experience will count  the candidate must be familiar with some scripting language such as python or perl  the candidate must have strong knowledge base of database performance and tuning versioning tools such as perforce and git is a plus but not required  knowledge of financial instruments would be a great benefit but not required personal skills integrity  ownership good team player ability to work under time and resource dependencies and constraints ability to find simple and effective solutions high degree of motivation to expand technical and business knowledge

",,NY,False,data_engineer
Data Engineer,"job overview
we are looking for a dedicated data engineer to help kickstart and grow business intelligence services at aftershock studiosfoxnext games for our premier mobile game titles including james cameron’s avatar
responsibilities
design implement debug document test and maintain code and systems for ingestion transformation storage and consumption of data from multiple games and millions of players
collaborate with game teams product managers data analysts and technical stakeholders to craft the best solutions for our data driven business
estimate engineering effort to contribute to sprint planning and keep our delivery on track
ensure data quality is delivered timely and consistently with active alerting and notifications for escalation
bachelors in computer science or related field or equivalent work experience
4 years of experience with software engineering
deep understanding of functional and object oriented programming
expert etl techniques and best practices to handle large data volumes
expert sql and nosql database experience
experience with data warehouse architecture and data modeling best practices
experience with relevant scheduling batch and stream processing frameworks eg apaches spark kafka airflow
experience with relevant managed services eg aws kinesislambda gc pubsub
cloud infrastructure devops to support deployment and data management
excellent communication skills both written and verbal
preferred qualifications
python javascript nodejs mongodb bigquery
infrastructure management on amazon web services and google cloud platform
docker container deployment on kubernetes
restful web service api development
mobile development in android and ios
experience in games or fast paced company such as growth phase startup
git github perforce jenkins splunk",,CA,False,data_engineer
Data Engineer,"we have the great privilege of helping patients and families rebuild their lives it’s extraordinarily meaningful work and the reason we greet the day with optimism and anticipation when patients “ask for mary” they experience a culture that has been sculpted for more than a century our hallmark is to carefully listen to patients and innovatively serve them

mary free bed is a notforprofit nationally accredited rehabilitation hospital with 167 inpatient beds – 119 acute and 48 subacute there are numerous outpatient programs as well as home and community services with the most comprehensive rehabilitation services in michigan and an exclusive focus on rehabilitation mary free bed physicians nurses and therapists help our patients achieve outstanding clinical outcomes

mission statement
restoring hope and freedom through rehabilitation

diversity and inclusion
mary free bed values diversity and inclusion among patients families and staff we strive to hire people who reflect the communities we serve our employees will serve all patients families and each other with dignity and respect

summary
as a member the data architecture team the data engineer develops data solutions for advanced analytics and operational support across the organization this role provides expertise in the design implementation and maintenance of data objects and models using supported enterprise it platforms and guidelines data engineers gather and integrate data from the enterprise data warehouse edw which is stocked by multiple source systems and data streams to support these needs data engineers work in conjunction with data architects to research prototype and pilot emerging analytics tools and platforms this role further promotes the analytical operations of the organization by providing expertise in report automation and the development of selfservice dashboard solutions using enterprise supported platforms


essential job responsibilities
support the enterprise business intelligence platform by acting as the primary steward of the edw presentation layer
participate in data modeling and data source creation– provide and support technology that allows data analysts to meet the organization’s reporting needs
participate in optimization efforts – within both the backend and frontend of the bi platform
enforce bi platform governance administer platform technology and maintain user permissions and security
participate in bi product evaluations rfp’s poc’s and business decisions to ensure fit and scale into the platform and the organization
understand the business objectives and provide solutions that efficiently meet the objects in a timely manner with a focus on data integrity and quality
assist data architects with etl and warehouse development when necessary
performs other duties in support of departmental and corporate objectives and initiatives as assigned
essential job qualifications knowledge education and training requirements
a bachelor’s degree or equivalent background and work experience in computer science application programming software development information systems database administration mathematics engineering or other related field
at least 2 years’ experience providing data solutions analytics and or data development
requires strong and very effective verbal and written communication skills ability to express complex technical concepts effectively both verbally and in writing
proven ability to handle multiple tasks and projects simultaneously
excellent analytical skills attention to detail and problemsolving skills
willingness to learn and stay current on technology trends and upcoming features
ability to work in a teamoriented environment
must be selfmotivated and demonstrate strong initiative
demonstrated ability to establish priorities organize and plan work to satisfy established timeframes
physical demands
able to exert up to 10 pounds of force occasionally up to 13 of the time
able to lift carry push pull up to 20 pounds occasionally
able to sit for the majority of the time but may involve brief periods of time involving walking or standing
able to use keyboard frequently 34 of the time
technical skills
knowledgeand experience with sql programming tsql preferred
knowledge of software development methodologies relational and dimensional database skills and design skills
experience using a modern business intelligence stacks ms sql server preferred
experience with data visualization technologies tableau preferred
mary free bed is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion gender national origin age genetic information veteran status disability or other legally protected characteristic",,MI,False,data_engineer
Data Engineer,"facebooks mission is to give people the power to build community and bring the world closer together through our family of apps and services were building a different kind of company that connects billions of people around the world gives them ways to share what matters most to them and helps bring people closer together whether were creating new products or helping a small business expand its reach people at facebook are builders at heart our global teams are constantly iterating solving problems and working together to empower people around the world to build community and connect in meaningful ways together we can help people build stronger communities — were just getting started
at facebook we have many opportunities to work with data each and every day in this role as a data engineer on the analytics team your primary responsibility will be to partner with key stakeholders data scientists and software engineers to support and enable the continued growth critical to facebook’s data center organization you will be responsible for creating the technology that moves and translates data used to inform our most critical strategic and realtime decisions you will also help translate business needs into requirements and identify efficiency opportunities in addition to extracting and transforming data you will be expected to use your expertise and provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices including streamlining of data sources and related programmatic initiatives the ideal candidate will have a passion for working in white space and creating impact from the ground up in a fastpaced environment this position is part of the infrastructure data center team and located in our menlo park office
responsibilities

apply proven expertise and build highperformance scalable data warehouses

design build and launch efficient  reliable data pipelines to move and transform data both large and small amounts

securely source external data from numerous partners

intelligently design data models for optimal storage and retrieval

deploy inclusive data quality checks to ensure high quality of data

optimize existing pipelines and maintain of all domainrelated data pipelines

ownership of the endtoend data engineering component of the solution

collaboration with the data center smes data scientists and program managers

support oncall shift as needed to support the team

design and develop new systems in partnership with software engineers to enable quick and easy consumption of data
minimum qualifications

bsms in computer science or a related technical field

7 years of sql oracle vertica hive etc experience and relational databases experience oracle mysql

7 years of experience in custom or structured ie informaticatalendpentaho etl design implementation and maintenance

7 years’ experience in data engineering experience in applying dwhetl best practices

7 years of java andor python development experience

2 years experience in lamp and the big data stack environments hadoop mapreduce hive

2 years experience working with enterprise de tools and experience learning inhouse de tools
preferred qualifications

technical knowledge of data center operations",,CA,False,data_engineer
Data Engineer,"as the fastest growing highestperforming charter school network in new york state success academy has reimagined public education nationally recognized for achieving outstanding academic results for students from all backgrounds and zip codes we have created an innovative k12 school model that is preparing current and future generations of children with the subject mastery and skills to succeed in college and life we now need talented highly motivated data engineers to help us build the best possible data products and insights that will propel us to our public goal of building and managing 100 schools in nyc
reporting to the director of data management  analytics the data engineer will help to enhance the learning experience for thousands of children across the five boroughs of nyc by becoming the glue that binds together hundreds of disparate data sources and third party apis that our schools use every day to improve curriculum across our network of over 50 schools imagine working for a company that has the iterative constant improvement practices of a startup applied at scale to curriculum and schooling operations our data team is at the heart of how this organization operates
key responsibilities include
building scalable and reliable data pipelines in python by leveraging data processing technologies like aws spark airflow etcwriting modular reusable code in python to build and enhance our data frameworkwriting complex high performing sql queries against postgres mysql and mssql databases andinterfacing with thirdparty apis to collect data from various sources and transform them into our central data warehouse

a successful applicant will have the following experience and characteristics
experience with data warehousing streaming architecture machine learning pipeline and workflow scheduling with airflowexperience with service oriented architectures and interfacing with thirdparty apisa high level of comfort using python data libraries particularly pandas and sqlalchemyexperience with python web development frameworks flask django or pyramidexperience with data analysis and visualization methodsseeks a fast paced collaborative environment with capacity to work with multiple teams to complete a variety of projects
has 35 years of experience on a data science team andhas a strong interest in education reform and working for a mission driven organization

to join our team please upload a cover letter and resume that outlines your candidacy your cover letter should explain in detail your qualifications for the position resumes without cover letters will not be reviewed

success academy charter schools is an equal opportunity employer and actively encourages applications from people of all backgrounds compensation is competitive and commensurate with experience success academy offers a full benefits program and opportunities for professional growth",,NY,False,data_engineer
Data Engineer,"company mission and highlights
mpulse mobile the leader in mobile health engagement drives improved health outcomes and business efficiencies by engaging individuals with tailored and meaningful dialogue mpulse mobile combines technology analytics and industry expertise that helps healthcare organizations activate their consumers to adopt healthy behaviors with 9 years 60 healthcare customers and more than a hundred million messages sent annually mpulse mobile has the data the experience and the technology to drive healthy behavior change
our core values
model integrity and collaboration
drive innovation and thought leadership
support decision making at all levels
create value for clients by empowering consumers
improve customer experience through simple design
celebrate success… often
purpose of the role
the mission of the data science and analytics dsa team at mpulse is to uncover insights from data in order to help drive better patient engagement and health outcomes we are looking at everything from tactical optimizations to broad level strategic direction that is grounded in data evidence and heavy analytical rigor
this requires a multidisciplinary blend of data science behavioral science and business strategy all applied in tandem to discover key insights that lie hidden in our data sets the data engineer will help build a researchbased and datadriven approach to optimize mobile customer engagement this role will focus on deep diving into a broad variety of exploratory initiatives to improve segmentation tailoring and personalization of mobile engagement
duties and responsibilities
querying and processing data using etl tools generating reports and visualizing data
working with the data science team to refine and develop data science and analytics dsa product roadmap
improving team data report quality by crosschecking crossvalidation documentation and code reviews
follow our hipaa compliant data policies
building rich and interactive data visualizations used for internal analysis reports and in client presentations
understanding and participating in analytics group’s data mining techniques and analytics efforts
ability to deliver reports and visualizations within tight timelines
skills abilities and experience
required
strong background and solid skills in interactive data visualization shiny d3js
12 years experience with python pandas numpy scikitlearn sql and r
strong academic record ideally in economics mathematics computer science engineering operations research statistics or other quantitative field
strong team player with organizational skills attention to detail and ability to collaborate
preferred
25 years of experience in a corporate startup or research environment
experience in research methods and exploratory data analysis and familiarity with machine learning approaches
intense intellectual curiosity – strong desire to always be learning
analytical creative and innovative approach to solving difficult problems and a cando attitude when outside your comfort zone
able to work in a demanding deadlineoriented startup environment
the perks
enjoy unlimited pto and flexible work hours
full vision dental and healthcare  all individual premiums paid by mpulse
401k program with a 4 match
weekly team lunches to celebrate victories
paid parking as well as car pooling incentives
laptop fitness stations
ping pong conference table and foosball
free snacks and drinks
contact information
mpulse mobile inc
attn hr dept
16530 ventura blvd suite 500
encino ca 91436
careersmpulsemobilecom
mpulse is an equal opportunity employer",,CA,False,data_engineer
"Intern, Data Engineer / Data Sciences Developer","internshipintern  data engineer  data sciences developer 
job number
 043033 
description
 summer 2019 paid internship

zions bancorporation is currently accepting resumes for our data engineer internship position the intern will have the opportunity to
work with other developers and data scientists to code proofofconcept projects on large scale data sets
assist in developing data processing and system integration applications
assist in constructing web based user interfaces and visualizations
document design decisions code and work flows
assist in designing developing and testing etl applications consistent with application architecture guidelines
qualifications
preferred candidate will be pursuing a degree in computer science software engineering or computer engineering
strong analytical organizational and problem solving skills
ability to elicit gather and analyze user requirements
ability to work independently and provide updates to management
requires strong interpersonal skills
must be able to meet deadlines
technical knowledge in the following is preferred
programming languages including r tcl java ruby and python
sql and nosql data stores and solutions
knowledge of big data technologies eg apache hadoop spark
work locations
 utahsalt lake cityzions bancorporation  hdqtrs
business operations
sep 12 2018",,UT,False,data_engineer
"Business Intelligence Engineer, Field FP&A","job description
we are looking for candidates who want to help shape the future of ops finance specifically we are looking for an outstanding business intelligence expert and data engineer who is able to partner effectively with both business and technical teams to drive the growth of our rapidly expanding global business from your first day you will own the architecture and build out of new data infrastructure using mysql and etl in this role you will also develop and support the analytic technologies that give our teams flexible and structured access to their data including partnering with other software and business teams in order to build robust and scalable solutions for the entire na ops finance organization

the successful candidate will be an expert with sql etl and general data wrangling and have a demonstrated ability to quickly translate business requirements into technical solutions the candidate will need to be a selfstarter and team player demonstrate exemplary communication skills and able to think big while paying careful attention to detail

responsibilities

you know and love working with business intelligence tools can model multidimensional data sets and can partner with customers to answer key business questions you will also have the opportunity to display your skills in the following areas

design implement and support a platform providing ad hoc access to large datasetsinterface with other technology teams to extract transform and load data from a wide variety of data sources using sqlmodel data and metadata for ad hoc and prebuilt reportinginterface with business and finance customers gathering requirements and delivering complete reporting solutionsown the design development and maintenance of ongoing metrics reports analyses dashboards etc to drive key business decisionsrecognize and adopt best practices in reporting and analysis data integrity test design analysis validation and documentationcontinually improve ongoing reporting and analysis processes automating or simplifying selfservice support for customersparticipate in strategic  tactical planning discussions including annual budget processesleverage large data sets to form recommendations on forecasting along with web app product experimentation
basic qualifications
bachelor’s or advanced degree in math finance statistics engineering computer science or related disciplineexperience in data mining sql etl data warehouse etc and using databases in a business environment with largescale complex datasetsadvanced sql and excel skills familiarity with statistics or other analytical techniquesproven ability to solve complex quantitative business challenges experience in the development of pricing analysis is a plusexcellent written and verbal communication skills
preferred qualifications
knowledge of data visualization and exploration tools looker tableau etcstrong data extraction analytical and problem solving skillsthe right candidate thrives in a high energy environment where tactical and strategic activities are expected to be driven in parallelhighly innovative flexible and selfdirectedadvanced degree in math finance statistics engineering computer science or related discipline
amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,,False,data_engineer
Data Engineer,130000  170000 a yearour client is looking for a data engineer to work on fast data infrastructure leveraging data streaming batch processing and machine learning to personalise experiences for their customerswe would hope that you havebachelor’s degreeat least 1 years’ experience with leading big data technologies such as cassandra spark hadoop postgresql redshift and mongodb2 years experience with aws cloud2 years of experience in java scala or python2 years of experience building data pipelines1 years of experience working with cloud technologies aws google azurejob type fulltimesalary 13000000 to 17000000 yeareducationbachelors preferred,150000.0,NY,False,data_engineer
Data Engineer,135000  160000 a yearbuild data pipelines using apache spark scala python apache airflow etccollaborate with user experience and engineering teams in the planning of new productswrite unit tests and get close to 100 code coveragework on aws – s3 for storage ec2 and emr for processinganalysisfollow agile methodology for the software developmentidentify problems and propose resolutions6 year of engineering experience focus on backend development andor data engineeringindepth programming knowledge with java python and scalaexperience with spark hadoop or hivestrong experience with aws including ec2 ebs redshift emr elb sns rds cloudformation and moreexperience with tools like maven jenkins gitable to perform as an effective member of a geographically dispersed team across multiple timezoneseducation bachelor’s degree in computer science or closely related fieldclearance must be eligible to obtain a public trustlocation rockville mdjob type fulltimesalary 13500000 to 16000000 yearexperienceaws – s3 for storage ec2 and emr for processinganalysis 3 years requiredjava python scala 5 years requiredspark hadoop or hive 3 years requiredengineering focused on backend developement 6 years required,147500.0,MD,False,data_engineer
Data Engineer,"jebbit is looking for mid to seniorlevel data engineers that are problem solvers looking for a fastpaced and flexible environment to build cool things with a fun team we have a design for scaling out our infrastructure and need a dedicated and knowledgeable engineer to build troubleshoot and optimize on current and future iterations of the jebbit platform’s infrastructure from etl to analytics reporting and data science

our base technology stack consists of psql ruby on rails emberjs and nodejs but not knowing some or all of these is not a show stopper for a bright candidate who can learn the intricacies of the data formats and infrastructure that works best with these technologies most of our infrastructure resides on aws and we also employ kubernetes elasticsearch and redshift having a firm grasp of fundamentals and having experience scaling architecture is more important than being a master of any singular domain

originally founded at boston college jebbit was named one of the top 25 most promising companies in the world by cnbc and our cofounders are forbes 30 under 30 honorees we’re a graduate of techstars and located in bostons fort point near south station

the jebbit platform enables marketers and others to create branded personalized mobile experiences to engage profile and convert any audience while allowing them to leverage the usergiven declared data to activate and personalize marketing for their customers

responsibilities
work with department and team leads to expand our architecture’s scalability
build pocs for etl and other highbandwidth services to help discover problems early
help design instantiate and maintain data storage setups for analytics and data science
troubleshoot all parts of the data pipelines as necessary
interact with product and client teams to better understand the market and what roles our technology plays in it
qualifications
enjoys solving complicated technical puzzlesissues
effective verbal and written technical communication
5 years as a software developer working on movement and storage of large data sets
previous work with redshift elasticsearch and aws datapipeline a plus
ability to program in ruby and javascript also are pluses
willingness to learn and try new things
perks
relaxed office culture
weekly lunch and learns to encourage developer and team growth
flexible schedule and wfh policy
side projects are encouraged

no recruiters please",,MA,False,data_engineer
Data Engineer - Technology Startup,"110000  130000 a yearare you interested in working for a cool startup focusing on using data that helps our unique client base make better business decisions are you looking for an innovative creative fastmoving environment that lives and breathes data using the newest tools

what is the job

as a member of our growing engineering organization you will work very closely with our data scientists to reach our product goals by owning and maintaining our etl and data pipeline processes you will build out extensive highperformance and secure data extraction processes as well as the reporting platform that delivers actionable insight to our clients

within this role you will work heavily with apis and leverage aws as well as thirdparty tooling to solve challenging problems the distributed systems you will develop will take on issues such as scale and performance the platform you and your team will build will have a direct impact on our product and customers

who are we

we are one of the fastest growing startups in the data space we use sophisticated machine learning and ai for data extraction to provide predictive analytics and market insight to our client base

what skills do you need


must be experienced in a spark environment in a commercial setting
everything we do is in the cloud so you must be experienced in it preferably using spark clusters and s3
you should have a working knowledge of scala kafka and python

compensation


we offer a fully comprehensive and competitive compensation package that includes base  bonus  equity
salary range 110000130000
100 fully paid medical dental and optical coverage
too many other sweet perks to list

why should you join

this is phenomenal opportunity for an experience data engineer to join a great organization and make an impact immediately if you want to work for a company with an amazing technology culture that puts people first then come and see what were all about",120000.0,NY,False,data_engineer
Big Data Engineer,"integral ad science ias is a global technology and data company that builds verification optimization and analytics solutions for the advertising industry and were looking for a data engineer to join our team if you are excited by technology that has the power to handle hundreds of thousands of transactions per second collect tens of billions of events each day and evaluate thousands of datapoints in realtime all while responding in just a few milliseconds then ias is the place for you

what youll do

as a data engineer you will work with data scientists to take their prototypes and turn them into scalable production code these datasets will be used to train machine learning algorithms that are core to our business
work with data science product management and development teams to understand requirements and technical specifications and work as part of an agile product team

who you are and what you have

its critical that you have experience with big data and have a strong understanding of etl and batch concepts
experience with java python or scala
hadoop or similar big data tools
curiosity about new approaches like stream processing
agile software engineering

what puts you over the top

prior adtech experience
safe methodology
prior experience with statistical analysis
masters or phd in quantitative discipline
aws

about integral ad science

integral ad science ias is a global technology and data company that builds verification optimization and analytics solutions to empower the advertising industry to effectively influence consumers everywhere on every device we solve the most pressing problems for brands agencies publishers and technology companies by verifying that every impression has the opportunity to be effective optimizing towards opportunities to consistently improve results and analyzing digitals impact on consumer actions built on data science and engineering ias is headquartered in new york with global operations in ten countries our growth and innovation have been recognized in inc 500 crains fast 50 forbes americas most promising companies and icoms smart data marketing technology company ias was also named to crains best places to work in nyc for three years running great companies to work for in nys and adages list of best places to work in the us

equal opportunity employer
all qualified applicants will receive consideration for employment without regard to race color religion sex national origin protected veteran status or disability status eeoaamfdisabledvets

to learn more about us please visit httpintegraladscom  httpintegraladscom  or httpbitlyglassdoorias  httpbitlyglassdoorias 

attention agency3rd party recruiters ias does not accept any unsolicited resumes or candidate profiles if you are interested in becoming an ias recruiting partner please send an email introducing your company to recruitingagenciesintegraladscom  recruitingagenciesintegraladscom  we will get back to you if theres interest in a partnership",,NY,False,data_engineer
Sr. Data Engineer With Machine Learning,110000  180000 a yearjob summaryare you a highperforming software engineer passionate about building productionquality applications using cuttingedge machine learning algorithms our client experiments and innovates leveraging the latest technologies to engineer breakthrough customer experiences and bring simplicity and humanity to banking at the center for machine learning c4ml youll be part of an elite team accelerating machine learning solutions within by building enterpriseclass applications that solve big problems and meet real customer needsas a data engineer in c4ml you will build fast data and machine learning solutions to address some of the many complex problems in the financial services industry youll leverage full stack technology solutions including streaming big data state of the art machine learning microservice architecture distributed computation engines and intuitive visualizations in the cloud we work with several cuttingedge technologies and actively develop and contribute to the open source community you will work alongside highly technical peers with deep domain expertise from cyber threat prevention to sophisticated nlp and partner with product and business teams to deliver game changing solutions for our customersqualifications and skillsbachelor’s degree or military experienceat least 2 years of experience with python java or scalaat least 2 years of experience in deploying scalable distributed systems or multinode database paradigmspreferred qualificationsmaster’s degree or phdat least 2 years of experience with cloud software design using microservices and distributed cachingat least 2 years of experience delivering applications from architectural design to production implementationat least 1 year of experience working with machine learning deep learning or artificial intelligencejob type fulltimesalary 11000000 to 18000000 yearexperiencemachine learning 4 years required,145000.0,NY,False,data_engineer
Data Engineer - Yahoo Sports,"take yahoo and aol fuse them and you get a media and technology company operating at massive global scale it takes powerful technology to connect our combined media brands and partners with an audience of 1 billion nearly half of oath’s employees are building the code and platforms that help us achieve that and we’re only getting bigger whether you’re looking to write mobile app code engineer the servers behind our massive ad tech stacks or develop algorithms to help us process 4 trillion data points a day what you do here will have a huge impact on our business—and the world want in yahoo sports connects fans to the sports and fantasy games they love most and is the first screen for the next generation of sports fans worldwidewho crave realtime personalized quality content and superior fan experiences every day


data engineer  yahoo sports


a little about us

we are sports fans we love our teams we love our code our data our products and our people we are also relentless about improving ourselves and are looking for someone who shares our values to join our team and make us even better

a lot about you
you get data you have a thirst for knowledge and insight you thrive and strive to present data in ways that product design engineering marketing and executive teams understand and act upon your data is 100 accurate and credible your reports are always clear and actionable
you get growth you are a consumerfocused datadriven and growthenabling analyst who has supported growth strategies roadmaps scrums and final product rollouts across the analyticsinsights acquisitionreferrals activationonboarding and adoptionretention loop
you get mobiledigital you have significant industry experience – and a strong understanding of the mobiledigital ecosystem – from apps to advertising and analytics you have successfully applied the latest mobiledigital tools to help drive reach retention and revenue growth
you get it done you have successfully worked with product design marketing and executive teams to understand requirements translate business needs into data requests develop methodologiesplans analyze data and present findings that are embracedenacted


your day
use deep analytical capabilities to transform data into actionable insights and effectively present your findings to partners and executives to help make datadriven product and business decisions
provide data tracking requirements and support reporting needs
maintain a relentless focus on data quality always striving to identify logging issues and improve the accuracy of the data
work with teams to understand business problems frame the problem into questions that can be answered through data analysis formulate and implement analysis plans analyze data and deliver actionable insights
analyze and present ab test results with launch recommendations
define create monitor and improve key performance indicators kpis to aid in decision making and overall strategy
building positive relationships and trust through strong crossteam interactions ontime delivery high quality products and innovation


requirements
bsms in highlyquantitative field analytics computer science mathematics or equivalent is required
technical experience and expertise
big data technologies such as hive hadoop mapreduce pig google bigquery oozie etc
scripting with programming languages such as perlpython
comfort working in a unixlinux environment
proficiency with business intelligence tools looker tableau etc
solid understanding of computer science fundamentals like algorithms and data structures
familiarity with mysql or other rdbms is a nice to have
3 years as a data analyst generating insights for consumerfocused mobile  web products
3 years experience playing fantasy sports or active knowledge of major sports football basketball baseball hockey soccer etc
track record of proactively establishing and following through on commitments
demonstrated use of analytics metrics and benchmarking to drive decisions
excellent interpersonal organizational creative and communications skills
team player in driving growth results combined with a positive attitude
strong work ethic and strong core values honesty integrity creativity
problem solver who never stops thinking about ways to improve


oath is proud to be an equal opportunity workplace all qualified applicants will receive consideration for employment without regard to and will not be discriminated against based on age race gender color religion national origin sexual orientation gender identity veteran status disability or any other protected category oath is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment please let us know if you need a reasonable accommodation to apply for a job or participate in the application process


currently work for oath please apply on our internal career site",,CA,False,data_engineer
Data Engineer,"if you are you passionate about big data want to be part of a great team and love building new technology we want to speak with you as a data engineer you will work with our technology team to build and maintain our suite of data pipelines stores and databases that power sophisticated marketing products used by many of the world’s largest advertisers we are looking for smart and hardworking individuals who have the dna needed to build world class software the right candidates will be creative thinkers who can design and deploy professional applications using the newest technologies to solve real business problems
who you are
you have bachelor’s degree in computer science or similar
you’re a whiz in sql
you have experience with querying and loading data etl database design and query optimization
you have basic command line knowledge and git
you have dealt with large databases that contain millions of rows and know how to architect databases for performance
you can write engines that generate wickedfast sql statements
you can write sql statements and stored procedures in your sleep
you have a natural commitment to quality and thoroughness
you thrive in everchanging environments
you’re organized you manage your time well and you stand behind your work
you communicate well with coworkers of all levels
you’re confident forwardthinking who’s well versed in web and objectoriented development processes and concepts
you have a passion for learning new technologies
your drive to innovate is inspiring
what youll do
you’ll work fulltime for a great salary in a collaborative and growing privately held company
you’ll work within robust data systems and develop custom solutions while consulting with external customers
you will recommend and implement improvements to data processeswarehouses that improve supportability usability and scalability
you’ll optimize and refactor existing code
you’ll improve efficiency scalability and reliability of applications
you will use your top notch collaboration skills with other team members across all departments
you’ll participate in lively technology discussions where your opinion is truly valued
who we are…

we’re connecting travelers with experiences through best in class technology and innovation

koddi is an advanced reporting bid management and campaign intelligence software platform for metasearch publishers like google hotel ads tripadvisor kayak trivago and other travel products that enables hotel supplier ota and agency clients to reach more customers at higher returns koddi was built with the digital marketer in mind and provides a fast intuitive interface custom onthefly reporting bulk and granular bidding tools and alerting functionality",,MI,False,data_engineer
Data Engineer,"design and execute stateoftheart data systems for input data for various energy models including electric grid operations and capacity expansion and transportation and fuels modeling design implement and document data workflows ensure quality of both data and archival records perform complex operations on large datasets especially resource data time series work in a dynamic crossdisciplinary team using cuttingedge analysis and visualization techniques create new capabilities to analyze scenarios and design solutions for complex challenges in sustainable energy development to solve real world energy system design problems

the successful candidate will help to develop data architecture quality control systems datasets and archival systems especially for time series resource data inputs to electric grid operations models duties will include
integrating multiple data sources models and software tools with scientific and engineering workflows for decision support and data analysis these workflows will include the use of distributed computing and utilization of both cloud and highperformance parallel computing hpc resources
developing new methods to help researchers clients and stakeholders analyze and evaluate design strategies to implement sustainable energy solutions at various geographic and temporal scales
modeling complex systems by integrating large spatiotemporal datasets of economic demographic and energy related information
creating visualization interfaces that enable realtime examination of design scenarios as desktop immersive and web frameworks to allow for design processes by stakeholders around the world
evaluating and communicating results through written research reports for publication and presentation at seminars participating in group meetings and seminars and assisting in developing grant proposals for new research directions

the ideal candidate will bring a deep background in data analysis and programming skills to integrate various models and tools to solve complex design problems the candidate will demonstrate experience in
defining project requirements that balance constraints from the users available hardware software framework complexity etc the candidate must be willing to work in an interdisciplinary field together with computer scientists policy analysts and engineers and will require excellent interpersonal and communication skills

other required skills include
highly proficient and extensive experience with time series resource data analysis and modeling techniques demonstrated experience in management of large datasets especially spatiotemporal data
strong scientific programming and algorithm development skills and demonstrated use of python
other required programming languages sql nosql postgresql r for statistical analysis
demonstrated ability to produce scientific visualizations

this position is in nrel’s strategic energy analysis center see httpwwwnrelgovanalysis for more general information about our work and impact on the energy sector both domestically and internationally

required education experience and skills
relevant masters degree or relevant bachelors degree and 2 or more years of experience general knowledge and application of scientific technical standards principles theories concepts and techniques training in team task or project leadership responsibilities intermediate abilities and knowledge of practices and techniques beginning experience in project management good technical writing interpersonal and communication skills

preferred qualifications

submission guidelines
please note that in order to be considered an applicant for any position at nrel you must submit an application form for each position for which you believe you are qualified applications are not kept on file for future positions please include a cover letter and resume with each position application

eeo policy
nrel is dedicated to the principles of equal employment opportunity nrel promotes a work environment that does not discriminate against workers or job applicants and prohibits unlawful discrimination on the basis of race color religion sex national origin disability age marital status ancestry actual or perceived sexual orientation or veteran status including special disabled veterans

nrel validates right to work using everify nrel will provide the social security administration ssa and if necessary the department of homeland security dhs with information from each new employee’s form i9 to confirm work authorization",,CO,False,data_engineer
Data Engineer,"los gatos california
data engineering and infrastructure
netflix makes up 13 of internet traffic and were proud to deliver entertainment that over 100 million global customers enjoy behind the scenes netflix is delivered by open connect a custombuilt content delivery network that connects our content to thousands of isps around the world

decisions on how to improve streaming performance for our customers and evolve open connects architecture are driven by data were looking for someone to transform petabytes of incoming data on video performance and network efficiency into welldesigned highquality data structures that empower critical decisionmaking for teams within netflix

we track every customer action and each byte of data transferred so youll work with data at incredible scale and collaborate with bestinclass data engineers and analytic experts youll become an authority in the world of video streaming delivery no prior knowledge necessary but curiosity to learn is a must and the projects youll work on will be truly impactful
in the meantime learn more about the streaming data engineering team
what youll do
you’ll take ownership and increase automation and scale of complex data sets that drive use cases by our analytical partners such as hardware capacity planning and failure prediction understanding network topology and forecasting network traffic flow and monitoringimproving efficiency of deployment and turnover of netflixencoded assets to the network
you’ll build robust data pipelines of high data quality in a scalable fashion both data and maintainability
every video or audio file you stream from netflix started as a file living on an editor’s hard drive and became a netflixencoded asset sitting on a server ready to be played you’ll create the data pipelines that will let us quantify and understand that life cycle by merging system activity and customer behavior
we need to process data more quickly than ever to enable rapid experimentation in an increasingly nimble engineering organization you’ll help implement our business logic to be compatible with realtimestream processing frameworks
who you are
have several of the characteristicsskills listed below and have passion and selfdrive to quickly learn in areas of less familiarity we believe the experience in your years is more important than your years of experience
enjoy a high level of autonomy in managing crossfunctional engineering projects we enjoy a culture of freedom  responsibility
have experience building production data pipelines using one or more frameworks such as spark flink or hivehadoop have hands on experience with schema design and data modeling
have programming proficiency in at least one major language such as java scala or python you have a software engineering mindset and strive to write elegant maintainable code and youre comfortable working in a variety of tech stacks you may even be a software engineer with a focus or passion for datadriven solutions
have strong sql skills and knowledge and familiarity with other distributed data stores such as elasticsearch or druid
have excellent communication in sharing context to effectively collaborate with analytical partners domain experts and other consumers of your work preferably in supporting an engineering or product function we like to collaborate across teams and so should you
ambitious and willing to take action but not stubborn awareness to recognize when youre wrong and move past your own mistakes we are humbly confident in ourselves and our work
netflix culture

our culture is unique and we live by our values you will need to be comfortable working in the most agile of environments requirements will be vague and iterations will be rapid you will need to be nimble and take smart risks learn more about netflix’s culture",,CA,False,data_engineer
Data Engineer,"overview


snagajob is working to transform the hourly job seeking experience we have an unparalleled level of access to americas hourly workforce  and the employers who are desperately looking for their help to make their businesses grow as a data engineer your job is to drive the connections between these complex data entities and their underlying systems which power our marketplace

data engineers work to build and maintain systems that process amounts of generated platform data optimizing ingest pipelines and database systems that support our data platform data engineers are the glue between our latent data and our machine learning systems which build rich intelligence to power our business

what well expect



work on a high performance big data environment processing 100 million events per day
share ownership of an app portfolio with a highly collaborative development team that includes dedicated api and qa resources
explore new technologies and frameworks to drive our architecture and processes forward
use agile development practices to focus on engineering craftsmanship quality and best practices
teach and learn with the team check out the snagajob engineering blog  httpengineeringsnagajobcom 

what youll bring



2 years writing software we currently use java c and python
2 years working on big data platforms such as hadoop spark flink beam or other similar systems
2 years working with nosql databases such as mongodb cassandra dynamo or other similar systems
2 years working with relational databases such as mssql or postgres
experience with machine learning  data processing toolkits such as scikitlearn pandas juypter notebooks a plus
willingness to collaborate explore and share
desire to build inspiring data centric experiences that thrill our users
commitment to remaining curious open and active in your pursuit of the best practices
degree in computer science or equivalent experience

what you can expect from snag


snag offers a highly competitive compensation and benefits package including medical dental vision and life insurance 401k plan health and fitness incentives 20 days of pto to start and 2 days of paid community service time and a casual fun work environment with an award winning culture at snag we dont just accept difference  we celebrate it we support it and we thrive on it for the benefit of our team our products and our community snag is proud to be an equal opportunity workplace

about snag


snag is the largest platform for hourly work with 90 million registered hourly workers and 450000 employer locations nationwide with snag employers staff up faster hire smarter and keep shifts filled snags platform for hiring and managing teams allows people to land the right work while ensuring employers find the right workers when and where they need them snags flexible work platform snag work launched in 2017 and provides a network of workers the opportunity to select the shifts they want when they want from a variety of employers and locations and helps employers optimize their shifts

with offices in arlington va richmond va and charleston sc snag has been named to fortune magazines great place to work® list for eight years in a row",,VA,False,data_engineer
Data Engineer,"sun basket is the 1 healthy meal kit in the us which is backed by toptier investors and led by one of san franciscos top chefs as the company continues to explode in size 0300m arr in 3 years we are adding a data engineer to our bi and analytics team and to continue this momentum we are looking for a data engineer who is passionate about analytics has solid experience working with data warehouse possesses an innate curiosity about our business and is eager to dive into large complex data sets and ultimately create actionable business insights
sample projects
centralize data and support the analytics team to deliver worldclass insights
set up analytics data warehouse and data infrastructure and develop a flexible data model for unstructured tracking data
perform all of the necessary data transformations to populate data into a warehouse table structure that is optimized for bi reporting
work on data integration projects for onboarding new vendors such as cdps or attribution vendors can inform best practices on data taxonomy hierarchy or naming conventions
own data quality throughout all data life cycles including acquisition cleaning processing and validation
designing integrating and documenting technical components for seamless data extraction and analysis on big data platform
build an experimentation platform to help facilitate ab testing and model selectiona portion of your time will be used to maintain automated test suites using advanced frameworks
build analytics tools utilizing the data pipeline to provide actionable insights for our product and data science teams
be able to directly communicate with senior business leaders to embed yourself with business teams and to present solutions to business stakeholders

education and experience
bachelors degree in a highly quantitative field including data science computer science math engineering statistics economics and hard sciences
34 years experience with sql and relational databases such as postgres or mysql
experience with devops tools github jira
great knowledge of data warehousing principles schema design data governance data pipeline automation and query  database tuning techniques with excellent debugging and troubleshooting skills
ability to automate data pulling and reporting process
working knowledge of amazon aws services redshift aurora dynamodb s3 rds
experience with visualization software such as looker or tableau
python or r coding skill is a plus
experience with google analytics api and facebook business manager api is a plus
personality and values
ready to grow the bi team is the engine driving sun baskets stupendous growth and you are eager and ready for this job to get bigger over time
problem solver you have the ability to answer unstructured business questions and work independently to drive projects to conclusions
effective communication present and communicate analysis to stakeholders in order to drive business decisions
passion for food sun basket brings healthy nutritious meals to thousands of people every week ideally you like food and are excited to be part of that

sun basket is an equal opportunity employer and does not discriminate on the basis of race color national origin religion gender age veteran status political affiliation sexual orientation marital status or disability with respect to employment opportunities we value diversity and encourage all qualified candidates to apply

pursuant to the san francisco fair chance act individuals with a criminal background are encouraged to apply",,CA,False,data_engineer
Cloud Data Engineer,contractproven expertisesuccess building robust data pipelines for batch and realtime analytics at scale using a modern “lambda” style architecture ideally with the aws toolsetarchitecting enterprise datawarehouses migrations data cleansing modeling and normalization of raw data into prepared starschema experience with snowflake a big plus tacit knowledge of redshift and google bigquery expert level sql and json handling experience working with binary columnar data formats eg parquetorchestration and monitoring of complex etl and elt workflows using aws stepfunctions lambda coordinators and runner functions glue andor other tools eg airflow spark experience a plus ideally with emr or glue python wpyspark a plusimplementing custom kinesis applications using the kinesis api kcl and kpl using lambda polling to transformaggregate instream data and building tooling to monitor and dynamically reshard as needed light api development using aws api gateway kinesis and lambda to process pushbased events at scale 200k records per secondserverless aws architectures leveraging aws lambda with state management using elasticache memcached redis dynamodb etc with careful consideration for monitoring logging and error handlingexperience automating 3rd party cli tools shell scripting and integrating with api’s for data acquisitioncloudformation or terraform and modern cicd pipelines for automated code deploymenttestingtacit knowledge of one or more cloudcentric cots etl tools eg informatica talend matillion10 years experience in dataarchitecturerelated roles data pipelines warehousing productizing analytics preferably for large saas or online d2c businesssolid references that can speak to expertisesuccess with aboveat least bs in computer science or ee ms preferredjob type contractsalary 15000000 to 20000000 yearexperiencedata warehousing 5 years requiredsoftware development 5 years requiredanalytics 5 years requirededucationmasters preferredlocationsanta monica ca 90404 requiredlanguageenglish required,,CA,False,data_engineer
Software Data Engineer Internship,"internshipour software data engineers build systems and analytics used by health care organizations around the country for managing risk you will gain a deep understanding of structured and unstructured data sets from the health care domain as well as proprietary and industrystandard analysts calculated on this data your technical challenge will be to design develop and test a system that ingests aggregates and presents millions of records of complex health data to our customers if you enjoy programming data analysis and quickly learning your way into new areas then you are probably a good fit for this role

there will not be work sponsorship offered with this position

experience level

bachelor’s candidate in a pertinent degree eg computer science software engineering applied statistics  mathematics etc

this is an entry level position intended for but not limited to college students we will give preference to students closer to graduation as we wish this internship to serve partly as an extended interview for full time employment

there will not be work sponsorship offered with this position

business overview

milliman medinsight is one of the healthcare industry’s most highly regarded platforms for data warehousing and healthcare analytics and has been adopted by payers purchasers providers and other healthcare clients

milliman prm analytics located in indianapolis in is a product group that operates in parallel with the medinsight practice our products are used by health care administrators medical directors health care providers and others to manage the clinical and financial risk in a patient population

milliman inc is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color sex sexual orientation gender identity religion national origin age protected veteran status disability status or other characteristics protected by law

position description

our software data engineers build systems and analytics used by health care organizations around the country for managing risk you will gain a deep understanding of structured and unstructured data sets from the health care domain as well as proprietary and industrystandard analysts calculated on this data your technical challenge will be to design develop and test a system that ingests aggregates and presents millions of records of complex health data to our customers if you enjoy programming data analysis and quickly learning your way into new areas then you are probably a good fit for this role

the software data engineer is required to work in the indianapolis in office of milliman

this position is intended to represent a summer internship opportunity during a college break for candidates not attending college this could represent an approximately six month long internship

responsibilities

on a daily basis you will

write code to maintain and enhance dataanalytics pipelines
strive for fault tolerant processes and scalable solutions
understand and work with complex data structures and advanced analytics
work with teammembers to propose technical solutions to business problems
contribute to the growth of your team by sharing knowledge
minimum qualifications

bachelors candidate in a pertinent degree eg computer science software engineering applied statisticsmathematics etc
communication that is clear logical and cordial
a helpful collaborative and teamoriented attitude
insatiable appetite to learn
professional poise
grit to make it through the difficult problems
pride and ownership to want to make everything better
desire to work with code and data
basic statistics and an intuition for data
basic software development principles eg dont repeat yourself
toolstechniques we utilize and will teach as needed ie candidates are not required to know any of these

git and github
python
r
apache spark
jenkins
saltstack
kanban workflows
why milliman

milliman is a global consulting and actuarial firm and a recognized leader in the markets we serve we owe our standing to the quality of our consultants and employees who are among the most satisfied in the industry

milliman offers talented and selfmotivated individuals a place to achieve and grow our entrepreneurial environment rewards excellence and innovation our unique culture creates an atmosphere where bright employees have the opportunity to produce superior work and can chart their own careers with our clientfocused approach and unmatched depth and breadth of expertise milliman delivers practical solutions to challenging futureoriented business problems
qualifications
behaviors

preferred
dedicated devoted to a task or purpose with loyalty or integrity
team player works well as a member of a group
motivations

preferred
growth opportunities inspired to perform well by the chance to take on more responsibility
education

preferred
bachelors or better in applied statistics or related field
bachelors or better in computer science or related field
bachelors or better in software engineering or related field

equal opportunity employerprotected veteransindividuals with disabilities
the contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant however employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by the employer or c consistent with the contractor’s legal duty to furnish information",,IN,False,data_engineer
Data Engineer,"job description

we are looking for an ensusiastic databig data engineer to join our growing team of data services experts
the hire will be responsible for building and optimizing our data provisioning architecture around initiatives supporting visa productsthe candidate must have the ability to think both strategically and tactically to enforce global architectural principals while tuning sql performance at the detail level an understanding of data warehousing olap oltp naming standards data federation governance and metadata is key to this position the ability to work independently and learn quickly is essential the role offers great opportunities to learn various tools and technologies used in a sophisticated data architecture within the business intelligence and analytics data services team in data products development organization
responsibilitiesduties
handson execution as well as leadership of the following
assemble large complex data sets that meet functional  nonfunctional business requirements
create and tune complex sql for views across federated sources including hadoop db2 and oracle
collaborate with product management  product owners on defining user experience demos and training
collaborate with bi report developers on design for optimal performance
assist on data analytics projects involving data modeling and architecture
assist on building integration with other data  metadata tools in the architecture
assist on some database administration tasks for the data virtualization platform
use business requirements to document clear and concise technical designs
maintain design and naming standards
contribute to project planning discussions provide status updates for development progress and be a critical resource for issue resolution

qualifications

bachelors degree in computer science or related discipline
experience with big data tools hadoop spark kafka etc
minimum 3 years of experience writing and tuning sql
experience with rdbms technologies db2 oracle
experience with sqlonhadoop preferred hive impala
familiarity with web services apis and related architectures
excellent written and oral communication skills
experience with basic windows and linux administration is a plus
experience in agile development methodology  scrum is a plus
additional information

visa will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of article 49 of the san francisco police codeall your information will be kept confidential according to eeo guidelines",,CA,False,data_engineer
"Data Engineer - Quality, Cleansing, Process","about the role  
do you like helping customers and partners solve technical problems would you like to do this using the latest cloud computing technologies do you have a knack for helping people understand technology
if the answer is yes logic2020 is looking for a data engineer to join our seattleareabased team this is a great opportunity to have a positive impact on a variety of different key areas in the company the role will be responsible for providing technology services to a major local client through a managed cloud service offering
about you  
the ideal candidate is someone who
enjoys engaging with people
relishes taking on challenges
has a continuous thirst for knowledge and is a perpetual learner
strives to make themselves and everyone around them better
has a passion for technology
improves processes and approach in large it organizations
quantifies the efficiency of your own work and works towards success
validates consistency accuracy and completeness of the data identify patterns in systematic data issues and propose robust solutions
applies your 6 sigma skills in it
qualifications  
identified data issues performs rca and provides optimal solutions
creates an overall picture of old new and potential data issues  across the organization and conceptualizes solutions  then works with the team to implement
quantifies the impact of the data cleansing efforts
master certified in six sigma
consulting experience
mdm  master data management
dmm  cmmi certification
sql
about the team  

work within a team focused on overall corporate strategy in shared service engineering teams

about logic2020  

logic2020 is one of seattle’s fastest growing full service consulting firms our core competency is creating simplicity and efficiency in complex solutions although we make it look like magic we succeed by combining methodical and structured approaches with our substantial experience to design elegant solutions for even the most intricate challenges our rapid growth is in response to our ability to deliver consistently for our clients which is directly related to the quality of the people we hire

the past three years we’ve been in the top 10 “best companies to work for” … why our team members are highly selfmotivated comfortable conceiving strategies on the fly and enjoy working both individually and as part of a team our environment is very highenergy and demanding and individuals with remarkable enthusiasm and a cando attitude are joining our team we have lots of fun focus on our employees and our clients and work to bring our best to every opportunity",,WA,False,data_engineer
Data Engineer – Big Data/Python,"110000  135000 a yearus citizens  green card holders only
no c2c
candidates will work on capgemini w2
pay can range from a 110k base to 135k base
title data engineer – big datapython
location nyc ny

job responsibilities
must have skills
senior developer who has indepth knowledge of big data predictive analysis including relational data mining neural network nearest kneighbor association rules time series regression trees and sequence clustering
extensive experience in python programming worked extensively on aws hadoop ecosystem tools and concepts like hive nosql spark scala hbase sqoop map reduce pig excellent command over sql and relational databases including writing complex queries data transformation conversion on big data
good hands on development of etl packages
nice to have skills
tableau for data visualization",122500.0,NY,False,data_engineer
Data Engineer,"company spotx inc
requisition id 24222

we’re spotx one of the toprated companies to work for in colorado if you would like to learn more about us our team is inviting you to join us for one of our events

spotx engineering recruiting open house
sustaining our communities hackathon

spotx is seeking a talented data engineer who can contribute brilliantly to our data intelligence team located in broomfield co our team solves problems important to the business giving the opportunity for high impact

the data engineer role will interface with business product owners and the data analytics team to deliver timely and quality data sources in support of reporting through software like tableau and superset

we don’t believe in “culture fit” we believe in you being a genuine human being and pleasant to work with sure we might share a beer at work or after work but you don’t have to you just need to be a contributing member of our team who is thoughtful and wants to do quality work

making an immediate impact
develop and maintain accurate and robust data sources from very large datasets
work closely with the data analyst team in development and support of reporting
root cause and corrective action assessments of data discrepancies often with minimal information
support software creation maintenance and enhancements
work with management and product team in accurately planning and executing sprints
perform additional duties assigned by management

needed spotx’er talents
bachelors degree ba from fouryear college or university
2 to 3 years experience working in big data
strong knowledge in python and mysqlhqlsql
knowledge of hive and spark
comfortable working in a linuxmac development environment
possess strong analytical skills with the ability to analyze raw data
effectively manage multiple tasks large and small delivering accurate and timely data
work independently in a fastpaced environment often without formal requirements and with minimal supervision
be a highly motivated selflearner
have excellent verbal and written communication skills

bonus spotx’er talents
ad tech experience
druid ingestion experience
airflow dag creation experience
scala experience

spotx perks
worklife balance
unlimited ptowork it out with your team first company closed from christmas to new years
make a real difference  your code reaches millions of people as soon as you release it
work in a fun casual team environment – flip flops ok
frisbees foosball table and ping pong
benefits such as medical dental and 401k

spotx is the leading global video advertising platform that enables media owners and publishers to monetize premium content across desktop mobile and connected tv devices

visit our about us page to learn more",,CO,False,data_engineer
Big Data Engineer,150000 a yearcontractwe are looking for talented software engineers to join our bigdataservices development team your past experience matters but more important to us is what you can do going forward if you are technically talented and have the tenacity to build upon your current skill set then we want to talk to you the ideal candidate has both a willingness and desire to work in a dynamic environment and is a selfmotivated developer who mentors and shares knowledgeresponsibilitiesdefine ideal architecture evaluating tools and frameworks standards  best practices for implementing scalable business solutionsimplement batch and realtime dataingestionextraction processes through etl streaming api etc between diverse source and target systems with structured and unstructured datasetsdesign and build datasolutions with an emphasis on performance scalability and highreliabilitycode test and document new or modified datasystems to create robust and scalable applications for dataanalyticsbuild datamodel for analytics and application layersworking closely with multiple teams and business partners for collecting requirement and providing optimal solutionrequired knowledge and skillsproven experience on hadoop cluster components and services like hdfs yarn zookeeper ambaricloudera manager sentryranger kerberos etcability to participate in troubleshooting technical issues while engaged with infrastructure and vendor support teamsexperience in building streamprocessing systems using solutions such as kafka storm or sparkstreamingproven experience on bigdatatools such as spark hive impala polybase phoenix presto kylin etcexperience with integration of datafrom multiple datasources using etl tool such talend etcexperience building solutions with nosql databases such as hbase memsqlstrong experience on database technologies datawarehouse datavalidation  certification dataquality metadata management and datagovernanceexperience with programming language such as javascalapython etcexperience implementing web application and web services apis restsoapsummary 1 hive – must have2 hbase mo sql – nice to have3 spark sql – must have required 1004 python – nice to have5 java background a plusjob types fulltime contractsalary 15000000 year,150000.0,CA,False,data_engineer
Data Engineer,"contractjob title data engineer



terms 6 month contract

about trianz
trianz is a global professional services firm committed to enabling leaders to develop and execute operational strategies leverage new business and technology paradigms and achieve results expected by senior management in their organizations predictably

what we stand for
our clients are transforming their businesses competitive strategies product and service portfolios customerpartneremployee interactions and their ecosystem the cost of misses is not financial alone but a lost window of opportunity so getting things right the first time is absolutely critical

as a result trianz is focusing on three important themes in our engagement model with clients
crystallize business impact from a top management point of view
help clients achieve results from strategyby making execution predictable through innovative execution techniques
create a positive enriching partnership experience in everything we do

industries clients  practices
trianz works with clients across high technology banking insurance manufacturing retail telecom ebusinesses and public services most clients are fortune 1000 organizations and our relationships are sponsored by senior leaders in enterprise analytics sales finance marketing human resources operations and information technology we partner with our clients to address the following key service areas

cloud
analytics
digitization
infrastructure
security

job description
need to have 3 years of experience

strong data engineer able to
strong sql and relational database experience
strong python
customer has pyspark environment so you need to have spark experience as well you can also have sparkscala as long as you have the python experience
those who are shortlisted will be given a a problem and need to walk through the solution

in person discussion at sanjoseca


we are growing rapidly 20172018 highlights
trianz is growing above the average of the professional services industry here are some highlights

voted significantly above other services firms by 90  of clients for business impact execution predictability and organizational commitment in the recent trianz wide client satisfaction survey

won the “customer obsession award” from amazon web services for our innovation and execution record in cloud infrastructure and business applications strategy and services

won unicom awards for the 1 digitization and 1 analytics project over a wide array of competition

featured by idc in their spotlight series under the theme of “operationalizing strategies through execution excellence a new paradigms in technology delivery”

achieved 50 revenue and employee growth compared to prior year’s exit showing an increasing acceptance of our models and success from our differentiated methodologies in strategic execution

talk to us join us  develop into leaders
come join a dynamic global company we are an open nonbureaucratic and nononsense culture we believe in a culture of innovation encouraging our people to create we believe training and development of all our associates is the most important thing we can provide to our talent we are investing heavily in classroom online and on the job training seeing our talent develop into leaders is what’s fundamental for everyone at trianz
 we are hiring at all levels of trianz and we are hiring globally so if you have a passion for execution and would like to develop into a leader capable of taking on anything or are already a leader talk to us
 equal opportunity employer
trianz does not discriminate on the basis of race color creed national or ethnic origin gender religion disability age political affiliation or belief disabled veteran veteran of the vietnam era or citizenship status except in those special circumstances permitted or mandated by law",,CA,False,data_engineer
Senior Data Engineer,"250000  300000 a yeara million people a year die in car collisions around the world that number can be zero you can help us build an insurtech company that uses the latest technology data science and behavior modification methods to save lives by preventing car collisions before they happen to this end we helped launch hiroadcom a cloud native insurance solution that rewards people for the act of driving well we are a well funded team of elite developers data scientists and business people who truly care about making a difference in the world located in the financial district of san francisco the field is rich with data and we will be pushing the boundaries of what is possible with it if this sounds like a match for you and what you are up to please apply wed love to hear from you
skills and requirements
youve built streaming data applications using open source tools
youre deeply familiar with the smack stack and scala
youve deployed machine learning models in production
you are a solid software engineer
ideal but not required
you have been responsible for supporting largescale dataintensive deployments and have the scars to prove it
you know how to put together a machine learning model
you have wrangled trip data location accelerometer gyroscope etc
more details
salary we invest in firstrate people and pay topofmarket salaries for most positions factoring in experience and talent we are unable to offer equity
benefits full medical dental vision coverage 401k daily catered lunch wellness reimbursement  onsite shower four weeks of vacation six weeks of parental leave panoramic views and more
location near montgomery street bart station san francisco california locals preferred but relocation within the us considered for outstanding candidates
all are welcome at blue owl we are an equal opportunity and affirmative action employer who values diversity and inclusion and looks for applicants who understand embrace and thrive in a multicultural world we do not discriminate on the basis of race color ancestry religion sex national origin sexual orientation age citizenship marital status disability gender identity or veteran status pursuant to the san francisco fair chance ordinance we will consider for employment qualified applicants with arrest and conviction records",275000.0,CA,False,data_engineer
Data Engineer,"about scoop

scoop brings coworkers and neighbors together to enjoy a smooth carpooling experience—unlocking new opportunities to create friendships improve their wellbeing and make the most of their valuable time

learn more in forbes httpswwwforbescomsitesmiguelhelft20171108with36millioninfinancingscoopwantstomakecarpoolingmainstream

engineering  scoop

few companies get to face such diverse technical challenges as scoop and we’ve built a team of people excited to face these challenges together while investing in each others’ growth

scoop’s engineering team may move bits and pixels but we also put real live human beings in cars together we’re touching problems academics have written about for years and have data that no other company has ever collected

but scoop knows engineering is not a lone discipline we’re a small team with varied backgrounds big companies vcbacked startups bootcamps academia we like to build together and we like to learn together our entire team and process are built around helping you grow and be successful and we’d love to tell you more about the impact you could have at scoop
in this role you will
architect develop and deploy infrastructure on which data moves
operationalize machine learning—from research into faulttolerant productionscale deployments
apply grit and inventiveness both in writing new software and also deploying existing tools like airflow spark
work closely with data scientists and scoop’s product team to understand their needs and create a platform that empowers them
you should
have experience with building and deploying large scale etl pipelines
previously have worked in a datadriven company
know the many pain points of aws
be proficient in python andor scala
life  scoop

founded in 2015 and based in downtown sf our team mixes technology and elbow grease every day with one statistic in our crosshairs 80 of americans drive alone to work at scoop we envision a world where commuters feel empowered — starting with a choice to make their commute a meaningful part of their day we embody that same spirit within our own culture empowering every team member to make this the most meaningful experience of their career

walk into scoop and you’ll find a furry tailwagging welcoming committee in many ways these fluffy faces exemplify the energy that flows through our office they are a reminder that while we’re focused and driven we shouldn’t take ourselves too seriously they also help bridge the gap between our homes and our workplace just like a scoop carpool

the atmosphere overall is dynamic and unique it’s influenced by our backgrounds at successful startups big tech companies and premier consulting firms — blended and crafted into what feels natural and right for this company it plays out in our balance of scrappy and strategic frameworks and fast thinking

at scoop we’re all united by our desire to change the way people get to work — and committed to enjoying the journey together along the way",,CA,False,data_engineer
Data Engineer,"the role
come help us and our customers learn about the world through data with industry leading companies using insights gleaned from our data to understand how purchase and travel behavior is changing in america the ability to marshall the volume and complexity of our data is paramount

as the data science team’s first data engineering hire you will be responsible for scaling our operations for deep internal analysis and customer deliveries to handle the next stage of growth while prioritizing data security and user privacy you will design implement and maintain the infrastructure on which our data move you will develop predictive modeling pipelines for scientists and data models that enable nontechnical colleagues to ask questions of our data you identify and vet new technologies that will help us ingest and transform data

you
you are deeply curious and are passionate about building tools that become vital you creatively work through problems and have the natural itch to follow obstacles to their root cause you are expert at building data products that empower users you think deeply about the problems ahead and are comfortable moving between tools in your toolbelt and you are quick to learn implementing new approaches when facing questions that demand it

you are comfortable being the decision maker and relish the opportunity to take ownership of challenges you are passionate about helping others make sense of data and are excited to shape our long term data strategy you are a strong advocate for data best practices within the company

requirements

expertise in designing and building pipelines in a distributed environment spark hadoop managing data flow kafka loading data into warehouse platforms redshift snowflake and traditional data stores sql
strong experience in a scripting language python scala
familiar with working in a cloud environment aws
bachelors in computer science related discipline or equivalent experience
3 years of experience managing and manipulating large data sets
excited by a high learning curve
excellent written and oral communicator

compensation and benefits

highly competitive salary and benefits
stock grants preipo at a company backed by top investors
take unlimited responsible vacation

about us
edison provides intelligent email solutions for users and competitive intelligence for businesses the largest most valuable and as yet untapped data on earth is in mail 3x larger than the worldwide web through our user base of more than 3 million users we empower investors brands and technology companies to understand trends in the marketplace and gain deep insights into consumer behavior patterns

as a team we’re collaborative engaged and committed to continually improving as we serve our mission none of us are on an island we trust our teammates to lend a hand when we’re stuck and our egos take a backseat to figuring out the best approach to tackling problems we’re energized by tough problems and are excited to know that a challenge ahead of us does not have a textbook solution finally we’re always in a posture of learning there is a lot we do not know but that does not hold us back from making an attempt at solutions we lead thorough blameless postmortems to become better analysts scientists and leaders",,CA,False,data_engineer
"Data Engineer, Finance","niantic’s engineering team seeks a data engineer to create a finance data analytics warehouse that supports pokémon go ingress and harry potter wizards unite and the hosted real world platform underpinning these niantic engineering leads the advancement of ar and other immersive technologies while creating engaging apps for a user base in the billions

responsibilities
create and maintain data warehouses
work with finance to overlay calculations
provide technical implementation and support
use etl technologies to cleanse load and transform data for financial analysis and accounting purposes
qualifications
you have a bachelor’s degree or above in information systems computer science or related field
you have previous experience with etl solution
you have 2 years of experience with sql  query logic
you have 2 years of work experience building software in a professional team setting
you have a proven record of being comfortable with large volumes of complex data
you are proficient at coding in python
plus if
you have prior experience with financial analysis andor accounting systems
you have experience with data modeling
you have experience with netsuite
join the niantic team
niantic is the world’s leading ar technology company sparking creative and engaging journeys in the real world our products inspire outdoor exploration exercise and meaningful social interaction

originally formed at google in 2011 we became an independent company in 2015 with a strong group of investors including nintendo the pokémon company and alsop louie partners our current titles include pioneering globalcontrol game ingress and recordbreaking ar game pokémon go our third title harry potter wizards unite is currently in development

niantic is an equal opportunity and affirmative action employer we believe that cultivating a workplace where our people are supported and included is essential to creating great products our community will love our mission emphasizes seeking and hiring diverse voices including those who are traditionally underrepresented in the technology industry and we consider this to be one of the most important values we hold close

were a hardworking fun and exciting group who value intellectual curiosity and a passion for problemsolving we have growing offices located in san francisco sunnyvale bellevue los angeles tokyo and hamburg",,CA,False,data_engineer
Data Scientist,"job description
would you like to be part of a team focused on improving customer experience as well as helping amazon save lots of money are you passionate about data

as a data engineer with global it’s finance business operations team you will be working in a large extremely complex and dynamic datadriven environment we are looking for data engineers with expertise and passion for analyzing data designing and building predictive and decision models and designing metrics to measure the performance of the business you will interact with business groups that rely on the metrics and the decisions produced using predictive models

key responsibilities of the role include
interface with business customers gather requirements and deliver complete reporting solutions
own the design development and maintenance of ongoing metrics reports analyses dashboards etc to drive key business decisions
develop a deep understanding of our vast data sources and know exactly how when and which data to use to solve particular business problems
work with internal stakeholders to root cause identified defects

basic qualifications
bachelors degree or higher in an analytical area such as computer science physics mathematics statistics engineering or similar
demonstrated ability in data modeling etl development and data warehousing
strong verbalwritten communication and data presentation skills including an ability to effectively communicate with both business and technical teams
experience with big data
preferred qualifications
industry experience as a data engineer or related specialty eg software engineer business intelligence engineer data scientist with a track record of manipulating processing and extracting value from large datasets
coding proficiency in at least one modern programming language eg python java scala
experience building data products incrementally and integrating and managing datasets from multiple sources
linuxunix including to process large data sets
strong ability to interact communicate present and influence within multiple levels of the organization
masters degree
excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions",,WA,False,data_engineer
Data Engineer,why work herearkatechture began in 2012 with a passion for data business and getting things done we are a team of data lovers and technical experts who use our skills to help businesses big and small harness utilize and optimize their data at arkatechture we work hard and we play hardwe genuinely love what we do and thats what makes us differentwe take great pride in being new englands data resource weve been based in maine and new hampshire since our founding and have no plans on leaving we love being a part of our communities and many of our team members are involved in local activities and organizations we offer a competitive benefits package that includes health and life insurance an annual bonus based on company performance and paid time offthe positionarkatechture is seeking candidates for a data engineerposition to support various data initiatives for our clients particularly in the data warehousing and bi world we are looking for a selfstarter who is passionate about data and excited to work on new and emerging technologies the ideal candidate is someone who understands and has implemented full endtoend data warehousing solutions including data architecture data provisioning data integration data publishing and can execute effectively as part of a team must have handson experience working on bi and data warehousing projects should be able to work effectively with the business and technology teams while collaborating with projectprogram managersresponsibilities sourcetotarget mapping including detailed business and transformation rules data modeling data profiling data quality analysisremediation database table index and view creation designing developing testing and review of code elt or etl views stored procs etc communicating with both technical and nontechnical collaborators requirements elicitation estimation and working with project manager on task allocation additional responsibilities as assignedminimum qualifications bachelors degree in computer science or related major 1 to 3 years of experience in a similar individual contributor role 2 to 4 years of experience in a leadership role implemented several data management projects for data lakesdata warehousing hands on experience using etl tools like talend alteryx alooma matilion informatica datastage etc experience in any one programming language like python javascript c java etc experience working on any one database such as snowflake sql server oracle aurora postgresql mysql etc excellent sql skills and understanding of database models and tuning experience working with apis specifically rest apis sdks and cli tools as part of etl provisioning experience working with multiformat files likes json xml csv flat etc exposure to cloud technologies such as aws azure or gcp certified practitioner at any level is a nice to have strong understanding of microservices architecture a strong understanding of agile software development life cycle and methodology using toolsets such as jira confluence etc exposure to nosql databases like mongodb or dynamodb nice to havethis position is based out of our portland me office this is not a telecommuting or hardware it positionhow to applyplease send a cover letter along with your technical skills resume must have prior project experiences listed along with technologies used and salary requirements with your application if you do not currently live in the portland me area please explain your relocation plans in your cover letter you must submit all requested documents to be considered for the positionjob type fulltimeexperiencerest apis sdks and cli tools 2 years requiredmicroservices architecture 2 years requiredexcellent sql skills and understanding of database models 2 years preferredjson xml csv flat etc 2 years requiredaws azure or gcp 1 year preferredleadership 4 years requiredpython javascript c java etc 2 years preferredsimilar individual contributor role 3 years requiredsnowflake sql server oracle aurora postgresql mysql etc 2 years preferredtalend alteryx alooma matilion informatica datastage 2 years preferredagile software confluence jira 2 years preferrededucationbachelors requiredlocationportland me requiredwork authorizationunited states required,,ME,False,data_engineer
Data Engineer,"description

about us
founded in 1962 raymond james financial inc is a fortune 500 diversified holding company providing financial services to individuals corporations and municipalities through its subsidiary companies engaged primarily in investment and financial planning in addition to capital markets and asset management headquartered in florida raymond james financial has approximately 7500 financial advisors in 3000 locations throughout the united states canada and overseas with 119 consecutive quarters of growth and service 1st culture raymond james financial aims to be the premier alternative to wall street

about the role
as a data engineer you will be part of the data engineering team building enterprise data integration solutions and working on enterprise class data integration initiatives our vision in information technology is in parallel with the firm’s vision we strive to be the premier provider of financial services technology and support through innovative solutions reliable performance and a service 1st culture besides our headquarters in st petersburg fl we also have presence in southfield mi memphis tn and denver co


responsibilities
builds scalable and reliable data integration solutions which are flexible scalable and elasticdevelops low latency data integration solutions to provision data near real time for multiple consumerscollaborates with data engineers data architects and service developers to build optimal and efficient etl and database codeproduces dynamic data driven solutions to support the strategic business goalsfocus on designing building and launching efficient and reliable data infrastructure to scale and compute to meet business objectiveshelp develop an enterprise scale data lakedesign and develop new systems and tools to enable folks to consume and understand data fastersupports etl batch processingprovides oncall support of data integration batch processes on a rotating basis and other oncall as requiredproduces dynamic data driven solutions to support the strategic business goalsperforms other duties and responsibilities as assigned

qualifications

qualifications
minimum of a bachelor’s degree in computer science mis or related degree and five 5 years of relevant development or engineering experience or combination of education training and experienceexpertadvanced level experience with etl tools odi preferablyexpert level experience with oracle as a database platformdeep experience in sql tuning tuning etl solutions physical optimization of databasesexperience or understanding of programming languages like python java r etcexperience or understanding of big data platforms

licensescertifications
none required

competencies and behaviors
analysis identify and understand issues problems and opportunities compare data from different sources to draw conclusionscommunication clearly convey information and ideas through a variety of media to individuals or groups in a manner that engages the audience and helps them understand and retain the messageexercising judgment and decision making use effective approaches for choosing a course of action or developing appropriate solutions recommend or take action that is consistent with available facts constraints and probable consequencestechnical and professional knowledge demonstrate a satisfactory level of technical and professional skill or knowledge in positionrelated areas remains current with developments and trends in areas of expertisebuilding effective relationships develop and use collaborative relationships to facilitate the accomplishment of work goalsclient focus make internal and external clients and their needs a primary focus of actions develop and sustain productive client relationships",,FL,False,data_engineer
Data Engineer,temporaryone of our largest retail client is looking for experienced data engineerdescriptionvery strong engineering skills should have an analytical approach and have good programming skillsprovide business insights while leveraging internal tools and systems databases and industry dataminimum of 5 years’ experience experience in retail business will be a plusexcellent written and verbal communication skills for varied audiences on engineering subject matterability to document requirements data lineage subject matter in both business and technical terminologyguide and learn from other team membersdemonstrated ability to transform business requirements to code specific analytical reports and toolsthis role will involve coding analytical modeling root cause analysis investigation debugging testing and collaboration with the business partners product managers other engineering teammust havestrong analytical backgroundselfstartermust be able to reach out to others and thrive in a fastpaced environmentstron background in transforming big data into business insightstechnical requirements knowledgeexperience on teradata physical design and implementation teradata sql performance optimizationexperience with teradata tools and utilities fastload multiload bteq fastexportadvanced sql preferably teradataexperience working with large data sets experience working with distributed computing mapreduce hadoop hive pig apache spark etcstrong hadoop scripting skills to process petabytes of dataexperience in unixlinux shell scripting or similar programmingscripting knowledgeexperience in etl processesreal time data ingestion kafkanice to have development experience with java scala flume pythoncassandraautomic schedulerrr studio sas experience a plusprestohbasetableau or similar reportingdash boarding toolmodeling and data science backgroundretail industry backgroundeducationbs degree in specific technical fields like computer science math statistics preferredadditional job detailspotential cth must havesexcellent knowledge and experience with hive and sqlexperience with spark sqlproficientwith one programming language javascalapythongeneralunderstanding of how to build end to end data pipelines good to haveexperience n architecting data pipelines – from data model to the jobs and the sequence of jobsability to build dashboards with tableau or thoughtspotsoftwareengineering knowledge – ability to build web applications using javajob type temporaryeducationbachelors preferred,,CA,False,data_engineer
Data Engineer - Advanced Analytics and Data Science,"how would you like a career where you get to use your best analytical skills to make a substantial difference in the wellbeing of people across the globe bring your skills and talents to lilly and our advanced analytical and data sciences organization where you’ll have the opportunity to make an impact on the lives of patients
as an innovation driven company we work to discover and bring lifechanging medicines to those who need them improve the understanding and management of disease and give back to our communities through philanthropy and volunteerism

our advanced analytical and data sciences organization is growing to support the entire lilly enterprise from discovery to development to manufacturing and commercialization of our medicines to solve the complex problems of a global business and the everevolving data and analytics landscape the organization generally requires advanced degrees in statistics mathematics econometrics operations research and computer science we are playing a leading role in transforming the way the company discovers and develops new treatments identifies personalized treatment regimens drives efficiency in our operations and optimizes our commercialization of new products we are doing this with an emphasis in the areas of machine learning and artificial intelligence natural language processing and other approaches to unstructured data advanced mathematical and predictive modeling visual analytics and more whether you are intrigued by the research and development of new medicines or optimizing our commercializationbusiness or driving efficiency into our operations we have a position for you you will be encouraged to identify important business problems and to further your own research interests in these areas including presentations and publications at professional meetings come join us on our amazing journey to make life better

key responsibilities include
partner with key business partners and work within team to identify scope and execute analytic efforts that leverage data to answer business questions solve business needs and add business value
maintain a broad understanding of the pharmaceutical industry from discovery to commercialization and be fully engaged with teams bringing an objective voice to the table and facilitating decisions grounded in data
collaborate with other analytics team members to review and provide feedback on the analytics work being done and be willing to seek feedback from other team members about your own work
streamline and prepare data for analysis through understanding of data flow and integration
creating and driving standards for data capture storage and transformation

company overview
lilly is a global health care leader that unites caring with discovery to make life better for people around the world for more than a century we have stayed true to a core set of values—excellence integrity and respect for people—that guide us in all we do discovering medicines that meet real needs improving the understanding and management of disease and giving back to communities we also are committed to investing in our employees and supporting a culture of wellbeing —through competitive pay comprehensive employee benefit programs and training and development resources

we’re doing extraordinary things join us and you could be too

basic qualifications
master in statistics computer science biostatistics operations research mis or related areas
qualified candidates must be legally authorized to be employed in the united states lilly does not anticipate providing sponsorship for employment visa status eg h1b or tn status for this employment position
additional information
lilly is an eeoaffirmative action employer and does not discriminate on the basis of age race color religion gender sexual orientation gender identity gender expression national origin protected veteran status disability or any other legally protected status
additional skillspreferences
proficiency with one or more relevant programming languages such as r sql sas python c
deep knowledge of database structures
strong communication skills
bring an insatiable desire to learn to innovate and to challenge yourself for the benefit of patients
has a passion to learn new things such as machine learning artificial intelligence algorithms
lilly is an eeoaffirmative action employer and does not discriminate on the basis of age race color religion gender sexual orientation gender identity gender expression national origin protected veteran status disability or any other legally protected status
regionnorth america
country
usa
cityindianapolis
workplace arrangement
local
job expires14feb2019",,IN,False,data_engineer
Data Engineer,"passionate about data come noodle with us

we are accelerating our growth as our company gains increasing traction in the exciting ai for the enterprise market we are looking for talented technologists who want to be part of a worldclass team and bring with them a healthy mix of intellectual curiosity desire to learn and passion for excellence

as a data engineer you will collaborate with the noodle client service team data scientists sw engineers and ux designers as well as industryspecific experts from our clients you will be responsible for developing maintaining and testing data solutions with a wide variety of data platforms including relational databases big data platforms and nosql databases you will develop various data ingestion  transformation routines to acquire data from external data sources manage distributed crawlers to parse data from web sources and develop apis for secure exchange of data you will be involved in securing access to the data based on appropriate rights implementing data quality routines and mechanisms to flag bad data for correction and building qa and automation frameworks to monitor daily ingestion of data and provide alerts on errors and other problems

qualifications
must haves


36 years of experience with engineering data pipelines
bebtech or advanced degree in a relevant field computer science and engineering technology and related fields
excellent knowledge of relational databases like sql server postgresql or mysql
proficient with writing sql queries stored procedures and views
strong fundamentals in any programming language like c python or java
familiarity with any etl tool like ssis informatica power center talend or pentaho
excellent at writing code to parse json  html  javascript etc
passion for learning and a desire to grow – noodlers are lifelong learners

nice to haves


strong knowledge of what works and what doesnt this includes common pitfalls and mistakes when designing a data pipeline
comfortable working with both high performance onpremises sql installations and cloud instances
familiarity with hadoop and spark
demonstrated energy and passion that extends beyond your field of study – are you a computer engineer who writes poetry a mathematician who loves psychology an engineer passionate about public policy we want to build something with you
experience with and excitement for interdisciplinary collaboration

want to help shape the future of enterprise artificial intelligence

lets noodle",,CA,False,data_engineer
Data Engineer,"overview
the media solutions team at mwg is seeking a data engineer to help build out a new ad tech team we are seeking experienced full stack ad tech rock star unicorns to join us in this journey real time bidding big data machine learning  we want to take our product offering to the next levels
responsibilities
extract transform and analyze large volumes of structured and unstructured of data from various sources
architect and maintain data stores for big data
write and optimize complex sql queries for these data sets
create dashboards for visibility into these datasets
stays abreast of industry trends and tech
lead architecture and tech decisions
mentor junior team members
qualifications
3 years of development experience focusing around bigdata
3 years of development experience java scala c golang r
experience building and deploying large scale etl pipelines
degree in computer science math or equivalent experience
strong understanding of math algorithms data structures and design patterns
a desire to learn and teach others along the way
a desire to constantly push the bar to the next level
experience working on a fast pace agile team
willingness to participate on on call rotations
experience with rtb frameworks  platforms openrtb rtbkit beeswax etc
experience with machine learning tensorflow caffe2 torch
strategy and planning an ability to think ahead and plan over a 1224 month time span
problem analysis and problem resolution at both a strategic and functional level

required skills
rdms experience mysql percona
nosql experience mongodb elasticsearch redis
bigdata experience hadoop spark hive
windows linux docker",,NY,False,data_engineer
Data Engineer,"as a sr data architect at engage3 you will lead a technical team that architects builds maintains scales monitors administrates and secures engage3s retail pricing platform you will actively work in a multidisciplinary fastpaced environment your ultimate goal is to create a solid flexible stable system that enables us to deliver bestinclass analytics products to retailers and brands in the face of massive growth
this role requires a broad range of skills and abilities you will be the functional lead manage staff and do the work your primary responsibility is to enable data access data processing and data products by architecting maintaining scaling monitoring  securing
ml production system aws python
data warehouse snowflake
etl system  data pipelines
bi system tableau online
as a qualified applicant
you have planned built  managed data infrastructures in a public cloud
you have strong experience with working with tools  platforms within the aws ecosystem ec2 s3 aurora lambda api gateway etc
you have indepth experience with mysql databases and snowflakes data warehouse
you have managed a business intelligence system
you have demonstrated experience of etl developments
you are proficient in at least one programming language like python scala and java
you have familiarity with big data technologies like hadoop spark hive
you are comfortable with setting and meeting slas for data availability and quality
you have an understanding of machine learning  ai principles in data engineering
you are a mentor to your team  colleagues and have passion in sharing your knowledge
youve worked in an agile environment you thrive on iteration you make opportunities to bring value sooner rather than later
you value datadriven decisions you are always looking for opportunities to quickly produce the right data to make decisions quickly you keep cool under pressure
you are a selfdriven highly motivated technologist who can work with a high degree of autonomy is able to prioritize effectively and drive the data architecture vision",,CA,False,data_engineer
Data Engineer,"join our data engineering team and help build a scalable realtime analytics platform that processes streaming data to make our product even more intelligent own and extend our data pipeline perform data modeling and improve data reliability and quality become part of a team focused on creating innovative realtime analytics and machine learning feedback loops

responsibilities
work with the team to manage the data warehouse and etl for all of perfect world entertainment products
design build and launch new data models in production
interface with engineers from other products to ensure proper data collection
implement new requests from product managers and data analysts to fulfill their data needs
ensure data quality by implementing data detection mechanisms
support existing processes running in production and optimize it when possible



required qualifications
2 years of industry experience in a data engineer role
a bachelor degree in a quantitative field such as computer science applied mathematics or statistics or equivalent professional experience
working experience with sql python 3x and scala is a plus
working experience on an etl system
strong communication skills both written and oral and an ability to convey complex results in a clear manner


desired qualifications
working experience with machine learning and predictive analytics
familiarity with hadoop framework
experience with spark is highly desirable
familiar with data visualization through tableau or other tools",,CA,False,data_engineer
Data Engineer,"are you adept at transforming and organizing dynamic complex data do you have experience in data engineering with various types of data structures and formats our data analytics team is seeking a data engineer with strong technical knowledge and a real passion for addressing business needs through data analysis as an individual contributor on this team you will build data pipelines that use existing tools while also exploring advances in data engineering to address business questions and support enterprise level efforts you will work sidebyside with internal partners from our data analytics data science and functional teams to tackle problems and derive insight from data we’re looking for selfstarters with a solid sense of urgency who thrive when operating in a fastpaced environment the ideal candidate is comfortable wearing multiple hats – data modelingarchitecture sql  python coding data analysis and business analysis – all while looking for creative ways to solve business challenges

key responsibilities
perform data analysis to understand how well data is aligned and identify possible data quality issues present results in a way that is easy for business users to understand and consume
partner with the data analytics team and various functional partners to understand the data conversion necessary to drive analytics
design and develop relational database objects including tables views indexes etc
develop and maintain plsql code including packages procedures jobs tables triggers indexes constraints db links and functions
partner with etl team to build target tables design logical source to target mapping processes and quality test the data after etl processing
fix data and reporting issues propose solutions to meet emerging business needs
optimize the performance of the solution from coding to automation routines and identification of optimal methods for processing data
propose new solutions and technologies that could transform the way we handle data and contribute to the business
lirs1
qualification
bachelor’s degree or higher in computer science or related discipline
5 years of experience with sql database queries and programming plsql
experience programming in java or python
familiarity with data quality cleaning and masking techniques
conceptual understanding and experience with data warehousing operational data stores and etl is key including factdimension modeling and hierarchies
understanding of basic functional business concepts including headcount balance sheet and pl accounting journal entry  sub ledger
ability to communicate regarding data definitions and data quality with business users
strong alignment to data privacy standards and ethics
strong interpersonal and communication skills and a proven ability to work and collaborate in a team environment
preferred qualifications
strong communication interpersonal and collaborative skills
demonstrated analytical and problemsolving abilities
knowledge of distributed data processing and management systems
demonstrated ability to organize and incorporate complex systems requirements into product features and prioritize features effectively",,MA,False,data_engineer
LCA Technology - Data Engineer,"more about this job
what we do
at goldman sachs our engineers don’t just make things – we make things possible change the world by connecting people and capital with ideas solve the most challenging and pressing engineering problems for our clients join our engineering teams that build massively scalable software and systems architect low latency infrastructure solutions proactively guard against cyber threats and leverage machine learning alongside financial engineering to continuously turn data into action create new businesses transform finance and explore a world of opportunity at the speed of markets

engineering which is comprised of our technology division and global strategists groups is at the critical center of our business and our dynamic environment requires innovative strategic thinking and immediate real solutions want to push the limit of digital possibilities start here

who we look for
goldman sachs engineers are innovators and problemsolvers building solutions in risk management big data mobile and more we look for creative collaborators who evolve adapt to change and thrive in a fastpaced global environment
compliance technology provides technology solutions to help compliance manage the firm’s regulatory and reputational risks and enables them to advise and assist the firm’s businesses
lca tech data team is seeking java python rdmbs angular js and c developers with deep knowledge of distributed computing principles the candidate is responsible for design development deployment and support of products and platforms that leverage big data technologies and enable large scale event processing where events are inspected by machine learning and statistical policy based models successful candidate will join a team of talented and motivated developers working on strategic and highly visible projects within the firm
responsibilities and qualifications
how you will fulfill your potential
play an key role in architecting the compliance big data platform to handle storage of very large datasets design pipelines and business metrics to scale with growing trading volumes
build disruptive solutions using cutting edge technologies with measurable commercial outcomes
develop technical specifications high leveldetailed design testing strategies and implementation plans from business requirements
manage endtoend systems development cycle from requirements analysis coding testing uat and maintenancework in a fast paced environment

skills and experience we are looking for
java python rdbmssqlbig data visualization tools

about goldman sachs
the goldman sachs group inc is a leading global investment banking securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations financial institutions governments and individuals founded in 1869 the firm is headquartered in new york and maintains offices in all major financial centers around the world

â© the goldman sachs group inc 2018 all rights reserved goldman sachs is an equal employmentaffirmative action employer femaleminoritydisabilityvet",,NJ,False,data_engineer
Big data engineer,60  85 an hourcontractjob summarybig data engineer with scalaspark experience nashville tn 12 months contractmandatory skills experience coding in scala  sparkdeploying on and sing multiple components of aws cloudjob type contractsalary 6000 to 8500 hour,,TN,False,data_engineer
"Associate, Data Engineer, Healthcare","innovate collaborate shine lighthouse – kpmgs center of excellence for advanced analytics – has both applied data science ai and big data architecture capabilities here youll work with a diverse team of sophisticated data and analytics professionals to explore the solutions for clients in a platformdiverse environment this means your ability to find answers is limited only by your creativity in leveraging a vast array of techniques and tools be a part of a highenergy diverse fastpaced and innovative culture that delivers with the agility of a tech startup and the backing of a leading global consulting firm for you that translates into the chance to work on a wide range of projects – covering technologies and solutions from ai to optimization – and the power to have a real impact in the business world so bring your creativity and pioneering spirit to kpmg lighthouse
kpmg is currently seeking an associate to join our kpmg lighthouse  center of excellence for advanced analytics to work with our healthcare team
responsibilities
rapidly prototype implement and optimize architectures to tackle the big data and data science needs for a variety of fortune 1000 corporations and other major organizations develop modular code base to solve real world problems while conducting regular peer code reviews to ensure code quality and compliance following best practices in the industry
work in crossdisciplinary teams with kpmg industry professionals to understand client needs and ingest rich data sources such as social media news internalexternal documents emails financial data and operational data
develop and maintain da solutions on premise cloud kpmghosted or hybrid infrastructure be the team champion of some mainstream biedwbig data toolsets like tableau alteryx informatica pentaho erwin and power designer
help in research and experiment of leading and emerging biedwbig data methodologies such as serverless data lake aws redshift athena glue gcp bigquery and ms powerbi and apply them in solving real world client problems
help drive the process for pursuing innovations target solutions and extendable platforms for lighthouse kpmg and client
participate in developing and presenting thought leadership and help in ensuring that the lighthouse technology stack incorporates and is optimized for using specific technologies
qualifications
minimum of one year of relevant software development experience in multiple programming languages and technologies preferably related to professional services experience with objectoriented design coding and testing patterns as well as experience in engineering commercial or open source software platforms and largescale data infrastructures proficiency
with healthcare analytics and data structures is preferred
bachelors degree or masters degree from an accredited collegeuniversity in computer science computer engineering or related field
ability to pick up and learn new technologies quickly experience or knowledge of rdbms design data modeling mpp edw system implementation handson experience and knowledge in distributed computing architecture massiveparallel processing big data platforms  such as hadoop mapreduce hdfs spark hiveimpala hbasemongodbcasandra teradatanetezzaredshift
handson experience and knowledge in biedwbig data toolsets tableau alteryx informatica pentaho erwin power designer handson experience and strong knowledge in mainstream cloud infrastructures aws ms azure and gcp including their darelated microservices and ability to implement data lake and serverless data lake
marketleading fluency of sql handson experience of linuxunixwindowsnet marketleading fluency in several programming languages bashkshpowershell pythonperlr and understanding of programming methodologies version control testing qa and development methodologies waterfall and agile fullstack development capability is preferred
ability to travel up to eighty percent of the time applicants must be currently authorized to work in the united states without the need for visa sponsorship now or in the future
kpmg llp the us member firm of kpmg international offers a comprehensive compensation and benefits package kpmg is an affirmative actionequal opportunity employer kpmg complies with all applicable federal state and local laws regarding recruitment and hiring all qualified applicants are considered for employment without regard to race color religion sex sexual orientation gender identity national origin disability protected veteran status or any other category protected by applicable federal state or local laws the attached link contains further information regarding the firms compliance with federal state and local recruitment and hiring laws no phone calls or agencies please",,NY,False,data_engineer
Data Engineer,"job description
summary
provide basic project or application level team support to include business and technical solutions planning design and support to ensure the information technology it solutions strategy and architecture align with business strategy

essential job functions
acts as the subject matter expert for a project or application and serves as the system architecture authority within that scope
defines technologybased business solutions within scope of project assists project teams in the appropriate use of technology
reviews and approves design decisions within established level of authority prior to implementation
assists in advising client company management regarding it vision and strategy technology innovations and enterprise architecture services provides production problem diagnosis and technical offshore strategy and processes support to project team assists in implementing resolution
leads system design activities andor reviews system designs to assure that applications solutions will exhibit expected levels of performance security scalability maintainability appropriate reusability and reliability upon deployment
assists in the preparation of it vision and strategy work products technology and product analysis white papers and responses to management queries on technology and product related topics




basic qualifications
bachelors degree or equivalent combination of education and experience
bachelors degree in computer science information technologies or related field preferred
three or more years of information technology experience
solid knowledge of structured query language and stored functions
knowledge of python avro
knowledge of elasticsearch hadoop redis
knowledge of kafka or other streamprocessing platform
knowledge of luigi azkaban airflow or others for data workflow
knowledge of machine learning and analytical workloads nearest neighbor and other algorithms transaction theory
ability to present technical information to various audiences
understanding of the security requirements for handling data both in motion and at rest
other qualifications
excellent communication skills
interpersonal and presentation skills
analytical and problemsolving skills
organizational and time management skills to prioritize work
ability to work in a team environment
ability to set technical direction for a project or application
ability to perform within defined direction
work environment
office environment
may require occasional evening or weekend work",,FL,False,data_engineer
Data Engineer 3,"who we are

fueled by a fundamental belief that having access to financial services creates opportunity paypal nasdaq pypl is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy our open digital payments platform gives paypal’s 244 million active account holders the confidence to connect and transact in new and powerful ways whether they are online on a mobile device in an app or in person through a combination of technological innovation and strategic partnerships paypal creates better ways to manage and move money and offers choice and flexibility when sending payments paying or getting paid available in more than 200 markets around the world the paypal platform including braintree venmo and xoom enables consumers and merchants to receive money in more than 100 currencies withdraw funds in 56 currencies and hold balances in their paypal accounts in 25 currencies
when applying for a job you are required to create an account if you have already created account  click sign in
creating an account will allow you to follow the progress of your applications

note
provide full legal first namefamily name
do capitalize first letter of first and last name example john smith
dont capitalize entire first andor last name example john smith
note use correct grammar for names with multiple cases example mcdonald or oconnell

provide full address details
resume is required
multiple attachments can be uploaded including resume and cover letter for each application


job description summary
the essbase application team is looking for a full time experienced customeroriented businessfocused and analyticallydriven data engineer to support the delivery of essbase operations and project portfolios commitments

job description
the essbase application team is looking for a full time experienced customeroriented businessfocused and analyticallydriven data engineer to support the delivery of essbase operations and project portfolios commitments the data engineer will interface with teams customer and leaders alike to ensure seamless technological support of business process by ensuring the technologies we support are not an inhibitor to the business process

ensure quality  base the delivery model on best practices to drive efficiency  manage risks
operational excellence  deliver on all commitments with no business disruption
be accountable for continuous improvements
communicate effectively to instill confidence as well as build trust and strengthen partnerships

the role will be responsible for supporting global stakeholder departments and working domain leads and data citizens across different geo’s such as americas emea and asia pacific because the position requires interaction with geographicallydisbursed teams so the candidate must be a selfstarter with strong leadership qualities projecttask management skills and analytical skills and comfortable working with distributed teams without direct management oversight day to day

heshe must be able to contribute to programsinitiatives and collaborate with the financial stakeholders and users as well as eds analytical teams to drive alignment around essbase application services and support for paypal these accountabilities will be achieved through developing high trust relationships with internal and external customers critical data analysis attention to detail and a customer focus process development and optimization as well as deliverables management will be a focus for the role

essential functions tasks and responsibilities

works with paypal business units and product dev teams to design develop and deliver data solutions on one of the largest data platforms in the world
supports paypal business units by providing data in a readytouse data financial analysts data scientists and leadership for to drive decision support around critical financial business processes
owns and is accountable for the design and development of a data solution essbase or a data pipeline example cross team integration such as essbase peak and tmis to bring innovation in or supporting data aggregation for an executive dashboard or report on tpv growth trend
code is wellcommented easy to maintain and can be reused across a subsystem or feature code may persist for the lifetime of a software version code is thoroughly tested with very few bugs and is supported by unit tests
leads feature or subsystem design reviews and code reviews and be recognized as the goto developer for that component
recognized as the goto developer for a product or major subsystem and is seen as a leader in their specialized field
leads feature or component design reviews and code reviews and is fully recognized as the goto developer for that component
participates in architecture discussions proposes and discusses solutions to system and product changes that are directly related to their area of focus
responsible for managing multiple domains within an applications area providing necessary support and maintenance activities
should be comfortable working in an agile environment and with crossfunctional teams should have appetite to learn and be flexible to pick up new technology

subsidiary
paypal

travel percent
0

primary location
san jose california united states of america



additional locations






were a purposedriven company whose beliefs are the foundation for how we conduct business every day we hold ourselves to our one team behaviors which demand that we hold the highest ethical standards to empower an open and diverse workplace and strive to treat everyone who is touched by our business with dignity and respect our employees challenge the status quo ask questions and find solutions we want to break down barriers to financial empowerment join us as we change the way the world defines financial freedom


paypal provides equal employment opportunity eeo to all persons regardless of age color national origin citizenship status physical or mental disability race religion creed gender sex pregnancy sexual orientation gender identity andor expression genetic information marital status status with regard to public assistance veteran status or any other characteristic protected by federal state or local law in addition paypal will provide reasonable accommodations for qualified individuals with disabilities",,CA,False,data_engineer
Data Engineer,position descriptionpersivia is seeking data engineer who will help support our customer base as well as our development team this position requires extracting data from meditech mckesson epic and other hospital systems the qualified candidate will be a data specialist who exhibits expertise in extracting data from meditech and possess strong knowledge focus on data extracts for a quality reporting perspectivekey activitiesperform system setup and extraction of medical data from hospital’s databasesmaintain xslt sql and java scripts for mass loading and rendering of xml filestroubleshoot problems reported by customers and help solve technical issuesperform coding tasks using c net and sql javaanswer questions from customers as well as prospective customers about the features and capabilities of our solutionsdevelop customerfacing documentation for our solutions on an asneeded basiscommunicate customer needs and wishes to our product teamwork in highly secure environmentsrequired skillsexpertise in extracting data from multiple hospital systemsability to maintain and execute xslt sql and java scripts for batch loading and rendering of xml fileshandson experience working with hl7 v3 preferred xml and web servicesknowledge of relation databases sql server oracle a huge plusexperience working with hospital emrs such as meditech mckesson epic and cernerexperience working in java c net and mssqlthe ability to be a good listener and to really understand a customer problem or question and help them solve itbachelor’s degree in computer science technical field or equivalent experienceminimum 4 years of relevant work experienceexcellent written and verbal communication skillsstrong customer service skillsstrong organizational skillsjob type fulltimeexperiencesql  xslt 3 years requireddata engineering 4 years requiredemr 2 years requirededucationbachelors requiredwork authorizationunited states required,,MA,False,data_engineer
Data Engineer - Application Support Engineer: 18-03458,"contractakraya is looking for a data engineer  application support engineer for one of our clients if the job description below is a fit please apply directly or call ruhana at 4085122363 if this position is not quite what you’ re looking for visit akrayacom and submit a copy of your resume our recruiters will get to work finding you a job that is a better match at one of our many clients

primary skills big data business intelligence sql python unix
duration 012 months
contract type w2 only

responsibilities
bachelor s degree in computer science software engineering or other technical degree
3 years experience developing business critical big data solutions including datamodeling data architecture data platform development and optimization for same
3 years architecting  building business intelligence olap solutions using sql or similar
familiarity in one or more scripting languages eg python and unix
self starter who can meet critical deadlines in a fast paced environment with little direction and guidance


please apply directly with your update resume or call ruhana at 4085122363

about akraya
akraya inc is an awardwinning staffing firm that works with many of the leading technologybased companies around the world we have been ranked as one of the “ best staffing firms to temp for” by staffing industry analysts on multiple occasions and are a preferred staffing vendor within numerous staffing programs please visit akrayacom to search through all of our current openings or to submit your resume to our recruiting team",,CA,False,data_engineer
Employee Success Data Engineer,"job category
employee success


job details
we are looking for a senior analyst to support our employee success strategy  analytics organization in this role you will work with regional leaders across salesforce functions to understand business needs wrangle data from various systems and perform sophisticated analysis to develop insights and intelligence the role focuses on developing employeeorganizational insights and applications for the company leaning towards our recruiting organization it will provide the opportunity to learn the requirements and needs of a growing business focused on optimizing our organization and talent


you will have to get your hands dirty and love working with data you must be able to design an analysis approach mine the data and provide an output which can be easily understood and used by the business you will need to pull data from multiple systems to produce the analysis requested with little direct guidance and an understanding that the results may be iterative you must be able to illustrate complex analysis in a concise and simple fashion using tables charts and graphs most of all you must have curiosity and a drive to create new knowledge ways of doing things andor applications


responsibilities
work with business partners and recruiting to conduct ad hoc queries and analysis
develop and build sustainable statistical models and analysis to better understand employee behavior and data
drive the maturity of the people analytics function in the region

required skillsexperience
5 years of experience in applied statistics data mining and analysis andor management consulting
proficiency with excel sql r einstein analytics or python to conduct analysis
excellent powerpoint skills with a deep understand of graphs and visuals
strong analytical and problemsolving skills
excellent verbal and written communication skills ability to communicate effectively with different levels of management as well as the business and technical communities
extremely adept at integrating disparate information and understanding data trends
must be able to proactively communicate status and identify risks
teamfirst mentality
must be comfortable with changing requirements and priorities
must be results oriented and able to move forward without complete information and with minimal supervision
bachelor’s degree

desired skillsexperience
experience with hcm ex workday sap etc and data visualization tools  ex tableau
experience with data quality assessment and implementing solutions to improve the data quality
experience with hr technology system optimization and implementation





posting statement

salesforcecom and salesforceorg are equal employment opportunity and affirmative action employers qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender perception or identity national origin age marital status protected veteran status or disability status headhunters and recruitment agencies may not submit resumescvs through this web site or directly to managers salesforcecom and salesforceorg do not accept unsolicited headhunter and agency resumes salesforcecom and salesforceorg will not pay fees to any thirdparty agency or company that does not have a signed agreement with salesforcecom or salesforceorg",,IN,False,data_engineer
Senior Data Engineer,"fusion is currently seeking a senior data engineer to join our fastgrowing software development team the data engineering team is responsible for developing and maintaining the data processes for our clients tasks will include import and export of data data migration from legacy systems interface development reporting development as well as maintenance and support for all our existing data projects

about us

fusion was founded in 2006 and has since become a major disruptor in the corrections and public health sectors of government recognized by inc magazine as one of the fastest growing private companies in the united states fusion is looking to expand its handpicked team to include a candidate through this job placement

from a company culture perspective we are a vibrant and young group who have come together to be leaders in healthcare it and software for government agencies the office provides open working spaces several meeting areas as well as a café  gym on premise

because of the niche fusion belongs in as well as the business model we operate with we are looking for not only skilled and qualified candidates but also candidates who have an outgoing personality and fit well with our other team members

to date fusion has a phenomenal retention of our team members our fundamental belief is that employee satisfaction is critical to achieving our mission so we provide competitive compensation professional development career advancement opportunities and a supportive teambased atmosphere we also provide a full range of health related benefits including medical dental vision and 401k and we offer worklife enhancements like flexible hours business casual dress code and an easygoing corporate structure

fusion has been recognized by inc 5000 list of fastestgrowing private companies – thanks to the tireless efforts of our team if you are a talented professional and our mission speaks to you please speak to us

job roles

communicate with partner companies to develop and support bidirection data communication
migrate data for new clients from old systems to new systems
create meaningful insight with data to help our customers meet compliance standard
develop reports to allow customers to view their data in the format they request
meet with government clients to understand their environment and work with project managers to determine the optimal solution for their needs
work with project managers to create and execute a technical implementation plan for larger client roll outs
work closely with product management to understand current and new product features so they may be implemented correctly
act as a rolemodel for junior employees to help them learn industry best practices


required experience

javascript
sql plus if it is sql server
crystal reports or any comparable reporting tool
c
windows network experience
familiarity with most common structured or delimited file formats csv xml json etc
familiarity with data transfer methods sftp http tcp soap rest etc
qualifications

8 years of professional software development experience
bachelor’s degree in computer science or any itrelated field
working hours

standard hours for this role are mf start between 8 and 9 expected to put in 8 hours
willingness to provide weekly oncall coverage rotationally
additional notes

it is not expected that applicants have any familiarity with fusion’s proprietary applications ge healthcare software or correctionspublic health business processes qualified candidates will be able to demonstrate experience in this role as well a demonstration of working well with the fusion team
this is an onsite fulltime salaried position",,NJ,False,data_engineer
Product Development Data Engineer,110000  130000 a yearwe are in search of a high energy selfmotivated product development analyst with strong analytical and technical skills this role is an ideal opportunity for someone with experience and interest in a fastgrowing big data analytics environment the selected candidate by having deep understanding of our data sources will support the cimba product owner in ensuring that our platform delivers value you will work closely with teams across the company and around the world applying strong analytical skills to add definition to problems and solutions types of detailed analyses will include product valueadd discovery supplemental partner discovery support implementation team data compliancethe product development analyst belongs to the mcp business intelligence team also known as the cimba team cimba is responsible for creating a worldclass big data analytics platform for cimpress serving a diverse set of audiences throughout the company and its partners around the world the ideal candidate will be an excellent collaborator with all company functions particularly finance manufacturing technology groups and the mcp business intelligence team itself this position will be a key role in building the cimba team’s reputation as a trusted partner of our internal customers across the company evangelizing the cimba platform throughout cimpressresponsibilitiesperform data forensics to discover validate and propose solutions of data anomalies and data outliersdesign develop and deploy data integrity validation and reporting solutions in support of cimba internal monitoring as well as partner notificationsupport the cimba product owner as well as other teams with ad hoc projects and initiatives as requesteddefine required metrics and dimensions and work with engineering or other teams to improve relevant data collection and “best practices” to maintain high standards of data integrityextract appropriate information from rich data sources analyze results and present findings and recommendations when neededproduct owner responsible for managing and extending the cimpress data catalog environment to include training development product evangelizing vendor management and partner engagementbecome the goto expert in use of cimba for functional business units leveraging cimba data for analysisprofessional qualificationsbachelor’s degree in computer science database engineering or equivalent – mcs a plus610 years’ professional experience as a data analystintense curiosity ability to learn quickly and apply new tools and techniques to identify and define problems and work with business owners to resolveable to handle multiple tasks and possesses excellent problemsolving skillsoccasional travel approximately 10 to global facilitiesstrong written and oral communication and presentation skills confidence communicating openly with stakeholders in a growing global organizationexcellent communication written and verbal analytical and interpersonal skillsability to handle multiple tasks under tight deadlinesability to multitask and excellent problemsolving skillsability to work in a fastpaced team environmenttechnical qualificationsstrong understanding of statistical inferencestrong knowledge of sql ideally experience with multiple database platformsadvanced understanding of visualization technologies such as tableau qlikview tibcospotfire or lookerexperience with management and support of application to include applying upgrades custom modifications extending functionality using open source or 3rd party integrationsfamiliarity with r sas spss or other statistical packages a plusdeveloper skills sufficient to build poc solutions for data validation and notification systemswe produce millions of affordable highly customized personalized physical products for small businesses and consumers were boldly going where no one has gone before here at cimpress the scale complexity and sheer scope of what we do requires us to innovate and solve problems that havent been solved before with over 21bb in revenue and 40 offices and manufacturing facilities across the globe creating more than 46 million uniquely designed items annually that serve over 17 million customers worldwide were a unique combination of stability strength growth and innovation were also a place where ideas matter whether they come from our newest or most senior team members theres also a lot of fun that goes with doing things no one has ever done before and you can feel itjob type fulltimesalary 11000000 to 13000000 yeareducationbachelors preferredrequired travel25 preferred,120000.0,MA,False,data_engineer
Big Data Engineer - Oct 20th Drive- Locals Preferred,contractjob title  big data engineer  oct 20th drive  locals preferredlocation  fort worth txduration  6 months contractskills requiredspark with python spark streaming and sqlsqoop hive and big data conceptsshell scriptingnifi is good to havejob descriptionthe big data and predictive analytics team is seeking an individual to standardize and automate open source processes and functions primarily this position will focus on automating quality assurance testing and provisioning processes extended areas of concentration will be creating end user applications intended to expedite and automate data acquisition integration and control processesdutiesresponsibilitiesresponsible for identifying and designing automation opportunitiesbuild a working knowledge of all existing operational analytics and data pipeline methods and functionalitycreate effective and automated processes to drive efficiency and consistency across all areas of big data and advanced analytics projectswork closely with peers and leadership within technology services to develop an automation frameworkcreate an infrastructure to support continued growth in the open source environmentbasic qualificationsbachelor’s in business information technology computer science or other related discipline or equivalent work related experiencestrong personal and organizational skills to execute project deliverablesexcellent verbal and written communication skills to lead a cross functional teamproficient with automation tools and framework designexperience in automation scripting and web application developmentapache hadoop software library knowledgepreferred qualificationsmba or equivalent degreeworking knowledge of hortonworks 23 or greaterexperience in using java python scala spark shell scriptbackground in etl data warehousingjob type contract,,TX,False,data_engineer
Hadoop Data Engineer,"work closely with data scientists to identify and develop methods to collect and integrate a wide variety of data to be used in predictive analytics machine learning or other data science use case
develop data pipelines and iterative models for data experimentation using a variety of tools such as kafka hadoop and cassandra storm and spark
apply big data technologies such as hadoop spark or streams with nosql data management and related programming languages for analytics and experimentation with large multistructured data sets
design and maintain hadoop workflowsetl for all the data products
design implement or translate data science to hadoop ecosystem for scale
act as a big data consultant in recommending the right toolslibraries to solve big data problems
work closely with customer’s business engineering and executive teams using data to drive iterative analytical models
design develop quality assurance qa and maintain application code
provide thoughtleadership and dependable execution on diverse projects
position requires unanticipated travel throughout us up to 50 of time

qualifications

master’s degree or foreign equivalent in cs comp engineering comp applications or a related field and two years of experience in the following linux operating systems hadoop oracle informatica and teradata
use toolstechnologies like kafka hadoop and cassandra storm and spark and spark or streams with nosql
email resume with cover letter to careerscloudwickcom",,CA,False,data_engineer
Senior Data Engineer (REMOTE),"
senior data engineer remote


about us


with over 15 million active users and 90 million in venture funding life360 is the worlds largest mobile app for families today we are very focused on location sharing and safety but our mission is to become the musthave family membership that gives families peace of mind anytime and anywhere

our team is focused on building technology that helps families feel safe and together even when they are outside of the home and apart from personalized locationbased alerts that help make daily coordination easier to advanced sensor tech that can detect if you are in a car crash and automatically send you an ambulance we are leveraging smartphones to their fullest extent to reinvent how families get through the day

you will be joining life360 at a key moment in our history we doubled active users and tripled revenue in 2017 and we are scaling our team to accommodate this rapid growth we currently have 95 full time employees with offices in san francisco las vegas and san diego

about the job


at life360 we collect a lot of data 60 billion unique location points 12 billion user actions 8 billion miles driven every single month and so much more as our first dedicated sr data engineer you will be responsible for helping build out our data processing and storage pipelines and workflows you should have a strong engineering background and even more importantly a desire to take ownership of our data systems to make them world class

responsibilities



design and develop resilient pipelines using a variety of different technologies
manage our data from ingestion through etl to storage and batch processing
automate test and harden all data workflows using tools like apache airflow
architect logical and physical data models to ensure the needs of the business are met
participate in rotational oncall support and provide ongoing maintenance of all data infrastructure
be part of an awesome infrastructure team handling massive scale with tons of automation

requirements



always be learning and staying up to speed with the fast moving data world
minimum 4 years of experience working with high volume data infrastructure
extensive experience programming in one of the following languages python  java  scala
experience with writing sql queries performance tuning and data modeling
knowledge and proficiency in the latest open source and commercial data frameworks

were a growth company which means that youll be part of a tightly knit and highly driven team some days will be busy other days will be even busier but its never boring and the work is stimulating were looking for someone who is a star in their own right and can inspire others but at the same time roll up their sleeves and own key components of the business

perks



competitive pay and benefits
health dental and vision insurance plans
401k plan
200month quality of life perk
whatever makes you stronger makes us stronger we buy you the things you need to improve yourself and get your job done

",,,False,data_engineer
Data Engineer,at wag we build products that help dogs and their parents live more joyful lives working with our technology and engineering team is part art part skill—and all heart we like to surround ourselves with other smart people that will challenge us and bring new thinking to the team to help us build better products were all about automation and were constantly pushing the limits on what can be delivered automagically—from qa to deploying code in production our patentpending woof pack scrum structure allows us to work more independently faster and with the right level of autonomy and accountability for producing results if theres a way to integrate it into slack weve probably done it we love music food and drinks—anything that helps us be the team possible and maybe most important—we dont like to leave our dogs home alone so be ready to spend your days in the office hanging with the pupswe are moving a mile a minute to make sure that wag customers walkers and partners are able to experience the magic of wag were looking for a talented dog lover to help our data engineering team build out our trust  safety data pipeline you will help us move our data systems to the next level you will not only be working with data but also help define the way trust and safety performance is calibrated and what questions should be asked you should be excited to contribute new ideas and articulate them to a variety of stakeholders you should also be committed to learning seeking to innovate and raise the bar on how we use data for our trust and safety efforts specifically you will be responsible for the followingwhat youll be doingbuilding out a robust ts data platform from how we define ts issues to developing reporting mechanisms to share that data with key stakeholdersmonitoring and managing incident rates globally and working proactively to identify opportunities for improvements in data quality andor trust and safety effortscollaborate with crossfunctional agile teams including product marketing analytics and data science to understand design and develop data models to support business reporting and analysisassist the data services team lead in maintaining optimal data pipeline architecture and performanceresearch design and share your ideas in technical design and architecture discussionsidentify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etcbe subject matter expert of our data warehouse stack mysql alooma snowflake dbt and tableauensure compliance with international data storage regulations eg gdprship codeprovide coaching to junior data engineers and data modellers and share and learn from your peersdevelop your craft and build your expertise in data engineeringrepresenting trust and safety in companywide data efforts with engineering business intelligence and othersdesigning analytical and reporting frameworks to make complex data easy to understand and drive decision making for stakeholderswhat you’ll bringadvanced working knowledge and experience working with relational databases mysql preferredexperience modelling building and optimizing data pipelines architectures and data setsexperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementstrong and deep refactoring skills and the ability to impart them to other developersexperience working with large codebases and writing robust and testable codeexperience supporting and working with crossfunctional teams in a dynamic environmentmust require masters degree or higherbonus points forexperience with safety or risk dataa desire to stay at the forefront of data pipeline technologyexperience with mysql alooma snowflake and dbtworking knowledge of message queuing stream processing and highly scalable ‘big data’ data storesexperience with big data tools hadoop spark kafka etcexperience with dbt andor willing to learn it getdbtcomexperience with aws cloud services s3 rds emr databrickexperience with docker kubernetes ansible and terraform and other devops and infrastructure as code technologiesexperience with pythonability to tolerate questionable dog puns and a sense of funwhy work here competitive salarymedical dental vision life insuranceunlimited ptocatered daily lunches snacks galore and endless coffeeoffice dogsget in on the ground floor of a fastgrowing startupabout usat wag were crazy about dogs and the people who love them and everything we do is intended to bring them joy and keep them safe our company was founded in 2015 and born from a love of dogs and an entrepreneurial spirit to help make pet parenthood just a little bit easier so dogs and their humans can share a life full of joyful momentswe invented ondemand dog walking by connecting an already passionate community of local dog walkers with pet parents launching in los angeles in 2015 wag services are now available in 43 states and more than 100 cities nationwide our walkers and sitters are vetted and pass a robust screening process—and our services are bonded and insured we know your dogs are members of your family and taking care of them is the highest honor you can give wag walkers and sittersjob type fulltime,,CA,False,data_engineer
Senior Data Engineer,120000  200000 a yearmy confidential preipo client is hiring a senior data engineer in manhattan ny this candidate is ready to bring new ideas to the table and loves to dig into the data to find the source of a problem or validate an assumption they need someone who can quickly understand discuss and optimize the performance characteristics of a complex offline data pipelinequalifications3 years of proven experience working with hadoop mapreduce andor other big data technologies and pipelinesyou consider yourself both a data scientist and a senior developer and are just as happy working on challenging data problems as you are tinkering with the clusteryou have a solid foundation in computer science fundamentals with particular expertise in data structures algorithms and designyou obsess over data everything needs to be accounted for and be thoroughly testedyou are constantly thinking of ways to squeeze better performance out of the pipelinesstrong java or other objectoriented programming experience or even better experience andor interest in functional languagesjob type fulltimesalary 12000000 to 20000000 yearexperiencedata engineering 3 years required,160000.0,NY,False,data_engineer
Data Engineer,"your core responsibility will be to maintain and scale our infrastructure for analytics as our data volume and needs continue to grow at a rapid pace this is a high impact role where you will be driving initiatives affecting teams and decisions across the company you’ll be a great fit if you thrive when given ownership as you would be the key decision maker in the realm of architecture and implementation

responsibilities
architect systems and endtoend solutions that provide fast efficient and reliable interfaces to heterogeneous data meta data for internal users of the analytics infrastructure
automate existing processes and create systems that favor selfservice data consumption
own the quality of our analytics data
implement a robust monitoring  logging framework that guarantees the traceability of inevitable incidents
evaluate whether the best solution for each problem at hand is to build buy or contract the work
interface with data scientists analysts product managers and all other customers of the analytics infrastructure to understand their needs and expand the infrastructure as we grow


requirements
bsba in computer scienceengineering or relevant technical field with 2 – 3 years of experience as software engineer andor data engineer andor frontend engineer andor fullstack engineer
ability to manage data warehouse plans and communicate them to internal clients
at least 4 years of experience as a data engineer or in a role that required expertise in data pipeline technologies
strong overall programming skills able to write modular maintainable code and high quality code
strong in webbased programming css html php
experience in one or more data visualization libraries like tableau plotly infogram material design
strong python programming specially in python machine learning and data mining libraries scipy panda numpy
strong in linux and shellscripting
specialized experience with at least one of hdfs emr redshift spark flink or presto
experience with sql rdbms is required
experience in clientserver restful architecture and tools like jenkins rundeck
experience in basics of data mining clustering classification and comfortable to work with large matrices of data effectively
familiar with cuda blast and machine leaning engineers like tensorflow torch pytorch digits",,CA,False,data_engineer
Data Engineer,"“we focus on results encourage mastery and enjoy the benefits of being part of something big without the frustrations of corporate work culture”

intriguing right that’s how one of our very own developers described stonecrop technologies

we are a recognized leader in transforming cellular and microwave deployments through an innovative technology platform that aligns rf designs supply chain and installation processes

since 2001 we have worked with large corporations to deliver solutions by speeding the build and upgrade of carrier networks while maintaining a culture that encourages peer collaboration and diverse expertise to drive our mission for relentless innovation to improve performance

we believe in being agile as a way to focus on delivering real business value within a culture that gives an opportunity to be innovative and move fast

this is an excellent opportunity for an experienced data engineer who wants to help build our infrastructure and support our analysts business users and clients with access to timely accurate data in this role you will develop construct test and maintain the data architecture that supports our bi platform and manage data flow through our web and mobile applications

to excel in this role you should have experience working on and building data pipelines and etl processes that are reliable and scalable you should have a solid understanding of how to access and extract data have worked on cloudhosted platforms such as aws and have the soft skills to work with technical teams at different levels

you are

enthusiastic about data its uses and best practices
a habitual learner who is always looking to grow and add new skills
able to translate business requests into reliable scalable infrastructure and database design

you have

experience in airflow git the linux command line and working with etl tools
strong knowledge of aws platform and technologies particularly aws streaming data solutions and redshift
several years experience writing python for data processing and api integration ruby  rails knowledge is a bonus
experience optimizing sql queries in postgresql  redshift
bs or ms in computer science

you will

help plan build and maintain the next iteration of our data pipeline
recommend and implement ways to improve data reliability efficiency and quality
collaborate with data architects modelers and other team members on project goals

to join our team you should

be motivated to excel individually and as part of a small team
be looking to constantly grow and learn and enjoy bring others along with you

",,CA,False,data_engineer
Data Engineer,"blackwood seven brings artificial intelligence to media analytics and planning we have developed the worlds first automated media allocation platform which maximizes the effect of a companys media spend using our advanced predictive analytics framework built on machine learning and artificial intelligence ai using realtime modeling and advanced kpi prediction the platform produces optimal on and offline media plans to maximize business performance

revolutionize the media industry with us as we lead the industry with our innovative artificial intelligence and use of analytics and data to deliver measurable results to our impressive roster of clients we value trust transparency and team  we continuously train mentor and invest in our people

blackwood seven is looking for data engineers who has experience on aws python and sql to work on a variety of media data sets in various formats

responsibilities

work closely with analytics business intelligence and marketing sciences data sciences teams to understand the data needs of the agency
design build and deploy new data models and etl pipelines into production
be accountable for operational efficiency and be proactive in monitoring data pipelines
experience contributing to full life cycle deployments with a focus on testing and data quality
define and manage overall schedule and availability of all data sets
work closely with other engineers to enhance infrastructure improve reliability and efficiency
make smart platform and engineering decisions based on data analysis and collaboration
make recommendations regarding standards for code quality and timeliness
participate in agile development process

skills  qualifications

degree in computer science or a related field or a minimum of 4 years working as a data engineer
3 years experience in custom etl design implementation and maintenance
3 years experience with sparkpyspark or equivalent distributed processing systems
3  years experience with aws services athena glue redshift dynamodb fargate s3 and python
indepth knowledge of how to write and optimize sql statements
experience with schema design logical and physical
drive to analyze data to identify deliverables anomalies and gaps
ability to quickly learn complex domains
accountable curious and organized
experience in data analytics tools such as tableau a good to have

as a blackwood seven employee you will enjoy

competitive compensation package
unlimited paid time off policy
flexible working hours
benefits health dental vision life insurance 401k flexible spending account and more
fitness reimbursement
catered lunches and stocked kitchen with fresh fruit snacks premium coffee  tea and cold brew coffee
ongoing learning and classes for employees
team events and outings

about blackwood seven
blackwood seven brings artificial intelligence to media analytics and planning with an innovative proprietary media platform we calculate each clients media effect formula which allows attribution of all channels – online such as search youtube and facebook as well as offline such as tv print and ooh our platform optimizes clients media mix and provides a predictive forecast of expected results in real time using a holistic planning approach we combine analytics with industry expertise to build profitable scalable campaigns for our clients from strategy development to execution and optimization

blackwood seven has 175 employees in munich copenhagen los angeles new york and barcelona

for more information please visit wwwblackwoodsevencom  httpwwwblackwoodsevencom ",,CA,False,data_engineer
"Big Data Engineer (PySpark, Python, Spark)","we are looking for a big date engineer to create and manage solutions that turn data into knowledge and drive insights from growth heshe will help us build leading edge analytics solutions and platforms to solve big data data science and traditional reporting needs this individual should be analytical have a background in data and analysis and a strong communicator this role will be responsible for writing well designed efficient code using best software development practices to build and enhance our business intelligence and big data systems
function specific activities
function related activitieskey responsibilities
write application and database codes based on business requirements or user stories architectural requirements and established coding standards
validate code against business and architectural requirements
translate business needs to technical specifications
design build and deploy traditional bi solutions and big data solutions leveraging the data lake
maintain and support data analytics platforms eg ms azure bi  analytics platforms  tools
create tools to store data eg olap cubes
conduct unit testing and troubleshooting
evaluate and improve existing bi systems
collaborate with teams to integrate systems
develop and execute database queries and conduct analyses
create visualizations and reports for requested projects
develop and update technical documentation
provide technical support under devops model
education requirements
bachelors degree required bscba in computer science engineering or relevant field
related work experience
05 years of work experience in relevant field
proven experience as a bi  big data developer
1 years of spark pyspark coding experience
background in data modeling andor data mining
experience with one or more of the following strongly preferred
nosql databases azure cosmos db document db mongo db etc
pyspark python scala spark
azure functions
azure data factory
azure sql db
knowledge of database management systems online analytical processing olap and etl extract transform load framework
familiarity with bi technologies eg microsoft power bi tableau
knowledge of sql server sql server integration services ssis informatica etl solution andor azure cloud analytics platforms preferred
development methodology experience using agile methods such as extreme programming xp scrum crystal dynamic systems development method dsdm lean development andor featuredriven development fdd
devops experience andor training in devops methods and tools such as jira github docker kubernetes bamboo bitbucket
development languages experience coding in one or more of the following desired c erlang gfm go ios java javascript perl php python r restful web services ruby sql xml python and java a plus
proven abilities to take initiative and be innovative
analytical mind with a problemsolving aptitude
job requirements

years of experience

leadership behaviors

drive innovation generate new or unique solutions and embrace new ideas that help sustain our businessencompassing everything from continuous improvement to new product and package innovation
collaborate with system customers and other stakeholders develop and leverage relationships with stakeholders to approximately stretch and impact the system company and bottler
act like an owner deliver results creating value for our brands our system our customers and key stakeholders
inspire others inspire people to deliver our mission and 2020 vision demonstrate passion for the business and give people a reason to believe anything is possible
develop self and others develop self and support others development to achieve full potential
growth behaviors
growth mindset demonstrates curiosity welcomes failure as a learning opportunity
smart risk makes bold decisionsrecommendations
externally focused understands the upstream and downstream implications of hisher work tracks and shares external trends best practices or ideas
performance driven and accountable has high performance standards outperforms herhis peers
fastagile removes barriers to move faster experiments and adapts thrives under pressure and fast pace
empowered brings solutions instead of problems challenges the status quo has the courage to take an unpopular stance
we are an equal opportunity employer and do not discriminate against any employee or applicant for employment because of race color sex age national origin religion sexual orientation gender identity andor expression status as a veteran and basis of disability or any other federal state or local protected class",,GA,False,data_engineer
Senior Data Engineer,"as a senior data engineer heres what well be looking for you to bring


handson engineering leadership
proven track record of innovation and expertise in data engineering
tenure in coding architecting and delivering complex projects
deep understanding and application of modern data processing technology stacks for example spark hadoop ecosystem technologies and others
deep understanding of nosql technologies including column family graph document and keyvalue data storage technologies
deep understanding of relational database technologies and database development techniques
understanding of how to architect solutions for data science and analytics
data management for reporting and bi experience is a plus
understanding of agility including core values guiding principles and key agile practices
understanding of the theory and application of continuous integrationdelivery
passion for software craftmanship
a rich breadth of industry experience and background working across different organizations ranging in size from startups to large corporations
strong stakeholder management and interaction experience at different levels
any experience building and leading an offshoreoutsourcing function would be highly beneficial

theres no typical day or engagement for our senior engineers heres what youll do


be the sme develop big data architectural approach to meet key business objectives and provide end to end development solution
you might spend a few weeks with a new client on a deep technical review or a complete organizational review helping them to understand the potential that big data has to solve their most pressing problems
on other projects you might be acting as the architect leading the design of technical solutions or perhaps overseeing a program inception to build a new product
it could be much more about getting stuck into a delivery project where youre equally happy coding and tech leading the team to implement the solution
whatever your role the team always look to draw on your experience when things get tough and you often handle the difficult client conversations allowing the team to continue delivering without undue pressure
you have great relationships with our new business team and work collaboratively to support presales meet prospective clients and ultimately influence and shape our portfolio of work
you recognize that building your network with a client is absolutely key to enable you to perform in your role youll be drawing on all of your passion for technology handson experience and knowledge of latest big data and engineering best practices to help you gain the respect and credibility of those around you

regardless of what you do at thoughtworks youll always have the opportunity to


think through hard problems and work with a team to make them reality
learn something new every day
work in a dynamic collaborative transparent nonhierarchal and egofree culture where your talent is valued over a role title
travel the world
speak at conferences
write blogs and books
develop your career outside of the confinements of a traditional career path by focusing on what youre passionate about rather than a predetermined onesizefitsall plan
be part of a company with social and economic justice at the heart of its mission

not quite ready to apply or maybe this isnt the right role for you

thats ok you can stay in touch with accessthoughtworks  httpswwwthoughtworkscomcareersaccessutmsourceapplyjobsutmmediumjdutmcampaignaccessthoughtworks  our learning community tick contact me about recruitment opportunities to hear about jobs in the future

lina",,NY,False,data_engineer
Data Engineer,"shippo lowers the barriers to shipping for businesses around the world as free and fast shipping becomes the norm better access to shipping is a competitive advantage for businesses through shippo ecommerce businesses marketplaces and platforms are able to connect to multiple shipping carriers around the world from one api and dashboard businesses can get shipping rates print labels automate international documents track shipments and facilitate returns internally we think of shippo as providing the building blocks of shipping

join us to build the foundations of something great roll up your sleeves and get important work done everyday founded in 2013 we are a diverse set of individuals based out of san francisco shippo’s investors include bessemer venture partners union square ventures uncork capital versionone ventures fundersclub and others

as a data engineer you will be responsible for building systems to collect process and store events at massive scale to gain operational and business insights into the performance and optimization of shipping services

responsibilities


implement and maintain data extraction processing and storage processes in large scale data systems data pipelines data warehouses for internal and customer facing analytics and reporting features
implement and maintain machine learning systems feature generation learning evaluation publishing primarily using spark for our data scientists
integrate data from various data sources internal and external to ensure consistency quality integrity and availability of data sets and insights
work closely with engineers product managers data scientists and data analysts to understand needs and requirements
design build and launch new data models and datasets in production
define and manage sla for datasets across the different storage layers
maintain and improve existing systems and processes in production

requirements


2 years working experience as a data engineer
ability to implement etl processes using batch and streaming frameworks such as hadoop hdfs mapreduce and spark
work experience with rdbms such as postgresql or mysql nosql and columnar data stores
investigate analyze identify and debug data related issues to ensure stability quality and integrity of datasets
familiar with columnar data warehouse technologies in particular redshift
understand business processes overall application components and how data is gathered and design a data model that ties the application telemetry data to metadata and transactional data
build expertise and own data quality for various datasets
fluent in scripting languages such as python ruby or perl
collaborate with multiple teams in high visibility roles and own the solution endtoend
selfstarter individual who truly enjoys a fastpaced innovative software startup environment with a focus on delivering business value in a teamwork centric environment groundbreaking technology
excellent written oral communication and presentation skills
bs or ms in computer science or related technical discipline or equivalent job experience

preferred


building monitoring managing and maintaining large data processing pipelines using frameworks and patterns such as mapreduce spark and pig and distributed columnar data warehouses including but not limited to redshift and druid
batch and streaming data transport using traditional etl aws kinesis and kafka
workflow management tools such as airflow and data serialization formats such as avro and parquet  and data modeling concepts methodologies and best practices
machine learning infrastructure such as tensorflow or mxnet
cloud environments and devops tools working experience with aws and its associated products

benefits


benefits medical dental vision 90 covered by the company incl dependents
takeasmuchasyouneed vacation policy  flexible work hours
free lunch  drinks  snacks
fun team events outside of work hours  happy hours “escape the room” adventures hikes and more

",,CA,False,data_engineer
Data Engineer | Fortune 100 Retailer,110000  140000 a yearbicp a dedicated bi analytics  big data consulting firm is currently looking to hire 2x data engineers for an engagement at our longstanding and direct fortune 100 retail client in portland or we’re looking for candidates with 1 years of experience with data engineering with emphasis on data analytics and reporting must possess strong experience with sql and relational database engineering oracle sql server or teradata and have expertlevel sql abilities any experience with aws emr snowflake hadoop pig hive sqoop spark shell python tableau or cognos is ideal we’re not looking for people that have done all of the aforementioned but should have tangible experience in at least a couple of these areas any supply chain or retail experience is a huge plus we’re looking to hire candidates that can thrive in an agile environment and who possesses great interpersonal and communication skills to work effectively with parallel technical teams and can closely collaborate with the business we’re looking to hire selfstarters that can thrive in a highly agile environment and who possesses excellent interpersonal and communication skills to work effectively with parallel technology teams and the businessif you’re looking to join an organization where there is tremendous growth opportunity that operates with transparency and with a highly collaborative approach then bicp could be a great career choice for you we offer excellent compensation and we will reimburse the cost of relocation to portland telecommuting is not an optionplease note  us citizens and those authorized to work in the us are encouraged to apply we are unable to sponsor h1b visas at this time and this is a salaried or w2 positionjob type fulltimesalary 11000000 to 14000000 yeareducationbachelors requiredwork authorizationunited states required,125000.0,OR,False,data_engineer
"Data Engineer, Advertising Measurement","job description
amazon is one of the world’s most highly trafficked sites and with a data footprint multiple business areas delivering impactful advertising using amazon data to help customers find the right products and help brands connect with their customers is one of our key business initiatives the advertising measurement team is building a big data platform to provide machine learning based solutions to measure and optimize advertising spend across media channels the platform and measurement services are consumed by different amazon brands across device retail and online video businesses of amazon

you will play a key role in building the appropriate data ecosystem and leverage big data solutions to deliver insights and optimize roi for marketing dollars the ideal candidate will have extensive experience with traditional data warehouse dw concepts and have the aptitude to incorporate new approaches and methodologies while dealing with big data excellent business and communication skills are a must to develop and define key business questions and to build data sets that answer those questions you should be able to work with business customers in understanding the business requirements and implementing reporting solutions

this position will need to have substantial interaction with the analytics teams located in seattle london nyc and bangalore as well as stakeholders in us eu and asia international travel may be required
basic qualifications
4 plus years of relevant experienceexposure to big data ecosystem and handson knowledge on hadoop hive pig sparkexposure to aws ecosystem and handson knowledge ondeep handson knowledge in using advanced sql queries experience in writing and optimizing efficient sql queriesexperience in bi projects converting business needs to data warehousing and reporting solutionsexcellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions
preferred qualifications
strong unix shell scripting abilitiesstrong in any programming languages such as java pythonstrong ability to interact communicate present and influence within multiple levels of the organizationexposure to managing and writing data processing jobs such as emrspark or similar",,WA,False,data_engineer
Data Engineer,"overview
be here be great working for a leader in the insurance industry means opportunity for you great american insurance group a member of american financial group is a fortune 500 company consistently recognized as a top place to work we combine a small company culture where your ideas will be heard with big company expertise to help you succeed with over 30 specialty property and casualty operations and a variety of financial services there are always opportunities here to learn and grow
great americans predictive analytics division is looking for a data engineer to join their growing and dynamic team
responsibilities
work with project team and business stakeholders to determine data requirements for analysis
acquire and manipulate internal and external data to create clean reproducible data sets to facilitate predictive modeling
build comprehensive data sets from various source systems including hadoop oracle warehousesmarts sql server api’s xls etc
work with information technology to develop production solutions to bring predictive analytics to the enterprise
research and evaluate new methods and tools to improve data gathering processes
design and implement database structures for modeling solutions
complete descriptive analyses on various data sets
research business unit queries regarding model outputs this includes score shifts missing items reason messages etc
qualifications
superior organizational leadership skills
integrates multiple concepts across job functions with a goal of overall benefit to the organization
ability to communicate develop and leverage strategic business relationships across the organization and externally
requires advanced technical and business knowledge
selfmotivated team player who excels in a collaborative environment
contributes beyond job role and responsibilities
excellent problem solving skills
required
strong sql and database knowledge oracle preferred
understanding of etl techniques and processes
strong excel knowledgeexperience including macros and vb development
soap and rest web service experience testing and development
preferred
previous experience in the pc insurance industry
report developmentdesign experience tableau  cognos preferred
strong software engineering practices developing enterprise applications – java spring xml jdbcjpahibernate
familiar with approximate string matching techniques fuzzy matching
hadoop development– interfacing with data stored in hadoop environment familiar with technologies including hive pig spark hdfs sqoop flume hawq zeppelin
experience with informatica data quality suite  infomatica data integration suite powercenter
experience in linux
experience with rrstudio
text mining experience utilizing python or r a plus
education bachelor’s degree or higher in information technology informatics computer science information systems or equivalent experience
experience 06 years of relevant experience",,OH,False,data_engineer
Data Engineer,"oath a subsidiary of verizon is a valuesled company committed to building brands people love we reach over one billion people around the world with a dynamic house of 50 media and technology brands a global leader in digital and mobile oath is shaping the future of media


the marketing systems team builds systems and data pipelines that enable the marketing org to grow our audiences through multichannel ad campaigns user journeys and personalized newsletters we deal with data at massive scale leverage cutting edge technology to engineer applications for effective campaign targeting optimized ad spend and measuring campaign performance

responsibilities

you are a self driven and motivated individual that wants to make an impact by offering innovative solutions in the big data and custom applications space you are a free thinker have a hunger to learn willing to try out new tools and technologies and willing to look for the best and most practical solution to any given problem rather than the quickest or easiest you take on challenges head on and work well under pressure no task is too big or small or you and you treat everything with equal merit you are a good team player and thrive as part of a team of equally talented and motivated individuals you are a strong communicator
work on development initiatives as part of a scrum team on sprint cycles
closely interact with our stakeholders product ownersmanagers business analysts others for clarity on sprint items and for verification of developed solutions
participate in team activities such as sprint grooming sessions project or product discussions brown bags as well as the occasional team outing
follow appropriate coding standards and best practices as applicable
document your work well
participate in code reviews for your peers
collaborate with your peers for finding solutions to complex problems share knowledge with your peers and also learn from them as required
work on operational and production support for the applications we build and maintain
work towards quarterly team and organizational goals that should be result oriented and measurable

minimum qualifications
ms in computer science or related field or bs with 3 years of relevant experience
able to produce testdriven modular and efficient code in java
able to tame scalable distributed software systems

preferred
experience with nosql and big data systems and tools hbase redis
experience with javascript html5 css
experience with cryptography httpstls
experience with api design
experience with ai and machine learning
experience with unix os


oath is proud to be an equal opportunity workplace all qualified applicants will receive consideration for employment without regard to and will not be discriminated against based on age race gender color religion national origin sexual orientation gender identity veteran status disability or any other protected category oath is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment please let us know if you need a reasonable accommodation to apply for a job or participate in the application process


currently work for oath please apply on our internal career site",,CA,False,data_engineer
Spark Data Engineer,"the mission of our data team at red ventures to make data easytouse for everyone we are hiring spark engineers who are excited to overcome challenges work with the latest aws technologies and continue making our data better

our spark engineer will be a key part of building our data infrastructure this includes using spark for streaming applications andor as an etl tool data aggregation column operations user defined functions caching and using the spark ui to analyze behavior and performance

you will join a team of highly skilled engineers who design develop and automate highquality scalable solutions across the entire data lifecycle from raw data to powerful insights and analytics basically we are using spark as our universal program on how we are transferring data across multiple platforms

if you want to be a part of a dynamic team solving business problems using data this is the role for you

skills

spark working in rdds and dataframesdatasets api with emphasis on dataframes to query and perform data manipulation
spark structured streaming
experience building large scale spark applications ideally with either batch processing andor streaming processing
scala would be ideal but a solid knowledge of java is also acceptable
experience in sparksql broadcast joins
experience with cloud computing platforms we use aws kinesis s3 lambda dynamodb
has experience with ansi sql relational database oracle sql postgres mysql

nice to haves

linux common working knowledge including navigating through the file system and simple bash scripting
general knowledge of distributed systems and distributed data processing frameworks
experience with storm kafka or cassandra is a plus
knowledge about agile software processes

about red ventures
red ventures is a multibilliondollar portfolio of digital companies that specializes in bringing consumers and brands together through bespoke technology integrated digital commerce and sales distinguished partnerships data science and original content from the companys proprietary brands and marketplaces red ventures provides better endtoend consumer experiences throughout the buying cycle headquartered in the charlotte metro area red ventures has more than 3600 employees globally in offices across the us uk and brazil",,CA,False,data_engineer
Scala Data Engineer,"we are a small startup on a mission to revolutionize the world of digital advertising we are currently looking to add an experienced and dynamic scala data engineer to our growing team the ideal candidate for this position is excited innovative and is not afraid to handle new challenges within the programmatic mediabuying space if you have experience working on a large volume lowlatency data platform this job is for you

this position uses the following technologies but is not limited to spark druid kafka cassandra postgres finagle hdf and airflow

what you’ll do

contributing new reporting features to our system eg http services various custom reporting solutions
constructing and scaling both new and existing spark streaming applications
constructing new ingest pipelines such as s3 kafka etc
collaborate with your data science colleagues productionize any ml pipelines
work with other engineering teams to organize various data models
collaborate with our devops team to grow out monitoring and alerting coverage as necessary scale nosql appliances
tune all spark applications to accommodate a quickly evolving platform

so what are we looking for


someone who has worked with spark hadoop andor other big data processing platforms within high volume environments
familiarity constructing and maintaining etl pipelines
fluent in sql and a good understanding of relational data models
a high comfort level working in a linux environment
a driven mentality and is unafraid to approach new challenges and the latest technologies

liar1",,CA,False,data_engineer
Data Engineer,"
this role can be based in chicago il or mount olive nj

this is an exciting time at mars we’re using digital data and user insights to transform our business by finding answers to problems that we’ve often never asked ourselves before from joining the dots to improve our petcare data ecosystem to streamlining the efficiency and automation of our supply chain and quality operations we’re already seeing some brilliant results in fact we’ve built so much momentum that we’re now looking for industry leaders in business translation data science and data engineering with different and complementary skills to influence how we operate and grow beyond anything we’ve achieved before join us and discover a company set up to develop your capabilities and ambitions and a group of colleagues ready to support and inspire you working together we’ll create a better world for our planet our communities and our pets

what you’ll do

keeping the data flowing and readily available to solve problems as and when they need solving is core to what you’ll do you might do that through agile sprints or selfservice analytics  it’s up to you the daytoday you’ll be working within a sprint team building both new data pipelines and establishing or improving new platform capabilities without people in this crucial role treating data as an asset we won’t be able to become the business we want to be

working in a small agile team alongside global analytics data source systems business translation and integration colleagues you’ll partner with product owners to establish and maintain the data pipelines etlbatchstreaming within and between different technology platforms such as sapsap bw and microsoft azure you’ll also work closely with users from our segments and markets around the world as part of scrum teams this exposure will also give you the exciting opportunity to influence and contribute true ‘firsts’ that’s new and emerging approaches that mars and maybe even the industry hasn’t seen before

data integration orchestration and automation – you’ll build data flow components of mvp analytic solutions and you’ll do it across the entire mars data landscape that’s on premises cloud internal external formal  informal data you’ll look to the future too that means thinking about how data assets yet to come can be integrated into the endtoend mars data landscape

in everything you do you’ll be thinking about the bigger business picture and making sure your solutions address specific business challenges on top of that you’ll work closely with the enterprise architecture function and other mars digital technologies capabilities to ensure alignment with the enterprise architecture initiatives and capacity and infrastructure planning

what you’ll need

to do all this you’ll need

bachelors degree in it or similar experience
at least 3 years data integration and a year data orchestration experience with microsoft azure
indepth experience of designing and implementing data flows and pipelines
23 years experience as a data engineer is highly desirable
experience of working in an agile ideally scrum team
comfortable being hands on with data data modelling query techniques
background in the data management space
experience of the fmcgcpg industry
a good understanding of and adherence to data security standards

so if you’ve got the skills we need and you’re looking for the opportunity to really make a mark in a worldrenowned and supportive business going through a period of fast and massive digital transformation this could be the role you’ve been waiting for

mars is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability status protected veteran status or any other characteristic protected by law if you need assistance or an accommodation during the application process because of a disability it is available upon request the company is pleased to provide such assistance and no applicant will be penalized as a result of such a request

mars is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability status protected veteran status or any other characteristic protected by law if you need assistance or an accommodation during the application process because of a disability it is available upon request the company is pleased to provide such assistance and no applicant will be penalized as a result of such a request",,IL,False,data_engineer
Data Engineer,trend logic is currently seeking an experienced data engineer for a full time position in richmond vaposition descriptionthe data engineer will work on projects to transform big data into curated data sets feeding analytics initiatives and helping organizations operationalize new insights quickly to increase the agility and responsiveness of the analytics that drive the businessyou will be responsible for working with the devops team on tools for continuous integration builds and monitoring of solutionsyou will join an established team in an open collaborative environment using agile delivery methods any experience in converting legacy etl into the newer technologies is highly valued as wellabove all we are looking for applicants who will thrive in an open energetic flexible funspirited collaborative environment and desire creative freedom and an opportunity to work on high performing teamsrequired skills  experiencebachelors degree in computer science or relevant area of study2 years of experience and knowledge of apache spark apache kafka java and pythonexperience using etl extract transform and load toolsexperience with scala and apache camel is also a plusthis is a full time position located in richmond va remote candidates may be considered with semiregular travel to richmond expectedexcellent salary and benefits including employer paid insurance bonuses and lots of perksthis is a directhire position applicants must be available for employment without sponsorshipjob type fulltimeeducationbachelors preferred,,VA,False,data_engineer
Data Engineer,"data engineer

bluestem brands inc is the parent company to 13 dynamic ecommerce retail brands we have one mission to build a dynamic retail enterprise that wins with directtoconsumer excellence and entrepreneurialminded employees focused on serving our customers’ unique needs our leadership is responsive and supportive empowering those smart and passionate employees who drive our success we are continually innovating and improving we take risks learn from mistakes and celebrate success as a team

you work hard and you deserve more than just a paycheck bluestem works to do what’s right for employees from the big things great benefits employee discounts and incentive plans to small touches jeanseveryday dress code this is the place you’ll want to be and we don’t just talk about worklife balance we try to live it join the bluestem brands team to make an impact be inspired and be valued every day

we are seeking a data engineer for bluestem brands to be located at our office in el segundo ca

what you’ll do

implement technology solutions to manage large amounts of data
deploy state of the art machine learning algorithms to production environments for real time credit adjudication
build algorithmic experimentation framework
design and develop code and data pipelines that leverage structured and unstructured data integrated from multiple sources
collaborate with data scientists to help tell meaningful stories and evaluate continued needs to drive innovation and add significant profitability to the bottom line


what you’ll need

advanced degree ms or phd in computer science physics applied mathematics engineering or other technologyquantitativehard science
expertise in general purpose programming languages such as python java c c etc…
expertise in shell scripting
experience with distributed computing tools such as mapreduce hadoop hive pig spark
experience with building complex and noninteractive batchdistributed systems
extensive experience working the full length of the data pipeline
experience using git
experience using amazon web services aws for cloud computing
experience with extract transform load etl processes and sql expert
experience working with various data serialization forms xml json etc…
experience with any of the following r matlab sas or other mathematicalstatistical programming environment is a plus
experience with graphical processing units gpu computing for improving performance is a plus
exposure to popular machine learning techniques is a plus


required skills

required experience",,CA,False,data_engineer
"Initiative - Director, Data Engineer (DMP)","the audience director is responsible for the management of audience first marketing strategies across initiative’s key markets the role is predominately us focused however opportunities across global clients exist across markets including us uk germany and australia your role as a key player within the initiative global analytics team is to support initiative client and client teams to maximize data management technology solutions to fulfill audience marketing objectives specifically this role is responsible for being the primary contact providing direction to all stakeholders for the successful delivery of merck pharmaceuticals recently adopted salesforce dmp


essential functions
oversee the endtoend successful execution of merck’s dmp scope of work
establish goals kpis and delivery timelines with client and initiative teams for the successful delivery of the dmp scope of work
manage dmp workload across the account providing recommendations for project prioritization
document and communicate requirements to meet program objectives
help initiative media teams manage use case impacts across the merck portfolio
provide initiative with direction and instructions on how to deliver on dmp needs – make it as simple as possible from a work flow perspective
provide consultation on best practice audience targeting using both initiative inhouse technology and client owned technology ie dmp
step in and trouble shoot tasks where assistance is needed
provide governance and communication strategy for key stakeholders and senior leadership
partner with merck and dmp vendors to develop a roadmap and timeline for key deliverables
work with special business units including programmatic search social and data teams across media brands to successfully onboard client dmp technology
monitor and analyze dmp data ensuring delivery against client goals
prepare and distribute dmp performance summaries to clients and initiative teams
provide ongoing troubleshooting with data and media platformpartners validation of data from tags on a regularly basis ensuring that variability between platforms and ad servers in a reasonable range

other responsibilities
identify delivery gaps and work with initiative and sbu teams for viable solutions
manage delivery expectations with senior management across initiative and merck
actively present potential project conflicts or work that compromises initiative in any way
cultivate relationships with current client directors and ensure analytics vision is being delivered
work closely with initiative analytics team to ensure a united front for any work put in front of clients
foster a collaborative relationship with all stakeholders providing support and direction where required
support diversity and inclusion goals for cia and initiative


qualifications
education
bachelor’s degree

work experience
5 years industry experience including 5 years of management experience
experience managing small teams– including those directly managed vs teams that are responsible for your product but not under your control

skills
track record of successfully managing mediumsmall accounts and markets
strong experience with data management platforms and the application in media
strong experience with modeling research business intelligence platforms
ability to communicate complex concepts at varying levels from superficial to detailed
excellent communication organizational interpersonal and problem solving skills
ability to proactively drive the business forward ie being able to take the initiative rather than rely on direction",,NY,False,data_engineer
Data Engineer,85000  125000 a yearjob descriptionan edtech companya company located in bethesda is looking to onboard a data warehouse engineer to join their data engineering team this team reports directly to the chief product officer and is responsible for the future direction of the companys flagship anlytics product on top of this this team is also at the intersection of various facets of the business and is developing new ways the company can utilize its massive amounts of data ideal candidates are those who are familiar with a big data environment have experience working with etl sql python the hadoop ecosystem and redshiftrequired skills  experiencebs in computer science or related field2 years of java1 years of pythonexperience with etlexperience with hive netezza and uzi2 years of sqldesired skills  experiencems in computer science or related fieldexperience with redshift1 years of nosql databasesexperience with awsjob type fulltimesalary 8500000 to 12500000 yeareducationbachelors preferred,105000.0,MD,False,data_engineer
Data Engineer,"the earnest research company

earnest research is a vcbacked data innovation startup driven to change the way professionals understand consumer and business behavior working with worldclass data partners we transform raw data into a source for business and investment professionals to ask better questions so they can make better decisions we believe in the right hands data has the power to change the way we work

data engineer

earnest is seeking a data engineer to help scale up our data infrastructure you will be part of a datadriven decisionmaking culture and collaborate with software engineers in building out the data tools and processes to support the creation of insights that will drive our business the role will involve the design and implementation of the entire data pipeline from capturing and storing disparate data sources to processing that data and making that data available to other team members you will be working across the company to understand their data needs and creating systems that provide consistent and complete information to help solve various business problems

responsibilities


maintain and implement tools and systems that ingest transform organize and expose data insights
collaborate with other engineers to help implement and design our next generation data warehouse system
work together with our data analyst team to gather technical requirements and provide support on analytics processes
develop and maintain data pipelines with a focus on writing scalable clean and faulttolerant code to handle disparate data sources
implement new product features and performance improvements to existing products
help drive optimization testing and tooling to improve data quality across the product line

qualifications

required skills

proficiency in one of python java scala or a similar programming language
experience with hadoop and related technologies hive pig spark presto impala
strong sql experience mysql redshiftpostgres
comfort with source control github and working in a linux environment
experience with handling and processing large data sets in a business environment
understanding of structured and unstructured data designmodeling
strong analytical quantitative problemsolving and critical thinking skills
excellent interpersonal verbal and written communication skills
extremely committed hard working and thoughtful with the ability to work both independently and in a collaborative team environment

additional preferred skills

experience with aws tools ie especially emr redshift data pipeline
experience working with large volumes of time series financial data
exposure to data science
knowledge of machine learning and natural language processing
nosql experience hbase mongodb
familiarity with bi and analytics tools eg looker tableau

benefits  perks

100 company paid medical plan options additional medical dental and vision plans available too
health  fitness reimbursement program
401k retirement plans with employer matching
flexible and generous time off
pretax savings plans for public transportation and parking expenses
fully stocked kitchen and cold brew on tap
regular company happy hours lunches  events

earnest research is an equal opportunity employer and we encourage people with a diverse range of backgrounds to apply",,NY,False,data_engineer
Data Engineer,"the company

were a tech company thats changing how people bank and think about their finances we value empathy curiosity craft and efficacy our mission is to help people feel confident with their money we do that by bringing humanity elegance and ease to the consumer banking experience and we make banking beautiful

the team

the data engineering team builds and operates the pipeline that feeds simples data needs currently using postgres kafka and redshift the team is composed of data management specialists working together to reduce operational defects and increase the capabilities of simples internal data customers in product and platform engineering risk management analytics and customer support

about you
you love both the human and technical challenges of building data solutions that create awesome business impact youre hungry to learn about technology  data and what it can unlock for our customers you thrive in a collaborative environment that values discussion and empirical reasoning and believe these components lead to a successful outcome for the team and the business

what youll do all day

as a data engineer you will contribute to the teams initiatives and projects youll participate in development and operational work that meets standards of practice for both youll interact across the platform and engineering teams in order to have an impact on the business at large


ensure our data pipeline is healthy and operational
respond to alerts and customer requests for data and analytics support
participate in design and implementation of pipeline features and enhancements

wed like to see

minimum 3 years of relevant experience
experience with sql and python
familiarity with data modeling warehousing and analytics concepts and technologies
experience with aws or other cloud services
experience designing and implementing data systems for business impact

details
we recognize the dire lack of diversity in our industry and were not okay with it we actively seek to address it with our hiring and retention processes as well as our office culture if youre on the fence about whether youre a fit we say go for it and apply

why simples a great place to work

based in portland oregon a beautiful place to live and work
competitive salary and benefits package
a supportive and nurturing place to work we actively consider how we can improve employees quality of lifeboth inside and outside the office
committed to hiring quality human beings simple is a place where others will watch out for you and help you learn we actually like and respect each other
we give a damn about what we do both as individual contributors and as a company on a mission to change banking were passionate and nerdy about our work in fact were kind of that way about things outside of work too

in compliance with federal law all persons hired will be required to verify identity and eligibility to work in the united states and to complete the required employment eligibility verification document form upon hire email our team at careerssimplecom  careerssimplecom  if you need an accommodation in the application process

a background check will be required for this opportunity

simple provides equal employment opportunities eeo to all employees and applicants for employment without regard to race color religion sex national origin age disability​ or genetics in addition to federal law requirements ​simple ​complies with all ​applicable state and local laws governing nondiscrimination in employment in every location in which the company has ​employees this policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation and training

by submitting this application you certify that the facts contained in your application are true and complete to the best of your knowledge if you are employed false statements on your application will be grounds for termination",,OR,False,data_engineer
Data Engineer,"gridwise a mobility solutions startup headquartered in pittsburgh pa is looking for a highly motivated individual to join our team as a data engineer
gridwise techstars mobility 17 is a mobility startup that is creating solutions to improve the efficiency of ondemand rideshare fleets as mobility is rapidly changing gridwise is aiming to improve the ecosystem through its datadriven solutions created to help human  autonomous rideshare drivers best know when and where to drive we are seeking motivated individuals to help us capture this massive opportunity as a leading provider of ondemand mobility solutions we encourage you to join us for the ride if you value the opportunity to make a huge impact on the mobility ecosystem of the future
as an early member of the data team at gridwise you will have an opportunity to contribute significantly to our success by helping us shape our data strategy processes and infrastructure as we continue to scale our technology the ideal candidate for this position thrives at the intersection of data science and software engineering
as a data engineer at gridwise you will
assist in designing building and deploying infrastructure necessary to implement mlbased product features analytics jobs and manage large geospatial datasets
develop processesalgorithms to clean and refine imperfect datasets
work with data team to refine and productionize various models for use in our applications
perform exploratory analyses on gridwises data to extract new insights and product ideas
take on a leadership and mentorship role within the data team as the organization continues to grow
required experienceskillstraits
graduate degree in engineering machine learning or computer science field
3 years experience designing and building softwaredata infrastructure to support mlbased software features and other data science projects
skilled in working with large imperfect realworld datasets
experience working with a variety of database technologies sql nosql geospatial graph etc
experience with big data  streaming infrastructureframeworks such as hadoop spark kafka etc
comfortable with data science toolslibraries such as numpy pandas scikitlearn etc
able to select and apply appropriate machine learning methods for a given use case
passionate about entrepreneurship and the mobility industry
exceptional candidates will have one or more of
phd in computer science data science machine learning or related field
strong experience implementing production software and infrastructure for machine learning systems
experience designing and deploying data pipelines etl processes and distributed systems
experience storing querying and working with geospatial and timeseries datasets and databases
this position is fulltime and is located in pittsburgh pa remote work is unfortunately not an option at this time
compensation  benefits include
competitive salary  stock options
medical dental and vision benefits
unlimited vacation days
maternitypaternity leave
relocation if applicable
if you’re interested in this opportunity and feel that you’d be a great fit for our team please apply and tell us why
we look forward to hearing from you soon",,PA,False,data_engineer
Data Engineer Co-op,"internshipwant to join a team of passionate engineers who are excited to work at the intersection of fitness and mobile technology come join our team a bostonbased mobile company with more than 55m users worldwide a little bit about our app runkeeper transforms your phone into a personal trainer helping you track your activities set your goals and stay motivated to go that extra mile

we are looking for a data engineering coop to work on consolidating key data for the entire asics organization into our cloudbased data warehouse snowflake during this initiative you will get to work with several interesting technologies and solutions to bring our etl framework into production you will work in an integrated scrum team with other fulltime data engineers data analysts and data scientists

and lastly while we are a fast moving company many of us are not fast or even moderately fast runners the idea of helping make the world a healthier place is the most rewarding piece for us
potential projects you could work on
consolidating asics data with runkeeper data into our data warehouse
learning and playing with the latest devops techniques like containerized solutions
designing solutions on how to consolidate multiple sources of data for consumption
collaborating on personalization initiatives for engaging users with our new fitness app and other asics services
what youll do
handson design and development in our cloud native data warehouse snowflake
handson development in amazon web services services and solutions for delivering software
develop etl extract transform and load processes for data ingestion purposes
what you bring to the table
currently enrolled in a bsms program in computer science or equivalent
experience with a couple of the following java python sql containers
one other perk of the job 50 of asics gear best in class sneakers athletic apparel and training gear  or just for building up a huge sneaker collection

 asics digital is committed to creating a diverse environment and is proud to be an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion gender gender identity or expression sexual orientation national origin genetics disability age veteran status or fitness level",,MA,False,data_engineer
Big Data Engineer,"who is trace3

at trace3 our mission is to remain the leading transformative it authority providing unparalleled it solutions and consultation services to our clients

we began our humble journey in 2002 – as a traditional var fast forward to today we have evolved to be a leader in the it space – solidifying us as a force to be reckoned with we integrate it products and services with insightful consultation in order to provide total business transformation for our clients equipped with elite engineering and dynamic innovation we empower executives and organizations to keep pace within the itcorporate landscape through the transformative power of it

our culture at trace3 embodies the spirit of a startup with the advantage of a scalable business we offer competitive compensation and awesome perks like onsite workout classes stocked kitchen with snacksbeverages and a focus on a healthy worklife balance as a part of trace3 we want you to have the opportunity to grow your career and have fun while doing it

trace3s hq campus is located in irvine ca with office locations in san diego los angeles denver northern california and phoenix

ready to discover the possibilities that live in technology

ideal candidates will have qualities true to our core…

street smart you are flexible and resilient in a fast changing environment you know how your job affects the whole mission you get the bigger picture you understand why your job matters to trace3 and how to help grow the business you exercise good business judgment in making high quality decisions in a timely manner

entrepreneurial spirit you think like an entrepreneur you constantly innovate come up with solutions and drive change you solve problems for the betterment of the company you look for new and productive ways to make an impact you find better ways to sell or provide solutions and are good at it

juice you are a wellrespected achiever that gets things done and drives results you bring the weather by demonstrating leadership character and passion you lead without a title empowering others and inspiring trust you treat others with respect admit mistakes give credit where its due and demonstrate transparency you hug people in their trials struggles and failures not just their success

about the role
the data engineer will be responsible for leveraging new and emerging technologies to solve key technical challenges for our clients the data engineer will act as an expert and trusted advisor who develops implements troubleshoots and optimizes data solutions across many platforms this role will work closely with clients partners and other business units to ensure consulting engagements are successful

what youll do

responsible for design development and handson implementation of data intelligence solutions including data platform buildup proof of concepts or pilot implementation software development software integration and documentation
perform hands on development of apache big data technologies and framework
serve as a data intelligence technical resource in teams efforts to determine the needs of our clients businesses that will simplify and automate the applications as well as make them more efficient
align solutions with standards and best practices working with crossfunctional engineering and consulting teams
collaborate and communicate with sales and account management team to ensure smooth and successful delivery and assist with the identification of additional advanced services and sales opportunities within the customers environment
establish strong and lasting relationships with key stakeholders and decision makers in client organizations
contribute to the development of internal best practices as well as new innovative consulting services offerings that we can take to market
build a community and following around our company solutions and brand awareness

qualifications  interests

bachelors degree from an accredited university required
previous experience working for a consulting or services organization strongly preferred
5 years of software development experience in distributed systems and building largescale applications
5 years of experience in building large scale high performance high availability systems and strong computer science fundamentals algorithms data structures
hadoop nosql or other big data certifications are a huge plus
experience with big data technologies spark hdfs hbase cloudera mapr hadoop and other frameworks in hadoop ecosystem
deep knowledge of hadoop tools mapreduce spark oozie elk kafka hue hbase
fluency in several programming languages such as python scala or java with the ability to pick up new languages and technologies quickly
intermediate knowledge with software engineering best practices
must be able to quickly understand technical and business requirements and be able to translate them into technical implementations
ability to mix deep technical expertise with simple everyday language to deliver a story that is memorable educational and useful
highly organized detailoriented excellent time management skills and able to effectively prioritize tasks in a fastpaced highvolume and evolving work environment
ability to approach customer and sales requests with a proactive and consultative manner listen and understand user requests and needs and effectively deliver
comfortable managing multiple and changing priorities and meeting deadlines in an entrepreneurial environment
motivated selfstarter who loves to troubleshoot and solve challenging problems and feels comfortable working directly with customers

the perks

competitive compensation
comprehensive medical dental and vision plans for you and your dependents
401k retirement plan 529 college savings plan life insurance and add
training and development programs
stocked kitchen with snacks and beverages
collaborative and cool office culture
worklife balance where we dont encourage fun and relaxation time we actually require it
unlimited vacation to relax restore and refresh

to all recruitment agencies trace3 does not accept unsolicited agency resumescvs please do not forward resumescvs to our careers email addresses trace3 employees or any other company location trace3 is not responsible for any fees related to unsolicited resumescvs",,CA,False,data_engineer
"Data Engineer, Webex Teams","who you’ll work with
how connect with people every day do you chat video calls meetings have you ever had trouble connecting to audio or video from a meeting room have you had a hard time coordinating with your team around a common goal or initiative we all need to connect with people to get our work done we are uniquely positioned to make it amazing across hardware and software with a leading market position in meetings our next goal is to redefine how people work where communication is at the core of all productive collaboration

we are an experienced group of product managers engineers and designers who are finding new ways to leverage data from communication people interaction and collaborative content creation to craft new collaboration experiences in ways that nobody but cisco can these new collaboration experiences will give a stronger voice to the remote worker make distributed teams as efficient as colocated teams and drive the new generation of everyday collaboration between teammates

what you’ll do
webex teams is looking for a data engineer with data modeling experience who can help us reimagine and reinvent our data strategy we need someone who is passionate about leading change exploiting and optimizing customer engagement driving experiences across our collaboration stakeholders growing our platform incorporating new workloads and expanding our capabilities you’ll be working alongside a team focusing on how people communicate across messaging calling and video as well as collaborate on documents schedules and tasks we want to make everyone more productive every day

who you areyou can understand and translate business needs into data models supporting longterm solutionswork with the application development team to implement data strategies build data flows and develop conceptual data modelscreate logical and physical data models using best practices to ensure high data quality and reduced redundancyoptimize and update logical and physical data models to support new and existing projectsdevelop best practices for standard naming conventions and coding practices to ensure consistency of data modelsperform reverse engineering of physical data models from databases and sql scriptsevaluate data models and physical databases for variances and discrepanciesvalidate business data objects for accuracy and completenessanalyze datarelated system integration challenges and propose appropriate solutionsdevelop data models according to company standardsguide system analysts engineers programmers and others on project limitations and capabilities performance requirements and interfacesreview modifications to existing software to improve efficiency and performanceexamine new application design and recommend corrections if required

basic qualificationsexperience in designing and delivering enterprisegrade high transaction volume data platform as a services dpaas and experience with data lakes analysis services sql cosmos or an equivalent set of cloud capabilities6 years of experience in building data platforms data engineering andor software engineering including experience working with agile methodologies and cloud technologiesexperienced in leading and building solutions under agilescrum methodologiescuriosity with a desire to continuously learn share and collaborate to improve yourself and your teammatesstrong communication negotiation and consensus building skills when dealing with stakeholders and team membersstrong problem solving and algorithmic thinking capabilitystrong crossgroup collaboration and effective communication skills to drive issues to resolution with ability to communicate insights to both technical and nontechnical audiencesbs in data engineering master’s preferred computer science or related field of study for software development is required

why cisco
at cisco each person brings their unique talents to work as a team and make a difference

yes our technology changes the way the world works lives plays and learns but our edge comes from our peoplewe connect everything – people process data and things – and we use those connections to change our world for the betterwe innovate everywhere  from launching a new era of networking that adapts learns and protects to building cisco services that accelerate businesses and business results our technology powers entertainment retail healthcare education and more – from smart cities to your everyday deviceswe benefit everyone  we do all of this while striving for a culture that empowers every person to be the difference at work and in our communities

colorful hair don’t care tattoos show off your ink like polka dots that’s cool pop culture geek many of us are be you with us wearecisco",,WA,False,data_engineer
Lead Data Engineer - Sales Transaction Platform,"description
join us as a lead data engineer – sales transaction platform
the data science and engineering team at target is a hypergrowing dynamic and collaborative team data engineers work closely with data scientists to create valuable insights using voluminous data collected from internal and external systems on a largescale business operations are empowered with these insights to achieve target’s strategic initiatives while providing worldclass shopping experiences
about this opportunity
as a lead data engineer you will have the opportunity to create software solutions using agile practices and devops principles responsibilities will include designing programming debugging and supporting high quality distributed systems and largescale solutions on the latest big data tech stack javascala hadoop spark druid kafka etc

we’re looking for a highly motivated and talented big data programmer who’s a team player wants to work on largescale data products grow their skillscareer as well as have fun in an exciting retail data environment
key responsibilities
develop software systems using test driven development employing cicd practices
partner with other engineers and team members to develop software that meets business needs
follow agile methodology for software development and technical documentation
innovate constantly and stay current with latest technologies while staying focused on solving problems
requirements
ms degree in computer science or relevant experience
5 years of experience in developing software applications
3 years of experience working on big data tech stack like hadoop spark and hive
proficiency in atleast one of the following languages java scala or python
excellent understanding of software design and development at scale
worked on building and supporting web services end to end
experience with rest services preferred
experienceknowledge of kafka streaming solutions
team player who collaborates and enjoys solving technical challenges with huge data sets

qualifications",,CA,False,data_engineer
Data Engineer,"our entrepreneurial group of technologists and analytics experts is looking to add an experienced data engineer to our technology team in philadelphia the ideal candidate will be adept at problem solving interested in pursuing new ideas and will play a key role in the strategic initiatives of an innovative global investor responsibilities include gathering requirements building out a data warehouse establishing and maintaining data integrations developing data governance best practices and optimizing data flow
we are looking for candidates that are passionate about building and optimizing data systems the data engineer will collaborate with our developers data scientists and technology products they will also support nontechnical colleagues in the collection and use of structured and unstructured data they must be selfdirected and comfortable supporting multiple projects and teams this hire will contribute to data transparency across the organization driving operational efficiency and providing decision makers with actionable insights
job description
project management – gather project requirements establish timelines track progress and manage to milestone achievements
modeling – determine the most appropriate schema for storing structured and unstructured data
extract transform load – apply business logic to move data from one system to another and validate data quality
integration – determine the optimal methods for collecting and incorporating new data into data warehouses
governance – establish and educate the organization on data governance standards
strategic reporting – collaborate with colleagues to scope out new data requests and methods to extract and present data from various data sources
automation  implement internal process improvements with an aim to automate manual processes and optimize data delivery
necessary qualifications
5 years experience in data engineering preferably in financial services
babs in related field eg computer science mathematics engineering
must have experience with objectoriented programming languages and agile software development
must have proficient technical skills in sql and relational databases exposure to data integration tools and experience building and consuming apis
must have experience building a data warehouse in a professional environment
exposure to statistical data analysis tools eg r and data visualization tools eg tableau is a plus
must have proficient communication skills be proactive and be able to comfortably lead projects independently that include cross functional collaboration
we offer a competitive salary annual discretionary bonus and a comprehensive benefits package which includes medical prescription dental paid time off 401k plan life and disability insurances tuition reimbursement health club reimbursement and flexible spending accounts
hamilton lane is an equal opportunity employer all qualified applicants will be considered for employment without regard to their race religion ancestry national origin sex sexual orientation age disability marital status domestic partner status or medical condition as a registered investment adviser employees of hamilton lane may be subject to certain limitations on political contribution and personal investment activities",,PA,False,data_engineer
Data Engineer - Global,"job description
at amazon our goal is to be earth’s most customercentric company and to create a safe environment for both our customers and our associates to achieve that we need exceptionally talented bright dynamic and driven people if youd like to help us build the place to find and buy anything online this is your chance to make history we are looking for a talented data engineer to join the restricted products team based in our seattle office

this role will be a key member of the rp business intelligence team focused on supporting the restricted products supplier engagement team and responsible for developing robust scalable data models to support new supplier risk detection assessment and enforcement programs and tools you’ll be challenged to innovate using a variety of technologies and data sources and you will work with topnotch technical and nontechnical professionals across multiple organizations and regions in order to develop and deliver complex solutions that will sustain operational excellence we are looking for someone who is motivated by thinking big moving fast and inventing new ways to create and use data and available technologies at amazon


this role requires strong attention to detail excellent analytical abilities deep knowledge of business intelligence solutions solid work ethic and drive the ability to work independently and with primary stakeholders to solve complex medium and large scale issues the ability to recommend solutions to unstructured problems and the skill to manage both with and without authority the successful candidate will be a motivated selfstarter comfortable with ambiguity and will be comfortable extracting data from various sources to designconstructexecute complex data architectures that help to solve business problems

responsibilities

design implement and support analytical infrastructureinterface with other technology teams to extract transform and load data from a wide variety of data sources using sql python and aws big data technologiesexplore and learn the latest technologies to provide new capabilities and increase efficiencycollaborate with business analysts and business intelligence engineers bies to recognize and help adopt best practices in reporting and analysis data integrity test design analysis validation and documentationcollaborate with other tech teams to implement advanced analytics algorithms that exploit our rich datasets for statistical analysis prediction clustering and machine learninghelp continually improve ongoing reporting and analysis processes automating or simplifying selfservice support for customersprovide wingtowing data engineering support for project lifecycle execution project planning execution risk assessment and system availabilityparticipate in developing strategy recommendations
basic qualifications
bachelors degree in computer science engineering mathematics or equivalent professional experience in a related technical discipline4 years of industry experience in software development data engineering business intelligence data science or related field with a track record of manipulating processing and extracting value from large datasetsdemonstrated strength in data modeling etl development and data warehousingexperience using big data technologies hadoop hive hbase spark etcexperience using business intelligence reporting tools tableau business objects cognos etcknowledge of data management fundamentals and data storage principlesknowledge of distributed systems as it pertains to data storage and computing
preferred qualifications
experience working with aws big data technologies redshift s3 emrproven success in communicating with users other technical teams and senior management to collect requirements describe data modeling decisions and data engineering strategyexperience providing technical leadership and mentoring other engineers for best practices on data engineeringfamiliarity with statistical models and data mining algorithmsknowledge of software engineering best practices across the development lifecycle including agile methodologies coding standards code reviews source management build processes testing and operationsmasters in computer science mathematics statistics economics or other quantitative fieldsa proven track record of delivering initiatives from conception through completion on time within budget and on or beyond scope",,WA,False,data_engineer
Data Engineer,"73052  148967 a yeardata engineers focus on the design implementation and operation of data management systems to meet the cias business needs it includes designing how the data will be stored consumed integrated and managed by different data entities and digital systems data engineers work together with data consumers to determine create and populate optimal data architectures structures and systems data engineering requires an extensive knowledge of data manipulation databases data structures data management and best engineering practices

data engineers must also plan design and optimize for data throughput and query performance issues this requires constantly updating expertise in areas such as platform network and storage technologies bandwidth management data bus implications and design

additionally data engineers play a key role in the selection of backend database technologies sql nosql hpc etc their configuration and utilization and the optimization of the full data pipeline infrastructure to support the actual content volume etl and periodicity of data to support the intended kinds of queries and analysis to match expected responsiveness

offices of the cia  directorate of digital innovation

the directorate of digital innovation ddi is at the forefront of defining the future of digital expertise within the cia ddi focuses on developing the workforce with cuttingedge skills investing in it infrastructure and modernizing the way the agency does business ddi officers help accelerate the integration of innovative methods and tools to enhance the cias cyber and digital capabilities on a global scale and ultimately help safeguard our nation learn more about the directorate of digital innovation

life at cia

in addition to a comprehensive benefits package the cia offers exciting career opportunities and a dynamic environment were on the forefront of worldaltering events  as they happen so working here isnt just a job its a mindset and a lifestyle

minimum qualifications

bachelors degree preferably in mathematics computer science engineering management information systems or related fields
gpa of at least 30 on a 40 scale
the following items must be attached to your online application pdf format preferred

your resume
a cover letter in which you specify your qualifications for one or more positions
unofficial transcripts for all degrees
all positions require relocation to the washington dc metropolitan area

all applicants must successfully complete a thorough medical and psychological exam a polygraph interview and an extensive background investigation us citizenship is required

to be considered suitable for agency employment applicants must generally not have used illegal drugs within the last twelve months the issue of illegal drug use prior to twelve months ago is carefully evaluated during the medical and security processing

important notice friends family individuals or organizations may be interested to learn that you are an applicant for or an employee of the cia their interest however may not be benign or in your best interest you cannot control whom they would tell we therefore ask you to exercise discretion and good judgment in disclosing your interest in a position with the agency you will receive further guidance on this topic as you proceed through your cia employment processing

to apply

save the positions that interest you in the job cart you can add up to four 4 positions job cart selections will only be retained during this site visit so be sure to click “apply now” before closing the browser window after clicking apply now you will be taken to the application account creation page the positions will appear in the cart once you have created an account do not submit multiple applications this will only slow the review of your application and delay processing please read the application instructions carefully before you begin the online application process",111009.0,DC,False,data_engineer
Data Engineer,"about the job
can you envision working closely with all aspects of data from application to cloud services
come join our team as a data engineer 

at 8x8 we have many opportunities to work with data on a daily basis can you envision working on data and build the infrastructure that are critical to drive valuable business insight how about building a scalable data pipelines to drive critical data analysis for our end users and enable data science experimentation our enterprise data analytics team works closely with all aspects of data from our application to our cloud services we’re looking for data engineer with experience building efficient data pipelines reliably moving data across various and eager to build the scalable data tools for data exploration your work will greatly influence our program teams and analysts you’ll take an active role in driving our analytics strategic projects that takes on some of the most challenging problems to solve this is a full time position in our office in san jose


build data expertise and own data quality for all data pipelines you build
track events that are critical to drive business values
work with new data models that provide intuitive analytics
move data from large scale data warehouse and data storage both internally and externally
 develop new systems and tools to enable folks to consume and understand data faster
use your expert coding skills across a number of languages from python java and php
work across multiple teams in high visibility roles and own the solution endtoend
requirements

2 years of java andor python development experience is necessary
2 years of sql mysql hive etc experience is required
3 years of experience with dimensional data modeling  schema design in data warehouses
2 years of experience in etl design implementation and maintenance pentaho elastic search
100 passionate for reliable data pipelines and intuitive user interfaces
ability to write wellabstracted reusable code components
excellent communication skills including the ability to identify and communicate data driven insights
bs or ms degree in computer science or a related technical field

lirm1",,CA,False,data_engineer
Data Engineer,"rated 32nd most successful saas company in the world by montclare gooddata is on a mission to fundamentally change how analytics are used and adopted throughout the organization with more than 50 percent of the fortune 500 using gooddata millions of end users and a massively scalable and secure enterprise insights platform gooddata works with customers to drive a business outcome focus allowing data to finally drive meaningful change for the business
today some of the most wellknown brands are using the gooddata enterprise insights platform to disrupt their industries improve productivity and make business critical decisions to create revenue generating smart business applications according to forrester insightsdriven businesses will steal 12 trillionyear from traditional market players by 2020 this is the transformation gooddata is enabling globally
gooddata is headquartered in san francisco and backed by toptier investors like andreessen horowitz general catalyst partners intel capital totvs and others for more information visit our website and follow gooddata on twitter and linkedin

job description
as a key member of our consulting team within professional services the solutions engineer will be the data engineer that helps guide our customers through their data product implementation working directly with customers a team of data product managers solution architects and engineers drive requirements gathering the project design and the qa process you will implement data warehouse data models and dimensional data models deliver etl in sql and write multidimensional queries in maql
the right candidate for this position is customer oriented with strong communication and technical skills you must be able to demonstrate deep technical expertise and clearly articulate technical topics even to nontechnical audiences
this role is best suited for someone who has 2 years of work experience has a quantitativelyoriented degree of any variety from a toptier school and who thrives in extremely analytical technicallyoriented consultative role this role is located in san francisco ca and no relocation assistance is offered

responsibilities
in collaboration with architects implement data solutions that solve business problems
design conceptual logical and physical data models
implement effective and scalable endtoend data pipeline solutions
optimize sql queries for scale
build metrics and reports
address functional requirements and quality attributes
possess a comprehensive understanding of the gooddata products and services

qualifications
2 years of overall experience
fluency in sql and experience in extract transform and load etl development in sql
understanding of dimensional and normalized database models and their applications
having a programming mentality and problemsolving skills

bonus points
experience in the business intelligence bi  data warehousing dw industry
it consulting skills and experience
experience with cloud based saas platforms
experience working in professional services organization
experience with columnar databases
experience with ruby
experience with javascript
experience with rest apis
interest in machine learning

additional information
at gooddata you won’t just grow your career you’ll be a part of a movement that is changing how people work and make decisions
why you should join gooddata
help drive the future of business
solve meaningful problems
build and promote great technology
work with brilliant people
we are committed to creating a diverse work environment and proud to be an equal opportunity employer all your information will be kept confidential according to eeo guidelines
no relocation assistance is offered for this opportunity at this time and local candidates will be given priority consideration
agency recruiters take note
please do not spam us with unsolicited candidate resumes unless you have a fully executed agreement with us we will consider them a gift do not send resumes to any of the executives",,CA,False,data_engineer
Senior Data Analyst,"about leaflink
leaflink is a marketplace that provides licensed cannabis retailers the ability to order from their favorite brands as well as a suite of software tools for those brands to manage and scale their operation

with over 2000 dispensaries and more than 600 leading brands in colorado washington california oregon nevada maryland and arizona leaflink is setting the industry standard for how cannabis brands and retailers work together

our team backed by funding from leading vcs is poised to define the cannabis wholesale market this year leaflink was named one of fast companys top 10 most innovative companies in enterprise joining the ranks of amazon slack and vmware  and were just getting started

the role
leaflink seeks a senior data engineer to join our growing product and engineering team to contribute to our industry and internal data insights efforts we have some exciting data efforts in front of us which include


situate the organization with a business intelligence tool to help us drive business decisions
own the design and development of automated dashboards
drive internal business decisions and directions through establishment of core kpis
create industrydefining metrics and standard reporting to help drive the cannabis industry
support adhoc data analysis or reporting needs from teammates or customers
proactively conduct adhoc analyses to discover new product and business opportunities
develop new metrics to better identify trends and key performance drivers within a particular area of the business
empower teammates to develop reports by assisting them with concepts and sql

qualifications

5 years working at an established saas or ecommerce company
5 years working with sql and other data insight tools
proficiency in at least one programming language such as python
strong grasp of statistics and experience with open source big data technology
3 years of working crossing functional to create kpis which drive or support strategy decisions
has owned business intelligence platforms such as periscope looker tableau or domo
has published industry reports or worked closely with a marketing team to showcase powerful data insights to establish thought leadership

benefits

healthcare matching
3 weeks paid vacation a year
fun office environment
competitive salary
benefit matching medical dental vision
generous stock options
team events
cool swag
brand spanking new office in fidi

",,NY,False,data_engineer
Data Engineer,"engineer  data focus

door is expanding its engineering team and is searching for a fulltime software engineer passionate about data we are looking for crossfunctional software practitioners who are involved in delivery across the full stack and the full lifecycle with a focus on data retention access and reporting door is heavily invested in aws and this role will be responsible for


developing schemas and storage solutions for structured and semistructured data
deploying data solutions via cloudformation
working with various storage backends possibly including postgres redshift dynamodb and snowflake
contributing to docker services in nodejs and python
modeling and documenting a consistent view of persistent and transient data
ensuring the security maintainability and robustness of the data and schema
ensuring the quality and correctness of data access

the ideal candidate


must have sql and nosql database experience
must have experience designing and changing data models
must have experience with a reporting and visualization tool
should have nodejs or python experience
should have exposure to aws services aws certification a plus
should have exposure to security practices iam experience a plus
should be a polyglot developer interested in new languages tools and technologies
should be passionate about delivering quality software to quality people

this role reports to engineering lead in our dallas tx office",,TX,False,data_engineer
Data Engineer,the data engineer is responsible for working with and improving the quality of our clients’ data coordinating with our technical and client teams to continually refine our data management and integration processes ideal candidates have several years of experience working with data and utilizing ms sql and a good understanding of data processing cleansing and integrating techniques to enhance our globallyused saas platforma technical screen will be conductedresponsibilitiescontribute to leveraging big data machine learning and advanced analytics to deploy analytical solutionsdesign and improve dataintegration procedures to collect distribution and store datahelp drive optimization testing and tooling to improve data qualityidentify inefficiencies in queries and etls and investigate solutions for performance tuningwork with business teams to assist with datarelated technical issues and support their data needsenhance and maintain our business intelligence platform to deliver improved analytics for end userscoding testing and troubleshooting features and enhancements in the current database environmentmonitoring and finetuning databases for optimal performancequalifications  experience2 years of data modeling etl and data warehousing experience2 years of development experience with ms sql serverstrong computer science fundamentals including data structures and algorithmsbachelor’s degree in computer science or relevant educational background including certificationsexperience with ms sql and related toolsexperience in data warehousingexperience in designing data integration  etlknowledgeable about data modeling data access and data storage techniquesability to manage a workload based on shifting prioritiesability to work in a fast paced and dynamic environmentexcellent written and verbal communication in englishexperience in agile or scrum practices a plusjob type fulltimeexperiencedata modeling 2 years requiredsql 2 years requirededucationbachelors preferredlocationatlanta ga required,,GA,False,data_engineer
Data Engineer,"functional area
it  information technology


estimated travel percentage  no travel


relocation provided no


american general life insurance company


aig life  retirement group seeks a data engineer to work closely with softwareapplication development teams and business users to design database structures and solutions based on the data storage and retrieval needs within each solution the data engineer will be responsible for developing our target state data storage processing and analysis architecture with a focus on cloud and hybrid on premisecloud architectures
the data engineer is responsible for choosing the right technology and proper data design and implementation in various projects and solutions candidate is expected to demonstrate handson skills in processing large data sets familiarity with data structure big data concepts cloud computing opensource tools and optimization techniques excellent oral and written communication skills client focus and the ability to support and enable teamwork must be selfmotivated and able to operate independently with limited guidance and direction
data engineer responsibilities
design build and deploy database applications
design and implement effective monitoring on the different database technologies to proactively identify performance issues
serve as expert on the data lake relational and nosql implementations
help maintain the integrity and security of the company data
provide insight into the changing database storage and utilization requirements for the company and offer suggestions for solutions
analyze database implementation methods to make sure they are in line with our data strategy and goals
manage the retrieving and analyzing of large volumes of data
attend key design meetings and provide support and expertise
work closely with vertical development teams ensuring proper implementation and following of the design

data engineer requirements
bachelor’s degree in computer engineering or related field required
experience of it platform implementations in a highly technical and analytical role
strong sql skills and proficiency with oracle required
must be able to develop creative solutions to problems
experience with the full development life cycle of an application stack  from architecture through test and deployment
experience with key reporting solutions including cognos qlikview and power bi will be highly valued
familiarity with big data concepts cloud computing opensource tools and optimization techniques is preferred
implementation and tuning experience specifically using talend aws emr spark
strong analytical skills ability to analyze raw data draw conclusions and develop actionable recommendations
organized detailoriented qualityfocused
prior experience in financial services industry
demonstrated ability to think strategically about business product and technical challenges in an enterprise environment
strong verbal and written communications skills and ability to lead effectively across organizations
hands on experience leading largescale global data warehousing and analytics projects
demonstrated industry leadership in the fields of database data warehousing or data sciences


it has been and will continue to be the policy of american international group inc its subsidiaries and affiliates to be an equal opportunity employer we provide equal opportunity to all qualified individuals regardless of race color religion age gender gender expression national origin veteran status disability or any other legally protected categories

at aig we believe that diversity and inclusion are critical to our future and our mission – creating a foundation for a creative workplace that leads to innovation growth and profitability through a wide variety of programs and initiatives we invest in each employee seeking to ensure that our people are not only respected as individuals but also truly valued for their unique perspectives",,CT,False,data_engineer
Business Data Engineer,"automattic is the company behind wordpresscom jetpack woocommerce and more we are looking for a fullstack data engineer with a head for business

you’ll work with business leads analysts data scientists and fellow engineers to build data products that empower better decision making you’re relentless about data quality in business metrics you’ll understand business drivers and analytics use cases you’ll evaluate and help to craft technology choices and you’ll implement the data tools required to tackle business use cases

what we’re looking for

handson production experience with big data technologies hadoop hive impala hbase and data pipelines
experience in developing business analytics and data visualization tools for business metrics
strong analytical skills and a fervor for data quality
the curiosity and determination to understand and improve data flows
we’re serious about growing diversity in the tech industry we want to build automattic as an environment where people love their work and show respect and empathy to those with whom we interact diversity typically includes but is not limited to differences in race gender sexual orientation gender identity or expression political and religious affiliation socioeconomic background cultural background geographic location disabilities and abilities relationship status veteran status and age to work on diversity means that we welcome these differences and strive to increase the visibility of traditionally underrepresented groups read more about our dedication to diversity and inclusion

how to apply
does this sound interesting if yes please send a short email to jobs  this domain telling us about yourself and attach a résumé let us know what you can contribute to the team include the title of the position you’re applying for and your name in the subject

proofread make sure you spell and capitalize wordpress and automattic correctly we are lucky to receive hundreds of applications for every position so try to make your application stand out if you apply for multiple positions or send multiple emails there will be one reply

if you’re reading this on a site other than automatticcom please ensure you visit automatticcomworkwithus for the latest details on applying
please answer the following questions in your cover letter applications without these questions answered will not be considered

tell us some details about an interesting data problem you’ve worked on what made it interesting
include a link to a recent favorite blog post or paper about working with lots of data
what questions do you have for us",,CA,False,data_engineer
Data Engineer,"do you want to make an impact on the future of ecommerce and blockchain technologies
who we are

we are located just minutes away from salt lake city utah and several worldclass ski resorts and within hours of five national parks  overstock is an original resident of  silicon slopes  one of the fastest growing technology hubs in the country we’re a passionate group of collaborative problem solvers and creative innovators working on cuttingedge technology like our awardwinning retail app with amazing ar functionality  and leading blockchain and machine learning technologies our team embodies unique values and diverse perspectives making overstock a hidden treasure in the tech industry

our mission

overstock’s mission is to use build and find cuttingedge technology that helps connect people with products and services in new and unexpected ways our website offers millions of brand name products at discount prices to inspire people to make their dream homes a reality

a data engineer role provides direct support to the data science group as well as the company at large


as with any data related position this role would include integrating data from multiple sources

via a variety of tools this would necessitate using but also possibly researching

the appropriate technologies for such integrations

job responsibilities
aid data scientists and others in transforming their work into scalable production solutions

set up and manage big data or hadooprelated environments

become familiar with existing big data development and database systems at overstockcom

preparation and cleaning of data for analysis

as needed research and select proper architecture of and uses of big data tools
perform other duties as required and assigned by manager and upper management
follow legal policies as directed

job requirements
5 years it industry experience
proficiency in sql
experience with hadoop ecosystem technologies
some proficiency in tools such as spark pig mapreduce or hive
etl experience
ability to work with a variety of roles such as dbas big data engineers data scientists and etl developers
experience in at least one programming language preferred languages python java scala
administration and tuning of linux servers and applications a plus
skills
sql python spark hadoop hdfs pig hive cloudera java scala linux
education
bs in computer science information systems or related field
certifications
physical requirements
equal employment opportunity it is our policy to provide equal employment opportunity for all applicants and associates this policy includes our commitment to ensure that all employment decisions are made without regard to race color religion gender national origin disability pregnancy veteran status including vietnam era veterans age sexual orientation gender identity or any other nonjobrelated characteristic protected by law


what we offer
leed gold certified 19acre campus  global hq
onsite daycare center
401k 6 match
onsite health clinic
flexible schedules
tuition reimbursement leadership development program  mentorship program
onsite fitness center with group fitness classes and trainers
onsite cafe with additional coffee shop and juice bar
indoor bike storage
summer party at lagoon utahs largest theme park
employee fall concert past performers include flo rida snoop dogg and jason mraz
medical dental vision coverage
onsite greenhouse providing fresh fruits  vegetables for our cafe
life insurance short and longterm disability coverage
onsite salon services massages  autodetail services
discounts on ski passes cell phone plans
overstock womens network own

benefits vary based on location position tenure and employee election

what we value
wellness  balance
sustainability
corporate social responsibility
innovation  discussed on medium  digital trends  and digital commerce 360 

physical requirements

this position requires you to sit stand and perform general office functions you may also be required to lift up to 25 pounds occasionally bending stooping and reaching are also frequently required

equal employment opportunity

it is our policy to provide equal employment opportunity for all applicants and associates this policy includes our commitment to ensure that all employment decisions are made without regard to race color religion gender national origin disability pregnancy veteran status including vietnam era veterans age sexual orientation gender identity or any other nonjobrelated characteristic protected by law",,UT,False,data_engineer
Big Data Engineer,"job description

captech big data engineers are tasked with designing and implementing big data solutions for our clients captech employees enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other captech developers architects and our clients
specific responsibilities for the big data engineer position include
design develop document and test big data solutions
understand the challenges being addressed by an engagement and collaborate with team members and clients to deliver a technical solution that meets the unique needs of our clients
create quality deliverables to communicate technical solutions to appropriate audiences
learn continuously leveraging captech’s training resources and selfdirected training sharing knowledge and skills with others
provide mentoring and leadership to more junior resources

qualifications

specific qualifications for the senior big data engineer position include
demonstrated growth over 5 years’ experience working as a data engineer
high level understanding of big frameworks
development experience with big datanosql platforms such as hbase mongodb or apache cassandra
expert knowledge of sql and nosql tools
knowledge of mapreduce and mapreduce generating tools like pig or hive
experience with message buses or realtime event processing platforms is a plus
java development experience
scripting language experience perl python etc
understanding of nosql data modeling
knowledge of how to assess the performance of data solutions how to diagnose performance problems and tools used to monitor and tune performance
additional information


we offer challenging and impactful jobs with professional career paths all captechers can keep their hands on technology no matter what position they hold our employees find their work exciting and rewarding in a culture that filled with opportunities to have fun along the way
at captech we offer a competitive and comprehensive benefits package including but not limited to
competitive salary with performance based bonus opportunities
single and family health insurance plans including dental coverage
shortterm and longterm disability
matching 401k
competitive paid time off
training and certification opportunities eligible for expense reimbursement
team building and social activities
mentor program to help you develop your career

candidates must be eligible to work in the us for any employer

captech is an equal opportunity employer
captech is a drugfree work place
candidates must have the ability to work at captech’s client locations
all positions include the possibility of travel",,VA,False,data_engineer
Data Intelligence - Edge Data Engineering - Data Engineer (D...,"more about this job
what we do
at goldman sachs our engineers don’t just make things – we make things possible change the world by connecting people and capital with ideas solve the most challenging and pressing engineering problems for our clients join our engineering teams that build massively scalable software and systems architect low latency infrastructure solutions proactively guard against cyber threats and leverage machine learning alongside financial engineering to continuously turn data into action create new businesses transform finance and explore a world of opportunity at the speed of markets

engineering which is comprised of our technology division and global strategists groups is at the critical center of our business and our dynamic environment requires innovative strategic thinking and immediate real solutions want to push the limit of digital possibilities start here

who we look for
goldman sachs engineers are innovators and problemsolvers building solutions in risk management big data mobile and more we look for creative collaborators who evolve adapt to change and thrive in a fastpaced global environment
the data intelligence organization aims to make data a strategic asset for the enterprise by providing a platform that enables the structuring management integration control discovery usage and governance of our data assets
the team leverages a wide variety of cutting edge technologies including hadoop hbase spark apache beam apache flink kakfa sql olap platforms presto hive java and python your impact will be to curate design and catalog high quality data models to ensure that data is accessible and reliable build highly scalable data processing frameworks for use across a wide range of datasets and applications provide datadriven insight and decisionmaking critical to gs’s business processes in order to expose data in a scalable and effective manner understanding existing and potential data sets in both an engineering and business context
responsibilities and qualifications
how you will fulfill your potential
• • deploy modern data management tools to curate our most important data sets models and processes while identifying areas for process automation and further efficiencies
• • evaluate select and acquire new internal  external data sets that contribute to business decision making
• • engineer streaming data processing pipelines
• • drive adoption of cloud technology for data processing and warehousing
• • engage with data consumers and producers in order to design appropriate models to suit all needs

skills and experience we are looking for
23 years of relevant work experience in a teamfocused environmenta bachelor’s degree masters preferred in a computational field computer science applied mathematics engineering or in a related quantitative disciplineextensive knowledge and proven experience applying domain driven design to build complex business applicationsdeep understanding of multidimensionality of data data curation and data quality such as traceability security performance latency and correctness across supply and demand processesindepth knowledge of relational and columnar sql databases including database designgeneral knowledge of business processes data flows and the quantitative models that generate or consume dataexcellent communications skills and the ability to work with subject matter expert to extract critical business conceptsindependent thinker willing to engage challenge or learnability to stay commercially focused and to always push for quantifiable commercial impactstrong work ethic a sense of ownership and urgencystrong analytical and problem solving skillsability to collaborate effectively across global teams and communicate complex ideas in a simple manner

preferred qualifications
financial services industry experienceworking knowledge of more than one programming language python java c c etcexperience with the hadoop ecosystem hdfs spark
about goldman sachs
the goldman sachs group inc is a leading global investment banking securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations financial institutions governments and individuals founded in 1869 the firm is headquartered in new york and maintains offices in all major financial centers around the world

â© the goldman sachs group inc 2018 all rights reserved goldman sachs is an equal employmentaffirmative action employer femaleminoritydisabilityvet",,NY,False,data_engineer
Data Engineer,"want to be part of shaping the future our breakthrough ability to unlock insights from the web radically improves intelligence and cyber threat visibility were a highenergy fastpaced and fastgrowing company that partners closely with our customers this role is integral in delivering best practice threat intelligence solutions to our customers and building lasting productive relationships between users and the company our ideal candidate has outstanding communication skills proven history in customer community building or engagement and is excited about building collaboration around cyber threat intelligence problem sets

the data science team takes ownership of this unique dataset we implement crucial harvesting capabilities manipulate our data structures to obtain solutions and insights and explore new use cases and capabilities for the data were looking for smart and ambitious people with a strong engineering foundation and a quantitative mindset to help us get the most out of our unparalleled collection and analysis technology you will join a team of motivated people working on a tough problem and help us shine a light into the dark corners of the internet

qualifications

technical education ba bs ms or phd in computer science or related discipline with a strong academic record
programming solid programming in python and at least one other language comfort with developing production code javascript experience is a plus
data skills comfort working with complex data structures you love shaping data into a usable product and you know how to write the code that makes that happen
excellent communication your clarity of thought is always apparent in your crisp and articulate emails slack chats phone calls and inperson conversations
bonus if you have experience or interest in the area of cybersecurity

we realize we can only succeed with a team of very smart and passionate people if youre looking to work in a unique environment with ambitious dedicated colleagues the chance to collaborate with fantastic users and customers then we have a lot in common youll also be equipped with top technology enjoy trips the best coffee great food and fun we offer competitive compensation including stock options and a full range of benefits as well as a great culture commitment to professional development and social responsibility

dont forget to check out our podcast  httpsboardsgreenhouseioembedrecordedfuturecompodcast join the recorded future team special guests and our partners from the cyberwire to learn everything you want to know and maybe some things youd rather not know about the world of cyber threat intelligence all episodes are free and available on itunes googleplay and stitcher",,MA,False,data_engineer
Data Science Data Engineer,"jp morgan is a premier corporate and investment bank with a full suite of global financial services and capabilities the world’s most important corporations governments financial institutions pensions sovereign wealth organizations states and municipalities entrust us with their business in more than 100 countries we offer strategic advice lend money raise capital help manage risk extend liquidity buy and sell securities and provide many other banking services in markets around the world

we are looking for an experienced data engineer to join a small group of technologists who will work hand in hand with scientists on a daily basis to enable them to deploy their ideas into production quickly and

this role requires a wide variety of strengths and capabilities including
 bsba degree or equivalent experience
 advanced knowledge of application data and infrastructure architecture disciplines
 understanding of architecture and design across all systems
 working proficiency in developmental toolsets
 ability to collaborate with highperforming teams and individuals throughout the firm to accomplish common goals
 proficiency with hadoop and big data
 understanding of software skills such as business analysis development maintenance and software improvement
 design architect and build data platform solutions using big data technologies
 work with architecture and engineering team to define reference architecture for big datadistributed computing
 access stakeholder requirements prototype and iterate solutions to solve business problems using big data technologies
 proven track record selecting appropriate data storage technologies and etl technologies and building out ingestion pipelines
 6 years of hands on java development experience experience working on java server side frameworks  spring spring boot etc
 2 to 4 years’ experience on hadoop platform hdfs hive hbase spark oozie impala cassandra etc
 8 years of professional experience with an established track record as a full stack architect

our corporate  investment bank relies on innovators like you to build and maintain the technology that helps us safely service the world’s important corporations governments and institutions you’ll develop solutions for a bank entrusted with holding 18 trillion of assets and 393 billion in deposits cib provides strategic advice raises capital manages risk and extends liquidity in markets spanning over 100 countries around the world

when you work at jpmorgan chase  co you’re not just working at a global financial institution you’re an integral part of one of the world’s biggest tech companies in 14 technology hubs worldwide our team of 40000 technologists design build and deploy everything from enterprise technology initiatives to big data and mobile solutions as well as innovations in electronic payments cybersecurity machine learning and cloud development our 95b annual investment in technology enables us to hire people to create innovative solutions that will not only transform the financial services industry but also change the world

at jpmorgan chase  co we value the unique skills of every employee and we’re building a technology organization that thrives on diversity we encourage professional growth and career development and offer competitive benefits and compensation if you’re looking to build your career as part of a global technology team tackling big challenges that impact the lives of people and companies all around the world we want to meet you",,NY,False,data_engineer
Data Engineer,"description
we are looking for a data engineer to help us build our data pipeline data warehouse and technical data structures across the data landscape

responsibilities

partner with the product and engineering teams to develop scalable extensible data solutions for data transformation movement and manipulation
normalize transactional data disparate systems and transfer of data in a way that creates flexible and scalable data solutions
builds applications and scripts for specialized data processes to acquire manipulate and supply data to systems for various purposes
understands master data elements to be used when joining datasets and creating data maps
creates processes and data management systems including manual and automated processes such as cleansing and maintaining master data sets
builds automated faulttolerant processes to acquire and cleanse data routinely
develop new dimensional data models where highly complex data relationships and data flows exist
design and maintain data pipelines to simplify end user reporting and analytics
maintain the security data integrity and availability of data in the data warehouses and data hubs
build and maintain data pipelines between 1st and 3rdparty products and the data warehouse used for companywide analytics
collaborate with all teams across the company to ingest data and apply appropriate business logic
uses existing data assets to build new datasets for the purpose of gaining new insights

requirements
technicalbusiness experience


bachelor’s degree in computer science or related field
5 years overall experience working in development and enterprise data
experience with writing sql scripts and python or ruby apps for purposes of data manipulation
experience and background in building data platforms
experience with easymorph or alteryx preferred
minimum 3 years of experience with data architecturedesign
minimum 3 years of experience in software development with deep experience in objectoriented functional objectfunctional language and one of the major sql relational datastores we are a sql server shop

",,PA,False,data_engineer
Senior Data Engineer,"iheartradio is looking for a talented data engineer to help us in our datadriven mission to reshape the world of music and the spoken word you will work in a highly collaborative team of engineers and alongside data scientists and analysts to distill existing data processes import new external data sources and create complex data mashups your work will provide valuable insights and power important music data products expect to build high throughput data pipelines and improve the existing big data infrastructure you will also improve performance squash bugs and increase visibility across the data ecosystem you will have end to end ownership of your code though ideally you also relish reviewing a good pull request if you enjoy working with large sets of data and the challenges associated with them this is the role for you

you like

working in an agile development methodology and own data driven solutions endtoend
experimenting with various frameworks in the big data ecosystem to identify the optimal approach for extracting insights from out datasets
identifying performance bottlenecks in data pipelines and architect faster more efficient solutions when necessary
creating new data warehouse solutions and define and demonstrate best practices in schema and table design in varied databases like hive redshift spectrum etc
developing endtoend batch and real time pipelines for large data sets to our hadoopspark clusters and bring summarized results back into a data warehouse for downstream business analysis
when needed performing data housekeeping data cleansing normalization and implementation of required data model changes
increasing efficiency and automate processes by collaborating with our sre team to update existing data infrastructure data model hardware cloud services etc
designing building launching and maintaining efficient and reliable data pipelines in production
designing developing and owning new systems and tools to enable our consumers to understand and analyze the data more quickly

you have

2 years of experience ingesting processing storing and querying large datasets
2 years of experience working in the hadoopspark ecosystem
ability to write wellabstracted reusable code components in python scala or similar languages
ability to investigate data issues across a large and complex system by working alongside multiple departments and systems
a selfstarter who thrives in owning the products and pipelines they develop
experience with configuration management tools ansible chef puppet etc is a plus
experience with spark kafka or similar is a plus
experience with aws technologies s3 redshift ec2 rds emr dynamo is a plus
proven proficiency with scala is a plus

iheartradio iheartmedias digital radio platform is the fastest growing digital audio service in the us and offers users thousands of live radio stations personalized custom artist stations created by just one song or seed artist and the top podcasts and personalities iheartradio is a great environment for people who like to innovate and have the power to influence decisions we have 120 million registered users across over 200 different platforms and outside the us we are in new zealand australia canada and mexico",,NY,False,data_engineer
Big Data Engineer,"who we are

fueled by a fundamental belief that having access to financial services creates opportunity paypal nasdaq pypl is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy our open digital payments platform gives paypal’s 244 million active account holders the confidence to connect and transact in new and powerful ways whether they are online on a mobile device in an app or in person through a combination of technological innovation and strategic partnerships paypal creates better ways to manage and move money and offers choice and flexibility when sending payments paying or getting paid available in more than 200 markets around the world the paypal platform including braintree venmo and xoom enables consumers and merchants to receive money in more than 100 currencies withdraw funds in 56 currencies and hold balances in their paypal accounts in 25 currencies
when applying for a job you are required to create an account if you have already created account  click sign in
creating an account will allow you to follow the progress of your applications

note
provide full legal first namefamily name
do capitalize first letter of first and last name example john smith
dont capitalize entire first andor last name example john smith
note use correct grammar for names with multiple cases example mcdonald or oconnell

provide full address details
resume is required
multiple attachments can be uploaded including resume and cover letter for each application


job description summary
paypal’s global data science organization is in charge of developing unique bestofbreed mlai algorithms using cuttingedge technologies we are looking for a motivated and experienced big data engineer to join a highly skilled team of experienced professionals which believe in bestofbreed software craftsmanship clean and elegant coding using the right tool for the job and always exploring and learning new technologies and approaches

job description
we are looking for an experienced data engineer to help develop new projects on hadoop big data platform

be responsible for practicing technical design developing new functionality and maintaining existing components
deep dive into paypal’s world class risk systems and algorithms and work side by side with data scientists and analysts on data centric analytic solutions
contribute to paypal’s efforts to fight fraud using advanced algorithms and technology while deploying the code you develop into paypal’s live systems and having a true global effect

requirements
bs in computer sciences or equivalent
at least 8 years solid serverside development with java
solid knowledge of basic algorithms
a passion for developing robust scalable software systems
strong oop skills ability to analyze requirements and prepare design
hands on experience with common opensource and java ee technologies
spring
sql jdbcorm jms
app servers  servlet containers
mavengitcontinuous integration

advantage
experience working in agile methodology
experience working on big data platform
experience working on front end technologies
experience working both in startups and in large companies
good communication skill to global business and technical partners
highly motivated goal driven cando approach
innovative entrepreneurial team player ability to multitask

subsidiary
paypal

travel percent
0

primary location
san jose california united states of america



additional locations


masters degree or equivalent




were a purposedriven company whose beliefs are the foundation for how we conduct business every day we hold ourselves to our one team behaviors which demand that we hold the highest ethical standards to empower an open and diverse workplace and strive to treat everyone who is touched by our business with dignity and respect our employees challenge the status quo ask questions and find solutions we want to break down barriers to financial empowerment join us as we change the way the world defines financial freedom


paypal provides equal employment opportunity eeo to all persons regardless of age color national origin citizenship status physical or mental disability race religion creed gender sex pregnancy sexual orientation gender identity andor expression genetic information marital status status with regard to public assistance veteran status or any other characteristic protected by federal state or local law in addition paypal will provide reasonable accommodations for qualified individuals with disabilities",,CA,False,data_engineer
Siri - Speech Data Engineer,"play a part in the next revolution in humancomputer interaction contribute to a product that is redefining mobile computing build groundbreaking technology for large scale systems spoken language big data and artificial intelligence and work with the people who built the intelligent assistant that helps millions of people get things done — just by asking join the siri speech team at apple
we are looking for exceptional data engineers passionate about customer experience who love working with data for measuring and improving accuracy of ml models in products used by millions of customers all over the world

key qualifications
experience in the development and maintenance of tools for analyzing and processing large amounts of data under apache hadoop and spark
strong programming skills in cc andor javascala as well as scripting languages such as python perl and bash
prior experience working on asrmt training and test data sets in multiple languages is preferred
strong analytical skills and a real passion for data and data quality proficiency in visualizing data and statistics
description
you will be a part of a small collaborative team of talented researchers and engineers responsible for data analysis training and test data set creation and related tools development your focus will be on providing the speech recognition and machine translation teams with the best training and test data sets directly contribute to the accuracy of siri in all supported languages and devices you should thrive in a fast paced environment with rapidly changing priorities and collaborate well with other engineering teams at apple

education
bs or ms in computer science or equivalent experience",,CA,False,data_engineer
Data Engineer,"data engineer
engineering los angeles ca fulltime

about thrive

wholesome products at wholesale prices thrive market is a membership ecommerce platform on a mission to make the world’s highest quality natural and organic products affordable for every american family for 60year thrive members get access to their favorite healthy snacks supplements home beauty and baby products at 3050 off retail value—all shipped to their front door as part of our thrive gives initiative each paid membership on the site also sponsors a free membership for a lowincome family

the role

as thrive market continues to grow at an incredible rate youll have the opportunity to build the data infrastructure at the heart of the business at thrive weve created a transparent datacentric environment from the beginning and well need your help building out our existing data warehouse to provide reporting and data for our business departments and data science team

resposibilities
own data instrumentation and data quality and code enhancements for the thrive market web site apis and backend platforms for data collection and data integrity
participate in all aspects of a project lifecycle utilizing scrum methodology
performance tuning of json apis and frontend frameworks
works with dirty and messy data and leads instrumentation logging and validation of data analytics across the site
architect design and develop etl processes between multiple systems using different tools
work with other data engineers and analysts to meet business needs in a timely manner

qualifications
bachelor’s degree required computer science or related field master’s a plus
proficiency in at least one high level programming language like java  scala  python  c
proficiency in a data visualization tool tableau preferred is a plus
experience with apache spark kafka elasticsearch and large scale data analysis is a plus
ability to learn quickly and multitask in a fastpaced dynamic environment
experience with distributed systems and mapreduce architectures a plus
excellent communication skills fun personality and a strong sense of curiosity
excellent analytical and problemsolving skills

we offer
competitive salary doe  equity
flexible vacation time
free thrive membership
medical dental and vision plans to choose from
stocked kitchen and fridges with thrivetype foods
catered lunches in the office
optional yoga on wednesdays kombucha thursdays and weekly events
casual atmosphere and great people to work with",,CA,False,data_engineer
Data Engineer,"job description

our data engineering team builds and maintains a secure scalable flexible and userfriendly analytics hub that allows us to make informed and datadriven decisions they also construct and curate business critical data sets that allow us to realize the value of all the data we collect
a data engineer utilizes a multidisciplinary approach to providing etl solutions for the business combining technical analytical and domain knowledge
the perfect applicant for this role has strong development skills experience transforming and profiling data to determine risks associated with proposed analytics solutions a willingness to continually interface with analysts in order to determine an optimal approach and an eagerness to explore data sources to understand the availability utility and integrity of our data
you will accomplish this by
building and enhancing data ingestion pipelines using tools like python sql aws
leveraging devops best practices such as iac and cicd to build upon a scalable and extensible data environment
deploying and utilizing tools to ensure the curation of datasets that meet the needs of the business
processing and cleansing data from a variety of sources to transform collected data into an accessible and curated state for analysts and data scientists
assisting in data warehousing data analytics and data science efforts
you’d be a great fit if your current track record looks like this
35 years of progressive experience data engineering
experience with python development particularly for data manipulation and api integration
experience with data management platforms eg hadoop emr postgresql redshift bigquery cassandra
fluency with data acquisition and relational database platforms
strong capability to manipulate and analyze complex highvolume data from a variety of sources
effective communication skills with technical team members as well as business partners able to distill complex ideas into straightforward language
ability to problem solve independently and prioritize work based on the anticipated business value
qualifications
at least 3 years experience building software for high traffic websites using languages such as javascript or python
full stack experience preferred
experience with cloud services such as aws and apis
deep understanding of relational databases nosql databases and other types of data stores
a firm grasp of modern testing principles
ways we work
software craftsmanship  we want to be proud of our work come to utahscorg
testdriven development  we take responsibility for our code without qa engineers
agile development  we deliver business value quickly
pair programming  we value collaborative development
continuous delivery  teams independently ship code to prod every day
continual improvement  we take time to sharpen the saw and adjust how we work
autonomous  responsible teams  making their own product  dev choices
crossfunctional teams  collaborating through all phases of the product dev process
customer research  we build what our customers actually want
trusting leaders  who trust us to create and don’t impose deadlines or features
solid technology  of the team’s choice for the right job

qualifications

null

additional information

be yourself pluralsight is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion gender gender identity or expression sexual orientation national origin genetics disability age or veteran status",,UT,False,data_engineer
Data Engineer,"who we are

zume is on a quest to be the most powerful source of health and wellbeing on the planet to achieve our objective we must facilitate the provision of wholesome affordable food on a global scale and in a sustainable manner we are meeting this challenge by providing an endtoend scalable platform that reduces the time and distance between clean food sources and dense population centers using cuttingedge automation and transportation logistics by developing better tools and processes we can feed people healthier sustainablygrown food delivered fresh and free from chemical stabilization

the role

were looking for an experienced data engineer to own our science and modeling platform you will own the platform that powers our data science model training and evaluation and apis e2e

what youll do



build infrastructure to train and evaluate a variety of models
build tooling to normalize data data pipelines feedback infrastructure
stand up the apis used for production prediction and modeling
evaluate and improve model selection algorithms
deploy algorithms and models to improve prediction and ranking performance
generalize model training to include diverse data stores
develop scale and maintain our distributed systems
participate in the pizza production process

this role has the potential to evolve into a lead role as the team grows it is located in seattle wa

who you are

a generalist in data engineering and data science experienced in building production applications for data science and machine learning


degree computer science or other technical degree and equivalent work experience
experience with hadoop cosmos spark or the equivalent
understanding and familiarity with common ml techniques deep knowledge of optimization stochastic processes  markov chains or the like a plus
software development experience in python

bonus points


familiarity with hardware  robotics
understanding of supply chains andor operations
graduate course work in optimization
previous experience at a startup

what we offer


100 companypaid medical dental and vision for you and 75 for your dependents
ownership via stock options
flexible time off
daily catered lunch
free and discounted pizza
the opportunity to work with an incredibly supportive team of thinkers and innovators

",,WA,False,data_engineer
"Data Engineer, Infra Product Analytics","facebooks mission is to give people the power to build community and bring the world closer together through our family of apps and services were building a different kind of company that connects billions of people around the world gives them ways to share what matters most to them and helps bring people closer together whether were creating new products or helping a small business expand its reach people at facebook are builders at heart our global teams are constantly iterating solving problems and working together to empower people around the world to build community and connect in meaningful ways together we can help people build stronger communities — were just getting started
at facebook we have many opportunities to work with data each and every day we are looking for talented data engineers to build systems that will support fast and thorough analysis of our infrastructure products you will work crossfunctionally to define and track metrics that are critical to measure the adoption and efficacy of these products as the products evolve they will trigger new business questions  you will leverage the state of the art to build systems that will answer these questions quickly and comprehensively
responsibilities

work with engineers product managers and product analysts to understand their data needs

automate frequently requested analyses

evaluate and define critical business metrics and identify new levers to help move these metrics

design and evaluate ab experiments

monitor key product metrics and identify root causes behind anomalies

build and analyze dashboards and reports

influence product teams through presentation of databased recommendations

communicate state of business and experiment results to product teams
minimum qualifications

2 years of python development experience

2 years of sql hive oracle or mysql experience
preferred qualifications

2 years experience with data visualization and datamining

experience analyzing data to identify deliverables gaps and inconsistencies

experience initiating and driving projects to completion with minimal guidance

experience communicating the results of analyses",,CA,False,data_engineer
Data Engineer,mulligan funding is a technologydriven businessfinancing company that caters to the unique financial needs of small to midsized businesses headquartered in san diego we have a passionate group of software developers analysts underwriters and sales and marketing professionals we have funded over 150 million and have helped drive business transformation nationwidewe are seeking an enthusiastic and curious software developer to join our team to develop and manage data pipelines but we’re a new team with lots of opportunities to contribute to application design and infrastructure as well in this role you’ll work in a highly collaborative environment where communication with the marketing data science and backend engineering teams is key to your daytoday successresponsibilities write reliable software to ingest transform and distribute data into our internal applicationsautomate current processes and add logging and monitoringbuild data access platform for key stakeholders and data scientistsdesign develop and launch etl processes between multiple systemsdrive the advancement of data infrastructure by developing and implementing underlying logic and structure for how data is set up cleansed and storedpartner with marketing and data science teams to deliver data solutions that meet internal requirements within agreed upon timelinesscope points of failure and create alerts to ensure continual data availability accuracy and cleanlinessprovide ad hoc queries and analysis as neededbuild and maintain reportsdashboards to meet the needs of internal usersmonitor and remediate data quality issuesprocess semistructured data into a form suitable for analysisqualifications strong organizational skills and attention to detaildemonstrated proactive approach to problemsolving with strong decisionmaking capabilityability to balance highpriority longterm projects with immediate deadlinesexcellent verbal and written communication skillsability to work independently in a fastpaced rapidlychanging entrepreneurial environmentrequirements bachelor’s degree in computer science mathematicsstatistics or closely related field2 years of experience working with backend data systems to create and process clean data2 years of experience in developing etl solutions2 years programming manipulatinganalyzing data in python scala or java python preferredproficient in writing scripts with python ruby or javascript python preferredfamiliarity with manipulating dataframes and pandasproficient in sql currently sql server with ability to write complex sql for data manipulationexperience maintaining and updating a data warehouseexperience accessing data via web services and externalnonsql datasetsproficient with data visualization tools eg  tableau or powerbiexperience with aws or azure products ec2 rds aws data pipeline s3 rds dynamo or logic apps sql server and functions etcbenefitscompetitive compensation packagegenerous bonus incentivesmedical vision and dental benefits401kpaid sick vacation and holidaysan entrepreneurial fastpaced and growing environment with the ability to contribute meaningfully to the success of the enterprisemulligan funding is an equal opportunity employer eoe and takes great pride in building a diverse work environment qualified applicants are considered for employment without regard to age race religion gender national origin sexual orientation disability or veteran statusjob type fulltimeeducationbachelors required,,CA,False,data_engineer
Big Data Engineer,contractjob summarytitle big data engineerconsultantadminlocation phoenix az ohioclient hclduration contractwe are looking for a candidate who can work under our payroll ie w2responsibilities and dutiesminimum 1 year of relevant experience into big data and related toolsjob type contract,,AZ,False,data_engineer
Data Engineer,"100000  145000 a yearwe are a growing data engineering team looking to build up their team with strong fullstack data engineers we are a leader in the financial news and information space and need great engineers at the core of our business

come apply to us to learn more so we can tell you about this great opportunity

whats the job

the data engineer will be joining our 6person team here in downtown manhattan the role focuses on three things

1 data projects you will be working on etl building data pipelines data cleaning ingestion and working on everything to do with getting our data into our data lake

2 infrastructure you will be helping to maintain the data infrastructure supporting all of our analytics we use spark clusters kubernetes and aws for example you will be helping to build out upgrade and maintain these systems

3 tech liaison we need you to be able to work with our data scientists and analysts to make sure were providing them the data they need to do their jobs you will be finding out what they need then building out the systems they need

what skills do we need


we are looking for true engineers you should have good engineering fundamentals and open to working on different systems using the right tools
you should have a strong linux background
plus if you have experience with cloud systems data infrastructure andor data engineering

who are we

we are a large company that has been around for decades providing news information and insights to the financial industry we are known for our worklife balance stability and room for growth for our employees we have offices around the world and you will be working in our office in downtown manhattan

compensation


100000  145000 depending on experience
full benefits medical dental vision
401k plan with 3 match
generous paid time off pto policy with 3 weeks vacation from the beginning
great worklife balance
travel reimbursement

whats in it for you

for true engineers looking to flex their engineering experience and ability with a growing division this will be a great job for you we will provide the tools resources and direction to further your experience in the engineering space also you get to work with large interesting data",122500.0,NY,False,data_engineer
Data Engineer,"you cant improve what you cant measure so weve built the bestinclass analytics product for content marketers were looking for a strong data engineer to help us build and expand our analyticsdata science etl and api this is a top initiative within the company and with our best in class talent network and content production platform we have a lot of interesting data to analyze  come help us guide the industry with new insights

you should love working at a startup because it means driving initiatives with little supervision solving tough yet exciting problems each day working with a passionate and smart team in an agile environment and making our customers happy and successful

what youll do

collaborate with product management data scientists and engineers to define and translate feature requirements into sound creative software designs
creatively solve problems by bringing a unique perspective
produce solid thoroughly tested features including automated tests
plan and execute software releases using agile methods
big data modeling
build and expand our etl using technologies like apache spark airflow aws lambda kubeless and aws kinesis
work closely with data scientists and architect solutions that enable them to do their jobs

who you are

3  5 years software engineering experience ideally with python or ruby
strong software engineering  architecture fundamentals
bs in computer science or equivalent experience
bdd  tdd proficient with test frameworks such as pythons nosetests or rubys rspec
experience building restful apis ideally with python or ruby
experience with big data technology – apache sparkhadoop redshift elasticsearch and more
advanced working sql knowledge and experience working with relational databases postgres mysql oracle etc
experience in building infrastructure required for optimal extraction transformation and loading of data from various resources
you want to be part of a growing and entrepreneurial company with proven users and business model
you want to learn more build your experience and contribute within a fastpaced agile environment

bonus

you understand machine learning nlp and other advanced analytical techniques
experience working with aws andor google cloud technology

",,NY,False,data_engineer
Data Engineer,"working as a member of our data platform and analystics team gladson is looking for a handson data engineer who will focus on designing and implementing optimal data engineering solutions to scale with unpredictable data patterns while maintaining and monitoring them this is an individual contributor position requiring the ability to take on complex requests and transform them into clean data solutions and integrating that data with the architecture used across the company the role will be also be evaluating and implementating new tools and frameworks or extending existing ones by leveraging the onpremise and cloud services in support of the companys data science data warehousing and visualization initiatives

this full time role will be based in gladsons chicago office the interview process for this position will require the completion of a case study which will be sent to selected candidates after an initial phone screen with the recruiting team

responsibilities
design and implement end to end automated data pipelines from data ingestion to delivery while selecting and integrating tools and frameworks required to provide the requested capabilities as per business requirements
perform capacity planning required to create and maintain enterprise relational and nosql databases and processing demands while providing all facets of database administration to production development and quality assurance systems
implementing etl process and monitoring performance and advising any necessary infrastructure changes defining data retention policies database tuning parameters
designing and building selfimproving software by leveraging machine learning techniques and technology at scale
application of modern data processing technology stacks streaming data architectures and technologies for realtime and lowlatency data processing

skills
proficient understanding of distributed computing principles and integration of data from multiple data sources and formats
leverage data mining statistics and machine learning to develop bestinclass analysis techniques  data visualizations that answer strategic client  category questions
knowledge of various etl techniques and frameworks such as flume talend spoon and various messaging systems such as kafka
understanding of how to build solutions for data science and client delivery while productionizing any machine learning models and collaborating across various teams
understanding of agile development methods including core values guiding principles and key agile practices
understanding of the theory and application of continuous integrationdelivery
experience with sql  nosql databases such as mssql postgres mongodb cassandra neo4j
good understanding of cloud platforms  gcpaws  and lambda architecture along with its advantages and drawbacks
knowledge of high availability ha and disaster recovery dr options
qualifications
bachelors degree in computer science mathematics engineering or equivalent
4 years in bi or data engineering working with structured and unstructured data formats along with batch and streaming framework design  implementation
demonstrated knowledge and experience with software development and deployment in onpremise and cloud environments
strong consultative skills to establish relationships across the broader organization
comfort communicating and interacting with cross functional teams as well as understanding and translating the science of data to a more general audience
desire to roll up the sleeves and get into the heart of the business
demonstrable ability to work across a global matrix and ability to put strong communication leadership and influencing skills to work to be successful",,IL,False,data_engineer
Looking for Data Engineer/ Data Scientist at CA,role data engineerdata scientist business data analystlocation corte madera caduration 6 monthsskillssql python and rjob type fulltimeexperiencejava 7 years required,,CA,False,data_engineer
2019 Data Engineer or Database Engineer Internship,"internshippurposes
this is a 40 hour per week internship that is expected to last approximately 4 months internships will be for winter starts in january or for summer starts in may of 2019 normal office hours are between 630am530pm monday through friday get experience supporting systems and delivering services to users at church headquarters and millions of users throughout the world this internship position represents an unusual and exciting opportunity to work for one of the largest information technology centers in the wasatch front this individual works with divine guidance to provide or support technology that furthers the mission of the church and reflects the eternal impact of the gospel
this position will be located in riverton ut
responsibilities
works with teams to build process modelscompile reports on implementation and datamonitors processes and makes recommendations for efficiency and accuracycraft management reports to communicate statusseeks opportunities to improve processesgood organizational skillsattention to detail
benefitswork with stateofthe art tools to help develop enterprise solutionsmentor with highly experienced it professionalswe hasten the lords work in an important waygreat paybe a member of a creative spiritual and highly motivated team and cultureyou will gain practical experience
qualifications
we are looking for an upbeat and dedicated individual who loves to work on new technologies and is capable of working independently or in group settingsyou should be currently enrolled in an accredited college or universityinternship is for current temple worthy members of the church of jesus christ of latterday saintssolid business presentation skills articulates technical concepts clearly  visually and verballytechnology background is highly preferredexcellent communication skills for interacting with and providing information to management levels will be neededaptitude for database management technologies such as relational databases oracle sql and mysql nosql databases mongodb cassandra marklogic and data processing sql hadoopaptitude to learn business intelligence tools business objects crystal cordastrong aptitude for understanding and associating dataability to effectively communicate information with dataability and real passion for analyzing large amounts of information
worthiness qualification
must be a member of the church of jesus christ of latterday saints and currently temple worthy
posting noticemore info
please note all positions are subject to close without notice
find out more about the many benefits of church employment at httpcareersldsorg",,UT,False,data_engineer
Data Engineer - Marketing,"what youll do
you will be focused on enabling a datadriven approach to optimization by sourcing maintaining and ensuring the availability of data used to drive marketing insights to optimize ciscos marketing investments youll integrate both batch and streaming approaches to support standard business intelligence as well as decision automation and machine learning requirements
you will provide leadership and support for the development of an integrated digital marketing data foundation that will enable extensive business intelligence and machine learning for digital marketing and extended user communities
youll focus on data comprised of digital marketing and other supporting data eg weblogs salesrelated data customer and contact data social data third party purchase data etc
you will assist in planning designing building and documentation of digital marketing data foundation
youll work with digital marketing business and it teams to ensure high quality ontime deliverables that meet usability scalability quality and performance standards
youll provide handson technical support for development research and quality assurance testing dedication to performing due diligence checks to ensure quality
you will support change management efforts including proactive communication with other teams and users
who youll work with
cisco’s digital marketing organization will lead the next evolution in customer experience through the promotion of cisco products and software through digital channels web social media mobile direct mail point of sale etc the organization builds omnichannel personalized realtime customer experiences that engage and inform cisco customers and accelerate the purchase process the team has the unique opportunity to shape influence and craft digital experiences that build the cisco digital brand and accelerate cisco business

who you are
you have a bachelors degree and 5 years of relevant work experience you have previous experience with realtime streaming architectures such as lambda architecture using apache kafka solr you have experience building data pipelines with handson development of scripts using various programming languages including sql python unix shell hql spark programming java you possess a strong understanding and experience with structuredunstructured database environments eg oracle and big data environments eg sap hana hadoop you are very familiar with microsoft products excel word powerpoint access

desired skills
dashboards  visualization tools specifically domo and underlying tool data formats
statistical analysis products specifically r python
prior experience with marketing and sales systems eg sfdc eloqua etc
“can do”  “get it done”  “let’s just do it” attitude to run projects endtoend
good understanding of digital marketing and systems concepts processes and data
accountability mindset taking responsibility for work and deliverables
strong verbal and written communication skills
why cisco
at cisco each person brings their unique talents to work as a team and make a difference yes our technology changes the way the world works lives plays and learns but our edge comes from our people
we connect everything – people process data and things – and we use those connections to change our world for the better
we innovate everywhere  from launching a new era of networking that adapts learns and protects to building cisco services that accelerate businesses and business results our technology powers entertainment retail healthcare education and more – from smart cities to your everyday devices
we benefit everyone  we do all of this while striving for a culture that empowers every person to be the difference at work and in our communities
colorful hair don’t care tattoos show off your ink like polka dots that’s cool pop culture geek many of us are be you with us
wearecisco",,CA,False,data_engineer
Business Intelligence Data Engineer,"what can you tell me about this position

the hartford’s enterprise data office  business intelligence  analytics enablement team is seeking a business intelligence associate to work closely with our businesses and technical partners across the enterprise to enable the implementation of end to end business intelligence solutions in this fulltime position the associate will help drive community engagement train customers and provide technical support assist with proof of concept evaluations using modern selfservice bi tools and act as a bia subject matter expert

this role will provide the opportunity to research learn and master the business intelligence  analytics tools we support as they engage with various members of our community we regularly participate in evaluations of new tools which means that we are often some of the first people to use them and become the experts to roll it out across the company

the ideal candidate will have strong customer service skills technical aptitude natural curiosity a willingness to learn and work towards making technical concepts understandable to business users

the candidate will need to think critically to tackle complex challenges thrive in a fastpaced dynamic environment and help drive a culture of delivering actionable data insights rapidly in a selfservice manner

responsibilities
provide resident ‘super user’ bia tool expertise
train and advise analysts in areas including
tableau development and visualization best practices
building data wrangling workflows
tools can include but are not limited to alteryx trifacta etc
assist with community engagement activities
consult with business customers to develop strategies and governance practices that help move the business forward
provide process and technical bia solutions to the lines of business to drive best in class usage of the appropriate tools
own the creation of enterprise training materials for supported tools
provide line of business technical support to expedite the effective usage of tools
identify connection points across lines of business bi teams to drive enterprise problem solving
assist with the demand intake process and work queue
design build and maintain internal reports processes and analyses with a variety of business intelligence technologies eg tableau msbi business objects etc
ongoing assessment of the enterprise business intelligence  analytics bia landscape
partner with various members of the bia community to understand and document tool usage total cost pain points value achieved through modern bi processes and tools
assist with new selfservice tool proof of concepts and demos for business partners
assist with evaluation and rollout of new bi monitoring andor selfservice tools
evangelize modern bi execution and tool strategies to create a data driven culture
perform other jobrelated duties as assigned
qualifications
what are the qualifications
02 years of hands on experience with business intelligence and analytics tools such as tableau alteryx qlikview ibm cognos microsoft business intelligence ssis ssas ssrs sas business objects r rshiny python etc
knowledge of data warehouse design and usage
experience with agile bi project delivery methodology desirable
intermediate level sql skills highly desirable
training material creation and delivery
natural curiosity with a strong desire to learn maintain and apply knowledge of emerging bia tools strategy methodology and general best practices
strong team player that has a direct approach and is solution oriented
comfortable working independently and collaboratively in an ambiguous environment on multiple concurrent projects
highly analytical person with exceptional conceptual thinking skills equally comfortable coding and interacting with business partners
outstanding verbal and written communication skills with an ability to express complex technical concepts in business terms to effectively interface with all levels of management
entrepreneurial spirit  selfmotivated strong sense of ownershipaccountability and results oriented with the ability to manage time and schedules effectively
customer focus strives to give customers the best service and takes the initiative to add value
property  casualty insurance industry experience a plus
what else can you tell me
the hartford is committed to the education and growth of our information technology professionals a number of it certifications are available to enhance your career and growth potential it professionals at the hartford may qualify for a stipend up to 1000 per year for additional certifications

equal opportunity employerfemalesminoritiesveteransdisabilitysexual orientationgender identity or expressionreligionage

job function
 data engineering
primary location
 united statesconnecticuthartford
schedule
 fulltime
job level
 individual contributor
education level
 bachelors degree ±16 years
job type
 standard
shift
 day job
employee status
 regular
overtime status
 exempt
travel
 no
job posting
 sep 27 2018 53855 pm
remote worker option  no",,CT,False,data_engineer
SAP Purchase Master Data Engineer,"this position holder will be responsible to purchase price change including info record configurable parts pricing table and po line item in sap and give the prealert on price increase he  she monitors supplier material data creation and change are follow the process and ensures the price accuracy in sap
supplier master data creation for new suppliers
purchase mater data info record maintenance
po price adjustment for configurable parts
po line item price adjustment for standard parts
monitoring purchase price and po price increase and make sure each increase has been approved through process
providing analysis recommendation and developing compliance reporting to support purchase order integrity

mobility needs you
requirements
bachelor’s degree
3 years of sap especially mm martial management module and erp experience required
3 years of elevator engineering experience required
3 years of data analytics and big data management experience required
strong communication and interpersonal skills",,NJ,False,data_engineer
Software Data Engineer,"company overview

mosaic is building upon its success in solar and expanding into home improvement making it easy by leveraging technology and financial innovation with a goal of providing access to clean energy for everyone we are looking to collaborate with passionate thoughtful people who want to make a real social impact while working to solve climate change come join our team centrally located in beautiful downtown oakland and help build the movement towards 100 clean energy for all

the opportunity

to complement our rapid growth we are actively seeking a bright and talented software data engineer to join our growing data engineering team in this role you will work with a team of outstanding data engineers impacting the growth of renewable energy through building ecommerce and financial services applications

your daytoday


design and build robust data pipelines using scripting in spark airflow python and sql
design data warehousedata marts in aws redshift and other databases as appropriate
use optimization techniques in data load and query processing
validate and build audit balance and control of missioncritical data pipelines
develop cool viz using tableau and other open source viz tools as needed
identify best data sources among multiple sources to use for data pipelines to improve trust in data
fix bugs work collaboratively with team members

what you bring to the team


masters or equivalent in csengineering or another comparable discipline
you have at least 6 years of technical experience and strong data warehouse  data modeling skills
very strong skills in python sql spark redshift airflow aws
familiarity with agile methods we use agile tools
experience with reporting tools like tableau is a plus
team player agile highly accountable curious willing to learn implement and teach
ability to juggle multiple responsibilities and deliver to timelines
experience in the consumer lending industry required

bonus points


experience with open source tools such as kafka is a plus
experience in any jvm based language

why mosaic


as a customer focused and driventowin organization there are many exciting reasons to join the mosaic team we provide competitive salaries quality healthcare and an enjoyable beyourself office environment we are deeply mission and vision driven have unlimited vacation days and support flexible schedules when needed mosaic has a dynamic fastpaced and entrepreneurial environment which requires a professional flexible selfstarter attitude we believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation
we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status

",,CA,False,data_engineer
Data Engineer,"who is blueprint
blueprint technologies is a group of solution minded thinkers changing the face of technology in bellevue wa we follow a mission vision and core values that allow us to function as a collaborative unit

what are our solutions
blueprint is a technology solutions firm that connects strategy product and delivery we help companies digitally transform we have a special focus in cloud and infrastructure data platform and engineering data science and analytics organizational modernization and customer experience optimization

why you want to be a part of blueprint
we are innovators motivators thought provokers and coffee drinkers our collective backgrounds bring diverse perspectives that enable us to consistently think differently our people are our solutions we want you to bring your biggest and best ideas to help positively impact our culture clients and the community around us we believe in the importance of a healthy and happy team which is why our benefits include full medical dental and vision coverage as well as paid time off 401k paid volunteer hours and tuition reimbursement

blueprint is looking for data engineer to join us as we build cuttingedge technology solutions

qualifications and skills required

5 years of demonstrated data engineering experience
3 years of experience with big data technologies like hadoop or hive
advanced knowledge and expertise with data modelling skills advanced sql with oracle mysql and columnar databases
3 years experience in custom etl design implementation and maintenance
proficient designing and implementing data models and data integration
experienced in all aspects of power bi including establishing gateways use of embedding dax and m
handson experience deploying the pbi service to midmarket andor enterprise scale organizations
experienced deploying azure sql database azure data factory and wellacquainted with other azure services including azure data lake and azure ml
experience implementing rest api calls and authentication
experienced working with agile project management methodologies

",,WA,False,data_engineer
AWS Data Engineer,70 an hourtemporary contractexp  10  yrsall visa acceptedduration  long termexperience  10  yrsposition full time c2caws cloudauroraelasticsearchredshiftathenashould have expertise engineeringdesigndevelopetlperformance tuning the data solution in the above said data platforms in awsjob types fulltime temporary contractsalary 7000 hour,,MO,False,data_engineer
Data Engineer,mercy ships is currently looking for a fulltime data engineer in lindale tx if you are interested in making a difference with an organization that impacts and changes lives around the world please put your official application in at careersmercyshipsorgmercy ships is an international faithbased organization based in lindale texas that provides life changing medical procedures to people across the globe through our hospital ships and volunteers are ordinary people working together to achieve extraordinary things summary descriptionresponsible for supporting mercy ships departments in their data modeling warehousing and analysis needs also assists in the execution of mercy ships master data management strategy this includes data analysis product support and training knowledge worker support data source identification and classification data inventory maintenance supporting departments in data quality efforts and application of data governance policy process and proceduresessential duties and responsibilities include but not limited toassists and works with is staff and management to develop models and processes for the management and leveraging of mercy ships data assetssupports departments in the use of their data and development of insights by providing expert knowledge in data analytics and analytics productswork with data owners to determine develop and support data analysis goals and requirementswork with data owners and consumers to develop and document the master data inventorywork with the solutions development team in the design and development of data components in technical solutionswork with the enterprise architect to identify data models and activities that advance the established and desired future state of mercy ships enterprise architecturework with the information security director in providing input to and execution of data governance policy procedure and standardscollaborate with departments and other is staff as needed in the development and execution of mercy ships master data management strategyprepare administer and deliver data analysis trainingadvise on issues pertaining to the effectiveness of data architecture integration and data managementresearch and advise on emerging data management and analysis trends products and methodologiesqualifications knowledge skills abilities and requirementsstrong analytical and organizational skillsstrong customer service skillsdetailoriented and accuratetechnical skillsets data architecture principles and methodologies structured query language sql data analysis tools and techniques data modeling tools and techniques knowledge of relational database management systems rdbms flat file data object orientation and document database management systems knowledge of data integration and exchange technologies and formats familiarity with application architectures and interfacesexcellent listening interpersonal written and oral communication skillshighly selfmotivated and directedability to effectively prioritize and execute tasks while under pressureexperience working in a teamoriented collaborative environmentsupportive of mercy ships mission and vision and committed to its core valuesunderstand and apply servant leadership work collaboratively with integrity and demonstrate accountabilityeducation and experiencebachelors degree in the field of business administration computer science or information systems or the equivalent combination of education and experienceexcellent understanding and at least 3 years handson experience in data or database management principles practices and processessuccessful completion of mercy ships entry training will be required within the first yearwhy mercy shipsmercy ships provides resources and events that promote the feeling of family and communityour base located on 400 acres of scenic east texas land offers on campus dining a specialty coffee shop indoor basketball and racquetball courts weight room walking and biking trails a disk golf course and an outdoor pool for you and your familypaid time off holiday benefits and health and life insurancejob type fulltimeexperiencecustomer service 3 years preferredsql 3 years preferrededucationbachelors preferred,,TX,False,data_engineer
Data Engineer,"2da analytics is a early stage software company we build analytics that are used to optimize how energy commodities are delivered to the end user but it is more than that  our mission is to evolve how humans interact with data we believe that analytics is about uncovering the story hidden in the data

we are looking for a stellar data engineer to join the 2da team this is the role that is responsible for giving voice to the data so the world can hear it too the ideal candidate will in addition to having curiosity for learning have history of being curious pragmatic and actionoriented and being an highly skilled in the business or research domains you work in

we’re big fans of hiring people who are not just great at what they do but also have a flair for how they do it critical to our culture is building and maintaining a team that works well together and knows how to communicate effectively  not just within their own team but also across peripheral teams

2da analytics are looking for someone who embodies the best parts of opensource culture humility openmindedness honesty and respect for others a developer who doesn’t try to singlehandedly save the day but embraces input and collaboration as a means to find the best answer

your success in this role will be predicated on your ability to prioritize your work be selfmotivated and a selfstarter to speak up early and often and to work well with others you should be passionate about building great software and about building a product that is slated to revolutionize the world of data analytics in commodities we’re great at encouraging our people to learn different technologies continue their professional growth and try out new ways of doing things we’re in it for the longhaul and you should be too

our office is located in east austin
what youll do
own and mature backend data ingestion for 20 data sources in our backend data store
maintain and evolve our data science  engineering footprint in aws
add new customer accounts
own maintenance and change requests
deliver data to our frontend data store
what you have
2 years building and maintaining data pipelines
2 years experience with sql
2 years of experience with python
working knowledge of aws and pinchhitting in a devops role is a huge plus
a history of being an highly skilled in the business or research domains you work in
a history of being curious pragmatic and actionoriented
experience in multiple roles including internships is a huge plus
how you work
strong problem solving and communication skills
consults with colleagues and recommends solutions based on the best interests of customers and shareholders even when the opinion is unpopular
offers time and assistance to colleagues is widely regarded and respected as someone to go to for help
fosters friendly and cooperative relationships with others colleagues enjoy working with the employee
shares knowledge and mentors staff works to develop others’ knowledge as well as own
gives and shares credit as appropriate
contributes to recruiting and training efforts of others including candidate referrals job interviews and mentoring
attends and participates in company and department level functions inside and outside of the office
demonstrates an understanding of the urgent nature of our business and the need to proactively find and fix problems quickly and effectively takes ownership and follows through on decisions doesn’t minimize or forget about problems
determines and fixes root causes rather than just treating symptoms
applies novel techniques to solve problems that are more ambiguous challenges longheld beliefs when necessary
quickly and effectively identifies alternative solutions and the proscons of each confirms that a proposed solution has no unintended consequences
takes steps to mitigate risk
what youll get
fun casual fastpaced work environment filled with talented colleagues
flexible paid time off
flexible working options
competitive salary  stock options",,TX,False,data_engineer
Data Engineer Co-Op/Internship Spring 2019,"internshipcompany name kroger general office
position type intern
flsa status nonexempt
line of business
see what life is like at kroger technology
at httpswwwkrogercomlivekt

additional technology information

position summary
as an intern you will work on innovative and challenging projects that will help drive the technical landscape of the grocery industry you may work in a development analytical agile infrastructure or digital environment to gain exposure to the different technology areas and continue developing the leadership and business skills needed to enhance your technology career demonstrate the company’s core values of respect honesty integrity diversity inclusion and safety
essential job functions
complete assigned projects and tasks related to specific technology initiatives
partner with technology and business associates to assist with various projects to implement technical and corporate strategies
maintain and follow operational procedures and processes
participate in weeklymonthly department meetings
assist in working on new technology platforms that are revolutionizing the retail industry
engage with peers on committees that include philanthropy branding and community events
participate in intern programs that support technical and leadership development within the organization
must be able to perform the essential functions of this position with or without reasonable accommodation
minimum position qualificationseducation
pursuing an associates bachelor’s or graduate degree at an accredited institution
cumulative gpa of 30 or higher official transcripts available upon request
strong written and oral communication skills
ability to communicate and present information to all levels of the organization
ability to work within a team environment
desired previous job experienceeducation
pursuing a technical or business degree
manage multiple projects with competing priorities
involvement in leadership and community activities
education level other
required certificationslicenses none
position type intern
shifts mfield4
states ohio
keywords

jobs at kroger at kroger we hire people who have a passion for helping others and who want to build a relationship with our customers no matter what stage of your career you can build your future at kroger we look for people who want more aspire to be more and work hard to achieve their goals our focus on keeping the customer first is what makes us successful as the largest traditional grocery chain in the us and one of the worlds largest retailers we employee nearly half a million associates across 35 states we offer many opportunities not only in our stores but in manufacturing logistics marketing finance human resources and many other fields

company overview
kroger family of companies employs nearly half a million associates who serve customers in 2782 retail food stores under a variety of local banner names in 35 states our family of companies also operates 2268 pharmacies 274 fine jewelry stores 1489 supermarket fuel centers and 38 food production plants in the united states kroger is dedicated to our purpose to feed the human spirit™ by serving america through food inspiration and uplift and creating zerohungerzerowaste communities by 2025 careers with the kroger co and our family of companies offer competitive wages flexible schedules benefits and room for advancement",,OH,False,data_engineer
Google Cloud Data Engineer,contractjob summaryrequired experiencestrong data warehouse experience with various technologies strong knowledge of creating data warehouse in public cloud is required strong databasewarehouse migration to public cloud strong gcp data background bigtable bigquery cloudsql preferred gcp data engineer certification have traditional database background with migrationmust havegcp data bigtable bigquery cloudsqljob type contractexperiencegoogle cloud 5 years required,,CA,False,data_engineer
Data Engineer,70  80 an hourcontractshould have good experience on below skillsdata warehousedata modelingdata analyticshivebigquerysqlpython programmingjob type contractsalary 7000 to 8000 hourexperiencepython 1 year preferredsql 1 year preferredhive 1 year preferred,,GA,False,data_engineer
Big Data,"job classification
software engineers

location iselinnew jersey

skills
big data

description

phone  skype

sr big data engineer

must have a minimum of 10 years in it and 5 years in big data very senior position

senior big data engineerarchitect who will
work under the direction of rcg big data architectshave handson experience with most of the skills listed belowhave the ability to take ownership and accountability for work assignedhave the ability to work independently but not hesitate to ask for help when neededbe proactive in recognizing and raising issues earlyhave a good client interface with it mandatory and business preferably audienceshave excellent communication skills

musthave skills proven handson experience with
data platforms
o cloudera – setup install configure use and administer all components of the ecosystem
o aws – especially kinesis glue s3 emr ec2 dynamodb redshift elasticsearch athena
data ingestion processing  analytics
o contemporary big datafriendly etlelt tools like talend streamsets or equivalent
o scalapythonjava on spark
o frameworkbased metadatadriven implementations

nicetohave skills
data preparation trifacta talend data prep or equivalentbusiness intelligence big datafriendly eg zoomdata or traditional eg microstrategyindustrydomain knowledge financial services especially investment management",,NJ,False,data_engineer
Data Engineer,"about us
videoamp’s mission is to bridge the gap between television and digital advertising with campaign measurement planning and audiencetargeting solutions that dramatically improve the performance and costefficiency of advertising investment our engineers data scientists designers and media strategists are inspired by tackling one of the most challenging problems in media and marketing — bridging the divide between tv and digital media

responsibilities
were looking for a selfdriven software engineer with experience working with the latest etl frameworks who is eager to tackle new problems in a data driven environment as a data engineer at videoamp you will be working with a wide variety of datasets including tv viewership data and digital advertising data to help customers optimize their marketing spend

technology we use
python scala spark sql airflow hive hdfs and other technologies to support an etl pipeline data warehouse and reporting platform
required skills
experience working with python or scala
a solid and demonstrable understanding of etl workflows data warehousing and big data principles
a solid understanding of nosql datastores
sql fluency and an understanding of relational data models

responsibilities
designing and building out new data pipelines
analyze scrub and integrate third party data
building new and scaling out existing etl applications
collaborating with data scientists and productionalizing various data science models
coordinating data models with other engineering teams
perks
top compensation
comprehensive health benefits
meaningful equity
401k
unlimited vacation with a stipend for travel and accommodations of 2000year
unlimited inoffice gym use with personal trainer
childcare stipend
plenty of snacks and beverages plus dinner every day
corporate support for hackathons lunch and learns and attending conferences
personal and professional development",,CA,False,data_engineer
Data Engineer,contracturgent  data engineer sunnyvale ca  24 monthsin person interview  local candidates onlyjob description job overviewwe are looking for a savvy data engineer for our team the hire will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for cross functional teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up the data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our company’s data architecture to support our next generation of products and data initiativesresponsibilitiescreate and maintain optimal data pipeline architectureassemble large complex data sets that meet functional  nonfunctional business requirementsbuild the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql cassandra hadoop and other big data technologiesbuild data pipeline on premise and on google cloud platformbuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metricswork with stakeholders including the product data and design teams to assist with datarelated technical issues and support their data infrastructure needswork with data and analytics experts to strive for greater functionality in our data systemsqualificationsadvanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases experience building and optimizing ‘big data’ data pipelines architectures and data sets experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementstrong analytic skills related to working with unstructured data setsbuild processes supporting data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsworking knowledge of message queuing stream processing and highly scalable ‘big data’ data storesexperience supporting and working with crossfunctional teams in a dynamic environmentwe are looking for a candidate with 5 years of experience in a data engineer role who has attained a graduate degree in computer science statistics informatics information systems or another quantitative field they should also have experience using the following softwaretoolsexperience with big data tools hadoop spark kafka etcexperience with google cloud platform esp google pubsub big query data proc data flow cloud storageexperience with iot  time series data experience with relational sql and nosql databases including postgres and cassandra experience with streamprocessing systems storm sparkstreaming etc experience with objectorientedobject function scripting languages python java c scalaplease send your resume to anu at intersourcesinc dot comjob type contracteducationbachelors required,,CA,False,data_engineer
Data Engineer - Science Center,"data engineer

location culver city ca

the ipsos science center is a uniquely positioned group within ipsos we develop software tools and perform analyses both for clients and internal teams respond to advanced analytic requests and consult on a broad range of statistical and behavior science best practices working in a collaborative and supportive environment we seek to expand what is possible in market research with data science

we’re looking for a highly capable dataliterate person we need someone who is a better statistician than most programmers and a better programmer than most statisticians we are looking for someone with the communication skills to suggest analysis appropriate for a problem develop a prototype polish it if it works stand up an api if it’s worth distributing build visuals on top as needed and work through the challenges along the way we’re looking for a detailoriented developer who has the flexibility capability and curiosity to collaboratively work across the process in short we’re looking for a fullstack engineer for the analytic stack

as a data engineer you will

enhance and maintain existing tools used by the larger organization as well as the local team
design and develop new tools for internal users and external clients
work closely with team members on adhoc projects
collaborate on researching implementing and testing new algorithms and approaches


required skills
requirements

proficiency in advanced r andor python programming including the ability to develop packageslibraries and maintain existing ones
bachelor’s degree in computer science mathematics statistics or related
comfortable working in a highly collaborative consensusoriented environment
highlevel familiarity with analytics and statistics extracting and surfacing value from quantitative data
strong eye for detail and excellent timemanagement skills


pluses

professional or academic experience with analytics or machine learning eg caret scikitlearn
experience creating and deploying web applications eg flask web2py
experience designing and developing static and dynamic visualizations eg d3js ggplot2
working knowledge of sql and experience with database design and administration
experience with linux server and system administration
experience with collaboration tools eg atlassian suite and version control systems eg git
experience integrating r andor python with each other and cc
large dataset manipulation experience in distributed storage and computing
advanced degree ms but by no means required
experience in the field of market research



required experience",,CA,False,data_engineer
Data Engineer,"beeswax named one of business insiders hottest preipo startups is hiring top engineering talent for its growing new york office beeswax is a high scale high availability digital advertising platform founded by executives from google and funded by leading vcs including rre and foundry group we aim to offer the most extensible and transparent advertising system servicing technology enabled clients and executing and processing billions of events every day

the beeswax engineering team is a topnotch group with backgrounds from google amazon oracle and other premier technical teams because digital advertising operates at an extremely high scale millions of transactions per second and low latency the opportunity to learn about webscale distributed systems and hard scaling problems is a great advantage of our engineering culture and work

we are looking for a data engineer to build clean pipelines and maintain data products that our customers rely on

our products are built on a variety of technologies including c java python and lemp stack php mysql nginx and while our engineers typically specialize in one area they need to coordinate and integrate with a wide variety of systems including homegrown and awsnative services

this position will report into our chief data scientist sergei izrailev sergei brings over a decade of handson experience in data science software engineering and database design utilizing the best in breed tools and technologies

responsibilities

code in a variety of languages primarily python java andor c
design and implement data pipelines building scalable and optimized enterprise level data systems
work cross functionally with product ops and engineering counterparts
participation and collaboration from inception to deployment

requirements

ms in computer science math related technical field or equivalent practical experience
4 years of general software programming experience in java cc python and sql
large systems software design and development experience with knowledge of unixlinux
knowledge of database technology schema design and query optimization techniques
solid foundation in data structures algorithms and software design with strong analytical and debugging skills

preferred qualifications

phd in computer science mathematics or related technical field
familiarity with open source cloud and application platforms aws development experience
experience with big data technologies such as spark hive presto and impala
experience working with mpp databases such as redshift snowflake vertica and netezza
handson experience working in soa and high throughput environments

about you

you are passionate about learning mentoring and building a world class team and culture while constantly empowering others around you
you take a second to step back and look at the big picture before diving in head first
you care about the quality of the data flowing through your code as much as about the quality of the code
not afraid to take risks voice opinions or ideas that help build the next generation of data platforms all within a massive distributed system
youre the type to peel back the layers and use nonconventional means to solve the task at hand

",,NY,False,data_engineer
Lead Data Engineer,"the schoolzilla mission empower people to use data to increase student success

we want to change millions of students’ lives by enabling people to use data to run great schools teachers and school leaders need lots of data to make good decisions for their students but most of them can’t get that data in any kind of useful actionable format schoolzillas team of developers data visualizers seasoned educators and k12 experts have done just that weve made data easy to find understand and act on for school districts everywhere weve already helped thousands of schools make better faster decisions with our platform

we are a public benefit corporation and have in our bylaws our social mission to enable people to use data to improve educational outcomes for students especially students from underserved communities every day we live our values driven by mission better together teammates matter equity at the center and intellectual humilarity

how you can help

do you want to lead the charge in crafting delightful data experiences that have real impact in schools and classrooms across the country do you thrive on scaling for the next million students

the product engineering team is responsible for nearly all of the mosaic product experience from the user experience to the transformation of all the datasets used for analysis as a lead data engineer youd be at the forefront of our product innovation
responsibilities
design modern data architectures and endtoend data transformation solutions
build data structures pipelines and tools that enable robust analytics insights and personalization
collaborate with crossfunctional teams to understand how data is used within schoolzilla and by our users
define execute and release new services and features
help shape the internal engineering and product roadmaps and inform prioritization of data engineering projects
identify design and implement internal data process improvements including automating manual processes optimizing data delivery and redesigning infrastructure for greater scalability
provide technical leadership and mentor fellow engineers
skills  characteristics
experience with one or more major objectoriented programming languages python preferred
experience building enterprisescale data pipelines that are both efficient and intuitive
advanced sql knowledge and proficiency with major relational databases particularly ms sql server and postgres
missiondriven you feel a deep sense of ownership for your work and a relentless desire to deliver better results you are passionate about solving problems for our users
a lifelong learner you love learning new things youre curious and ask good questions you solicit feedback from others accept it with grace and act on it
flexible you are comfortable with technical ambiguity and rapid iteration
bonus points for
k12 education experience
familiarity with streamprocessing technologies like spark kafka and flink
experience leading agile development teams
schoolzilla is an equal opportunity employer we are committed to building a team and workplace that reflect the communities we serve we especially encourage people who are underrepresented in the tech industry to apply and welcome your application even if you do not meet every one of the above requirements

schoolzilla does not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status we have an office in oakland ca and are also remotefriendly candidates must be legally eligible to work in the united states",,,False,data_engineer
Data Engineer,"job description

the city of philadelphia shares hundreds of datasets with the public and between departments open data  opendataphillyorg metadata – metadataphilagov as a result residents can see if there’s been an uptick in vehicle breakins in their neighborhood civic associations can lookup landlords and see if they have violations before supporting their zoning variance voters can trust that campaign finance reports and city contracts are posted online for anyone to see

data engineering at the city is an adventure navigating a diverse technology portfolio understanding what the data represents and its various caveats removing sensitive information and presenting it to the public in a way that’s easily understood because most of the city’s data can be attributed by location experience with sql spatial and spatial python libraries is a must

we have begun building data pipelines using python based inhouse open source software and the data engineer will help expand or refactor this work these pipelines connect various systems of record business systems and semistructured data a centralized oracle based rdbms and saasbased environments including arcgis online and carto

beyond being a key asset to enterprise integration and open data initiatives the data engineer will help develop and support the city’s address information system – a cloudbased address search api leveraging databridge that enables developers to build applications that pull a myriad of the city’s information

essential functions

help city departments share data with other departments and with the public by

 working with business partners of varying technical ability to understand how their data is produced stored and updated
 setting up automated extract transform and load etl workflows
 improving the “platform” we use to share data reusable components scheduling logging centralized storage etc so that workflows are easier to write and maintain

other duties as assigned

competencies knowledge skills and abilities

ability to
 write clearly and concisely with organized structure
 reason about and work with data from across a variety of potentially unfamiliar domains
 write descriptive technical policies andor documentation of etl workflows
 communicate technical nuances in plain language with partners of varying technical background
 apply creative problemsolving when considering how to best address technical challenges
 advance several workflows at a time for different department datasets

knowledge of
 python with demonstrated experience in spatial and nonspatial etl
 sql spatial
 databases oracle preferred write queries  views in rdbms including oracle and postgres
 ability to maintain clean and secure data environments
 working in a hybrid environment onpremises and amazon web services
 github
 spatial data formats esri sde geojson
 minimal linux server administration

qualifications

at least 3 years experience in any of the following areas preferred
 developing software
 data integration
 architecting and maintaining relational databases
 moving a variety of data types ie csv fixed width geodatabase json between a variety of systems ie ftp server relational databases apis
 transforming and enriching data ie denormalizing geocoding reprojecting anonymizing
 establishing etl workflows processes and documentation for organizations

additional information

please submit a resume and cover letter with your application

successful candidate must be a city resident within six months of hire

the city of philadelphia is an equal opportunity employer and does not permit discrimination based on race ethnicity color sex sexual orientation gender identity religion national origin ancestry agedisability marital status source of income familial status genetic information or domestic or sexual violence victim status if you believe you were discriminated against call the philadelphia commission on human relations at 2156864670 or send an email to for more information go to human relations website at httpwwwphilagovhumanrelations",,PA,False,data_engineer
Data Engineer,"job summary
encodia is an emerging early stage biotech company developing the next generation of protein analysis tools encodia is seeking to recruit a data engineer with experience in designing and implementing pipelines for data ingestion analysis and visualization an ideal candidate would have experience with biological data eg dnarna sequencing and with analyzing large data sets
job responsibilities
design and implement data analysis and visualization workflows
develop and manage compute pipelines in production environments

collaborate across functions to identify and address analytical needs
requirements
bs andor ms in computer science bioinformatics computational biology or a related field
experience in data visualization analyzing large scale data and familiarity with statistical analysis and machine learning
selfmotivated with the ability to work with and support many functions across the organization
programming experience in python as well as some strongly typed language eg ccjava
experience with command line linux environments
experience using settingup and maintaining cloudbased computing environments eg awsazure
knowledge of git or other version control systems
benefits
encodia is an equal opportunity employer that offers a competitive and comprehensive employee benefits package including medical plans dental insurance vision plans ltd paid vacation and a stock plan",,CA,False,data_engineer
Data Engineer,"we are seeking an enthusiastic selfmotivated data engineer to work collaboratively with our internal research team and our operations team to meet the voloridge mission of delivering superior riskadjusted returns using proprietary modeling techniques our data engineers work with a emphasis on rapid deployment of prototype processes for new datasets at voloridge we are passionate about expanding our knowledge and capabilities and find pleasure in creating better ways to deliver quality services both internally and to our investors our teams are comprised of energetic hard working highly analytical individuals that thrive on innovation and problemsolving at the nexus of big data and finance

top reasons why you want to work for voloridge investment management
401k retirement plan 1 for 1 match up to 4 of compensation
regular inoffice massages weekly lunches stocked kitchens with snacks fruit and drinks
work off the intracoastal and 3 minutes from the beach
work in an office chosen by south florida business journal as one of the top 10 coolest offices in south florida in may 2016
profit sharing bonus
summary of job functions
understand the datarelated needs of all internal parties especially our research team
build datasets continually strive to improve them including increased automation usability transparency documentation and qa
develop and maintain prototype etl processes for new datasets including initial data modeling with an emphasis on rapid deployment balanced with stability and consistency
obtain and document requirements for new datasets
study new topics and gain domain knowledge related to data ingestion storage and delivery
have a consultant mindset always striving to understand and fulfill the needs of our researchers and traders
communicate and collaborate effectively with all internal associates including research management development and other operations personnel
investigate and troubleshoot data anomalies
represent the strategy data group in internal forums for planning and collaboration
assist with technical skill development and mentorship of junior personnel
perform other duties and responsibilities as assigned
minimum requirements
bachelor’s degree
7 years of data engineering work experience in a field such as accounting finance business intelligence or hard sciences
expertise using transactsql and familiarity with other data technologies and tools
experience with both transactional databases and data warehouses
excellent oral and written communication skills
must be able to demonstrate strong problem solving skills and flexibility to consider new ideas and approaches
the ability to work daily onsite in our jupiter fl office
preferred skills and previous experience
experience using visual studio and sql server management studio to createmanage ssis etl packages esp with high volume data
experience in performance tuning server monitoring and query optimization
strong focus on data quality and attention to detail
able to independently bring projects to successful completion
experience working with trading  financial  investment  accounting data
experience with master data management and data governance
experience with data analysis tools such as tableau excel
programming experience such as python java c vbnet c c
experience with leadership of small teams andor projects
demonstrated ability to work efficiently in a demanding teamoriented and fastpaced environment
compensation and benefits
highly competitive base salary
profit sharing bonus
health dental vision life and disability insurance
401k
credit and identity monitoring service
additional information
voloridge investment management is an sec registered investment advisor a private investment company founded in 2009 our mission is to deliver superior riskadjusted returns for qualified investors using advanced proprietary modeling technology conservative investment tactics and sophisticated risk management our market neutral equities strategy takes both long and short positions in the most actively traded equities and is designed to capture alpha while limiting exposure to directional markets risks our futures strategy takes both long and short positions in the most actively traded global futures and is also built to maximize alpha captured across all futures markets traded while capping exposure to any particular sector at a given time
voloridge investment management is an equal opportunity employer all qualified applicants are encouraged to apply and will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability protected veteran status or any other legally protected characteristic or status",,FL,False,data_engineer
Senior Data Engineer,"zocdoc is the tech company at the beginning of a better healthcare experience every day we are driven by our mission to give power to the patient building products and services that simplify and streamline the overall healthcare journey for patients and providers delivering the modern healthcare experience they expect and deserve our forwardthinking approach prioritizes collaboration agility and continuous learning in service of our longterm vision this has helped us drive significant innovation in a complex slowmoving industry and our talented team is looking for impactminded individuals to join us as we continue to reimagine the healthcare experience

as a senior data engineer youll help us build infrastructure for collecting storing processing and analyzing huge sets of data in batch and streaming pipelines you will contribute to the design and implementation of data flows and tools necessary to make key strategic decisions and power machine learning and personalization within the product

what youll do

work closely with the data science and business intelligence teams to develop data models for research reporting and machine learning
build data tooling to enable data lake data warehouse and analytics workflows within the aws cloud s3 redshift dynamodb spark kinesis kubernetes etc
contribute to our inhouse ecosystem of developer data tools
collaborate with partners across the company to assess data needs and prioritize accordingly be proactive about driving data collection and storage best practices
drive adoption of data tools give tech talks and demos on the newest capabilities and enhancements to the system
consult on data security design and scalability to product engineering teams

whats required

curiosity and vision you have a passion for technology and can think critically about performance scalability and reliability of software
5 years engineering experience 2 years working with data in the cloud ideally using aws
wellversed in one or more of the following languages and functional programming in general scala java python javascript
expert in sql and comfortable designing writing and maintaining complex sql based etl
experience with building largescale batch and realtime data pipelines etl design implementation and maintenance
experience with schema design and data modeling and the analytical skills to qa data and identify gaps and inconsistencies
experience supporting machine learning or business intelligence teams and products
computer science or related degree preferred

",,NY,False,data_engineer
Big Data Engineer,"our engineers move extremely fast while solving unique and challenging problems our team is small and nimble we release everyday to ensure that engineers are able to iterate quickly and make an impact immediately

we’re looking for engineers to work on our massive semistructured datasets youll develop software to process transform and analyze the data to identify signals from billions of event we collect everyday youll provide insights that improve the experience of hundreds of millions of users and 100000 stores in our marketplace
requirements
35 years of industry experience
bachelors degree in computer science software engineering or statistics required
passionate about big data
experience developing data extraction and transformation pipelines
expert knowledge in rdbms nosql and data warehousing
experienced with mapreduce framework such as hadoop
familiar with information retrieval softwares such as lucenesolr
experience in data visualization a plus",,CA,False,data_engineer
Global Data Engineer,"contractjob summary

to support the business objectives by overseeing installing and maintaining the servers virtualphysical storage systems replication environment as well as peripherals in the conshohocken global datacenter this includes managing configuring and maintaining the daily backup environment and managing outside storage you will work closely with network engineering on the setup of the firewalls lanwan and wireless networks you will work with the global infrastructure team on onpremise and cloud solutions this role is responsible for maintaining the integrity structure performance capacity and security of the erp environment to ensure that business critical data is secured

responsibilities
maintain update and upgrade the virtualization environments at the conshohocken datacenter and locations in the us and south america cooperate with regional it teams and with the emea datacenter engineer to keep the environment in both datacenters in line with each other definecreate a global standard for nondatacenter virtualization environments including a robust backup environment
collaborate with emea datacenter engineer and microsoft engineer on any global onpremise system and cloud solutions
administer configure and maintain the global infrastructure of the global barcoding systems and work with the senior network engineer on the setup of the wireless and wide area networks
assist senior manager of global infrastructure in selecting vendors and purchasing all equipment for the conshohocken datacenter keep track of components lifecycles assuring that the database asset register and purchase register of this equipment is current and available
assist senior manager of global infrastructure in maintaining a high level of security
general
analyze malfunctions and problems on global systems and initiate corrective actions communicate information and or corrective actions on global issues with the global counterparts to continuously improve quality of services to all users andor communicate issues with manager global datacenters and datacenter engineers
be aware of development in information technology and promote this and systems for quaker
keep information center library well documented
participate in activities and projects that are aimed at information processing and development identify promote and adapt after appropriate approval new technology and systems for quaker and support propagation of these new technology and systems globally

qualifications
bachelor’s or master’s degree preferably in information systems or computer science
7 years of relevant work experience in a data center or other critical environment
strong experience on virtualization using vmware vcp certification is a plus andor microsoft hyper v
strong experience with blade server technology fiber switches and san storage technology preferable ibm hardware and basic knowledge of hyper converged infrastructure systems
requires high knowledge of microsoft office 365 microsoft operating systems microsoft active directory microsoft server applications
basic knowledge of microsoft sql database environments and at least 5 years’ experience in installing and maintaining these products
knowledge of firewall lan and wireless equipment is a plus preferable cisco
is a team player and accustomed to participating in large projects
is fluent in english verbal and writing
the position holder is characterized by eg following qualities analytical operational tactical resultcustomer oriented team player action oriented and creative

company overview

at quaker chemical we are experts in the development production and application of process fluids lubricants and coatings for the steel metalworking and many other manufacturing industries with approximately 2000 associates in more than 20 countries we enable our customers to be more efficient  and ultimately more profitable its our obsession and we achieve this through our intimate knowledge of the industries we serve and each one of the moving parts that comes with it quaker is a global publicly traded company with a unique collaborative culture that supports career growth for its associates and offers competitive compensation and benefit programs",,PA,False,data_engineer
Data Engineer,"about the role
we are integrating multifaceted data streams such as realtime iot data purchase data at the fridge engagement data from the mobile apps production and logistics data so that we continuously improve and optimize our business and operations workflows we are looking for a data engineer to join our tech team and this could be you
in a typical week you will
grow our existing cloud and data infrastructure democratize access to data
champion the use of data and analytics at the company be the pioneer of a datadriven culture
work with tech marketing sales operations finance and other business functions to scope design and implement their data needs
help identify significant data sources and key variables for various business functions
lead the design and development of the data pipelines to productionize and ingest meaningful business data into a unified data model
develop machine learning and predictive analysis tools to identify new growth opportunities and personalize our services
minimum qualifications
bachelor’s degree in computer sciencecomputer engineering or relevant industry experience
proficiency in multiple programming languages particularly python r or javascript with minimum two years full time professional experience
you are proficient with sql and are rarely satisfied with the current query performance
you have developed data ingestion data warehouse and integration pipelines
you are comfortable with both batch and stream data processing
you know what it takes to build scalable and performant data models
you understand the differences between relational and columnar databases and when to use them
you are familiar with web development
you value writing tests and people who write tests
you have worked with one of the major public clouds preferably aws
ideally you have experience with data visualization
benefits
traditional benefits  health dental vision life short term disability ltd
10 paid holidays
generous pto policy
daily fridge credits
monthly cell phone credit
spontaneous company events and community service activities
work with a phenomenal team of individuals that are constantly pushing the market boundaries to offer healthy food at the utmost convenience
about farmer’s fridge
at farmer’s fridge we’re committed to making wholesome delicious food simply accessible so people can live a little happier we aim to remove the roadblocks to eating well on the go that means sourcing topnotch ingredients handcrafting meals in our kitchen packing  delivering fresh to our network of fridges and ensuring the best possible customer experience unpurchased items are regularly donated to local food depositories providing responsibly sourced nutrition to community members in need if you’re passionate about our mission to change the food system for the better our team just may be the right fit for you

view our disclosures related to external agencies and applicants below
httpswwwfarmersfridgecomcareerdisclosures",,IL,False,data_engineer
Junior Data Engineer,"ready to grow your career leveraging the latest data technologies

join a fastpaced and talented agile scrum team to unlock data capabilities for the hartford you will have an opportunity to participate in the entire software development lifecycle process in support of continuous data delivery while growing your knowledge with emerging technologies we use the latest data technologies software engineering practices agile delivery framework and are passionate about technology and building well architected and innovative solutions that drive optimal business value generation

this cutting edge and forward focused team presents the opportunity for collaboration selforganization within the scrum team and visibility as we focus on continuous business data delivery

what’s in it for you
experience deeper understanding of data analytics emerging technologies and development practices
collaboration with a highperforming forwardfocused team product owners and business stakeholders engagement
opportunity to expand your communication analytical interpersonal and organization capabilities
experience working in a fast paced environment – driving business outcomes in agile ways of working
enable and influence the timely and successful delivery of business data capabilities andor technology objectives
enhance your e ntrepreneurial mindset – network opportunity and influencing outcomes
hone your development capabilities using various tools such as hadoop informatica b2b plsql etc to build data assets that enable business value generation
appreciation and opportunity to learn and support rapid software construction and deployment using devops and cloud based future technologies
supporting environment that fosters cando attitude and opportunity for growth and advancement based on consistent demonstrative performance
optimize business value by leveraging your data experience and depth
be part of a scrum team – driving work independently or collaboratively towards achieving business outcomes
qualifications
what is the hartford looking for
highly motivated candidates looking to grow their career with the hartford
forward looking and focused on continuous improvement
team player and able to work with and through others
takes initiatives in building their own technical and soft skills
volunteers for extra assignments within the organization driving towards continuous improvements within our data delivery life cycle
ability to listen effectively process information ask appropriate questions for clarification and execute tasks accordingly
detail oriented and good documentation skills
bachelor degree with at least 13 years of applicable work experience
desired educational experience include but are not limited to computer science engineering it management information systems data analytics applied mathematics and business
desire candidates with prior data engineer competencies and prior experience with successful enablement of data delivery initiatives
understanding of current and emerging it products services processes and methodologies
prefer experience with big data technologies and concepts on a hadoop platform eg scoop hive pig nosql etc… and willingadapting to future technologies
prefer working knowledge of etl process across various tools and experience with sql skills

what else can you tell me
the hartford is committed to the education and growth of our information technology professionals a number of it certifications are available to enhance your career and growth potential it professionals at the hartford may qualify for a stipend up to 1000 per year for additional certifications

equal opportunity employerfemalesminoritiesveteransdisabilitysexual orientationgender identity or expressionreligionage

 no agencies please 
job function
 data engineering
primary location
 united statesconnecticuthartford
schedule
 fulltime
job level
 individual contributor
education level
 bachelors degree ±16 years
job type
 standard
shift
 day job
employee status
 regular
overtime status
 exempt
travel
 no
job posting
 aug 3 2018 20619 pm
remote worker option  no",,CT,False,data_engineer
Data Engineer,"who we are
build the business build the brand
at havas edge we influence people to act by combining multichannel marketing and commerce plus the creative and technology that powers them our work results in profitable growth and lasting relationships between customers and our clients brands
we are a fullservice direct response agency headquartered in carlsbad ca with offices in boston ma los angeles ca and london uk

what we need
responsible for developing and supporting data warehouse solutions built on the microsoft sql server technology stack rdbms ssis ssas and ssrs these solutions include etl data modeling data quality assessment and data delivery this resource will play a critical role in the development of data warehouse solutions utilized by internal and external clients

what youll do
create high performance data warehouse and etl solutions using ssis
performance tuning and optimization of ssis tsql and database structures
design and develop tables views triggers indexes constraints and stored procedures
monitor long running transactions and can optimize query executions using best practices and methodologies
assistsupport in the design process on an as needed basis
design data models for enterprisewide data integration incorporating
structured and unstructured data
real time ondemand batch and varying timing schedules
build data flow automation to retrieve transform and load data
manage data warehouse structure and file storage rules
data management functions including
metadata management
capacity planning
create alter delete grant permissions indexing updating
query tuning
storage backup and recovery
maintain best practices for handling storing and using data
tools
sql serverssis
unixlinux
javarperlpython
web analytics platforms google adobe etc
cloud technologies aws azure google

who you are
minimum requirements
bs degree in one of the following subject areas computer science business administration information technology or related field preferred
minimum of 5 years of experience developing large scale complex database solutions
demonstrated experience with bi database design
ability to track and resolve database related incidents as well as requests
strong understanding of database structures theories principles and practices
strong understanding of etl and data warehouse principles
extensive experience writing tsql
knowledge of reporting and query tools like ssrs and ssas
good interpersonal written and oral communication skills
technical documentation skills
ability to present complex ideas in userfriendly language
selfmotivated and directed with keen attention to detail
able to prioritize and execute tasks in a highpressure environment
experience working in a teamoriented collaborative environment
the ability to develop stored procedures triggers indexes and views

specific skills required
microsoft sql server 2014
minimum 35 years tsql experience including the ability to tune queries
minimum 35 years of etl experience
minimum 23 years of ssis
strong data warehouse knowledge
data modeling experience
some dba skills preferred but not required
experience with large data sets
python java c or r experience a plus
experience with rest api calls",,CA,False,data_engineer
Data Engineer,"nexon m is a mobile game publisher based in emeryville ca founded in 2013 nexon focuses on freetoplay games for mobile and counts some of the world’s best developers as its partners including big huge games maker of the topgrossing game “dominations” and pixelberry maker of topgrossing game “choices stories you play”

we focus on freetoplay games for mobile can be traced to our roots as a subsidiary of nexon corp as korea’s largest game company nexon is known for having created the first freetoplay games in the early 2000′s and has multiple games which recently passed their 10year anniversaries of live operation

were hiring a data engineer to join our platform engineering team our big data platform processes over a billion of events per game to support our analysts and other functional groups to make better business decisions this position develops and supports various realtime etl processes to transform data from different input sources including our own game sdk and effectively load into our data warehouse in a scalable manner

job responsibilities

create document and maintain various etl processes
write code to interface with 3rd party platform services
assist with all parts of our internal analytics system etl redshift airflow
provide technical support and advice to the analytics and data visualization team
other duties as assigned

job qualifications
work experience


experience with big data and analytics systems hadoop storm spark etc…
5 years doing backend web services programming java php
3 years doing database work mysql postgres  redshift
experience using amazon web services a plus
experience with scalable systems in a load balanced environment a plus

education professional training technical training or certification


bs in computer science

knowledgeskills


object oriented programming python  java
database technologies redshift  postgres  spark  presto
amazon web services s3 sqs kinesis ecs ecr emr

this is an onsite fulltime position with nexon m nexonmcom our studio is located in emeryville ca a casual friendly work environment comprehensive benefits package a competitive salary and a great opportunity for career growth and development are all part of what makes nexon m a great place to work

nexon is an equal opportunity employer

to all 3rd party recruiting agencies nexon does not accept agency resumes please do not forward resumes to our recruiters employees or any other company location nexon is not responsible for any fees related to unsolicited resumes",,CA,False,data_engineer
Data Engineer,"about stackpath
founded in 2015 stackpath provides inherently secure cloud services so that developers can build online solutions and services that are safe—for their own operations and for their end users more than 30000 customers already use stackpath technology ranging from fortune 100 companies to early stage startups we are a fastgrowing team headquartered in dallas with offices in orlando phoenix seattle tel aviv and belgrade
about the position
stackpath is hiring a data engineer enhance our data engineering team our data engineers empower stackpath and its customers by building data analysis platforms that ingest high volumes data streams from global sources and provide insight and analytics to internal and external customers
we are looking for passionate intelligent and motivated data engineers that want to be a part of a quickly growing team focused on collaboration and teamwork
the data engineer
works in a data focused engineering team on distributed data management platforms in a high ingest rate environment from batch and nearrealtime streams
performs analysis design programming and testing for the data flow and etl layers of data warehouses and operational data stores
designs and programs processes used for data storage and reporting tests and debugs these systems prior to implementation and troubleshoots and upgrades the system as needed
supports both internal and external customer facing systems occasionally the position will involve data warehouse administration dba ensuring the successful operation of data load and analysis jobs
writes code works not only in an etl ide or graphical administration tools
why you should apply
you love working with data in a highly collaborative environment
you wake up each day hungry to solve problems
you want to make the world a better place one customer or issue at a time
you want to make a difference and have input
help build an amazing company
you must have
experience in using postgresql
experience in scripting etl workflows on linux  unix in python and  or go
experience in building and maintaining data pipelines using kakfa or similiar
experience in writing analytic olap queries in sql
knowledge of common linux shell tools for text processing awk sed grep
familiarity with other relational database technologies such as clickhouse or mysql
quantitative skills that will allow the successful use of data in operational and business processes
you should be able to
handle data projects at a scale most companies don’t have
solve problems not seen before
quickly understand the complexities of the company’s products and markets
work with a team of data engineers and business leaders in both local and remote offices
you might also have
postgresql  mysql database administration experience
experience in
data analysis and visualization tools tableau grafana r
distributed query engines citus presto apache drill
distributed file systems ceph hdfs
stream processing platforms kafka
container management platforms docker kubernetes
bachelors degree in computer science math statistics or related quantitative experience
other details
at stackpath we take care of our employees and want you excited to get out of bed in the morning we provide competitive salaries and a full slate of benefits we invest in our people to ensure that they have everything needed to excel on the job
our goal is to make the internet a safer place we need more help from people with the right passion and skills to help us get there
this job description is not intended to be allinclusive",,TX,False,data_engineer
"Principal Data Engineer, Infrastructure Automation","job description
the ideal candidate is a motivated selfstarter with strong business acumen to join the team and build analytics driving actionable insights to accelerate the growth of the business the principal data engineer will partner with senior leaders product managers and other internal stakeholders within aws infrastructure and partner services

this role requires an individual with excellent analytical abilities deep knowledge of business intelligence solutions as well as a passion for problemsolving ideally you are comfortable with ambiguity and accessing and working with data from multiple sources you will analyze large amounts of data discover and solve real world problems and build metrics and business cases around key performance of this program you will be responsible for understanding the health of the service and business and drive necessary changes as needed this is a perfect position for someone who loves data and knows how to work fast and smart

some of the key responsibilities for this position include
propose and implement business metrics for senior management reviewswork with business intelligence and data engineers to design and develop data infrastructure strategy for the quality and software development organization of aws infrastructureenable effective decision making by driving partner teams to expose data pipelines and enabling the data team to aggregate data from multiple sourcesperform deepdives to find the root causes behind variances of key parameters over a given timeperioddevelop intelligent insightful selfreporting toolsmanage the data warehouse strategy

key responsibilities
work closely with management software engineering leaders and business teams to plan catalog data improvements so as to maximize customer improvement impacttriage many possible courses of action in a highambiguity environment making use of both quantitative analysis and business judgmentcollaborate with software engineering teams to integrate experimental capabilities into largescale highly complex amazon production systemsreport results in a manner which is both statistically rigorous and compellingly relevantassist in recruiting mentoring developing and training other data engineers and data scientists within the organization

basic qualifications
babs in computer science engineering mathematics or related field
demonstrated strength in sql data modeling etl development and data warehousing
10 years of relevant work experience in a role requiring application of analytic skills to integrate data into operationalbusiness planning or advanced degree
advanced skills in business analytics as well as any data visualization tools like tableau or similar bi tools familiarity with tableau and quicksight preferred
advanced ability to draw insights from data and clearly communicate them verbalwritten to the stakeholders and senior management as required
be selfdriven and show ability to deliver on ambiguous projects with incomplete or dirty data
an ability and interest in working in a fastpaced and rapidlychanging environment
preferred qualifications
mba or master’s degree in computer science engineering statistics mathematics or related field
expert in writing and tuning sql scripts
experience working in very large data warehouse environments
10 years of experience in a data engineer role with a technology company
experience conducting large scale data analysis to support business decision making
5 years of operations andor multiunit retail industry experience
familiarity with aws redshift and aws glue
experience with scripting languages pythonr",,WA,False,data_engineer
Data Engineer - Supply Chain Optimization Technology,"job description
have you ever wondered how amazon shipped your order so fast wondered where it came from or how much it cost us to help describe some of our challenges we created a short video about supply chain optimization at amazon  httpbitlyamazonscot

we in the order assignment team own and operate production systems that decide the most optimal strategy to ship a customer order simulation systems that allow internal customers experiment with whatif scenarios and analytical systems to help understand results and derive intelligence from the same when customers place orders our systems use real time large scale optimization techniques to optimally choose from where to ship and how to consolidate multiple orders so that customers get their shipments on time or faster with the lowest possible transportation costs the team in austin is focused improving the customer experience and on saving hundreds of millions of dollars using cutting edge science machine learning and scalable distributed software in the cloud that automates and optimizes shipments to customers under the uncertainty of demand pricing and supply

we are seeking an outstanding data engineer to join our team amazon has a culture of datadriven decisionmaking and demands business intelligence that is timely accurate and actionable your work will have an immediate influence on daytoday decision making at amazoncom

as an amazon data engineer you will be working in one of the worlds largest and most complex data warehouse environments we maintain one of the largest data marts in amazon as well as work on business intelligence reporting and dashboarding solutions that are used by thousands of users worldwide our team is responsible for mission critical analytical reports and metrics that are viewed at the highest levels in the organization we are also working on newer tools that help users discover data using visualization and big data technologies you should have deep expertise in the design creation management and business use of extremely large datasets you should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions you should be expert at designing implementing and operating stable scalable low cost solutions to flow data from production systems into the data warehouse and into enduser facing applications you should be able to work with business customers in a fast paced environment understanding the business requirements and implementing reporting solutions above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change

amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation
basic qualifications
degree in computer science or related field with 4 years professional experience in database development
proficient with processing data on relational databases like redshiftaurora
experience handling large data sets using sql and databases in a business environment
familiar with etl and dw processes
excellent verbal and written communication
strong troubleshooting and problem solving skills
thrive in a fastpaced innovative environment
preferred qualifications
knowledge of aws technologies
knowledge in using olap technologies and bi analytics
oracle redshift linux obiee experience
experience with multiple database platforms
familiar with computer science fundamentals including objectoriented design data structures algorithm design problem solving and complexity analysis",,TX,False,data_engineer
Data Engineer,you are a contemporary data engineer with data integration expertise and a passion for changing the data landscape if you are interested in working for a data driven company on the edge of industry disruption wed love to talk with you and if we ask you about bulk batch high volume data processing and your eyes light up and your brain goes into overdrive were talking to the right personwe are looking to hire a high performing data engineer with data integration etl experience as part of an integral member of our tech  data integration team you will transform and translate data into a form that is ready for use to solve the tough challenges of our business the data engineer will make data useful by moving it around transforming it distilling it combining it with other data addressing data quality issues and delivering it to a repository or consuming system in a performant manner you will work with various forms of data xml json text csv and data sources apis server logs external data nosql etc ultimately it will be you that manages clear capital’s complex data landscape in todays worldhere are a few exciting projects you get to work on mdm strategy and execution building new data domains aws cloud migration build out broader data integration service to support our data storeswhat you will dodesign develop automate monitor and maintain extract transform load etl data movement applications using our preferred etl tools and techniquesperformance tune etl applications to manage high volume batch data transfer to and from internal and external system locationstroubleshoot data issues recommend test and implement solutionsdevelop and document technical requirementsand solutionsparticipate in design and code reviewstroubleshoot issues making recommendations and delivering on those recommendationsengage in project planning and delivering to commitmentsinteract with project manager lead and agile team to estimate development efforts and ensure accurate requirementsfulfillmentparticipate in daily standup meetings planning meetings and review sessions using scrum  agile methodologyinteract with crossfunctional teams to ensure complete delivery of solutionsassist with configuration of applications softwareskills and experience you bringextensive experience with delivery using etl tools and techniques ie ab initio pentaho talend ssisprogramming skills in either java javascript sql or plsqlunderstanding of data warehouse and master data management approaches etl industry standards and best practicesexperience with cloud migration and cloudhosted etl environmentsexpert sql and database tuning skills for relational platforms postgresql oracle is a plusfamiliarity with revision control  gitdemonstrated experience with kimball etl architecture techniquesdemonstrated working knowledge of unixlinux operating systems and related data integration tools such as secure ftp serversexperience with aws technologies and stack such as lambda emr s3 rds and ec2experience with nosql databases cassandra is a plusexperience with apache airflow is a plusworking knowledge of an operating system scripting language ex bash using awk and sed python andor perlexcellent communication analytical and development skillsknowledge of current standards and practices in real estate information systems is preferredclear capital 101since its launch in 2001 clear capital continues to solidify its place as a leading provider of real estate valuation data and technology for banks lenders and sizeable investors clear capital—one of the leading real estate technology data  analytics providers—places each customer’s financial future in their own hands by providing the most clear transparent and trusted data to ensure the mortgage finance industry can make healthy and sound decisionsto all recruitment agencies clear capital does not accept agency resumes please do not forward resumes to our jobs alias clear capital employees or any other company location clear capital is not responsible for any fees related to unsolicited resumescompensationsalary commensurate with experienceclear capital is an equal opportunity employerjob type fulltime,,NV,False,data_engineer
Data Engineer II - Consumer Payments / Lending,"job description
the data engineer de will be a key member of the technical team at amazon lending contributing to a new and rapidly growing line of business for amazon this person will take the lead on optimizing our data architecture for the heavy analytics needed for this business
the role presents a significant intellectual and technical challenge with enormous opportunity for business impact amazon is expanding into lending services and has launched with the small business segment we believe we are in a unique position to serve our customers with exceptional value due to our deep understanding and insight into our base coupled with our datagrounded analytic and customerfocused approach to building products

we are looking for a talented and passionate data professional that can design a highquality and scalable analytic infrastructure that can automate our decisionmaking processes a successful candidate will be innovative technically versatile and be able to interact with customers to gather requirements and deliver the right set of data to support business growth

the key strategic objectives for this role include
a innovating to deliver missioncritical near realtime data feeds to optimize the business
b delivering a robust flexible and scalable data analytics environment to support amazon lending as it grows deeper in its existing lines of business and expands to new geographies customer segments and products
c collaborate with technical teams legal finance operations and product managers to drive process improvement and track progress against goals
basic qualifications
we are looking for data engineers who have a passion for supplying their clients with meaningful and trustworthy data you know and love working with analytic tools can write excellent sql and unix scripts can partner with customers to answer key business questions and you are an advocate for your customers you are analytical and creative and you don’t quit

you should also have the following skills or experiences
bachelors degree in cs or related technical field
5 years experience in data warehousing
strong data modeling and sql skills
excellent troubleshooting and problem solving skills
passion for learning and using new technologies
effective communication and strong collaboration skills
preferred qualifications
experience partnering with business owners directly to understand their requirements and provide data which can help them observe patterns and spot anomalies
proficient in big data processing eg hive scala
expertise in mpp and nosql persistent storage solutions
experience integrating with 3rd party data providers
amazon is an equal opporunity employer",,WA,False,data_engineer
Data Engineer,"make a difference help gallup fulfill our mission of providing analytics and advice on everything that matters by creating the infrastructure to fuel analysis insights and products
as a data engineer you will have the option to work from the comfort of your home office or from one of our worldclass workplaces responsibilities include consulting with data scientists and client teams to develop and implement prototypes and products to advise on quantitative research across a wide range of organizational topics in your role as an infrastructure builder you will work with internal teams to design construct install test and maintain highly scalable data management systems as well as integrate new data management technologies and software engineering tools into existing structures you will also partner with client teams to develop data pipelines that support a range of enterprise and government projects including supervised and unsupervised learning methods timeseries forecasting and network analysis you will also be responsible for helping consultants and data scientists produce highquality easily understood data products for clients
who we want

automation architects who can conceptualize manual processes generate coding and systems to reduce human dependency
experienced coders who can identify the right tools for the job and who have an eye for the smallest details and a talent for flawless execution
strategic thinkers who can apply their expertise to make discoveries in complex data
problem solvers who enjoy working with others to design and implement robust solutions to challenging realworld problems
creative analysts who are familiar with a variety of coding languages who enjoy participating in and winning hackathons and who have experience working across programming languages and systems to meet the needs of multiple stakeholders
missiondriven individuals who are motivated to create the best production prototype and research infrastructures because of their desire to change the world

qualifications
what you need

a bachelor’s degree from a computer scienceengineering computational social science or operations research program or related area required
minimum of three years of corporate experience in designing and building productionlevel data pipelines required
minimum of three years of experience in the fundamentals of machine learning and statistics with an emphasis on the engineering aspects needed to implement these algorithms at scale eg distributed computing required knowledge of an opensource statistical programming language eg r julia stan is a plus
mastery of at least one opensource generalpurpose programming language eg python go java javascript php perl and knowledge of a second are key requirements
must be authorized to work in the united states on a fulltime basis

what we offer

v irtual workplace opportunities are available
a strengthsbased engagementfocused and performanceoriented culture
worldclass managers who support position empower and engage you
ongoing learning and development opportunities
missiondriven work that changes the lives of people around the world

gallup is an equal opportunityaffirmative action employer that celebrates supports and promotes diversity and inclusion we will consider all qualified applicants without regard to race color religion sex national origin disability protected veteran status sexual orientation or gender identity or any other legally protected basis in accordance with applicable law
primary location
 united stateswashington dc
other locations
 united statesnew york city united stateschicago united statesomaha united statesatlanta united statesirvine",,DC,False,data_engineer
Data Engineer - Hadoop-Quincy,"we have an immediate opportunity with a large f500 client in the quincy ma area

we are looking for data engineer to work with one of our major healthcare clients in quincy ma

12 months

primary skill  hadoop

secondary skill no sql

roles and responsibilities
 develops etl extract  transform  load processes and tools for realtime and offline analytic processing

 collaborates with data science team to gain a deep understanding of their needs

 applies knowledge of hadoop architecture and experience designing  optimizing queries to develop large scale data structures and pipelines to organize collect and standardize data that helps generate insights and addresses reporting needs

 uses strong programming skills in python java sql or any of the major languagesjavascala to build robust data pipelines and dynamic systems

 builds data marts and data models to support data science and other internal customers

 integrates data from a variety of sources assuring that they adhere to data quality and accessibility standards

 analyzes current information technology environments to identify and assess critical capabilities and recommend solutions

 experiments with available tools and advises on new tools in order to determine optimal solution given the requirements dictated by the modeluse case

for immediate consideration please contact
harini

upstream global services

reply to projectsupstreamgscom

wwwupstreamgscom",,MA,False,data_engineer
IT Data Engineer,"heartland financial usa inc is a growing dynamic organization with many locations offering uniquely different banking and financial solutions for businesses and personal clients as a performance driven company we strive to create a culture of excellence with high standards and high values while providing outstanding growth and involvement opportunities for employees join a team that makes great things happen™



under general direction  the data engineer is the is solution administrator responsible for understanding htlf data warehouse type tools with a focus on developing reporting and business intelligence bi interfaces while understanding ms sql database structures
 

responsibilities
1 designs logical and physical databases or review description of changes to database design to understand how changes to be made affect physical database how data is stored in terms of physical characteristics such as location amount of space and access method

2 builds databases for data storage or processing and develop strategies for warehouse implementation data acquisition and archive recovery

3 optimizes data storage receptacles manage etl processes and clean and maintain databases by removing and deleting old data

4 establishes physical database parameters

5 responsible for fulfilling bi requests not outsourced or manageable by power users

6 codes database descriptions and specify identifiers of database to database management system or direct others in coding database descriptions

7 specifies user access level for each segment of one or more data items such as insert replace retrieve or delete data

8 specifies which users can access databases and what data can be accessed by user

9 evaluates new data sources for adherence to the organizations quality standards and ease of integration

10 tests and corrects errors and refines changes to database

11 identifies researches and resolves technical problems as well as answer user questions

12 confers with coworkers to determine impact of database changes on other systems and staff cost for making changes to database

13 works with project and business leaders to identify analytical requirements

14 manages aspects of the warehouses such as data sourcing migration quality design and implementation

15 scopes plans and prioritizes multiple projects

16 completes annual elearning plan and bank secrecy act bsa training as assigned and keeps uptodate knowledge of bsa as it relates to the job function

17 performs other duties as assigned


required skills  experience
1 bachelor’s degree in information technology or equivalent years of experience

2 57 years related experience in an isit department managing databases warehouses andor secondary repositories data mining using joins matching etc within said receptacles to extract pertinent records related to query requests and effectively building maintaining and troubleshooting etl procedures

3 experience with sql ms sql service and ms access

4 familiar with field’s concepts practices and procedures

5 familiar with data quality procedures and processes

6 familiar with metadata and data dictionary procedures and processes

7 understands the advanced analytics concepts such as clustering association andor data mining

8 ability to document procedures and build work instructions

9 high attention to detail

10 high level of independence and responsibility for own actions


scheduled weekly hours
40


time type
full time",,IA,False,data_engineer
Data Engineer,contractwe are looking for a savvy data engineer for our team the hire will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for cross functional teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up the data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our companys data architecture to support our next generation of products and data initiativesresponsibilitiescreate and maintain optimal data pipeline architectureassemble large complex data sets that meet functional  nonfunctional business requirementsbuild the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql cassandra hadoop and other big data technologiesbuild data pipeline on premise and on google cloud platformbuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metricswork with stakeholders including the product data and design teams to assist with datarelated technical issues and support their data infrastructure needswork with data and analytics experts to strive for greater functionality in our data systemsqualificationsadvanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databasesexperience building and optimizing big data data pipelines architectures and data setsexperience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementstrong analytic skills related to working with unstructured datasetsbuild processes supporting data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsworking knowledge of message queuing stream processing and highly scalable big data data storesexperience supporting and working with crossfunctional teams in a dynamic environmentwe are looking for a candidate with 5 years of experience in a data engineer role who has attained a graduate degree in computer science statistics informatics information systems or another quantitative field they should also have experience using the following softwaretoolsexperience with big data tools hadoop spark kafka etcexperience with google cloud platform esp google pubsub big query data proc data flow cloud storageexperience with iot  time series dataexperience with relational sql and nosql databases including postgres and cassandraexperience with streamprocessing systems storm sparkstreaming etcexperience with objectorientedobject function scripting languages python java c scalajob type contract,,CA,False,data_engineer
Data Engineer,"company overview 
resurety is a missiondriven organization solving the challenge of resource intermittency for renewable energy we work in partnership with the world’s leading energy and risk management providers to enable renewable energy consumers and producers to manage the fuel risk of the future the weather as a highgrowth profitable company that has already supported over 4000 mw of clean energy transactions we are a small team making a big impact our culture is open and collaborative we expect excellence from our team members and reward it with high ownership and flexibility if you’re a highachiever with a passion for clean energy then we look forward to receiving your application

position overview 
as a data engineer you will own and improve a worldclass data pipeline that is scalable reliable flexible and accurate to ensure that the resurety team uses the best available data to characterize risk and support development of renewable energy worldwide

key responsibilities 

centralize many different data feeds
work closely with the internal teams to understand their data needs
maintain existing and design new relational database and model data sets
build and integrate code interfaces for downstream users

required qualifications 

experience with data centralization processes
experience creating and maintaining relational and nonrelational databases
proficient in python or r

preferred qualifications 

bachelors degree in computer science computer engineering or a related field
2 years of related professional experience
experience with amazon web services s3 ec2 rds efs
experience with linuxbased systems

details

location boston ma
travel minimal

benefits

unlimited vacation policy
medical insurance
dental insurance
health savings account hsa
401k
gym membership reimbursement
blue bikes gold membership

resurety inc is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability status protected veteran status gender identity sexual orientation or any other characteristic protected by law",,MA,False,data_engineer
Data Engineer Co-op (Spring 2019),"internshipthe data engineer position would support the fgam60 big data product group in delivery use cases into production for both the sales and financial services organization the selected resource would work directly with the data scientists to harden code and implement the necessary security measures to move solutions into production without this position bmw would need to hire external resources to productionalize the use ases at a much higher cost or the number of use cases that could be implemented would be significantly reduced should this position not be approved

bmw manufacturing company is an eeoaffirmative action employer all qualified applicants will receive consideration for employment without regard to age race color religion sex gender identity national origin disability or protected veteran status
must attach a copy of unofficial transcript

possess a minimum cumulative gpa of 30
have full time status at an accredited four year college or university in the united states
completed at least 30 credit hours
able to complete 3 rotating terms for coop positions
have at least 1 remaining term in school after the completion of the coop or internship
transfer students must have a gpa from current university
complete and pass a substance abuse test before the work term
must have the legal right to work for bmw manufacturing co llc in the united states
bmw manufacturing will not provide sponsorship now or in the future",,SC,False,data_engineer
Big Data Engineer II,"big data engineer

as a big data software engineer youll use your data engineering knowledge to provide scalable enterprise data integration processes and technical support for our data management systems in this role you will be responsible for understanding data requirements security requirements metadata design development and testing activities to successfully implement and support the needs of the business

you will grow a longterm career while continuously receiving handson training and mentorship from senior level architects and developers in our data services organization

responsibilities

development of solutions duties include construction of basic andor complex solutions based on functional and technical specifications creation of operational specifications and procedures definition documentation and execution of unit test cases support quality services and user acceptance testing definition creation and execution of implementation processes and procedures assist in task identification planning and tracking
passionate about distributed processing and very largescale solutions
provide a high quality and reliable solution to solve business problems
review and manage work assignments includes support cases for team in an agile environment
provide technical representation and communicate with customers until issue is resolved

qualifications

bachelor of science in computer science or equivalent years of relevant work experience
strong knowledge of relational databases sql
3 plus years of java scala maven python spark sparksql sparkml nosql development experience
3 plus years of sql programming
strong experience working with hadoopbig data technologies ie hadoop mapr nosql database capability
strong analytical capabilities data processing development background and multiple dbms experience
clear understanding of hdfs file types and when to use which
clear understanding of the differences of the multiple data management systems available ie hdfs cassandra hive hbase
strong understanding of distributed systems and distributed computation
strong knowledge of linux scripting bash ksh jenkins
experience using tools such as atlassian jira wiki visual studio tfs power designer tortoisesvn is a plus
strong analytical and communication skills

perks

longterm growth opportunities
casual and diverse working environment
strong corporate commitment to this technology stack
bcd travel has received numerous awards as a best place to work
you will grow a longterm career while continuously receiving handson training and mentorship from senior level architects and developers in our data services organization

equal opportunity employer minoritieswomenprotected veteransdisabled",,,False,data_engineer
Data Engineer,"data is the fuel of ai we are looking for a strong data engineer to join our growing team of ai and computer vision experts

the successful data engineer will be responsible for expanding and optimizing our image and video data and pipeline architecture as well as optimizing data flow and collection for computer vision algorithm development and product teams

this person will use their skills and prior experience working with datasets to build our data ingest and metadata management automation pipeline as part of our data infrastructure effort he or she will deal with synchronization cleaning restructuring filtering and doing early analysis followed by exploratory and automatic data analysis as our statistics build up

the successful candidate is experienced with building image and video data pipelines and working with imaging data and is someone who enjoys optimizing data systems and building them from the ground up

the data engineer will support our algorithm developers software developers database architects data analysts and data scientists on building world class datasets and will ensure optimal data delivery architecture is consistent throughout ongoing projects

they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our image and video data architecture to support our next generation of products and data initiatives
key responsibilities
create and maintain optimal data pipeline architecture
assemble large complex multimodal image and video data sets that meet functional  nonfunctional business requirements
maintain and analyze large quantities of inbound and outbound autonomous driving sensor data
facilitate the ingress and egress of sensor data from our acquisition drives to and from annotation partners
review data for annotation
interface with annotation partners monitor and track quality and provide support
build analytics tools that automatically parse annotated data for valuable statistics and other information
dynamically generate datasets for training and testing of perception algorithms for autonomous driving
infrastructure and database support help automate processes
qualifications and requirements
bs or higher in computer science or related technical field
scripting skills in python shell or other common scripting language
experience in manipulating and analyzing real world image and video datasets
working knowledge of unixlinux environments
strong team player and communication skills
strong project management and organizational skills
 desired qualifications
knowledge of machine learning andor computer vision concepts
web based programming xmljson ajax html
database eg mysql mongodb",,CA,False,data_engineer
"Data Engineer, Business Intelligence","as a data engineer for business intelligence at compass you will be responsible for helping to build the datadriven decisionmaking culture throughout the organization youll work as part of a rapidly growing team in a fastpaced environment you will be responsible for managing largescale business systems initiatives that impact multiple functions and teams across the organization in this high impact role you will have an opportunity to work with emerging technologies while driving business intelligence solutions endtoend business requirements workflow instrumentation data modeling etl metadata reporting and dashboarding you are someone who loves data understands enterprise information systems and has a strong business sense

at compass you will

design develop and implement the infrastructure that elevates datadriven decisionmaking for our proprietary real estate technology
work with the enterprise business systems that facilitate the end to end experience of real estate transactions
work with company stakeholders and product and engineering teams to define analytics requirements
deliver flexible and scalable solutions from endtoend harvesting processlevel data and transforming it into normalized data marts from which operational and process metrics and analysis can be reliably generated

what were looking for

bachelors degree in computer science information systems or related field
3 years of sql development experience
3 years of data modeling etl and data warehousing experience
familiarity with etl tools such as informatica pentaho talend etc
expertise in modern oo language eg java c c objective c
3 years or python scripting experience
familiar with aws as a platform
strong business communication skills
experience with aws technologies such as redshift rds emr etc
comfortable in a linux environment
capable of data processing and transference outside of etl tools or databases custom scripts to pull and load from apis or files
experience writing software requirements
familiar with enterprise networking

at compass our mission is to help everyone find their place in the world this means we continually celebrate the diverse community different individuals cultivate as an equal opportunity employer we stay true to our mission by ensuring that our place can be anyones place

check out our engineering blog  httpsmediumcomcompasstruenorth ",,NY,False,data_engineer
Data Engineer,"about stanza

hundreds of millions of pageviews natural language processing realtime user analytics header bidding… these are just a few of the challenges we face at stanza to the consumer stanza is a seamless calendar integration allowing users to sync their favorite interests and events such as concerts sporting events movie releases and esports with partners such as warner brothers nbc sports cbs nfl nba nhl ncaa and many more stanza is becoming the default way to embed and share calendars on the web

we are redefining the purpose of a calendar with one core value in mind your time matters with hundreds of millions of synced events and global reach our goal is to make sure that each and every user spends more time doing what they love we are a fun bright diverse team thats passionate about solving problems in an elegant way using cutting edge technologies

stanza is backed by top tier venture investors and is headquartered in san francisco

what you will do


work with key developers to design and build a scalable data infrastructure and analytics system
build realtime analytics infrastructure kafka spark mllib amazon kinesis etc
build automated etl pipelines
drive the collection of new data and the refinement of data sources
identify and push efforts to improve data monitoring and automation

who you are


loves to code javascript python java
driven to make a huge difference and have positive impact in the company
handson distributed computing architect
6 years experience with hadoop mapreduce pig hive redshift
aws  cloud computing experience
deep understanding with data stores such as mongodb and sql
knowledge and experience performing advanced analysis in a statistical computing language eg python r sas is a plus
function well in a fastpaced open and bold culture in rapidlychanging environment
bachelors or masters in computer science
strong oral and written communication skills

what else


exciting startup environment with competitive salary with equity
commuter reimbursements
catered lunches several times a week
medical vision and dental benefits

",,CA,False,data_engineer
Data Engineer,"software engineer  big data

intertrust technologies corporation is a privatelyowned silicon valley company that provides products and services around security trusted computing and data management our groundbreaking enterprise trusted data platform enables iot data marketplaces in a diverse set of industries that include healthcare renewable energy media and targeted advertising
one of intertrust’s products is the personagraph data analytics platform™ intended for brand advertisers agencies media buyers and publishers to segment audiences based on a mobile user’s interests demographics and intents personagraph’s data management platform makes it easy to find understand and connect with audience segments and supports audience datadriven demand for open rtb realtime bidding and private marketplace programs the personagraph team is based out of intertrust headquarters in sunnyvale california with locations in india hyderabad bangalore mumbai and indore
we are seeking a software engineer data engineer to join our expanding team developing to support our data pipeline team developing scalable machine learning algorithms data acquisition and data visualization
responsibilities
work closely with cross functional teams to design and develop a big data platform
develop real time analytics data pipeline processing billions of events
work with qa and devops teams to troubleshoot any issues that may arise during production
data acquisition data gathering from different sources for example us census data mobile application data movies and music data location data like points of interest
develop queries and data visualization tools using technologies such as d3js druid or presto enabling data insights into user’s behavior

key qualifications
2 years of experience in software development in java or python andor machine learning
strong computer science fundamentals
expertise in big data technologies with spark extra points for hadoop
exposure to one of these technologies elasticsearch kafka sql nosql
experience designing building and maintaining largescale highperformance systems and frameworks
experience with at least one major language such as java scala python
strong understanding of data modeling and storage with nosql and relational databases
bachelor’s degree or higher in computer science computer engineering data science or similar field or equivalent years of experience
optional experience
experience with machine learning data science and analytics
rest apis aws
iot internet of things
functional programing experience or interest",,CA,False,data_engineer
Unstructured Data Engineer,"after several consecutive years of doubledigit revenue growth ktmine is investing in new markets content and software and is seeking an unstructured data engineer who can contribute to this expansion if you are a driven person seeking a fastpaced environment where every employee has a voice and collaborates daily with people who appreciate the contributions that our technology team makes to the company ktmine may be the ultimate environment for you

the unstructured data engineer will be responsible for aggregating multiple types of data from public sources sources include syndicated news corporate press releases or data pulled from scraping or crawling tools

this job requires a high level of creativity and ingenuity in order to be successful the challenges in this position are endless and the ideal candidate should be able to take arbitrary requirements and turn them into actionable tasks

once data is collected and stored within our environment this candidate should be able to work with the engineering team for integration into our databases and platforms depending on the context of the data

required skills
deep knowledge of data analysis using regular expressions nlp machine learning and entity extraction
deep knowledge of http and manipulation of web requests
data transformation and categorization into object models that can be used within the application
skilled at database design and normalization principles
knowledge of sql and full text index database systems
experience in agile development practices including fast paced development iterations
bachelor’s degree in computer science information systems data science or other
related experience
2 years’ experience as a software developer or a related field

ideal candidate will have
strong communication skills
an analytical and detail oriented approach to solving problems
infer nuance in complicated data structures
ability to persevere and pursue development objectives from start to finish
relentlessly and proactively attack problems and business challenges
drive for perfection",,IL,False,data_engineer
Big Data Engineer,"job description

in this role you will be responsible for a range of duties from basic data analytics to implementing and delivering advanced data engineering visualization solutions and high impact business projects you will get chance to leverage your business acumen programming skills technical knowledge of big data and machine learning techniques
the position will be based at visas headquarters in foster city california
responsibilities
work closely with technical leads and business analysts to understand and document business and technical requirements and constraints
work with business teams in understanding the overall client requirements and proposed big data solution
be handson in leading andor performing development work during the production cycle
experience with building streamprocessing systems using solutions such as storm or sparkstreaming
gather and process raw data at scale including writing scripts calling apis write sql queries etc
design and develop data structures that support high performing and scalable analytic applications
work closely with data science to integrate amazing innovations and algorithms into data lake systems

qualifications

we are looking for a strong analytics thinker and problem solver with a blend of business and technical skills
technical skills
high level of competence in spark and unixlinux scripts
extensive experience with sql for extracting and aggregating data
real world experience using hadoop and the related query engines hive  impalahbase
experience with data visualization and business intelligence tools like tableau microstrategy or other programs
experience
advanced degree in computer science or computer engineering plus relevant experience
5 years of working experience in developing and doing integration projects for enterprise level solutions
strong experience with big data technology including hadoop mapreduce spark is needed
strong experience in spark python scala and java is needed
work on mpp big data technologies like hadoop greeplum data governance implementations and support
produce technical specifications and design for development solution developmentmigration and systems integration requirements
participate and lead internal development and external collaboration meetings
oversee testing of data acquisition processes and their implementation into production
additional information

visa will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of article 49 of the san francisco police code
all your information will be kept confidential according to eeo guidelines",,CA,False,data_engineer
Data Engineer,"skip to main content
8886586462 infoforesightintelligencecom
open mobile menu
home
products we offer
fleet intelligence™
telematics devices
intelligent alert triage center
foresight intelligence center
financial reporting system
about us
company
news
careers
support portal
contact us
sql in the sun 2018

data engineer
our data engineer performs a wide range of job duties utilizing technical knowhow and an exceptional proactive customer service approach ensuring high levels of customer satisfaction maintains a very handson focus for technology matters combined with an affinity for solving complex technical issues and delivering projects on time and within budget

foresight culture is that of spirited team players in an environment energized by innovation and continuous improvement we truly believe it takes an entire team united behind something big so together we work hard we have fun we brainstorm we love ideas and we give highfives in the hallway foresight intelligence employees are encouraged to take a high degree of ownership and improve continuously we work in an environment where your voice matters and where your actions have a direct positive impact on the team and the customer

reports to vice president of operations

job duties and responsibilities

identify evaluate and recommend appropriate technologies and strategies for building products and delivering services from a database perspective
assist in design and development of database systems
secure the database and ensure its integrity
establish the needs of users and monitor the useraccess model control access permissions and privileges
develop databases functions scripts stored procedures etc to collect process and present data
monitor performance and manage parameters of the database and provide fast query responses to frontend users
synchronize the conceptual design with the actual database
enhance and refine the logical design of the database
ensure appropriate system storage requirements
update the database by installing and testing new versions of the dbms
develop and manage backups and construct recovery plans
create physical and logical database models according to business needs or requirements
provide technical assistance to sort out database related issues identify errors and then resolve in a proper way
prepare documentation related to the database
work with dbas to manage the company databases effectively
performs other duties and responsibilities as required or assigned
minimum requirements

bachelor’s degree in computer engineering or related field or equivalent knowledge skills and abilities in software engineering
5 years of technical experience in a database engineering role
excellent oralwritten communication skills and interpersonal skills with the ability to articulate ideas to both technical and nontechnical audiences
expert with mssql familiarity with c programming concepts
innovative selfmotivated and selfdirected with keen attention to detail exceptional service orientation
ability to work directly with customers understanding and fulfilling their needs in a competent manner
ability to discern user requirements and develop specifications
experience with microsoft system administration and web server configuration
knowledge of internet protocols database management systems revision control systems information security vulnerabilities and risk management
possessing a business understanding of the underlying data
ability to follow projects through to completion
ability to learn new technologies quickly step outside your own comfort zone and handle unfamiliar challenges enthusiastically
enjoys work overcoming obstacles is fun loves to help people and can work well independently or in groups
salary  benefits

competitive salary commensurate with experience

benefit plan

foresight intelligence pays 100 employeeonly premiums – health dental vision life add short term disability long term disability
enrollment in stock appreciation rights plan
health savings account with employer contribution
401k with employer matching
paid time off
employee recognition
weekly team lunch
fully stocked break room
salary commensurate with experience  foresight intelligence is an equal opportunity employer  applicants must have right to work in the us
email cover letter  resume to careersforesightintelligencecom
foresight intelligence strives to drive your organization into the future
schedule a private demo to find out exactly what our technology can do for you
free consultation
7077 east marilyn road
building six suite 150
scottsdale az 85254

8886586462
infoforesightintelligencecom
site map
about us
careers
contact us
financial reporting system
fleet intelligence
fleet intelligence demo
foresight intelligence center
form – free trial
intelligent alert triage center
news
telematics devices
news
foresight intelligence® featured on aemp podcast
foresight intelligence® named mixed fleet solution provider for john deere worksight™
calamp technology adopted by foresight intelligence to speed time to market of foresight’s fleet intelligence application for construction industry mixed fleets
social media
twitter
facebook
googleplus
linkedin
© copyright foresight intelligence all rights reserved
privacy policy
home
products we offer
fleet intelligence™
telematics devices
intelligent alert triage center
foresight intelligence center
financial reporting system
about us
company
news
careers
support portal
contact us
sql in the sun 2018

back to top",,AZ,False,data_engineer
Workspaces BI engineer,"job description
amazon workspaces is revolutionizing end user computing in the enterprise by providing desktop as a service from the aws cloud amazon workspaces allows customers to easily provision cloudbased desktops that allow endusers to access the documents applications and resources they need with the device of their choice including laptops ipad kindle fire android tablets and zero clients with a few clicks in the aws management console customers can provision a highquality cloud desktop experience for any number of users at a cost that is highly competitive with traditional desktops and half the cost of most virtual desktop infrastructure vdi solutions this aws offering has an immense greenfield market to tap into and is growing fast – this role is an opportunity to get on the ground floor
this role will work closely with product management and engineering teams you will help the bi team deliver financial and operational analyses surfacing opportunities to reduce cost and innovate manage projects improve processes and help take the business team to the next level as a member of this team you will leverage strong data extraction skills to drive worldwide reporting deliverables engineer ad hoc financial analysis support business planning and implement ideas for process improvement the individual must have the ability to communicate effectively across multiple technical and nontechnical functions successful members of this team collaborate effectively to solve data problems implement new reporting solutions and deliver successfully against high operational standards

responsibilities include
sourcing analyzing and reporting quantitative data perform ad hoc analysesanalyzing trends formulating projections and evaluating savings initiativessupport the development of continuouslyevolving automated forecast models and methodologies owning the quantitative analysis of the performanceprovide factbased insights into variances and trendspresentation of findings and recommendations to senior leaders


the ideal candidate will demonstrate the following abilities and characteristics
focus on customers and work backwardsbe highly analytical and detail orientedquickly build credibility and trust with internal customersdemonstrate work ethic based on a strong desire to exceed expectationsadvanced communication skills both verbal and writtensuccessful in an ambiguous environmentcomfortable with tight deadlines and prioritize workload
work on crossfunctional teams
basic qualifications
bsba degree in a quantitative field mathematics engineering sciences operations research
3 years of experience building business intelligence reports using one or more of the following tools tableau microstrategy and powerpivot4 years of relevant work experience in analytics as a data scientist data engineer business intelligence engineer or equivalentadvanced knowledge of sql and experience with efficient processing of large data sets is a mustfamiliarity with new advances in tools such as emr and nosql technologies like dynamodbtrack record for quickly learning new technologies
preferred qualifications
mba or advanced degree in a quantitative field preferredability to consistently meet deadlines and provide wellvetted reporting and business recommendationsexperience communicating results to business leadersadvanced problemsolving skills for difficult and complex issuesexperience with advanced statistical methods eg matching predictive modeling cluster analysis time series modeling etc and data visualizationproficient in at least one scripting language perl python etcexperience working with amazon web services aws tools ie s3 redshift",,WA,False,data_engineer
Data Engineer in Cloud Platform -- Co-op,"data engineer in cloud platform

how would you like to collaborate on building out large data processing architectures do you thrive on variety and innovation in your daily work and would you enjoy close interaction with a worldclass big data platform team are you passionate about making things work better stronger faster if so read on

bose is transforming the way audio devices interact with the cloud creating new experiences for connecting people to what they love the most we are imagining new datadriven experiences designing new services building software architecture and infrastructure and scaling our solutions to serve millions of users join us as a coop to help invent and build our cloud platform for the 21st century and power the next wave of innovation at bose

principal duties and responsibilities
as a coop on the cloud platform data team you will collaborate on designing and developing major database components of our next generation cloud platform our data platform team takes on these challenges
builds highly scaled data abstractions and infrastructure like keyvalue and secret storage
designs large graph infrastructure and querysearch interfaces
collects and processes data streams at scale including streamprocessing and batch etl
works closely with engineering teams to help build and maintain systems that support advanced analytics
quickly triages and analyzes complex performance and operational problems
works with platform architects on software and system optimizations helping to identify and remove potential performance bottlenecks
selects and deploys bestofbreed opensource software and work with the larger community for support and improvements
gains familarity with relevant technologies plugs into user groups understands trends and opportunities to ensure we are using the best techniques and tools








bose is an equal opportunity employer that is committed to inclusion and diversity we evaluate qualified applicants without regard to race color religion sex sexual orientation gender identity genetic information national origin age disability veteran status or any other legally protected characteristics for additional information please review 1 the eeo is the law poster httpwwwdolgovofccpregscomplianceposterspdfofccpeeosupplementfinaljrfqa508cpdf and 2 its supplements httpwwwdolgovofccpregscompliancepostersofccposthtm please note the companys pay transparency is available at httpwwwdolgovofccppdfeo13665prescribednondiscriminationpostinglanguagejrfqa508cpdf bose is committed to working with and providing reasonable accommodations to individuals with disabilities if you need a reasonable accommodation because of a disability for any part of the application or employment process please send an email to wellbeingbosecom and let us know the nature of your request and your contact information",,MA,False,data_engineer
Data Engineer,do you want to get a foot in the door at an online advertising and media company that has seen tremendous growth do you want to work in the world of online video one of the fastest growing advertising formats in the world then playwire is the place for youplaywire media is a fullservice digital innovation partner that leverages online advertising and proprietary technologies to build publishing brands in the gaming and entertainment verticalsto keep pace with our explosive growth we are currently seeking a data engineer for our deerfield beach officethe ideal candidate has a passion for all things data from input to output and loves understanding and tweaking every aspect of a successful data pipeline they should be adept at explaining data concepts both to software developers and nontechnical stakeholders helping them to understand core concepts and the pros and cons of different approaches candidates should like the responsibility and opportunity for ownership and vision within our dynamic fastpaced and fastchanging environment they must be ready to move quickly while also defending the fort making certain that we build our data systems in intelligent scalable waysessential functions work out of our deerfield beach office relocation assistance availablecreate and maintain optimal data pipeline architectureassemble large complex data sets that meet functional  nonfunctional business requirementsidentify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etcbuild the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using database and aws “big data” technologiesbuild analytics tools that utilize the data pipeline to provide actionable insights into key performance metrics for different areas of our businesswork with stakeholders to assist with datarelated technical issues and support their data infrastructure needsqualifications advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databasesexperience building and optimizing “big data” data pipelines architectures and data setsexperience performing analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvementstrong analytic skills related to working with unstructured datasetsbuild processes supporting data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsworking knowledge of options for realtime analysis and presentation of data extracted from pipelinesexperience supporting and working with crossfunctional teams in a dynamic environmentnice to haves working experience operating awsrelated data services particularly kinesis kinesis firehose kinesis analytics athena rds and redshiftknowledge of bi toolsetsexperience with error logging and reportingknowledge of javascript and rubystrong project management and organizational skillsjob type fulltimeexperiencebuilding big data 2 years preferredsql 2 years preferrededucationbachelors preferredwork authorizationunited states preferred,,FL,False,data_engineer
"Data Engineer, Python","hart is a medical software company utilizing technology to bridge the gap between patients and providers our health and fitness platform encourages users to engage with their health in realtime healthconscious individuals can manage activities medication nutrition sleep track progress with a personal health score and communicate directly with healthcare providers and employers

job description
as a data engineer at hart you will work with the companys engineering team to develop an entirely new software system this system will have the ability to automate segmented data sources and manipulate those data sources these applications may use apache spark to render the data primary responsibilities include requirements analysis to gain an understanding of business needs to develop level of effort estimates software design and development unit testing performing design and code reviews and development of technical documentation additional responsibilities include performing system analysis code modifications and functional testing to troubleshoot application production issues

you will be working with python to build out harts data discovery services for use with all our applications that support the hart ecosystem of applications and connected user devices this role will join a team focused on building products on the cutting edge of usability interaction and design

the data engineer python will work in a highcommunication environment where collaboration with the design and backend engineering teams is key to daytoday success our ideal candidate is someone whos comfortable taking ownership of their work and effectively searching for creative solutions to the complex problems we encounter

requirements


excellent programming skills in python
experience with spark and kafka  required
experience with hadoop and mongodb
understanding of distributed process management
scala java julia andor r experience is a plus

employee benefits package


100 medical dental and vision coverage for you and your family
unlimited vacation policy
paid paternity and maternity leave
life insurance
add insurance
gym membership

perks


macbook pro thunderbolt display magic mouse and keyboard
stocked kitchen with coffee drinks and snacks
daily catered team lunches provided by our chef

",,CA,False,data_engineer
Data Engineer,"our company national retail solutions nrs is a subsidiary of idt with many products including its flagship boss revolution products sold in tens of thousands of stores nrs uses this relationship to expand the offerings that idt provides to retailers

the technology division is a small highpowered development group with teams situated in the us and israel that produces interactive highperformance web applications that are both good looking and easy to use we use the same technology stack for apps deployed on the linuxbased point of sale systems as we do for single page web apps deployed in the cloud we currently have several openings for our development team

for all positions the successful applicant will be a selfstarter work independently or part of a small team when needed developing software for our merchants their customers and nrs internal operations and contribute to overall architectural and design discussions you will generally be responsible for the complete creation of a feature including design implementation deployment and support
we are looking for
data importexport development shell sql php database aws linux
minimum of 5 years of programming experience
degree in computer science
fluency in sql including optimization of queries
feel a t home with the linux command line and system
ability to create shell andor php scripts for import and export of data
comfortable using curl s3 tools and standard automated file transfer tools for data exchange
experience with using a distributed source code control system such as git preferred
we would prefer to see
experience with various aws services and their management and operations including ec2 rds kinesis sns sqs and lambda functions
experience with real time data feeds

additional nice to have though not required
ability to create php based web services apis using slim routing postgresql and redis
experience in creating scalable faulttolerant architectures in aws
experience with nodejs as a backend alternative
linux server management ability
nrs operates a pointofsale pos terminalbased platform for independent retailers and bodega owners nationwide our media division provides the ability for advertisers to reach our retail partners’ consumers the platform provides a robust portfolio of tools to help these retailers compete more effectively including rewards programs consumer coupons wholesaler discounts and integration with boss revolution® communication and payment service products consumer package goods cpg suppliers are able to leverage the nrs platform to provision promotions coupons and special offers to independent retailers and their predominantly urban customer bases nationwide nrs is a subsidiary of idt corporation nyse idt",,NJ,False,data_engineer
Data Engineer,"overview
walsh is currently seeking a data engineer for the power bi team based in chicago il

we are seeking an experienced power bi  ssas sql server analysis services engineer who can provide companywide strategic analytical and technical support for bi activities this is an opportunity to work in a fastpace team environment collaborating directly with all business units this is a handson results orientated role requires expertise in the microsoft toolset for data and data analytics including sql server data models in ssas and power bi dashboard creation

walsh is a rapidly growing highly diversified construction company and we constantly seek builders and business people to join our industryleading team walsh employees are built to succeed  competitive entrepreneurs with strong character who are energized by working on a team to meet challenges and are willing to take risks after careful planning there are many compelling reasons why exceptional people should consider a career with our company
challenging complex projects
creative and innovative problem solving environment
supportive communicative managers who reward your success
opportunities for growth training and development
flexibility to build what you want where you want
responsibilities
collaborate with business leaders to analyze critical data and translate business requirements into technical scalable specifications
design develop test and document new reports and dashboards
mentor others in using analytics tools
evaluate and enhance existing reports and dashboards
define and document business requirements for new metrics and reports
ensure accuracy and integrity of data and reporting applications through detailed analysis efficient coding writing clear documentation processes identifying and resolving problems as they arise
review and write complex sql queries and develop stored procedures and functions in sql
perform ongoing monitoring and refinement of reports and bi solutions
ability to work effectively within competing deadlines with minimal guidance
interact professionally and collaborate with a diverse group including executives managers and subject matter experts
qualifications
4 or more years of quality experience using sql server ssrs ssas azure and ssis
strong knowledge of relational and multidimensional database architecture
experience creating and maintaining documentation following standard creation and change control processes
proficient oral and written communication skills
ability to lead a meeting and present to small audiences
experience integrating power bi into web applications

equal opportunity employer disabilityveteran
liek1",,IL,False,data_engineer
Data Engineer,"spokeo is seeking a data engineer to join us in pasadena ca

spokeo is a people search engine that both enlightens and empowers our customers with over 12 billion records and 18 million visitors per month we reconnect friends reunite families prevent fraud and more every day our nimble team takes on enormous challenges in data science that push the limits of the cloud and search architecture

we are looking for a data engineer with an eye for building and optimizing big data systems to join our team working in an aws spark hadoop ecosystem this role will work closely with the engineering and analyst teams to direct the flow of data within the pipeline and ensure consistency of data delivery and utilization

responsibilities

design and build the infrastructure for data extraction preparation and loading of data from a variety of sources
build and manage existing analytic tools to provide deeper insight into the pipeline and capture key metrics
monitor technical performance and ensure that identified bugs are routed and resolved
mentor team members on working with highly scalable distributed systems and cluster architectures and maintain uptodate knowledge of technological advances
create and maintain technical documentation
work with large complex sqlnosql databases
create unit and stress test scriptsmodules
write wellabstracted reusable and efficient code

requirements

bachelors degree in computer science information technology or related field willing to accept foreign education equivalent
handson scripting or programming
experience working in big data ecosystem eg hadoop spark kafka with complex sqlnosql databases cassandra dynamodb
experience and understanding of etl tools
prior experience working with highlyscalable distributed systems and cluster architectures eg aws azure google cloud etc
prior experience working with large data sets   10 billion

recruiters or staffing agencies spokeo is not obligated to compensate any external recruiter or search firm who presents a candidate or their resume or profile to a spokeo employee without 1 a current fullyexecuted agreement on file and 2 being assigned to the open position as a search via our applicant tracking solution",,CA,False,data_engineer
Sr. Data Engineer,"we are a former real estate startup acquired by cbre in 2017 we are uniquely positioned within the organization to access global data tools resources and leaders throughout the industry we have the stability of secure backing and the freedom to explore and experiment to develop leadingedge products for more information about our team please visit httpnyccbrebuildcom

we are looking for the first data scientistengineeranalyst to help us understand and leverage all the data sources and products we have this person will have a great deal of autonomy and will be expected to come to the table with their ideas and suggestions for making our products better with data

responsibilities
analyzing proprietary commercial real estate data on availabilities lease rates and market statistics to identify trends and opportunities
refining predictive models for space estimation and timeforecasting for capacity planning
empowering user research and improving customer engagement through development and analysis of user metrics
architecting data models and developing etl functions to move data between rdmbs and nosql stores
leveraging machine learning and data mining to take multiple streams of data and create novel customer experiences
automating manual processes to generate data like lease availabilities and floor plan layouts
working closely with our heads of product and engineering as well as team leads across the company to address a wide variety of business problems
identifying new approaches and tackling ambiguous problems with creativity and improvisation


requirements
smart productive and tolerant of sarcasm
selfmotivated and curious crafty and driven
interested in building a friendly collaborative and transparent work environment
programming experience in python julia torch lua or other programming languagesframeworks
bachelors degree in a related field or equivalent work experience
minimum of 3  5 years of relevant experience required

why work at cbre build
great team  diverse smart nice we like to always keep learning
high impact  we’re a small team with a global reach in a trillion dollar industry
growth and development  we invest in employee development time to explore machine shop with a laser cutter and 3d printer funding for education conferences etc
benefits  unlimited vacation flexible work hours work life balance health vision dental for employees and their dependents 401k plan with a 3 match",,NY,False,data_engineer
Oath Analytics Data Engineer,"oath a subsidiary of verizon is a valuesled company committed to building brands people love we reach over one billion people around the world with a dynamic house of 50 media and technology brands a global leader in digital and mobile oath is shaping the future of media



the oath analytics team is searching for a qualified highly motivated data engineer this opportunity will require the individual to creatively approach problems from both an analytical and automation perspective in order to deliver scalable and innovative data reporting and dashboard solutions in a fast paced team oriented environment oath is a data intensive organization and this position requires the ability to transform large volumes of data into information for operational and financial decision making driven by your passion for data and utilizing various programming methods you will work with both internal and external partners to define and craft innovative reporting solutions in support of our leading global digital advertising products

required skills
• passionate about data and automation
• intermediate knowledge of relational databases and sql
• basic knowledge of python
• experience with unix based systems
• experience with etl processes
• experience with microstrategy building dashboards and adhoc solutions
• strong analytical and problem solving skills
• strong communication skills both written and verbal
• strong time management and prioritization skills
• familiarity with huehivepigsparkhadoop tableaudata visualization or web development javascript html css php a plus

preferred experience
• bachelor’s degree in computer science mathematics statistics engineering or economics preferred
• prior experience in a related analytics or developer role digital advertising or media experience a plus


oath is proud to be an equal opportunity workplace all qualified applicants will receive consideration for employment without regard to and will not be discriminated against based on age race gender color religion national origin sexual orientation gender identity veteran status disability or any other protected category oath is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment please let us know if you need a reasonable accommodation to apply for a job or participate in the application process


currently work for oath please apply on our internal career site",,NY,False,data_engineer
Data Engineer,"who we are
galaxesolutions
every day our solutions affect people throughout the world from fortune 100 companies to startups galaxe develops and implements strategic projects that are critical to the success of customers’ businesses and the lives of tens of millions of people

for over twentyfive years we have grown and evolved into a multinational firm that employs over 2000 team members worldwide but we’re not done evolving it took collaboration and innovation to get here and it takes collaboration and innovation to get where we and our customers want to be tomorrow

what does this mean for our employees they have the security of an established company with the benefits of working for a company where great minds hard work leadership and innovation are highly regarded and rewarded

as thomas edison said “there’s a way to do it better – find it” we want our employees to find it

we’re looking for creative people with an entrepreneurial spirit looking to work on awesome projects sound like you come work with us find out for yourself what it means to be part of the galaxe team

it’s not always easy but important work never is wearegalaxe

equal opportunity employerveteransdisabled
what you will do
full lifecycle application development
design code and debug software
perform software analysis risk analysis reliability analysis
participate in software modeling and simulation
integrate new software solutions with existing systems
extract and reverse engineer existing code
perform regular status reviews of problemsissues
participate in the development or refinement of proactive services andor data repositories
query database to provide data extracts
skills and experience you will need
required
5 years of development experience in at least one of these languages java python or c
experience with restful api design and implementation
experience in workflow and bpmn development using activiti camunda etc
experience with data migration transformation and scripting
proficient understanding of code versioning tools such as git
ability to work crossfunctionally with engineering and nonengineering teams
passionate about engineering quality testing automation and documentation of code and systems to ensure easy maintenance over a long period
experience working on highvolume server software
understanding and implementation of security and data protection
user authentication and authorization between multiple systems servers and environments
experience with nosql databases such as dynamodb
experience with data frameworks such as hadoop hive pig and spark
experience in building highperformant scalable backend services in the cloud especially aws
desired
experience with mulesoft application development
passionate about application scalability availability reliability and security
exposure to test driven development behavioral driven development frameworks and libraries
experience with collibra administration management working with apis
experience with anypoint apis",,MI,False,data_engineer
Big Data Engineer,contract7 years of it experience and 3 years of big datawork across multiple client projects that require developing and implementing big data analytics solutionsstrong understanding in at least one of python scala java or c13 years of working experience in apache hadoop sqoop avro flume oozie zookeeper yarnhands on experience working within a linux computing environment and use of command line tools including knowledge of shellpython scripting for programing common tasksmanage client deliverables communicate successfully with internal and external teamsexcellent communication skills to be able to effectively translate to business stake holderswith this position you will be on up2date technology solutions llc payrolland will be working at my clients site as posted on the job descriptionjob type contractsalary 5000 to 5500 yearexperiencebigdata 3 years preferred,,TX,False,data_engineer
Data Engineer - Big Data Technologies,"job description
amazon’s ecommerce platform ecp organization is responsible for the core components that drive the amazon website and customer experience serving millions of customer page views and orders per day ecp builds for scale

as an organization within ecp the big data technologies bdt group is no exception we collect petabytes of data from thousands of data sources inside and outside amazon including the amazon catalog system inventory system customer order system page views on the website and alexa systems we also support amazon subsidiaries such as imdb and audible we provide interfaces for our internal customers to access and query the data hundreds of thousands of times per day using amazon web service’s aws redshift hive and spark we build scalable solutions that grow with the amazon business

bdt is growing and the data processing landscape is shifting our data is consumed by thousands of teams across amazon including research scientists machine learning specialists business analysts and data engineers amazoncom is seeking an outstanding data engineer to join the big data technologies business intelligence team the business intelligence team delivers business intelligence to over 1000 internal customers and a diverse community of external customers amazoncom has culture of datadriven decisionmaking and demands business intelligence that is timely accurate and actionable if you join the amazoncom business intelligence team your work will have an immediate influence on daytoday decision making at amazoncom

as an amazoncom data engineer iii you will be working in one of the worlds largest and most complex data warehouse environments you should be skilled in the architecture of dw solutions for the enterprise using multiple platforms rdbms columnar cloud you should have extensive experience in the design creation management and business use of extremely large datasets you should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change

as a data engineer iii on amazoncom’s big data technologies team you will develop new data engineering patterns that leverage a new cloud architecture and will extend or migrate our existing data pipelines to this architecture as needed you will also be assisting with integrating the redshift platform as our primary processing platform to create the curated amazoncom data model for the enterprise to leverage you will be part of a team building the next generation data warehouse platform and to drive the adoption of new technologies and new practices in existing implementations you will be responsible for designing and implementing the complex etl pipelines in data warehouse platform and other bi solutions to support the rapidly growing and dynamic business demand for data and use it to deliver the data as service which will have an immediate influence on daytoday decision making at amazoncom

interfacing with business customers gathering requirements and developing new datasets in data warehousebuilding and migrating the complex etl pipelines from oracle system to redshift and elastic map reduce to make the system grow elasticallyoptimizing the performance of businesscritical queries and dealing with etl job related issuestuning application and query performance using unix profiling tools and sqlidentifying the data quality issues to address them immediately to provide great user experienceextracting and combining data from various heterogeneous data sourcesdesigning implementing and supporting a platform that can provide adhoc access to large datasetsmodelling data and metadata to support adhoc and prebuilt reportingworking with customers to fulfill their data requirement using dw tables  maintain metadata for all dw tables
basic qualifications
a desire to work in a collaborative intellectually curious environmentdegree in computer science engineering mathematics or a related field and 45 years industry experiencedemonstrated ability in data modeling etl development and data warehousingdata warehousing experience with oracle redshift teradata etcexperience with big data technologies hadoop hive hbase pig spark etc
preferred qualifications
industry experience as a data engineer or related specialty eg software engineer business intelligence engineer data scientist with a track record of manipulating processing and extracting value from large datasetscoding proficiency in at least one modern programming language python ruby java etcexperience buildingoperating highly available distributed systems of data extraction ingestion and processing of large data setsexperience building data products incrementally and integrating and managing datasets from multiple sourcesquery performance tuning skills using unix profiling tools and sqlexperience leading largescale data warehousing and analytics projects including using aws technologies – redshift s3 ec2 datapipeline and other big data technologiesexperience providing technical leadership and mentor other engineers for the best practices on the data engineering spacelinuxunix including to process large data setsexperience with aws",,WA,False,data_engineer
Healthcare Data Engineer,healthcare data engineercompany overviewimagine if we could accelerate healthcare discovery leading to more effective treatment and cures here at ispecimen we are working to get researchers the specimens they need from the patients they want to do just that headquartered in lexington ma ispecimen is the marketplace for human biospecimen collections the privately held company has developed the ispecimen marketplace an online platform connecting healthcare organizations that have access to patients and specimens with the scientists who need themhealthcare data engineer position overviewwe are looking for a highlyskilled selfmotived healthcare data engineer with strong communication and technical skills to join our collaborative environment this individual will be responsible for working closely with our team to ensure our data processes are efficient effective and well run the right individual will have a passion for data quality improvement data pipelines and reporting with a solid understanding of healthcare data vocabulariesresponsibilities of healthcare data engineerwork with the team to understand our suppliers’ data and how we can add valuedefine design implement improve and support etl solutions using the myriad healthcare and behavior measures and controlled vocabularies used to drive marketplacelead the data onboarding and transformation processes for various source datacontinuously improve control processes ensuring data integrity quality standardization and security throughout the etl processdevelop test methods measurement tools baseline reference data and measures and analyses to support our reporting and visualization technologies and applicationsfunction as a healthcare data subject matter expert to support the design development testing implementation documentation and support of our solutionsprovide complete documentation and communication of all processes methods and resultssupport production solutions and the ongoing updating and maintenance of our reference data sourcesparticipate in our data strategy design and deliveryqualifications of healthcare data engineerbsba degree in healthcare informatics information systems computer science or related information technology degree preferred advanced degree in one of these areas preferred5 years of experience in healthcare informatics and handson experience handling diverse healthcare data sets especially lab and transforming them into consistent high quality data sets3 years of experience exploring and analyzing data andor scripting etl processes using sql1 years of experience using a scripting language python bash perl etc to automate processesextensive knowledge of existing healthcare databases data sources and industry standard measures and code sets eg icd9 cpthcpcs drg ndc gpi loinc knowledge of current standards eg hl7 clinical lab andor biorepository experience a plusproficient using sql with solid familiarity and experience with database applicationssome database management experience with the ability to explore and manage database internals eg storagememory query performance users permissions etcexperience integrating tools andor workload automation software to streamline processesexperience with data analysisvisualization applications eg domo tableau to generate reportsadvanced analytic reporting and problemsolving skills around healthcare dataexperience with a cloud computing platform eg aws a plusexcellent written and oral communication skills with a proven ability to present solutions with both technical and nontechnical argumentsintensely curious not settling for accepted or superficial answers always asking why and digging deeperbenefitsispecimen offers a generous suite of comprehensive benefits including ten paid holidays per year paid time off pto for vacation sick or personal use health dental and vision insurance health savings accounts and a 401k retirement planjob type fulltimeexperiencehealthcare informatics 3 years requireddata analysis 1 year preferrededucationbachelors requiredwork authorizationunited states required,,MA,False,data_engineer
Tableau Developer/Data Analyst,45  50 an hourcontractlocation fl6 monthsleads team of developers responsible for the analysis design development testing and documentation of information management systems drives defining and maintaining development standards and development best practices and will participate in and contribute to technical feasibility studies business cases proposals and 3rd party assessmentskey duties and responsibilitiesacts as principle contributor in obtaining business and technical requirements gap analysis technical design development and documentation of information systems using data transformation techniques to move the data between systemsprepares detailed functional specifications design models and system work flows from which software applications will be developed and implementedprovides leadership and facilitation in the definition and development of the technical solution concept including vision scope and system architectureas part of production support supports troubleshoots and maintains production systems as required optimizing performance resolving problems and providing timely followup on identified issuesprovides business support on data comparison as requested by the businessdefines and maintains wellcare information systems is development standards and best practicessupports troubleshoots and maintains production and adhoc reports as required optimizing performance resolving problems and providing timely followup on identified issuesperforms other duties as assignededucationstate the minimum required for the jobeducation level education details requiredpreferreda bachelors degree in information technology or related field requiredor equivalent work experience additional 2 years of relevant work experience may be substituted in lieu of degree requiredwork experiencestate the minimum required for the jobexperience level experience details requiredpreferred5 years of experience in data engineer or similar technology related role requiredother internal candidate will require min 4 years of experience in data engineer or similar technology role required2 years of experience in healthcare preferredskillsstate the minimum required for the jobskill sets other skills proficiencydemonstrated interpersonalverbal communication skills advanceddemonstrated written communication skills advancedability to work as part of a team intermediateability to work in a matrixed environment intermediatedemonstrated project management skills beginnertechnologylist technical skills associated with the jobtechnology other technology proficiency requiredpreferredother structured programming language eg java python etc  based on the organization under eim that they report to this position needs one or more skills as required intermediate requiredother database design construction tuning and query  greenplum hadoop  based on the organization under eim that they report to this position needs one or more skills as required intermediate requiredother data cleansing and transformationinformatica powercenter bde data quality etc  based on the organization under eim that they report to this position needs one or more skills as required intermediate requiredother business intelligence tools eg tableau cognos sas etc advanced requiredother solution design and architecture intermediate requiredother master data management intermediate preferredlevel of supervision receiveda statement which describes the level of independence for this positionfunctions independently within broad scope of established departmental policiespractices generally refers specific problems to supervisor only where clarification of departmental operating policiesprocedures may be requiredproblem complexitya statement which describes how clearly a problem is defined when presented how much additional effort is required to understand the nature of the problem and the typical timescales for resolutionprovides resolution to a diverse range of recognizable complex problems analysis is required to identify root cause uses judgment within defined boundaries to develop solutionsjob type contractsalary 4500 to 5000 hourexperiencetableau 5 years preferred,,IL,False,data_engineer
Lead Data Engineer,"description
join us as a lead data engineer – digital data solutions
the data science and engineering team at target is a hypergrowing dynamic and collaborative team data engineers work closely with data scientists to create valuable insights using voluminous data collected from internal and external systems on a large scale business operations are empowered with these insights to achieve target’s strategic initiatives while providing worldclass shopping experiences for our guests
about this opportunity
as a lead data engineer you’ll have the opportunity to create software solutions using agile practices and devops principles responsibilities will include designing programming debugging and supporting high quality distributed and largescale software solutions on the latest big data tech stack designging and building data pipelines using large data sets on game changing servicesproducts in the innovative enterprise data lab

we are looking for a highly motivated engineering professional who is a team player and can engage with both technical and business team members while mentoringdeveloping sr data engineers on the team
key responsibilities
develop software systems using test driven development employing cicd practices
partner with other engineers and team members to develop software that meets business needs
follow agile methodology for software development and technical documentation
innovate constantly and stay current with latest technologies while staying focused on solving problems at hand
requirements
bs degree in computer science or relevant experience
5 years’ experience in developing software applications
3 years’ experience working on big data technologies like hadoop spark scala and hive
extensive understanding of applicationsoftware development and design
proficiency in atleast one of the following languages java scala python
worked on building and supporting web services experience with rest apis’ and services preferred
experienceknowledge of streaming solutions kafka apex
qualifications",,CA,False,data_engineer
Big Data Engineer,"supremus is an equal opportunity employer encouraging diversity in the workplace all qualified applicants will receive consideration for employment without regard to race national origin gender identityexpression age religion disability sexual orientation genetics veteran status marital status or any other characteristic protected by law

this is a general description of the duties responsibilities and qualifications required for this position physical mental sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed whenever necessary to provide individuals with disabilities an equal employment opportunity supremus will consider reasonable accommodations that might involve varying job requirements andor changing the way this job is performed provided that such accommodations do not pose an undue hardship

duties  responsibilities

supremus is seeking big data engineers with technical experience in optimizing of management and deriving insights from large nonstructured nonrelational data

in this role you will

apply semantic correlation ontology structured data and text analytics techniques and systems to analyze nonstructured data and identify critical insights
apply big data technologies such as hadoop or cassandra with nosql data management and related programming languages such as jaql hbase pig or hive
participate in all aspects of the software life cycle including analysis design development unit testing production deployment and support
formulate approaches and gather data to solve business problems develop conclusions and present solutions through formal deliverables
create big data accelerators to help deploy scalable solutions fast
you will be successful in this role if you enjoy problem solving and utilizing consulting skills team leadership experience is preferred

in this dynamic role you will have the opportunity to interact directly with clients as such travel to client sites may be required up to 4 days per week

qualified candidates are encouraged to please send resumes to careerssupremusglobalcom",,PA,False,data_engineer
Data Engineer,"overview
linden lab is hiring a data engineer to service our next generation vr and virtual experience platform sansar the data engineering team supports everything from business analytics to realtime fraud mitigation and this role will contribute by developing realtime and batch etl modeling data and helping build out our realtime data pipeline come join a friendly seasoned team and a great company as we change the world
what you’ll do
build etl code to populate our google bigquery data warehouse with apache airflow scheduled batch updates from our sansar virtual reality platform
develop realtime etl apps using google dataflow java or python to provide critical insights into the business
maintain improve troubleshoot and evaluate realtime data processing systems such as pubsub kafka and stackdriver
work closely with our data architect product managers and analysts to design and model new tables to meet constantlyevolving analytics needs
liaise with our systems engineers google support and our consulting partners to quickly assess the impact of production system changes to existing data warehouse processes
other duties may be assigned
what you need
extensive real time data engineering experience  we are not looking for a data analyst or scientist
3 to 5 years of active coding using python or java
strong analytics modeling experience
very strong sql and relational database experience
familiarity with nonrelational document stores
fluency in linux some system admin experience will be useful
experience with message queues like kafka pubsub kinesis etc and working with realtime systems prior experience with google dataflow andor spark is a big plus
experience working with largescale data warehouse platforms such as bigquery redshift snowflake teradata etc
desire to work in a collaborative entrepreneurial environment on really interesting problems
strong attention to detail and the ability to ensure that warehouse data is complete and accurate
bachelor’s degree in a computerdatabase related field or equivalent professional experience
what you’ll learn
advanced realtime processing concepts
advanced data modeling
google compute platform tools and methods
pioneer our use of graph databases",,CA,False,data_engineer
Data Engineer - Sales strategy,"key member of highperforming team providing fact base for sales transformation and sales acceleration activities for cisco’s entire sales force

collaborate with rest of sales analytics team data scientists analytics managers and data foundation project managers to drive company growth operational efficiency and profitability

build relationships with database architects and data stewards across cisco to discover new data sources and influence corporate decisions for greater functionality in our data systems

greatly enhance team productivity scale manual processes accelerate data visualizations and reduce data manipulation through inmemory data enrichment and metrics calculations

prototype data foundation improvements by working with sales stakeholders and peer analytics organizations to identify data infrastructure needs provide innovation pipeline to data foundation project managers to add to the company data warehouse

assist data scientists in building and optimizing sales analytics predictive models models under development include forecast models product recommendation models classification models and natural language processing


qualifications for data engineer

fast creative problemsolver to support projects in response to the realtime nature of sales leadership decisionmaking

continuous improvement mindset to optimize data architecture for repeatability and scalability greatly enhancing team productivity

strategic visionary for cisco’s data architecture to support next generation sales data initiatives

advanced working sql knowledge and experience working with relational databases query authoring as well as working familiarity with a variety of databases sap hana experience is a plus

a successful history of manipulating processing and extracting value from large disconnected datasets experience collaborating crossfunctionally to build and optimize ‘big data’ sets for both structured and unstructured data

5 years of experience in a data engineer role with a degree in computer science computer engineering information systems or another quantitative field",,CA,False,data_engineer
Business Data Engineer,"about us
swift navigation  httpswwwswiftnavcom  inc was founded in 2012 to make gps positioning technology more accurate and affordable its gps and gnss positioning products are available a fraction of the price of the competition and deliver 100 times better accuracy than the gps in a cell phone swift navigations technology benefits a multitude of industries and applications—including autonomous vehicles drones precision agriculture robotics surveying and space with its innovation and technology honored by incs 2016  httpwwwinccomprofileswiftnavigation  and forbes 2017  httpwwwforbescomprofileswiftnavigation  30 under 30 lists swift navigation is enabling a world where fields farm themselves drones fly safely and autonomous transportation can take you home swift navigation provides an endtoend gnss solution with a line of piksi® multi and duro® receivers and skylark™ cloud corrections service learn more online at swiftnavcom

about the job
swift navigation is looking for a business data engineer to help support our business marketing operations and product teams this person will manage the entire business intelligence ecosystem at swift—from gathering the raw data to the finished reporting product additionally you will be responsible for administration and architecture of cloud crm systems and operational process automation

the ideal candidate will be an independent jackofalltrades with a proactive approach incorporation of scalabilityautomation should be the primary concern of the finished product

requirements

previous experience in an analyst andor business intelligence developer role preferably in a startup creating systems and processes from scratch
experience with python you can interface apis and etl
mysqlpostgresql you can administer query tune and develop schemas on both server and rds
administrative knowledge of aws architecture and its constellation of services security and commandline boto3 you can architect a serverless pipeline
building dashboards and notification alerts
marketingsales automation tracking and analytics you can manage email lists and track a user through the system
salesforce marketing campaign and crm administration and development
excellent analytical and communication skills
track record of excellence in both academic and professional settings
quantitative undergraduate degree eg engineering analytics mathematics economics business computer science

strong candidates will also have

zapier slack api netsuite erpsoap api google api
kpi metric development and a strong business sense with the ability to interpret data
linux github docker cicd tools
gdpr
security best practices especially with aws
gis data
nodejs haskell c c

perks

open vacation policy competitive salary stock options employer covered health insurance 401k commuter benefits
fully stocked kitchen weekly catered lunches and techtalks free gym membership
dynamic engineering organization—technological innovation is at the core of our business
growth and learning opportunities from a startup environment include working closely with an international team of scientists engineers platform architects programmers and professionals

swift navigation is a diverse and inclusive team we are an equal opportunity employer we welcome applicants from all backgrounds to apply regardless of race ethnicity religion gender sexual orientation age disability status or other defining characteristics",,CA,False,data_engineer
Data Engineer (Data Science Focus),"the digitalization team at ch robinson is transforming the logistics industry our team is comprised of people who are passionate about delivering world class products we are looking for a data engineer to join the navisphere vision team at ch robinson in our agile environment we value personal initiative and team collaboration if you are motivated ambitious and like to be challenged we would like to talk with you
successful applicants are selfstarters who are well organized have outstanding communication skills are solution oriented and thrive in a collaborative environment in this position you will work with crossfunctional teams to define document and deliver business initiatives that leverage technology to grow our competitive advantage your main goal will be to understand the supply chain challenges our business has analyze internal and external data and work with our data science team to create and implement solutions for the rest of the vision team
responsibilities
build and maintain enterprise grade data pipelines to facilitate and advance predictive analytics projects and the product as a whole
partner with team architects technical leads and data scientists to translate requirements into system designs
provide expertise surrounding appropriate sources of data to solve novel problems and best practices to access this data
understand the data landscape both internally and externally
data analysis to identify opportunities for efficiency and savings in the supply chain and to work with data science team members to provide guidance on how best to use the data
collaborate with engineers and data scientists during design and development
proactively identify opportunities to improve and extend the quality of the product
participate in daily standups and periodic sprint demos retrospectives grooming and planning meetings
address issues and mitigate risks communicate status to it leaders and other it teams impacted by the project
supply chain and engineering knowledge and thought leadership to stay current with best practices tools and offerings
qualifications

required qualifications
advanced relational database knowledge for data analysis and verification
experience working with unstructured datasets and large loosely connected datasets
demonstrated expertise of data warehouse and pipeline design practices
powerful analytical abilities
demonstrated ability to write enterprise grade applications in a modern programming language eg python or r
familiarity with big data tools eg hadoop spark etc
working knowledge of linux command shell
understanding of machine learning and predictive analytics concepts
ability to use strong decision making and problemsolving skills logic and reasoning to identify the strengths and weaknesses of alternative solutions conclusions or approaches to problems
knack for anticipating both technical and functional impacts and requirements
excellent written and verbal communication skills
selfstarter and able to work with minimal direction
preferred qualifications
3 years of experience building data pipelines including processing large structured or unstructured data sets
extensive experience working with big data
working knowledge of a variety of databases
experience in information technology and enterprise level business analysis for custom software solutions
knowledge of supply chain management systems
knowledge of agile principles
required education
undergraduate degree or similar work experience
benefits

we offer a competitive compensation package and excellent benefits including medical dental and vision insurance prescription drug coverage paid holidays and vacation disability insurance life insurance 401k with company match profit sharing employee stock purchase plan and the opportunity to prosper in a fortune 500 company

about ch robinson

become a part of our team of over 500 talented it professionals work in collaborative agile development environment find continuing challenges and work with committed leaders stay with us – we’re large enough to build global solutions but small enough to make real impacts as individuals

ch robinson—accelerating careers with immense opportunities and professional growth within the global supply chain industry start here accelerate here

every individual working at ch robinson is integral to the success of our customers and our company ch robinson is a fortune 500 global company that values teamwork initiative accountability and integrity from its employees we work globally and innovate daily to enhance and execute supply chains that move goods around the world the fast pace of the logistics industry translates into a highenergy and collaborative workplace environment we are empowered to make decisions help our customers grow and accelerate our careers

no matter the product being shipped or from which corner of the globe ch robinson can help make it happen—quickly securely and reliably through personal connections and solid relationships our employees use their indepth knowledge robust tools and global network to help customers reach their goals quickly whether shipping by plane rail ship or truck ch robinson has the knowledge flexibility and dedication to deliver the goods that make our world go ‘round

join the 12000 employees worldwide who are accelerating their careers at ch robinson

equal opportunity employer

ch robinson  affirmative action employereoemfdisabledveteran
limm1",,MN,False,data_engineer
"Data Engineer, Global Specialty Fulfillment","job description
love food we do the amazonfresh and prime now operations finance team is seeking an experienced and innovative data engineer to build tools that support operations teams in amazonfresh and prime now we are an analytics team responsible for building tools analysis and reporting to support internal leaders within fulfillment last mile and supply chain operations this is a unique opportunity for someone interested in amazon’s startup consumablesfocused environment amazonfresh and prime now experiment fail fast learn and scale rapidly

ultrafast delivery delights amazon customers by delivering what they want quickly medication for a sick kid lunch at work when you forgot food and drinks for a party last minute gifts dinner from a local restaurant and so many more uses

the business model of ultrafast delivery is attractive and offers our engineering team the opportunity to work on any number of complex technical problems our team designs builds and owns our endtoend services from the ground up and works on large scale backend systems to support the entirety of our order and inventory pipelines

we are seeking data engineer in this role you will

you help build the infrastructure to answer questions with data using software engineering best practices data management fundamentals data storage principles and recent advances in distributed systems
you manage aws resources
you collaborate with business intelligence engineers bies to recognize and help adopt best practices in reporting and analysis data integrity test design analysis validation and documentation
you help drive the architecture and technology choices that enable a worldclass user experience
you develop expertise in a broad range of amazon’s data resources and know when how and which to use and which not to use
you encourage the organization to adopt nextgeneration data architecture strategies proposing both data flows and storage solutions
you are comfortable with a degree of ambiguity and willing to develop quick proof of concepts iterate and improve
you create extensible designs and easy to maintain solutions with the long term vision in mind
you have an understanding and empathy for business objectives and continually align your work with those objectives and seek to deliver business value you listen effectively
you are comfortable presenting your findings to large groups

we have a very flat team structure and offer a unique opportunity for technical leaders who want to work closely with the business in defining designing building and operating products that are in the early stage of fast expansion
basic qualifications
bs in computer science math physics or engineering
6 years relevant work experience in software development or related datadriven field
knowledge of data management fundamentals and data storage principles
knowledge of distributed systems as it pertains to data storage and computing
demonstrated experience in relational database concepts with an expert knowledge of sql
demonstrated ability in data modeling etl development and data warehousing
preferred qualifications
experience working with aws big data technologies
experience working with open source big data tools
proven track record of delivering a big data solution
experience developing tools for data engineers and machine learning
experience working with both batch and real time data processing systems",,WA,False,data_engineer
Vehicle Data Engineer,"platform science is a connected vehicle platform for transportation logistics currently focused on asset based trucking side of the market with top tier fleetswe have created a saas based iot platform for core telematics applications productivity compliance connected devices down to connectivity with physical locations like distribution centers and ports currently we offer out of the box solutions in addition to a development platform for the fleets and also 3rd party developers
based out of san diego our team is composed of product development experts leading softwarehardware technologist and transportation industry experts we have embraced san diego as a ground truth test ground for our very large test devices and as the natural playground we love our diverse team embraces creative thinking as we pride ourselves as collaborative force for innovation in iot
requirements
3 years python experience
3 years cc
linuxunix administration familiarity with embedded device linux variants such as openwrt or yocto with busybox a plus
at least 1 year of real world experience with vehicle can bus protocols obdii and j1939
experience with software distribution via package management solutions
understanding of basic networking
experience working with web services
good technical foundation with ability to pick up new skills and adapt quickly
desire to learn new technologies while supporting existing
some nice to haves embedded experience working with hardware aws java soa mobile dev experience vehicle simulator experience vector canalyzer au simulators intrepid neovivehicle spy
benefits
work in a fastpaced development environment where you will see the results of your work immediately
competitive base salary
work with an intelligent team and solve meaningful problems
exposure and experience working within a broad technology stack
cell phone reimbursement
health benefits medicaldentalvision
onsite gym",,CA,False,data_engineer
Data Engineer,"what strategic intelligence analyt contributes to cardinal health

strategic intelligenceanalytics is responsible for strategic datainformation value at stake analysis and other business analytics in support of strategic planning and execution

qualifications
bachelors degree preferably computer engineering mis data and analytics or related job experience
proficient with sql and familiar with a variety of databases
proficient with sql server integration services ssis or similar etl tools
experience analyzing data and identifying trends and patterns
experience supporting and working with crossfunctional teams in a dynamic environment
strong communication  analytical skills
minimum 3 – 5 years job related experience
project planning experience
accountabilities in role
applies comprehensive knowledge and a thorough understanding of database concepts principles and technical capabilities to perform varied tasks and projects
develops data solutions to a wide range of difficult problems solutions are innovative seek opportunities for automation of tasks and are consistent with organization objectives
identifies designs and implements internal process improvements by automating manual processes and optimizing data delivery for greater scalability
subject matter expert for data solutions with deep understanding of raw data sources and how the data is leveraged by downstream applications
demonstrates a passion for technology with a curiosity for business and strategy
acts as a mentor to less experienced colleagues
continues ongoing skills development to keep with evolving technologies
what is expected of you and others at this level
applies comprehensive knowledge and a thorough understanding of database concepts principles and technical capabilities to perform varied tasks and projects
develops data solutions to a wide range of difficult problems solutions are innovative seek opportunities for automation of tasks and are consistent with organization objectives
identifies designs and implements internal process improvements by automating manual processes and optimizing data delivery for greater scalability
subject matter expert for data solutions with deep understanding of raw data sources and how the data is leveraged by downstream applications
demonstrates a passion for technology with a curiosity for business and strategy
acts as a mentor to less experienced colleagues
continues ongoing skills development to keep with evolving technologies
cardinal health is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability or protected veteran status",,OH,False,data_engineer
Data Engineer,"as a data engineer you’ll work with our backend development teams to build and real time reporting  analytic capabilities for the restaurants and hospitality industry you’ll work with a number of cutting edge technologies to wrangle various data sources into industrial strength pipelines that feed the full portfolio of services we offer to the industry
who you are
you are an individual who thrives in a team atmosphere you believe in agile development and continuous delivery you’re a selfmotivated and intellectually curious engineer with superb problem solving and analytical skills you have a willingness to learn adapt teach and pitch in wherever possible to help your customers
we’re looking for teammates who bring
experience building data pipelines from disparate sources
handson experience building and scaling up compute clusters
excitement about learning how to build and support machine learning pipelines that scale not just computationally but in ways that are flexible iterative and geared for collaboration
a solid understanding of databases and largescale data processing frameworks like hadoop or spark  you’ve not only worked with a variety of technologies but know how to pick the right tool for the job
a unique combination of creative and analytic skills capable of designing a system capable of pulling together training and testing dozens of data sources under a unified ontology
roles and responsibilities
work with a team of developers to provide top tier features to a wide audience of restaurant  hospitality customers
build and maintain the etl for hotschedules using open source software
provide architectural guidance on integrating with multiple systems to move data between layers of the software stack
develop parallelized processes to analyze big data produce forecasts and insights for the restaurant industry at cost and scale
write quality maintainable code with extensive test coverage in a fastpaced professional software engineering environment
manage tasks within an agile framework clearing tasks and managing jira workflows
manage long and short term deliverables with product management according to a product roadmap
architectural design and implementation for both internal and external consumption
requirements
6 years experience in software development
4 years experience with python and scala or java
experience with multiple large scale distributed systems or data platforms including spark flink kafka dataflow bigquery bigtable dataproc etc
2 years experience working on aws with an emphasis on their emr s3 and kinesis
experience working with terabyte level realtime datasets
dedication and practical experience with microservice architecture
strong algorithm  data structure knowledge
comfortable with oncall coverage  rotations
excellent communication skills and the ability to work well in a team
strong team customer focus ownership urgency and drive",,CA,False,data_engineer
DATA ENGINEER,"primary job functions
support and building our core analytics product
building and maintaining client data integrations and scalable etl processes
ensuring data integrity and completeness
develop and support internal reporting systems
job requirements
3 years relevant work experience selftaught hackers encouraged to apply just know your code also medical experience a plus
3 years relevant work experience
strong skills in both a statically typed and a scripting language we mainly use javapython but the ability and willingness to learn will be important
strong sql skills including tuning and optimization
experience with relational database design esp postgresql
passion for developing efficient testable and welldocumented code
development of etlintegration processes including data integrity
pluses
interest or experience in machine learning and predictive analytics
experience with medical billing systems and ontologies
knowledge of reporting systems and software eg  apache poi jasper 
experience web development in java gwtspring or python django
experience with amazon web services ec2 s3 or equivalent cloud computing approaches
send your resume and a cover letter to jobsacustreamcom and please indicate the position for which you are applying in the subject line",,CO,False,data_engineer
Data Engineer,"our mission at civitas learning is to partner with forwardthinking colleges and universities harnessing the power of insight and action analytics to help a million more students learn well and finish strong data and predictive models are at our core to achieve this mission are you amazing at sql curious about big data and predictive models to deliver insights to leading institutions and students we are looking for smart and dedicated data engineers to join our data engineering team as a data engineer you will serve as a key datadriven implementation engineer and interact with customers on a daily basis during their deployment

the data engineer role at civitas learning is critical to onboarding colleges and universities onto our cloud platform and making the process smoother more flexible and faster we want to work with people who are passionate about our mission and have a desire to be part of a rapidly expanding high performance team we work hard but also like to have fun if this sounds like you keep reading

responsibilities


collaborate directly with external customers to understand their student success goals specify and design data solutions and commission products into production
develop etl transformations to map customer data systems into our canonical data model
build and operationalize data science models on aws
collaborate with teams across civitas to drive innovation and best practices into our data and data science platform
up to 20 travel visiting customer institutions for technical discovery andor uatqa of data mappings
develop data pipelines to integrate institutions onto our data platform using amazon web services aws
design implement and maintain database models

qualifications


bachelors degree plus 2 years experience designing developing testing andor implementing complex etl solutions using enterprise etl tools
expertise in writing complex database sql queries with a focus on postgres and redshift
strong understanding of etl best practices including experience with etl tools and command line scripting
proficient developing code with command line build tools
expertise in working with technical and business teams to extract and document data integrationexchange requirements
ability to work independently as well as in a crossfunctional team environment collaborating with others and sharing tools skills and knowledge
solid problemsolving and analysis skills that demonstrate resourcefulness and attention to detail
strong organizational skills and ability to meet deadlines prioritize workload and manage time effectively
strong customer service orientation
ability to express complex technical concepts effectively both verbally and in writing
ability to handle multiple projects and deadlines with minimal supervision

nice to haves


some experience with the following or their equivalents
pythonjavaruby or other programming language
amazon web services
github
predictive models
higher education student information systems or learning management systems ellucian banner peoplesoft blackboard lms etc
jira

about civitas learning
civitas learning offers medical dental and vision insurance as well as a 401k plan we also have a generous flexible paid time off policy we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion national origin gender sexual orientation age marital status veteran status or disability

civitas learning partners with universities and colleges dedicated to helping more students learn well and finish strong we provide tools and services for educators that bring together and make the most of their diverse and disconnected data streams personalize information and support for their students and deepen understanding of the impact of their studentsuccess initiatives through our work together our partners are empowering leaders advisors faculty  students—and measurably improving enrollment persistence and graduation outcomes

today civitas learning is a strategic partner to more than 350 colleges and universities serving nearly 8 million students together with our growing community of partners civitas learning is making the most of the world’s learning data to graduate a million more students per year by 2025",,TX,False,data_engineer
Data Engineer,"castlight is looking for seasoned data engineers who have a penchant for problem solving with a passion for innovation to join our provider directory data engineering team you must be comfortable dealing with large sets of imperfect data and designing components to process it you will be working in the context of a complex set of systems within a multitier enterprise architecture as our data volume explodes you will apply your deep knowledge of performance scalability and optimization to make appropriate recommendations as well as to help materialize them
to succeed in this role youll need to be a versatile engineer you must have an innate desire to build things the right way you should be painaverse  if some process or system isnt as streamlined as it could be you want to fix it you want to accelerate your career growth by taking on a role that will give you deep knowledge of a complex system acting as the gatekeeper of the results finally you should want to communicate and collaborate with a team of smart people just like you
responsibilities
participate in development efforts incorporating new data sources as well as in support of infrastructure improvements
enjoy working in a collaborative engineering team writing code and the test cases to go with it
participate in design discussions sizing exercises and code reviews
qualifications
bs or ms in engineering or computer science or related technical field
2 years of experience in production software development preferably in a saas environment
some experience handling complex data sources and large scale batch data infrastructure
proficiency in writing sql queries performance tuning and data modeling
proficiency in python or another objectoriented programming language such as ruby or java
experience working with very large data warehouses
knowledge of postgresql and greenplum a plus",,CA,False,data_engineer
Data Engineer,"at change we are a unique blend of engineers activists marketers designers and scientists with a common goal to give the voiceless a voice and a chance to be heard in today’s digital jungle to allow everyone to connect with likeminded community and help people change the world for the better people the members the activists and our employees are at the center of our mission and everything we do actually employees at change are a lot like the service itself bright brave and innovative collaboration is the foundation of our workforce and were looking for smart individuals who are selfmotivated and passionate to join us be a part of the team that creates a brighter future for everyone discover your future at change

change has a great opportunity for a data engineer with several years of diverse experience who will help deliver change to millions of people around the world we are looking for someone who will own lead and execute projects you should have outstanding analytical and programming skills with a deep understanding and proven track record of building robust scalable data processing pipelines as a member of our highly motivated team you should be dedicated to excellence and have a strong sense of personal responsibility we hold ourselves to high standards and take pride in our work we are looking for someone who is not afraid to get their hands dirty in data and be an integral part of the machine learning teams expansion

what you’ll do work with data scientists and other data engineers to productize analytics and data models developing and maintaining new etl flows for new applications driven by modelbased statistics and signals push the envelope with scalable data processing and model deployment solutions leveraging technologies such as spark kafka kinesis airflow dynamodb tensorflow tensorboard etc build and support internal ab testing and model evaluation platforms tool our systems for observability including logging metrics monitoring and dashboarding  have fun and make friends
experience were looking for
development experience of which 2 years are focused on data engineering working with big data technologies hadoop ie mapreduce hdfshive spark
team player with excellent communication and interpersonal skills
experience developing high quality software in python scala or java
proficient with data preprocessing data transformation and integration of data from multiple data sources etl processes
experience with one of the following distributed relational databases postgresql mysql
experience developing for linuxbased deployment platforms developing scalable multithreaded server side software for deployment
experience designing and configuring hosted and cloudbased data and machine learning infrastructure
experience unit testing with frameworks and a dedication to thorough testing to create high quality software ie junit
experience with productionizing feature engineering for machinedeep learning algorithms and exposure to machine learning algorithms andor statistical modeling methods
experience with api designdevelopment ie rpc rest json xml soap

bonus skills
experience with recommender or searchranking systems
experience with kafka and yarn or mesos
experience with aws services athena glue redshift kinesis or google cloud services bigquery bigtable
babs or above in computer science or a related field
experience with nosql databases and keyvalue stores such as cassandra redis

this is a fulltime opportunity the position is located in san francisco ca usa

changeorg is committed to being a diverse and inclusive workplace we encourage applicants of different backgrounds cultures genders experiences abilities and perspectives to apply

all qualified applicants will receive consideration for employment without regard to race color national origin religion sexual orientation gender gender identity age physical disability or length of time spent unemployed
apply for this job",,CA,False,data_engineer
Lead Data Engineer - Next Gen Analytics,"description lead data engineer – next gen analytics
join the edabi team where your goal is to unlock the value of the vast treasure of data available – make it accessible through natural language interfaces and build novel big data solutions to create insights – your customer is business analystsusers

in this role you will be at the forefront of creating high performance real time streaming as well as data at rest analytics platforms you will derive satisfaction from deploying nontrivial scale solutions to solve business problems and create insights that were either downright impossible until now or took several days of effort

use your skills experience and talents to be a part of groundbreaking thinking and visionary goals you will be required to
understand how to build scalable real time streaming based big data systemshave developed and been a key influential member in a fully delivered data product
lead the architecture and design of several modules related to the backend of a search system a real time relevance engine a system that computes several complex functions on the data on the fly etcbe a handson developer and lead by example as a programmerprovide guidance and contribute to coding standardsprovide leadership in sprints cicd and the devops efforts

requirementsms in computer science or related areas7 years of experience developing production grade softwareproficient in linux or related unix systemsexpert in one or more of c c java and python exposure to modern programming languages such as rust and go a huge plus
experience building and deploying large scale distributed systems
excellent written and verbal communication skills

qualifications",,CA,False,data_engineer
Data Engineer,"we are looking for a data engineer to join our operations team either at our albuquerque headquarters or remotely within one of the states in our region arizona colorado nevada new mexico and texas accion is embarking on a threeyear project to overhaul our technology infrastructure and implement a stateoftheart lending platform it will be the only endtoend lending platform in our industry and is fully owned and operated by accion allowing it to be customized to meet our and our customers needs this will have a transformational effect on accion our clients and the sector of lenders supporting underserved entrepreneurs as our data engineer youll be an integral part of this transformation helping us create a datacentered culture we need to make datainformed decisions

what youll be doing

youll work closely with our technology operations and engineering teams to understand business needs and designmaintain scalable data models
youll make databacked recommendations to the executive team to help inform business decisions and answer complex questions
youll own the design build maintenance quality and expansion of a data warehouse and support and scale the pipeline that relays data from accions lending platform back to the warehouse
over time youll act as a product manager determining project timelines goals and deliverables for updates to our lending platform

skills and experience

must have a passion for accions mission and a strong commitment to accions culture of exceptional customer service excellence and accountability
knowledge of etl processes and applications
experience in the financial services industry and familiarity with the lending process strongly preferred
advanced skills in sqljavaruby preferred
bachelors degree in computer science engineering applied mathematics or related quantitative discipline plus four years relevant experience preferred

accion offers an excellent total compensation package including competitive base salary the opportunity for exciting incentive pay health and dental coverage retirement benefits and generous paid time off

about accion
a nonprofit leader in the highimpact fields of community development and microfinance accion is dedicated to helping entrepreneurs realize their dreams and fuel increased economic opportunity and mobility through business ownership since 1994 accion has infused more than 123 million in the growth and success of more than 8000 small businesses across arizona colorado nevada new mexico and texas

accion is a member of the accion us network the largest and only nationwide nonprofit micro and small business lending network in the united states since 1991 the members of the accion us network have collectively made more than 57000 loans totaling over 500 million globally accion is a pioneer in microfinance reaching millions of individuals through its international network of partners learn more at wwwusaccionorg  httpwwwusaccionorg ",,CO,False,data_engineer
Data Engineer - Big Data,contractjob summaryapplication developerbig data toolsjava j2ee map reduce hive spark sprint bootwork location phoenix az no tl no remotejob type contract,,AZ,False,data_engineer
Data Engineer,"atlassian is looking for a data engineer to join our data engineering team and build worldclass data solutions and applications that powers crucial business decisions throughout the organization we are looking for an open minded structured thinker who is passionate about building systems at scale youll be the genius who understands data at atlassian knows where to find it and manages the process to make that data useful for analytics you love thinking about the ways the business can consume this data and then figuring out how to build it

on a typical day you will be building the data models and etl processes to provide this data for business use youve got industry experience working with large datasets you are interested in reporting platforms and data visualization as the data domain expert you will be partnering with our technology teams analytical teams and data scientists across various initiatives
youll own a problem endtoend so those skills will come in handy not just to collect extract and clean the data but also to understand the systems that generated it and automate your analyses and reporting on an ongoing basis youll be responsible for improving the data by adding new sources coding business rules and producing new metrics that support the business requirements will be vague iterations will be rapid you will need to be nimble and take smart risks

more about you

as a data engineer you may have experience spanning traditional dw and etl architectures but for this role it is important to have industry experience working with big data ecosystems like sparkhadoop and redshift youve probably been in the industry as an engineer for 2 years and have developed a passion for the data that drives businesses
on your first day well expect you to have
deep understanding of big data challenges and ecosystem
experience with solution building and architecting with public cloud offerings such as amazon web services redshift s3 emrspark prestoathena
experience with spark and hive
expertise in sql sql tuning schema design python and etl processes
expertise in data pipeline with such workflow tools as airflow oozie or luigi
solid understanding experience in building restful apis and microservices eg with flask
experience in test automation and ensuring data quality across multiple datasets used for analytical purposes
experience with lambda architecture or other big data architectural best practices
a graduate degree in computer science or similar discipline
commit code to open source projects
experience with test automation and continuous delivery
its great but not required if you have
experience with tableau
experience with machine learning
have worked with data scientists
more about our team

atlassian is over a decade old but our team is much younger well have to blaze new trails to enable important growth decisions so were constantly growing learning and trying to do things differently youll be joining a team that is crazy smart and very direct we ask hard questions and challenge each other to constantly improve our work we are selfdriven but team oriented were all about enabling growth by delivering the right data and insights in the right way to partners across the company

more about our benefits

our offices are open highly collaborative and yes fun to support you at work and play we offer some fantastic perks ample time off to relax and recharge flexible working options five paid volunteer days a year to support your favorite cause plenty of food and beverages ergonomic workstations with sitstand desks unique shipit days a company paid trip after five years generous employerpaid insurance coverage medical dental and vision for you and your family 401k matching and more

more about atlassian

software is changing the world and we’re at the center of it all with a customer list that reads like a whos who in tech and a highly disruptive business model we’re advancing the art of team collaboration with products like jira confluence bitbucket trello and now stride driven by honest values an amazing culture and consistent revenue growth we’re out to unleash the potential of every team from amsterdam and austin to sydney and san francisco we’re looking for people who are powered by passion and eager to do the best work of their lives in a highly autonomous yet collaborative no bs environment

additional information

we believe that the unique contributions of all atlassians is the driver of our success to make sure that our products and culture continue to incorporate everyones perspectives and experience we never discriminate on the basis of race religion national origin gender identity or expression sexual orientation age or marital veteran or disability status

all your information will be kept confidential according to eeo guidelines

atlassian inc will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of sfpc art49",,CA,False,data_engineer
Data Engineer - Scala/Java,"if working on a high performance scalable data solution on one of the largest big data systems in the world that supports 70 billion transactions a day sound exciting and challenging enough for you then read on rubicon project is looking for passionate engineers to work on our industryleading reporting application which will offer worldclass user experience for our customerson a global scale

this is a great opportunity for a jrmid level engineer who is looking to gain experience on a larger scale and be involved with the data and uiapi side of reporting

what you will be doing

the main focus of this position is on the backend data processing and api definitely a great learning opportunity to be a fullstack developer
youll be working within a small but rapidly growing team to build the next generation reporting and analytics platform as we grow you grow along with the team and company together to earn technical experience

what we look for

bs degree or higher in computer science or related major
2 years working experience in mr spark and big data processing platform in high volume and low latency environment
good scala java sql skills are required
proficiency in working and developing on linux
proficiency in using relational databases and writing sql
proficiency in python
knowledge and experience of developing on druid is a huge plus
knowledge and experience in building restful webservices
familiarity with concurrency and multithreaded programming
familiarity with automated testing tdd mocking unitfunctionalintegration
familiarity with development continuous integration tools like maven git jenkins etc
great interpersonal written and verbal communication skills including the ability to debate technical tradeoffs and explain technical concepts to business users

whats in it for you

take time for yourself take what you need  our vacation days are unlimited and we close down the week of 4th of july and last 10 days of the year that is paid for as well
stay healthy choose from a variety of medical dental and vision plans to cover you and your loved ones at a very low cost
enjoy your stay we want to make it easy for you each rubicon project office enjoys a variety of benefits like daily catered lunches a fully stocked kitchen with healthy snacks and free vending machines

",,WA,False,data_engineer
Data Engineer,"data engineer
who we are
lululemon is a yogainspired technical apparel company up to big things the practice and philosophy of yoga informs our overall purpose to elevate the world through the power of practice we are proud to be a growing global company with locations all around the world from vancouver to shanghai and places in between we owe our success to our innovative product our emphasis on our stores our commitment to our people and the incredible connections we get to make in every community we are in
about this team and this role

the data engineer will be part of the engineering team building real time enterprise data streams ingesting data from multiple heterogeneous data sources and provisioning data as raw data streams and canonical business events essentially provisioning data once at enterprise level for any enterprise level data related use cases deploying and maintaining stream processing technologies to provision data to real time operational data stores raw data stores providing frameworks on how to transform raw data using big data technologies and helping data scientist in machine learning deliverables

ingest data from heterogeneous data sources and publish them as enterprise business events
responsible for building and consuming from api’s
building scalable data pipelines for generating training datasets for machine learning deliverables
mentor junior resources and drive end to end design implementation and delivery of engineering components
deploying maintaining and building apps on distributed stream processing engines such as storm flink nifi spark etc
building data transformation layers etl frameworks using big data technologies such as hive spark presto etc
experience working with container management technologies such as docker kubernetes
building and maintaining solutions on highly available environments
working knowledge of cicd
working knowledge of building data integrity checks as part of delivery of applications
build code that is performant as well as secure
collaborate with crossfunctional teams – business stakeholders engineers program management project management etc  to produce the best solutions possible
anticipate systemapplication challenges and proposes solutions for the same
contribute to story sizing and work estimates for implementation validation delivery and documentation
review user stories to ensure a quality user experience welldefined acceptance criteria and thorough test coverage
participate in design and code review to ensure quality and testability of feature code


qualifications

bs in computer science or related
5 years of data engineering experience
strong java coding experience
experience with devops real time analytics and real time messaging
experience working with kafka pulsar or bookkeeper is required
working experience of scripting data science and analytics sql python powershell javascript or r
2 years of performance tuning and optimization bottleneck problems analysis and technical troubleshooting in a sometimes ambiguous environment

desired qualifications

ms degree in computer science or related technical degree completed
experience with real time analytics and real time messaging
should be a java expert
experience with open source technologies spring is preferred
working experience with microservices is desirable
experience working with large volume data retail experience strongly desired
devops experience and use of docker chef puppet jenkins kubernetes istio or ansible
experience supporting machine learning recommendation engines and or search personalization is preferred
acknowledges the presence of choice in every moment and takes personal responsibility for their life
possesses an entrepreneurial spirit and continuously innovates to achieve great results
communicates with honesty and kindness and creates the space for others to do the same
leads with courage knowing the possibility of greatness is bigger than the fear of failure
fosters connection by putting people first and building trusting relationships
integrates fun and joy as a way of being and working aka doesn’t take themselves too seriously

note only those applicants under consideration will be contacted please accept our utmost appreciation for your interest lululemon is an equal employment opportunity employer employment decisions are based on merit and business needs and not on race color creed age sex gender sexual orientation national origin religion marital status medical condition physical or mental disability military service pregnancy childbirth and related medical conditions or any other classification protected by federal state or provincial and local laws and ordinances reasonable accommodation is available for qualified individuals with disabilities upon request this equal employment opportunity policy applies to all practices relating to recruitment and hiring compensation benefits discipline transfer termination and all other terms and conditions of employment while management is primarily responsible for seeing that lululemon equal employment opportunity policies are implemented you share in the responsibility for assuring that by your personal actions the policies are effective
limr1

job information technology
organization store support center
schedule fulltime
unposting date ongoing",,WA,False,data_engineer
Data Engineer,"a pioneer in k– 12 education since 2000 amplify is leading the way in nextgeneration curriculum and assessment our captivating core and supplemental programs in ela math and science engage all students in rigorous learning and inspire them to think deeply creatively and for themselves our formative assessment products turn data into practical instructional support to help all students build a strong foundation in early reading and math all of our programs provide teachers with powerful tools that help them understand and respond to the needs of every student today amplify serves more than three million students in all 50 states for more information visit amplifycom 


as an engineer at amplify you will join a talented team tackling the toughest problems in education with the best ideas in technology – including user experience apis and services data analysis and deployment pipelines you’ll play an active role in imagining and improving product design and the classroom experience

we hire engineers “for the slope not the intercept” – we’re looking for intellectual ability flexibility and ability to learn and commitment to work together in tightknit teams

what you’ll do
our data team builds augments and maintains the infrastructure that empowers teams across amplify and our customers to make sense of and tell stories with their data we believe strongly in teaching our teammates to serve themselves within a safe reliable and agile environment you’ll be building data systems but also the sharingandlearning culture so that every team uses these tools to improve their own lives and those of our students and teachers

impress the toughest customers around – seventh graders – by
helping teams create fun compelling apps by leveraging millions of data points
make life better for passionate overworked teachers by
helping teachers understand their students by building reusable data pipelines
make life better for passionate overworked marketing and sales teams by
using rest apis for sourcingsending data to saas like salesforce hubspot
help school administrators build great schools by
respecting privacy and ensuring security while offering useful insights by making smart choices in tech stack database design and encryption
helping school principals understand how teachers are teaching and how students are learning by architecting data warehouse schemas and sql transforms with just the right ctes window functions and pivots
analyzing performance and squashing tricky bugs using tools like aws redshift matillion python sql aws cloudwatch aws sns
learn every day by
immersing oneself in agile rituals and leveraging our infrastructure
leading collaboration pull requesting and mentoring on a crossfunctional team
participating in crossteam shareouts brownbags and workshop series
becoming an expert in the data models and standards within amplify and the educational industry in order to deliver quality and consistent solutions

example projects you might work on
building welltested and optimized etl data pipelines for both full and delta extraction
collaborating with data scientists to store aggregate and calculate captured students’ work
contributing to leading industry data standards such as caliper analytics or xapi
improving our deployment and testing automation data pipelines

you must have
bsms in computer science data science or equivalent
2 years of professional software development or data engineering experience
strong cs and data engineering fundamentals
proven fluency in sql and a development language such as python
understanding of etlelt pipelines and data warehousing design tooling and support
understanding of different data formatting json csv xml and data storage techniques 3nf eav model star schema data vault
strong communication skills in writing conversation and maybe silly gifs

extra credit for
experience with tools we use every day
storage aws storage services redshift redshift spectrum s3 glacier dynamodb parquet postgres
etlbi matillion looker
experience with tools we don’t use but should and the wisdom to know when to recommend them
proven passion and talent for teaching fellow engineers and nonengineers
proven passion for building and learning open source contributions pet projects selfeducation stack overflow
experience in education or edtech



amplify is an equal opportunity employer of minorities females protected veterans and individuals with disabilities

this position may be funded in whole or in part through american recovery  reinvestment act funds

amplify education inc is an everify participant",,NY,False,data_engineer
Data Engineer,"overview
the data engineer responsibilites include building a data processing pipeline that collects connects centralizes and curates data from various internal and external sources using a variety of languages and tools to marry systems together for the enterprise data warehouse develop highly scalable and reliable data engineering solutions for moving data efficiently across systems design implement test and deploy data processing infrastructure perform work in an agile team setting and break down estimate and provide justintime design for small increments of work this role is pivotal to the mission and vision of seattle children’s enterprise analytics team to transform healthcare for children by providing patient safety predictive analysis to cure diseases lowering cost of treatement etc 
requirements
required educationexperience
bachelors degree in computer science or related field or equivalent combination of education and experiencetechnical training that demonstrates analytical and technical competencyminimum of two 2 years technology industry or related experience including items such asbuild highly scalable scaledout architectures on large scale database platformsexperience working in a complex data infrastructure environmenttwo 2 years of experience in a data engineering roledata pipeline development experience with industry standard data integration toolsadvanced competency in sql with ability to perform query optimization in large scale database platformsexperience in sdlc process with requirements gathering analysis architecture design implementation testing deployment and technical supportexperience with any industry standard tool for source control and project managementexperience wrting test cases and test scripts for data quality assuranceexperience creating stored procedures and functionsexperience developing dimensional data model with any industry standard tool

required credentials
na

preferred
experience in healthcare or related industryexperience utilizing netezza datastage bitbucket jira confluence a plusexperience productizingautomating predictive models that use r sas python spss etccontinuous delivery and deployment automation for analytic solutions using tools like bamboofamiliarity with test driven development methodology for analytic solutionsagileapi developmentdata visualization andor dashboard development",,WA,False,data_engineer
Data Engineer (JetBlue Travel Products),"data engineer jetblue travel products
the jetblue travel products jbtp data engineer reports directly to the gm of data engineering and is responsible for developing and supporting the data management and analytics platforms including data infrastructure in order to support the evolution of travel products the data engineer is focused on the design and development of data ingestion processing and storage pipelines as well as the transformation of raw data into business insights that enable jetblue travel products to become a digital disruptor this role collaborates heavily with their matrix partners in jetblue’s it jetblue tech ventures and external business partners
the data engineer can change priorities and focus to meet business demands excels when working on complex projects is motivated to deliver results and exhibits the jetblue values of safety caring integrity passion  and passion
essential responsibilities
design develop and manage data management products from conception to retirementensure that the data engineering team delivers with consistency high quality and predictabilitycreate and promote a work environment focused on engineering excellence to attract develop and encourage a culture of technical innovationpartner with product management and marketing teams and help develop the product vision and roadmapcreate the jbtp data infrastructure and analytics environments understand the data and provide support for key business decisionsparticipate in the devops practice as it pertains to data engineeringhelp establish frameworks design and integration patterns as well as guide the software development performed by business partnershelp manage a collection of external technology products used to deliver business productspartner with jetblue tech ventures to identify monitor learn experiment and share information about emerging technology that is relevant to jetblue travel productsother duties as assigned
minimum experience and qualifications
bachelor’s degree in computer science or related technical field or equivalent practical experience with demonstrated capability to perform job responsibilities through four 4 previous years of combined experience and educationthree 3 years’ experience in an engineering rolegood understanding of software engineering environments and standardsdeep understanding of internet technologies protocols and methodologies for delivering webbased productsexperience managing service level agreementsexperience interacting daily with people at different levels within the organization including developing and maintaining ongoing relationshipsmust pass a ten 10 year background check and preemployment drug testlegally eligible to work in the country in which the position is located
preferred experience and qualifications
experience maintaining a public profile and building relationships throughout the organizationfive 5 years’ experience in technology rolesexperience in writing software in one or more languages such as java python go andor javascriptexperience architecting developing software or internet scale productiongrade big data solutions in virtualized environments such as amazon web services azure and google cloud platform
crewmember expectations
regular attendance and punctualitypotential need to work flexible hours and be available to respond on shortnoticewellgroomed and able to maintain a professional appearancewhen working or traveling on jetblue flights and if time permits all capable crewmembers are asked to assist with light cleaning of the aircraftorganizational fit for the jetblue culture that is exhibit the jetblue values of safety caring integrity passion and fun
equipment
computer and other office equipment
physical effort
generally not required or up to 10 pounds occasionally 0 pounds frequently sedentary


disclaimer the above statements are intended to describe the general nature and level of work being performed by the crewmembers assigned to this position they are not intended to be an exhaustive list of all responsibilities duties and skills required of individuals in this position may be subject to change as the needs of the organization change

jetblue airways corp is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin age marital status veteran status sexual orientation gender identity or expression disability status pregnancy genetic information citizenship status or any other characteristic protected by law this policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation and training


eeo is the law

eeo is the law gina supplement",,FL,False,data_engineer
Data Engineer,"custora exists to help our customers improve the relationships they have with their own customers we do this by ingesting data about every interaction a company has with each of their customers and then making predictions using that data about how those customers will behave in the future our customers then use these predictions to tailor their communications

data engineers at custora work on the pipelines that sit at the core of this architecture we work to make these pipelines faster more fault tolerant and to expand their scope
the volume of data is large were working with 7 of the top 20 largest retailers in the world  many more not in the top 20 and are ingesting data from them both in a regular batch and in nearreal time

weve carefully selected the types of data to ingest to favor high signal data so we care deeply about maintaining the correctness and completeness of the data being ingested as our models and therefore the output of our product

your work directly impacts both the predictions we are able to make and the day to day performance our customers experience when using our product

getting more specific you will

design and build complex data pipelines on the spark platform ingesting both batch and real time datasets
work with our data science team to deploy predictive models at scale
build tools to continuously validate incoming data and proactively identify and communicate data anomalies before they manifest into problems
we’re a small team so you’ll be working on and be able to meaningfully contribute to high impact projects from your first day
sure but what’s it really like

inspired by basecamp we work in 8 week product cycles first we work together engineering  product to identify the projects we think will have the biggest impact on our company goals here’s an example of a recent project we conceptualized and delivered over one of these cycles

migrate selfmanaged spark cluster to emr
to lower overall cost and to be able to easily scale to handle bigger datasets and processing volumes we recently switched from a self managed spark cluster to amazon’s elastic mapreduce service

our challenge was to move terabytes of data used by our clients while having no downtime some initial concerns were the performance on the emr cluster and the migration process itself because some clients ingest a combination of live data and batch based data the scale of our data sent meant that we had to switch several clients at a time to emr

after ensuring that hive backed by s3 was performant enough we built tools to move vast amounts of data in parallel to redirect requests to the correct cluster as clients were being moved and to validate the data after migration along the way we also had to reshape the data in terms of partition size to ensure efficiency of copying and loading into the hive database

the stack

while we make use of a wide variety of tools our primary web stack is es6react and ruby on rails deployed on aws we make extensive use of r for statistical analysis and our primary data stores are hive mysql and redis

what it’s like to work here

on monday we eat and meet as a team to chat projects and progress
we’re 50 genuinely nice people 25 men and 25 women we work together and experiment with how to do things
we move quickly you build something and the next day it comes to life you see and feel an immediate impact with the collective efforts of the team
we’re building a company and a team we love we’re in it for the long run
read more about what makes us us here
find out more here or here
custora is an equal opportunity employer we value diversity we don’t discriminate on the basis of race religion color national origin gender sexual orientation marital status veteran status disability status or socioeconomic status

qualifications

5 or more years of experience as a software engineer
degree in computer science or a deep competency achieved via other means
familiarity with ruby on rails aws and sqlbased databases
high standards for code quality and maintainability
nice to haves

experience with r scala spark andor chef
consistent record of delivering significant features or building out platforms and services
experience working in ecommerce
the perks

we’re a flexible work environment
competitive salary and meaningful equity
health dental and vision insurance 100 covered
free lunch every day plus free water — hot and cold
unlimited vacation take as much time as you need we recommend at least 3 weeks
monthly unlimited metrocard
401k",,NY,False,data_engineer
Data Engineer,"about hive

hive is a fullstack deep learning platform helping to bring companies into the ai era we take complex visual challenges and build custom machine learning models to solve them for ai to work companies need large volumes of high quality training data we generate this data through hive data our proprietary data labeling platform with over 500000 globally distributed workers generating millions of high quality pieces of data per day we then use this training data to build machine learning models for verticals such as media autonomous driving security and retail today we work with some of the largest companies in the world to redefine how they think about unstructured visual data together we build solutions that incorporate ai into their businesses to completely transform industries

we are fortunate that investors like peter thiel founders fund general catalyst 8vc and others see hive’s potential to be groundbreaking in ai business solutions we have over 100 rock stars globally in our san francisco and delhi offices please reach out if you are interested in joining the ai revolution

data engineer role

in order to execute our vision we need to grow our team of bestinclass data engineers we are looking for developers who conduct impeccable data practices and implement high quality data infrastructures we value hard workers who are comfortable improvising solutions to a stream of big data challenges while building a system that stands the test of time our ideal candidate has experience building data infrastructure from the ground up contributes innovative ideas and ingenious implementations to the team and is capable of planning out scalable maintainable data pipelines

as a data engineer you would at first work primarily on our hive media product taking realtime data from hundreds of television streams and turning them into a combination of realtime and scheduled outputs especially our signature ads feed your work would improve the quality of our results while reducing computational cost and latency expect truly novel challenges
responsibilities
writing scheduled spark pipelines that perform sophisticated query plans on the entirety of our datasets
writing realtime pipelines that execute complex operations on incoming data
synchronizing large amounts of data between unstructured and structured formats on various data sources
creating testing and alerting for data pipelines
building out our data infrastructure and managing dependencies between data pipelines
determining and implementing metrics that provide visibility into our data quality
requirements
you have an undergraduate and  or graduate degree in computer science or a similar technical field with a sound understanding of statistics
you have 12 years of industry experience as a data engineer
you have handson experience doing etl and have written data pipelines in either spark or mapreduce
you have a sound understanding of sql or cql
you have worked with data lakes such as s3 or hdfs
you have worked with various databases such as postgres cassandra or redshift before and understand their pros and cons
you have a working knowledge of the following technologies or are not afraid of picking them up on the fly mesos chronoscron marathon jenkins
you are fluent in at least one scripting language preferably nodejs or python and one compiled language such as scala java or c
you have great communication skills and ability to work with others
you are a strong team player with a dowhateverittakes attitude
what we offer you

we are a group of young and ambitious individuals passionate about creating a revolutionary machine learning company at hive you will have a significant career development opportunity and a chance to contribute to one of the fastest growing ai startups in san francisco the work you will do here will have a noticeable and direct impact on the development of hive

our benefits include competitive pay equity health  vision  dental insurance catered lunch and dinner and a corporate gym membership

thank you for your interest in hive",,CA,False,data_engineer
Big Data Engineer - Apple Pay Analytics,"looking for talented passionate and resultsoriented individuals to join our team building data foundations and tools to craft the future of commerce and apple pay collaborating with the head of data engineering for iss payments  commerce analytics you will create scalable extensible highlyavailable and high performance data pipelines that will help create insights for measuring performance and driving strategy you will collaborate with various data analysts instrumentation authorities and engineering teams to identify requirements that will derive the creation of data pipelines you will work closely with the application server engineering team to understand the architecture and internal apis involved in upcoming and ongoing projects related to apple pay
our culture is about getting things done iteratively and rapidly with open feedback and debate along the way we believe analytics is a team sport but we strive for independent decisionmaking and taking smart risks our team collaborates deeply with partners across product and design engineering and business teams our mission is to drive innovation by providing the business and data scientist partners bestinclass systems and tools to make decisions that improve the customer experience of using our services this will include using large and complex data sources helping derive actionable insights delivering dynamic and intuitive decision tools and bringing our data to life via amazing visualizations
you are a selfmotived teammate skilled in a broad set of big data processing techniques with the ability to adapt and learn quickly provide results with limited direction and choose the best possible data processing solution is a requirement

key qualifications
5 years of professional experience with big data systems data pipelines and data processing
practical handson experience with technologies like apache hadoop apache pig apache hive and apache sqoop
ability to understand server api specs identify the corresponding server events extract data from the events and define  derive actionable data pipelines
understanding on various distributed file formats such as apache avro apache parquet data structures and common methods in data transformation
expertise in python scripting
you have expertise in unix shell scripting and dependency driven job schedulers
expertise in oracle database and ansi sql
proficiency in core java
you have knowledge on scala
familiarity with apache oozie  apache spark and pyspark
familiarity with data visualization tools such as tableau
familiarity with rule based multistage data correlation on large data sets is a plus
you have excellent time management skills with the ability to run work to tight deadlines and handle the pressure of executive requests and product launches
description
 translate business requirements by analysts into data and engineering specifications
 build new scalable data sets based on engineering specifications from the available raw data and derive business metrics out of it
 identify and implement data validation rules and alerts based on data publishing specifications for data integrity and anomaly detection
 identify server api calls that needs to be tapped for data analytics and reporting and align the server events for execution in already established data pipelines
 analyze complex data sets identify and formulate correlational rules between heterogeneous data sources for effective analytics and reporting
 process clean and validate the integrity of data used for analysis
 develop python and shell scripts for data ingestion from external data sources for business insights
 work hand in hand with the devops team and develop monitoring and alerting scripts on various data pipelines and jobs

education
minimum of bachelor’s degree preferably in computer science information technology or ee or relevant industry experience is preferred",,CA,False,data_engineer
Big Data Engineer,contractjob summaryjob description candidate should have over all of 5 yrs of total it experience responsibilities and dutiesin which candidate should have 23 yrs of spark  scala combination on big data environmentrequired experience skills and qualificationsshould have good oral and written communication should have good confidence level and should be customer facingjob type contractexperiencespark and scala 2 years preferred,,CA,False,data_engineer
Associate Principal Engineer- Data Engineer,"with our portfolio of global power brands such as oreo and belvita biscuits cadbury dairy milk and milka chocolate and trident gum were the worlds 1 in biscuits and candy and 2 in chocolate and gum were mondelēz international a snacking powerhouse with operations in more than 80 countries with approximately 90000 employees globally and our brands are marketed in around 165 countries
our purpose and vision is to create more moments of joy by building the best snacking company in the world
purpose of role
building infrastructure and architecture to support data mining from complex rd data to deliver new insights to enable rapid high quality innovation across our chocolate biscuit gum  candy categories structuring solutions and systems from a wide range of data sources and types
main responsibilities

works with engineers and scientists to define complex technical challenges to be solved
defines system needs to maximize data as an asset to the rd function including combining data  connecting data from multiple sources
uses appropriate software tools and programming methods to harness data improving data quality reliability and efficiency to enable high performance solutions
builds tests and maintains architectures including planning and costing of new solutions
communicates systems needs and engages with stakeholders to enable expansion beyond the existing infrastructures
write and builds best practice documentation and actively strives to change traditional ways of working within rd
develops simplified software tools for others to use to add and interpret data and understand results
researches and keeps up to date with developments in data engineering techniques
maintains and develops data mining resources including hardware and software updates working with it department to maintain security and backup systems
bachelor degree or higher in a stem subject  computer science
5 years experience of data engineering in a large complex business with multiple systems such as sap lims etc and experience setting up testing and maintaining new systems
experience of a wide variety of languages and tools eg script languages to marry systems together
ability to simplify complex problems and communicate to wide audience
global experience and additional language preferred
mondelēz global llc is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability protected veteran status sexual orientation gender identity gender expression genetic information or any other characteristic protected by law applicants who require accommodation to participate in the job application process may contact 8479435460 for assistance
applicants must complete all required steps in the application process including providing a resumecv in order to be considered for this position",,NJ,False,data_engineer
Data Science Engineer,"carvana…

at carvana we sell cars but were not salespeople since 2013 weve been making it our mission to change the way people buy cars we saw a huge problem with how much it can suck to buy a car the traditional way so we committed ourselves to tackling one of the largest yettobedisrupted markets in the world – the 1t per year us car market yes thats trillion with a t

with the ability to search thousands of vehicles from our expansive inventory to highresolution 360° photographs of our vehicles interior and exterior to realtime financing and the ability to complete contracts without visiting the back room of a dealership we provide a seamless online car buying experience for consumers that can be completed from their desktop or mobile device all our vehicles are inspected and reconditioned based on our 150point certification checklist and come with a 7day return policy we also operate our own logistics network to deliver cars to customers as soon as the next day as well as offer customer pickup at our stateoftheart car vending machine locations yes you read that right by putting customer satisfaction at the core of our business weve built a nopressure nohaggle online car buying experience that our customers time and money

for more information on carvana and our mission sneak a peek at our company introduction video  httpsyoutubec5dpbrp0w 

job description

we are looking for a data engineer to support our data science and predictive modeling team the successful candidate will work with our data science and business intelligence teams to seek out consume and productionalize new data both structured and unstructured additionally you will be responsible for designing and maintaining the predictive modeling data pipeline from data acquisition and facilitation of model building to production scoring and model maintenance the candidate will thrive in a fastpaced challenging environment and be comfortable managing multiple disparate projects and using myriad tools such as spark ms sql python r etc as necessary to get the job done you will have an insatiable curiosity and drive to learn and implement new technologies programming languages and database systems to help ensure you and our data scientists are maximizing business impact

as a data engineer in data science you can expect to…


work with data scientists to support model building scoring monitoring and reporting
identify collect store process and analyze data using various storage engines ms sql server spark etc
design how data is stored consumed integrated and managed
be focused on choosing optimal solutions to use for those purposes and then implement maintain and administer them
design large relational data sets from unstructured data
create data flows to automate the use of algorithms created by our data scientists
plan design and optimize data processes and structures for throughput and query performance
ensure the accuracy and integrity of the data sets before they are presented to end users
create etls to integrate data between different systems and formats using tools like python sql server data tools etc
design processes that contain sensitive data in a responsible manner using certificates hashing ad permissions ensuring that necessary security practices are followed
have the ability to read beyond the initial specs of a project to determine if there is additional functionality that should be added
use basic statistical and visualization techniques to analyze the resulting data sets of your processes
learn and stay abreast of new technologies that can improve the efficacy of the analytics and data science teams

requirements


quantitative undergraduate degree such as math economics statistics engineering etc with a strong academic record graduate degree preferred
minimum 3 years of professional experience in analytics engineering or data science
you are wellversed in sql and python or a similar language that will easily transfer to python such as java or c
experience with a cloud platform such as aws azure or similar
experience with cicd pipelines such as jenkins azure devops vsts or similar
you hold or have the equivalent experience to a degree in a technical or quantitative field such as computer science information systems engineering statistics applied mathematics etc
you have extensive knowledge of etl processing – data manipulation database structure and data management
you follow software engineering best practices using tools such as unit testing and git
you are a selfstarter with the ability to lead and build trust quickly
you have strong diagnostic and analytical skills along with the ability to breakdown complex crossfunctional business problems
have a deep love for data an analytical brain and some serious technical aptitude
you are fearless of being unknowledgeable about a particular subject areatechnology you yearn to learn and ask questions with a strong desire to grow through challenging work and new technologies

nice to haves

exposure to a big data platform such as hadoop and aws
experience with a data visualization tool
knowledge of a statistics package such as r sas or pandas in python
experience deploying docker containers to production

what you can expect in return…


a fulltime salaried position
medical employee medical fully paid by carvana dental and vision benefits
a 401k with company match
all the snacks and drinks your heart desires plus iced coffee on tap
access to opportunities to expand your skill set and share your knowledge with others across the organization

legal stuff…

carvana is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin age protected veteran or disabled status or genetic information

this role is not eligible for visa sponsorship",,AZ,False,data_engineer
Data Engineer,"ispottv is a fast growing venture backed startup with rapidly ramping revenues we have a product that is changing how brands agencies and networks measure and assess the impact of tv advertising campaigns our software uses proprietary audio and video analysis to monitor and extract tv commercials movie trailers and other promotional content from tv at the same time our software analyzes consumer interactions with tv ads on the digital screen across search video and social interactions are matched with specific ads and attributed back to airings on tv
we are looking for an experienced data engineer to join our growing team of analytics experts this position will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for crossfunctional teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up
we are looking for someone that is highly motivated and knows how to get things done quickly and efficiently
responsibilities
create and maintain optimal data pipeline architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and aws ‘big data’ technologies
build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics
work with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
keep our data separated and secure across national boundaries through multiple data centers and aws regions
collaborate with data scientist and engineering team members to create data tools that assist them in building and optimizing our product into an innovative industry leader
work with data and analytics experts to strive for greater functionality in our data systems
qualifications
3 years of experience in a data engineer role who has attained a graduate degree in computer science statistics informatics information systems or another quantitative field
experience building and optimizing ‘big data’ data pipelines architectures and data sets
experience with python and aws redshift mysql java and spark are nice to have
experience in problemsolving and finding issues
strong entrepreneurial skills that bring customerfocused ideas to the projects
knowledge of best practices of software development including coding standards code reviews source control management build processes testing and operations
a natural collaborator with a proven ability to work across teams to get things done",,WA,False,data_engineer
Big Data Developer/Data Engineer,"big data developer

cognizant has immediate openings for big data if you meet our background requirements and skills and looking for an opportunity to be rewarded for your skills and expertise is the ideal opportunity for you

job description

hadoop python kafka â€¢ apply expertise and research designs with subject matter experts to devise requirements design specifications and usage criteria for big data solutions
 responsible for leading the design and maintaining solutions conformant to enterprise standards architecture and technologies
provide oversight direction and mentoring to ensure adherence to business direction architectural strategies and enterprise technology standards
 collaborate with developers and business users for overall design oversight on big data solutions
 maintain expertise and proficiency with big data technologies using business intelligence best practices
 documented experience in a business intelligence or analytic development role on a variety of large scale projects 5 years minimum
 expertise in hadoop and related technologies  apache hadoop kafka python apache spark including pyspark spark streaming scala mapreduce hive hbase


technical skills

snoprimary skillproficiency level rqrddsrd
1informatica powercenterpl1required
proficiency legends

proficiency levelgeneric reference
pl1the associate has basic awareness and comprehension of the skill and is in the process of acquiring this skill through various channels
pl2the associate possesses working knowledge of the skill and can actively and independently apply this skill in engagements and projects
pl3the associate has comprehensive indepth and specialized knowledge of the skill she  he has extensively demonstrated successful application of the skill in engagements or projects
pl4the associate can function as a subject matter expert for this skill the associate is capable of analyzing evaluating and synthesizing solutions using the skill

employee status  full time employee
shift  day job
travel  no
job posting  oct 05 2018
cognizant us corporation is an equal opportunity employer minorityfemaledisabilityveteran if you require accessibility assistance applying for open positions in the us please send an email with your request to careersna2cognizantcom

about cognizant
cognizant is one of the worlds leading professional services companies transforming clients business operating and technology models for the digital era our unique industrybased consultative approach helps clients envision build and run more innovative and efficient businesses headquartered in the us cognizant a member of the nasdaq100 is ranked 195 on the fortune 500 and is consistently listed among the most admired companies in the world learn how cognizant helps clients lead with digital at wwwcognizantcom or follow us on twitter usjobscognizant

cognizant is recognized as a military friendly employer and is a coalition member of the veteran jobs mission our cognizant veterans network assists veterans in building and growing a career at cognizant that allows them to leverage the leadership loyalty integrity and commitment to excellence instilled in them through participation in military service",,NJ,False,data_engineer
Data Engineer,"square root is built on understanding our customers data more deeply than they do and our data engineers are instrumental in that in this role youll take heterogeneous unstructured data mine it for insights and apply it to business problems in innovative ways while you dont need tons of experience youll need to be sharp and possess a genuine interest in using data to solve business problems youll be working side by side with experienced cloud architects and data engineers we want someone that will grow with us and is comfortable with the idea of programming algorithmic thinking and automated testing
sound like your kind of challenge dig in to learn more
the gig
youll design develop and improve our etl engine to allow for rapid customer implementations minimal customer investment data quality and consistency flexibility durability and availability
as part of our implementation process youll work directly with customers to integrate their business data youll work closely with different teams at square root to deliver enhancements ensure operational stability and define  refine product features
youll help expand the scalability of our system and maintain our customer relationships as we adapt to more clients and larger data volumes
were all about driving action from data and that includes putting our own enterprise data at the fingertips of all radicals to empower our own team
about you
you have a bachelors degree in computer science math physics or related field
youve demonstrated your ability as a leader and technologist we currently work with python sql cloud computing linux and kafka
youre able to articulate data insights to nontechnical customers
you should be eager to learn able to adapt and perfect your work  willing to seek out help and put it to good use
our radical culture
our culture is at the core of everything we do we have fun but we work hard so as we grow were not only looking to hire the best and brightest but were also looking for people that share our values this is the code we live by
think big do bigger we think big ideas are meant to be pursued so we think critically and have a bias for action and impact we continually iterate to deliver smarter direction and better software
be customerinspired we aim to overdeliver and delight by doing whats best not just whats expected thats why we make it a priority to understand how our customers operate and the challenges that they face
partner we build strong relationships by having a partnership mindset – internally and externally we go above and beyond to help our customers and one another succeed
thrive we set our internal bar high so that we can bring enthusiasm speed and innovation we revere personal drive growth and balance we celebrate successes and sometimes we just celebrate
the good stuff
founded in austin texas weve been bootstrapped and profitable since our start in 2006 along the way weve added a slew of benefits  perks inspired by our team of radicals heres a sample
flexibility no dress code office hours or vacation policy
competitive benefits and compensation
cozy campus of five 1920s craftsman homes in downtown
radicals get 3000 a year to learn anything seriously
team lunches stocked kitchen  bar coffeesnob compliant coffee machines
square root is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability status protected veteran status or any other characteristic protected by law",,TX,False,data_engineer
Data Analyst,"about us

thrive causemetics was born out of a friendship makeup artist and product developer karissa bodnar lost her dear friend kristy to cancer at just 24 years old kristy’s compassionate and vivacious spirit inspired karissa to establish thrive causemetics a beauty brand and philosophy that goes beyond skin deep by empowering women

thrive causemetics is beauty with a purpose  for every product purchased one is donated to help a woman thrive we believe changing the world starts with a single ingredient and that’s why we create vegan 100 crueltyfree formulas containing proven ingredients without the use of parabens and sulfates all of our highperformance cosmetics are developed with our customer in mind we control every step of the product development process

we are a company that believes everyone is responsible for doing anything and everything to contribute to our teams success this is why we thrive on a collaborative and crossfunctional workplace there is no such thing as thats not my job at thrive causemetics we offer a culture rewarding our driven hardworking team with special perks and benefits together we prioritize strong work ethic while maintaining a positive exciting environment where people are passionate about what they do

the role

the data analyst role at thrive causemetics is a hybrid role combining the skill sets of a data analyst business intelligence analyst and a data engineer you will work cross functionally with all departments helping out with data pipelines dashboard creation inventory forecasting and other ad hoc data requests as needed

responsibilities

creatively solving problems in diverse business areas
analyze customer data to inform our marketing strategy for both ecommerce and brand marketing
create dashboards containing a mix of data visualizations and tables providing real time insights for all departments
qa data to ensure accuracy prior to piping to the data warehouse
extract data from 3rd party tools using built in api’s cleaning the data and piping it into our data warehouse
provide insights into marketing ad performance to improve our ad efficiency
ad hoc data requests and queries as needed
daily  weekly  monthly kpi reporting for marketing operations and ecom
analyze current business processes regarding data and find ways to automate or streamline

qualifications

bachelor’s degree or higher in mathematics statistics economics computer science or related field
2 years of sql experience redshift or vertica experience preferred
12 experience with python for data analytics pandas sklearn matplotlib seaborn
experience with jupyter notebooks
experience working with data in json format
experience connecting to a diverse set of apis with varying authentication processes a plus
experiencing working with ecomm and growth marketing is a plus
periscope experience a plus
aws  s3 experience a plus

",,CA,False,data_engineer
Data Engineer,"if you are looking to join a great company that is committed to delivering highlevel client and employee satisfaction then dev technology is the company for you we are a growing software firm with a stellar history of supporting mission critical applications that protect and serve american citizens

dev technology group is looking for an experienced data engineer this position will have the following responsiblities
support data analysis to enable datadriven decisions by designing building and maintaining data structures and data processing systems
ability to collaborate with stakeholders and draw and communicate insights from data
create conceptual and logical models and support data integration
required skills and experience
minimum of three 3 years of experience in data analysis and software development
experience in java eejavascript programming languages
sql knowledge and experience working with relational databases query authoring sql as well as familiarity with a variety of databases
strong verbalwritten communication and data presentation skills
preferred skills and experience
experience in big data tools such as hadoop
experience data modelingdata visualization tools
experience with aws technologies
experience with aws cli and cloud formation templates
experience working with agile environment
experience working with devops or devsecops
ability to complete application development tasks with javabased technologies preferred
experience with deployment to a government supported cloud environment
education and certifications bachelors degree in computer science information systems engineering business or related field

clearance dhs public trust or the ability to obtain

we offer competitive compensation along with excellent benefits in a teamoriented environment learn more about us at wwwdevtechnologycom

dev technology group provides equal employment opportunities eeo to all employees and applicants for employment without regard to race color religion gender gender identity sexual orientation national origin age disability genetic information marital status amnesty or status as a covered veteran in accordance with applicable federal state and local laws dev technology complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities",,VA,False,data_engineer
Data Engineer,contractjob summaryrequired technical skillsproficiency in sql and plsqldemonstrated experience in decomposing complex problems and provide solutionsexpertise in identifying data relationships data patterns in the data sourced from different subject areasdemonstrated ability to produce visualizations and detailed analysis documentsstrong analytics and algorithm development skillsdemonstrated experience in management of data in sql andor nosql databases postgres oracle teradata hadoopexcellent performance tuning and debugging skills to work on large data setspreferred qualificationsexperience with largescale parallel computing in distributed environmentsexperience in analysis of large spatial and nonspatial datasetsexperience with a multitude of databases in general oracle postgres teradata and sqliteknowledge of statistics and experience using statistical packages for analyzing datasets r excel spss sas python etcknowledgeexpertise in aimlexposure to data visualization tool tableau or any similar toolsstrong programming language skill in net c sql javascript etcgreat technical and problem solving skillsknowledgeable in various software design patterns and be able to apply appropriate design patterns to solve businesstechnical problemsproficient in rdbms such as oracle sql server etc net 3540 with wcf wwf wpf and silverlight sql server 2008 2012 or 2016proficient in java  j2ee  oraclejava  rest apiknowledge of rpa bot tools automation anywhere koreaijob type contract,,TX,False,data_engineer
Data Engineer,40000  45000 a yearcontractabout the jobimpact research is looking for a detail oriented data engineer to support our company for a 3month contract period with the option to extend this position may be remote or onsite at our main facility in columbia maryland in this role you will be responsible for understanding the structure of source data typically flat txt or csv files transforming as needed and uploading data into a postgresql database you will be expected to validate final datasets using sql and document all assumptions and final organization of the dataabout the companyimpact research is a small business located in columbia maryland that specializes in transportation data analysis we are a highly motivated company working on impactful projects in the auto safety and railroad safety industryresponsibilitiesselecting and integrating any tools and frameworks required to provide requested capabilitiesimplementing documenting and maintaining etl processmonitoring etl and data performance and any necessary infrastructure changesbasic qualificationseducation bachelor’s degree in computer science software engineering a related field or equivalent experienceminimum 2 years’ experience working with relational databases such as postgresql or mysqlminimum 2 years’ experience working in linuxunix environmentdemonstrated ability to program in java bash scripting c or python to accomplish project goalsability to communicate with technical and nontechnical team membersdesired qualifications proficient understanding of distributed computing principlesminimum 2 years’ experience working with etl techniques and frameworks such as apache flume sqoop twister or nifiexperience with integration of data from multiple data sourcesexperience with nosql databases such as hbase mongodb or cassandraworking knowledge of big data query tools such as pig hive or impalaexperience working within the aws ecosystem a plusjob type contractsalary 4000000 to 4500000 yearexperienceetl techniques and frameworks 2 years preferrededucationbachelors preferred,42500.0,MD,False,data_engineer
Staff Data Engineer,"location uscasanfrancisco
sponsorship available yes
relocation assistance available no

position description

the staff data engineer is part of the global data science and analytics team the team’s project portfolio includes data analytics for manufacturing business marketing and tire performance associates come from a broad range of backgrounds and collaborate to develop new ways to analyze and model complex processes using the data available throughout the company and elsewhere due to the continuously expanding area of applications of team capabilities there are ample opportunities for team members to assume leadership roles within current projects lead the development of new exciting capabilities as well as explore career opportunities across many goodyear divisions
principal responsibilities
develop an understanding of the business technology manufacturing processes and data science related topics such as data systems data sources data gathering storing and business analytics business reporting procedures  kpis
serve as a specialist in data engineering to support large scale data science initiatives as well as lead data science projects in some instances
grow the technical competencies associated with data engineering within the data science team through the personal development of new skills and integration of new technology into the team

required experience and education
bachelor degree in computer science or related field
masters or phd in computer science or related field desired
3 years’ experience
application of big data technology
database design
designing developing and maintaining data flows
supporting data science and machine learning

personal skillsattributesand qualifications
big data technology eg hdinsightemr hivepig hdfsspark s3blob kafkastormkinesis
database design eg sqlnosql knowledge of database normalization graph database
data flows tools eg python r javascala c git cicd cloudwatch apache airflow rest api
data science tools eg knowledge of machine learning algorithms distributed computing gpu computing model serving
demonstrated leadership skills good communication technical writing skills and ability to work in a team environment

goodyear is one of the world’s largest tire companies it employs about 64000 people and manufactures its products in 48 facilities in 22 countries around the world its two innovation centers in akron ohio and colmarberg luxembourg strive to develop stateoftheart products and services that set the technology and performance standard for the industry for more information about goodyear and its products go to wwwgoodyearcomcorporate
goodyear is an equal employment opportunity and affirmative action employer all qualified applicants will receive consideration for employment without regards to that individuals race color religion or creed national origin or ancestry sex including pregnancy sexual orientation gender identity age physical or mental disability veteran status genetic information ethnicity citizenship or any other characteristic protected by law
if you need reasonable accommodation to complete the online application or any other part of the employment process please contact the goodyear candidate care line at 3307964500
click here for more information about equal employment opportunity laws and here for additional supplementary information",,CA,False,data_engineer
Market Data Engineer - London,"sun trading is looking for a talented market data engineer to join our london office our work environment is open fastpaced and highly professional the market data team is responsible for building and maintaining time series databases as well as analytics infrastructure this infrastructure is used for quantitative research back testing parameter calibration risk data modeling and compliance reporting
responsibilities
assist in developing and maintaining the market data teams kdb infrastructure this includes troubleshooting production issues and automating processes to make the team more efficient
work directly with the trading teams risk managers and compliance officers to identify and fulfill their market data needs
produce reports using market data internally generated data and other data sources analyze and compare new data sources and make recommendations
follow companywide software development policies including documenting code and code changes
build validation to ensure all data adheres to strict quality specifications
required qualifications  skills
bachelor’s degree or higher in computer science computer engineering or equivalent
very strong kdbq skills
exceptional troubleshooting and problem solving skill
a strong work ethic excellent communication skills and the ability to collaborate closely both within market data and with our customers outside the team
additional useful qualifications
working knowledge of building high frequency applications and realtime data processing
experience in python andor shell scripting
working knowledge of c development
understanding of exchange protocols standards and connectivity
experience in the financial services or trading industry
about us
sun trading international limited uk is a leading proprietary trading firm registered with the financial conduct authority we look for certain qualities in our industryleading traders technology professionals and operationalfinancial professionals our most successful applicants are typically both creative and analytical they’re intellectual risk takers who are disciplined in defining and adhering to our processes and procedures taking what you do – not yourself – seriously also is essential
we know that growth creates opportunities to learn new skills and expand what we’re capable of achieving both collectively and individually our firm’s future is always topofmind so continuously developing our upandcoming leaders is a priority sun trading is a meritocracy so exceptional accomplishment and increased responsibilities typically go handinhand
each day our team confronts mindbending challenges contributes valueadded skills and ideas and has the chance to reap the rewards of hard work in addition to highly competitive compensation excellent benefits and continuous educationprofessional development training we also offer the opportunity to be a part of something bigger than yourself
what we offer
excellent remuneration package including annual bonus
employee benefits that include exceptional insurance and fitness membership reimbursement
free inhouse lunch program
encouragement to attend industry related conferences training and continuing education
become part of a uniquely diversified vastly experienced and globally educated team
working on and access to top tier technology and related hardware and software
companysponsored social functions",,OH,False,data_engineer
Data Engineer,ability to perform etl operations on both onpremises and cloud based technologiessetting up instances for batch and real time etl operationsintegration and testing of data of models in development and production environmentsmedium proficiency and experience in implementing aiml codes in distributed node environmentjob type fulltime,,CA,False,data_engineer
Data Engineer,"overview





stansberry research is looking for a talented data engineer to join their business intelligence team this is a role that will collaborate with the technology team in building a world class bidw solution and will have a direct impact in building a culture of data driven decisionmaking where information is timely accurate and actionable

the data engineer will be responsible for integration and transformation of data sources into dimensional models for intuitive consumption this includes designing dwbi solutions for performance efficiency scalability and security you will have an opportunity to use the latest technology platforms in snowflake looker tableau talend and aws rds redshift and s3
responsibilities
work closely with the business and technology teams to create scalable data models for reporting and analytical consumption
identify and understand source data systems and become an expert of data sources and flows
design build and maintain etlelt processes
work with business and technology teams to extract data components related to customers sales marketing and accounting for intuitive consumption in the data warehouse
optimize and tune db schemas for faster performance
explore and recommend technologies and techniques to improve dwbi functions
qualifications
bsba in computer science information systems or related field or equivalent experience
3 years experience in database concepts with handson experience with mysql postgres oracle or mssql
experience in columnar store database concepts with handson experience with snowflake aws redshift or similar
experience working with etlelt tools informatica ibm websphere information integration sap data integrator or ssis and technologies
experience working with bi tools tableau looker business objects cognos microstrategy ssrs and qlikview
experience with scripting languages such as python powershell andor bash
if interested please submit a resume and cover letter to the link provided

about stansberry research
stansberry research is a subscriptionbased publisher of financial information and software serving millions of investors around the world their business is guided by two simple principles
they strive to give their customers the information theyd want if their roles were reversed
they only publish analysts whose advice and strategies theyd want their own families to read and to follow
they believe in offering a range of opinions experienced analysts with their own unique investment strategies and philosophies lead their franchise brands as a result they do not promote a single unified view of the markets but instead they publish a mosaic of opinions recommendations and strategies this multifranchise approach gives their work far greater breadth creating more diverse opportunities for their subscribers their franchises are linked however by a continuous commitment to risk management and a contrarian approach to identifying investment opportunities across all of their franchises they focus on investments that are unloved ignored or unknown it is in these situations where having an informed perspective gives their subscribers the best risktoreward opportunities learn more about stansberry research at httpstansberryresearchcom",,MD,False,data_engineer
Data Engineer,data engineerjoin our seasoned team of data engineering professionals to take your career to the next level as a data engineer you will face the most complex and uptodate challenges by helping our clients address their complex data management reporting and analytical challenges using big data technologies hadoop columnar nosql dbs python and cloud services aws azure gcpminimum requirements1 years of experience in working with global clients in data management and business intelligence using python and hadoop for data managementexperience in writing efficient data management code to support high performance parallelization requirements in complex environments such as distributed and high performance environments cloud and enterprise solutionsexperience in working closely with clientsbachelor’s degree in technology disciplinepreferred requirementsstrong linux and windows administration skillscertifications in cloud platform aws gcp azurestrong python programming and object oriented programming skillsexperience in hadoop based data managementmasters level educationskills  capabilitieswriting complex and high performance data pipelinesability to automate endtoend production data pipelines using automation technologies such as airflow aws emr hadoop aws lambda etcuser data and security administration including integration with enterprise directories and data encryptionstrong understanding of cloud server environmentsstrong understanding of sql 2 years programming languages and other scripting languages eg python perlstrong communication and project management skillsability to work effectively in a global teamjob dutiescreate high performance data pipelines to support complex data integration workflowsdevelop automation programs shell scripts and other utilities to support overall goal of end to end automationproduces a weekly status report documenting project health and progresssupport process flow analysis and etl process redesigndocument and gain approval for customer requirements definitionparticipate in completion and implementation solution documentationparticipate in user acceptance testing efforts as neededparticipate in training design documentation and delivery efforts in concert with other project team membersparticipate in internal projects as requiredjob type fulltimejob type fulltimeexperiencesoftware development 1 year requiredsql 1 year requiredpyspark 1 year required,,NC,False,data_engineer
"Senior Data Engineer, Data Acquisition","applecart deploys proprietary technology to run smarter advertising campaigns we work with some of the nation’s most prominent corporations nonprofit organizations and political candidates to activate and communicate with key target audiences our core offering the social graph leverages publiclyavailable data to map realworld relationships between individuals at a national scale we got our start in politics where we have tested and refined our methods on countless campaigns giving our clients a proven technological edge now we’re branching out beyond political campaigns to tackle new advertising challenges using relational data to provide decisive advantages for our clients

applecart’s political work has been featured by the colbert report cnn the washington post the associated press usa today the huffington post among other prominent news outlets

as a senior data engineer on our data acquisition team you will be responsible for designing building and maintaining scalable systems that acquire enrich and validate the data that feeds our social graph at applecart we live and die on the coverage and quality of our data  your work will directly affect our clients in the form of election outcomes increasing political and nonprofit fundraising yields and optimizing advertising spends and risk assessments

responsibilities

work with large quantities of structured and unstructured data of various integrity in both streaming and batch environments
handle the architecture and implementation of various data stores and schemas across data lakes document stores cache layers and data warehouses
lead the design of containerized autoscaling microservices for data extraction enrichment and validation
lead the design and implementation of testing monitoring and instrumentation across streaming and batch etls restful apis infrastructure and frontend interfaces
collaborate on technical estimates interface design and architectural decisions for crossteam data initiatives
mentor team members in best practices as they relate to objectoriented design testing optimization code reviews etc


basic qualifications

strong grasp of sql python and spark or hadoop
experience designing objectoriented software across all ends of the stack apis pipelines frontend interfaces python clients
experience in both batch using airflow luigi and streaming using pulsar kafka streaming or aws kinesis environments
experience with unit integration and functional testing in a dataintensive environment
experience with data architecture  fundamental understanding of document stores relational databases and data lakes as well as strong schema design
6 years as a software engineer including past ownership over a product or experience leading a team
bachelor’s degree or higher in computer science electrical engineering or related field


prefered qualifications

intermediate to strong understanding of java javascript andor scala
experience with containerization technologies like kubernetes or docker
experience with infrastructure tools such as terraform chef ansible or puppet
experience with search technologies such as elasticsearch solr or analogous tools
experience with web scraping or ocr
startup advertising or fintech experience is a plus
interest in professional growth and mentorship of engineers
interest in adtech politics predictive analytics andor graph technologies",,NY,False,data_engineer
"Data Engineer, Infrastructure Automation","job description
the ideal candidate is a motivated selfstarter with strong business acumen to join the team and build analytics driving actionable insights to accelerate the growth of the business the data engineer will partner with senior leaders product managers and other internal stakeholders to build metrics

this role requires an individual with excellent analytical abilities deep knowledge of business intelligence solutions as well as a passion for problemsolving ideally you are comfortable with ambiguity and accessing and working with data from multiple sources you will analyze large amounts of data discover and solve real world problems and build metrics and business cases around key performance of this program you will be responsible for understanding the health of the service and business and drive necessary changes as needed this is a perfect position for someone who loves data and knows how to work fast and smart

some of the key responsibilities for this position include
propose and implement business metrics for senior management reviewswork with business intelligence and data engineers to design and develop data infrastructure to support business growthenable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable formatperform deepdives to find the root causes behind variances of key parameters over a given timeperioddevelop intelligent insightful selfreporting toolsmanage the data warehouse
key responsibilities
work closely with management software engineering leaders and business teams to plan catalog data improvements so as to maximize customer improvement impacttriage many possible courses of action in a highambiguity environment making use of both quantitative analysis and business judgmentcollaborate with software engineering teams to integrate experimental capabilities into largescale highly complex amazon production systemsreport results in a manner which is both statistically rigorous and compellingly relevantassist in recruiting mentoring developing and training other research scientists as well as other technical roles when needed
basic qualifications
bs degree in mathematics statistics computer science or a similar quantitative field
3 years work experience in relevant field
experience in using sql to analyze data in a database or data warehouse and be able to use a major programming eg javac andor a scripting language perl unix shell python to process data for modeling
experience working with a wide range of predictive and decision models and data mining techniques as well as tools for developing such models
preferred qualifications
experience in data modeling etl development and data warehousing
experience buildingoperating highly available distributed systems of data extraction ingestion and processing of large data sets
experience with aws services including s3 redshift emr and rds
data warehousing experience with oracle redshift etc
experience with software coding practices is a strong plus
experience using linuxunix to process large data sets
meetsexceeds amazon’s leadership principles requirements for this role
meetsexceeds amazon’s functionaltechnical depth and complexity for this role
amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,CA,False,data_engineer
Data Engineer PSJH,"providence is calling a data engineer – psjh to providence health  services in either of the following locations renton wa seattle wa portland or beaverton or or anaheim ca
we are seeking a data engineer – psjh who designs and builds modern datacentric software applications to support clinical and operational processes across all parts of the health system these applications leverage cloud computing big data mobile data science and modern software development methodologies and frameworks builds the data pipelines enrichment processes provisioning layers apis and user interfaces to meet the requirements of key initiatives enjoys a fast pace and has a focus on regular delivery seeks simple solutions to complex problems through the use of modern and emerging methods and tools emphasizes sharing and enables collaboration with meticulous source control and documentation works closely with the product platform and architecture teams to deliver on joint efforts

in this position you will have the following responsibilities
design build and deliver quantitative applications that improve operations and generate value
participate in devops agile and continuous integration frameworks
stay abreast of emerging technologies open source projects and best practices in the field
data warehousing big data enterprise search business intelligence analytics modern and mobile applications
build processes that are faulttolerant selfhealing reliable resilient and secure
work effectively and in realtime with other developers product managers and customers to deliver on collective goals
actively participate in code reviews support the overall code base and support the establishment of standard processes and frameworks
take an open and transparent approach to the work by sharing code and expertise by consulting peers for problemsolving and by being a mentor to your peers
required qualifications for this position include
bachelor’s degree in in computer science engineering mathematics mis or similar field
3 years in technology roles
demonstrated analytical skills
demonstrated problem solving skills
possesses strong technical aptitude
cloud computing linux hadoop mapreduce spark hbase kudu and nosql platforms in general apache solr and lucene
java scala c python shell scripting andor similar languages
relational database platforms database design and sql
apis json rest and other relevant w3c open standards
modern application development frameworks
familiarity with commercial or open source etl tools
preferred qualifications for this position include
master’s degree",,CA,False,data_engineer
Data Engineer,"about earnin
our financial system is fundamentally unfair for people who live paycheck to paycheck people shouldnt have to wait weeks to get the pay theyve already earned this wait forces them to spend more than 100 billion a year on shortterm credit products late fees and overdraft fees

earnin helps people overcome this unfairness by giving them realtime access to their money as soon as they have worked  without fees or interest

our team is bound together by a desire to level the financial playing field our investors andreessen horowitz ribbit capital felicis ventures matrix partners and march capital believe we will change the world

you can help make a difference join us

about the team
we are a data driven mobile financial tech company and were looking for a data engineer to join us and help us build out our data infrastructure to aid in our mission of enabling people to gain access to their paycheck on demand

data engineers are an important function to interact with every team within earnin and you will be interfacing heavily with our analytics engineering and data science teams to help them advance our product utilizing machine learning intelligence

as a data engineer you will

focus on designing building and launching efficient and reliable data infrastructure to scale and compute for our business
help us build a world class data lakedata warehouse by building data pipelines
design and develop new systems and tools to enable folks to consume and understand data faster
use your expert coding skills across a number of languages from python java c go etc
work across multiple teams in high visibility roles and own the solution endtoend
design build and launch new data extraction transformation and loading processes in production
work with data infrastructure to triage infra issues and drive to resolution

some skills we consider critical to being a data engineer

bs or ms degree in computer science or a related technical field
advanced knowledge of java familiarity of python
familiarity with hadoop stack spark aws glue aws athena etc
diverse data storage technologies rdbms sql server mysql elasticsearch dynamodb s3 etc
deep familiarity with schemas metadata catalogs etc
ability to manage and communicate data warehouse plans to internal clients
strong communication skills including the ability to identify and communicate data driven insight

",,CA,False,data_engineer
Data Engineer,contractdata engineermarietta gacontractmdi group is seeking a data engineer for a project in marietta ga in this role you will be responsible for extracting transforming and loading data from an erp data source into a data repository for operational reporting we seek your experience in pulling this data from various data sources and loading this data into another database  data source this role is key to contributing to business intelligence solution delivery and development programming of datadriven reports day to day operations of reports bi dashboards and other bi toolsrequired skills  experience 5 years of experience in data engineeringexperience developing solutions to extract data from various data sources for loading into a data source for operational reportingreach out to mdi group today to learn more about this excellent opportunitycontactkaci raileykrailey at mdigroup dot comkrailey  mdigroup comin person interview required in marietta ga no skypejob types fulltime contractjob type contract,,GA,False,data_engineer
Data Engineer - Liquid Studios Boston,"accenture is a leading global professional services company providing a broad range of services and solutions in strategy consulting digital technology and operations combining unmatched experience and specialized skills across more than 40 industries and all business functions – underpinned by the world’s largest delivery network – accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders with approximately 425000 people serving clients in more than 120 countries accenture drives innovation to improve the way the world works and lives visit us at wwwaccenturecom
are you willing to come and shape the future of technology at the liquid studios we are part of accenture’s innovation architecture working on helping companies understand how to apply bleeding edge technologies like ai iot and blockchain to their business

the studio typically works on short projects our engagements usually last less than 12 weeks based out of the boston studio our engagements use the latest of devops agile and serverless to make sure that we deliver the value in a short period of time
job description

data engineers will create the foundations used to power the datadriven applications that are changing how businesses operate including realtime data feeds for iot devices distributed ledgers using blockchain or large data sets used for training machine learning algorithms
design implement and deploy custom applications using realtime data streams andor big data platforms
collect create and structure data sets from disparate sources to be able to leverage them for machine learning applications
build data pipelines to ingest transform and analyze data in artificial intelligence and analytics systems
design data architectures that address specific client needs using combinations of relational databases nosql databases and unstructured file stores in both cloud and onpremise settings
develop solutions and iterate rapidly
ensure code and design quality through the execution of test plans and assist in development of standards methodology and repeatable processes working closely with internal and external design business and technical counterparts

basic qualifications
minimum 2 years of handson technical experience implementing or supporting big data or realtime analytics solutions
high level of competence in sql python andor scripting languagesbachelor’s degree or associate’s degree with 6 years of work experience or equivalent work experience of 12 years
ability to travel about 10 of the time

preferred qualifications

• full life cycle development experience
experience with delivering big data solutions in the cloud with aws azure or google cloudability to configure and support api and opensource integrationsexperience administering hadoop or other data science and analytics platforms using the technologies aboveexperience working with devopsdesigning ingestion low latency visualization clusters to sustain data loads
experience developing solutions utilizing any of the following
o apache kafka or aws kinesis based streaming services
o relational and nonrelations databasesnosql
o amazon s3
o scala spark
o jenkins chef puppet

applicants for employment in the us must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the united states and with accenture


candidates who are currently employed by a client of accenture or an affiliated accenture business may not be eligible for consideration


accenture is a federal contractor and an eeo and affirmative action employer of femalesminoritiesveteransindividuals with disabilities


equal employment opportunity
all employment decisions shall be made without regard to age race creed color religion sex national origin ancestry disability status veteran status sexual orientation gender identity or expression genetic information marital status citizenship status or any other basis as protected by federal state or local law


job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process


accenture is committed to providing veteran employment opportunities to our service men and women",,MA,False,data_engineer
"Data Engineer, ETL","company overview


marketing evolution has been recognized by forrester as the industry leader in marketing optimization due to our bigdata personcentric decisionmaking saas platform marketing evolution has announced 206m in new 2018 funding from toptier global private equity and venture capital firm this funding will used to help us continue to lead product innovation focused on customer obsessed marketers our award winning platform the roi brain helps companies fully unlock the power of customer relationships and use insights to make the overall business more effective efficient and profitable our customers – including many fortune 500 brands – choose marketing evolution because they recognize the value of moving beyond the aggregated and backwardlooking limitations of marketing mix and attribution models due to very fast growth we are hiring at all levels but know that our preference is always to promote from within
position overview
marketing evolution provides marketing roi insights to fortune 500 companies by aggregating and analyzing vast amount of both public and proprietary data feeds as a data engineer you will be responsible for building and supporting etl pipelines to make data consumable by our predictive analytics process
responsibilities
design and implement new etl pipelines based on client business logic
optimize and scale existing etl pipelines
develop tools to support etl platform
perform adhoc queries to support client teams
technologies we use
python spark aws airflow bash docker sql scala hive
skills and experience

required
strong communication skills relating technical work to nontechnical people
bachelor’s degree or higher in a relevant technical field or comparable work experience
competence in python and sql
working knowledge of unix systems such as fedora centos redhat etc
understanding of data quality best practices
preferred
experience working with big data technologies such as hadoop hive pig spark presto etc
experience working in a cloudbased infrastructure such as amazon aws or cloudera
competence in at least one oop language such as java scala c etc
experience working with nosql database technologies such as mongodb cassandra etc
metrics for success
all employees have annual career growth goals based on their position and core skillsdevelopment areas you’ll receive projectbased performance reviews quarterly and career reviews biannually
customer satisfaction and the ability to drive large efficiency gains are the most important measures of success
marketing evolution cultural values
we seek candidates who are excited to work at a company with the following cultural values
disrupt the norm cherish the opportunity to find better ways to do things regardless of how disruptive or initially painful it might be
dissent then execute raise issues and fixes in the planning stage but when it’s time to execute execute diligently and without reservation
test and learn when developing new processes or features link it to a hypothesis and evaluate that hypothesis without bias
nothing is impossible imagine what’s possible and then have the discipline to execute it one without the other is not valuable
defect is treasure every mistake is an opportunity for the organization to learn and make improvements
share success given how hard it is to promote change in our industry celebrate each success along the way",,NY,False,data_engineer
Biotech Data Engineer Intern,"internshipwe are seeking a motivated biotech data engineer intern this position will be located in chesterfield missouri reporting to our data analyst and reporting lead and our data engineering lead
the successful candidate will join a team of developers in the biotechnology and chemistry organization that focuses on development and integration of next generation it platforms and solutions to deliver automated outcomes across biotechnology and chemistry this internship will center around improving laboratory analytics and infrastructure

this internship will be offered from mayaugust of 2019
responsibilities may include
analysis of laboratory software architecture and databases for novel new data integrationmessaging capabilities
development of cloud based etl processes aggregating data applying decision framework and automating outcomes throughout the organization
development of a standalone tool to facilitate lab information management

required skillsexperience
currently enrolled at a university within the us pursuing an undergraduate or graduate degree in computer science or majoring in life sciences or engineering with a minor in computer science
30 gpa on a 40 scale
must be returning to school to continue program of study upon completion of internship
experience with common programming languages for example java javascript c netc
experienced with relational andor graph databases
desired skillsexperience

experience with cloud computing platforms such as aws google cloud or microsoft azure
experience with git and docker
bayer successfully completed the acquisition of monsanto in june 2018 bringing together monsanto’s leadership in seeds and plant traits with bayer’s leadership in chemical and biological crop protection by joining forces we will create even more extensive career opportunities for talent around the world we’re a global team working to shape agriculture through breakthrough innovation that will benefit farmers consumers and our planet

while we are now bayer we will continue to hire using separate career sites until we can integrate our career platforms we invite you to explore the career opportunities available at the combined company by visiting advancingtogethercomcareers",,MO,False,data_engineer
Big Data Engineer,hii would like to share an excellent opening full time “big data engineer” do go through the details and kindly send me the updated resumelocation  charlotte  ncclient  cognizanttype of hire  full timejob description big data engineers hive spark pythonjob type fulltimeexperiencespark 1 year preferredpython 1 year preferredhive 1 year preferred,,NC,False,data_engineer
Data analyst,contractjob summaryskills needed expert level spark azure data engineeringo additional skills etl processes data pipelines sqloverall 10  years of experience as a data engineercommunication level 1010 and highly collaborativeanalytical mindset to solving a problemalmost a consultant like mind set of going into a project ready to rock and getting things done for the duration of the contractprevious leadership experience is a huge plusthanks  regardskanthibusiness development managermxpractice  alpharetta ga 30004contact number  17704060486job type contract,,WA,False,data_engineer
Data Engineer,"tradesy is a peertopeer marketplace for women’s designer fashion that’s pioneering a sustainable future for commerce backed by top tier venture capital firms our mission is to make the resale of consumer goods as simple safe and stylish as retail at scale we have millions of passionate members a product that people love and an office with an ocean view in sunny santa monica california

tradesy is seeking an exceptionally talented data engineer who works closely with other engineers data scientists architects and product owners to develop reliable efficient and scalable systems
the ideal candidate enjoys being heavily involved in the planning and design of our data pipelines storage warehouses and applications as we migrate and replatform our systems from aws to google cloud
you will
build and automate reliable data pipelines using batch and streaming technologies
design and test etl systems using the latest technologies
collaborate with other software engineers and data scientists to develop data driven applications
become a data warehousing expert if you aren’t already one and work with others to gain key insights
you have
excellent communication and collaboration skills
coding proficiency in at least one of java python c go scala
strong computer science skills with a focus on algorithms and data structures
experience querying data using sql andor nosql
familiar with mapreduce and other big data concepts
experience with batch processing technologies ie hadoop spark apache beam flink
pluses
understand trade offs among data formats such as csv json avro parquet
experience with stream processing technologies such as apache beam spark streaming flink kafka streams
etl experience on aws using emr firehose lambda
etl experience on google cloud using dataproc cloud functions dataflow
experience using a data warehouse such as redshift or bigquery
familiar with messaging systems such as kinesis kafka pubsub
familiar with automation tools such as apache airflow luigi aws data pipeline
compensation
competitive base salary plus meaningful equity
comprehensive benefits medical dental vision 401k
flexible paid time off
additional perks
daily catered lunches
dog friendly office
collaborative fun team",,CA,False,data_engineer
Data Engineer - Clinical Innovation,"strength through diversity

ground breaking science advancing medicine healing made personal
clinical innovation  req 2279732
data engineer
roles  responsibilities
are you ready to discover the limitless possibilities of big data analytics and machine learning on improving the patient’s care are you interested in learning and developing machine learning data product

the data engineer will work on learning and creating batch and streaming machine learning pipeline for accelerating translational research and improving clinical care day to day responsibilities include

create machine learning pipeline using bigdata technology stacks
work on python apache spark kafka mongodb and machine learning
additional responsibilities include developing prototypes and proof of concepts for the selected use cases and implementing complex machine learning pipeline
requirements
education masterphd degree in engineering eg computer science  biomedical informatics physics statistics

experience

good knowledge with at least 1 programming languages among
scalapythonjavacc
must be flexible and fast to pick up new languages
basic knowledge big data technology stacks like apache spark apache
kafka nosql and machine learning
preferred qualification

handson experiences on apache spark kafka mongodb apache nifi and other big data technology stacks and streaming tools
familiarity with and the ability to leverage a wide variety of open source technologies and tools
knowledge of cloud architecture and implementation on azure or aws is a big plus
strength through diversity

the mount sinai health system believes that diversity is a driver for excellence we share a common devotion to delivering exceptional patient care yet we’re as diverse as the city we call home culturally ethically in outlook and lifestyle when you join us you become a part of mount sinai’s unrivaled record of achievement education and advancement as we revolutionize medicine together

we work hard to acquire and retain the best people and to create a welcoming nurturing work environment where you can develop professionally we share the belief that all employees regardless of job title or expertise can make an impact on quality patient care

explore more about this opportunity and how you can help us write a new chapter in our story

who we are

over 38000 employees strong the mission of the mount sinai health system is to provide compassionate patient care with seamless coordination and to advance medicine through unrivaled education research and outreach in the many diverse communities we serve

formed in september 2013 the mount sinai health system combines the excellence of the icahn school of medicine at mount sinai with seven premier hospital campuses including mount sinai beth israel mount sinai beth israel brooklyn the mount sinai hospital mount sinai queens mount sinai west formerly mount sinai roosevelt mount sinai st luke’s and new york eye and ear infirmary of mount sinai

the mount sinai health system is an equal opportunity employer we promote recognition and respect for individual and cultural differences and we work to make our employees feel valued and appreciated whatever their race gender background or sexual orientation

eoe minoritieswomendisabledveterans",,NY,False,data_engineer
Business Intelligence - Data Engineer,"are you passionate about diving into data unraveling the complexities and building powerful business intelligence solutions
yelp’s business intelligence and data integration team works with groups throughout the organization and data from an array of diverse sources the team creates business intelligence solutions that enable business leaders to make quicker more informed decisions
you might be a great fit for this role if you are adept at data warehousing concepts including data profiling and analysis data extraction and transformation and dimensional modeling you should also be very comfortable working with multiple teams and various levels of management to explore opportunities elicit requirements and collaborate on reporting and analytics projects
what you will do
partner with business partners to understand data needs how business processes are accomplished in various data systems business rules and definitions and current data and reporting challenges
analyze source system data and design and implement etl pipelines relational and dimensional data models and other business intelligence infrastructure to address needs
create and distribute business and technical documentation and train analysts engineers and business partners
become a subject matter expert on yelp’s data and share knowledge with analysts engineers and business partners
explore emerging trends and new technologies to continue to improve yelp’s business intelligence capabilities
we are looking for
degree in computer science or related field
3 years professional experience building etl jobs performing dimensional modeling and using sqlscripting languages in a bi context
excellent working experience creating and optimizing complex sql queries
excellent working experience writing etl jobs snaplogic preferred and using scripting languages python preferred
working experience with rest soap and other web api technology
good understanding of financial management and human capital management systems like oracle ebs and workday and crm systems like salesforce
knowledge of open source technologies like kafka hadoop hive presto and spark is a plus
experience with redshift database administration is a plus
pursuant to the san francisco fair chance ordinance we will consider for employment qualified applicants with arrest and conviction records",,CA,False,data_engineer
Lead Data Engineer,"thoughtworks is a global software consultancy made up of around 4500 passionate technologists across 15 countries we specialize in strategy portfolio management and product design combined with digital engineering excellence

as a lead data engineer heres what well be looking for you to bring


handson engineering leadership
proven track record of innovation and expertise in data engineering
tenure in coding architecting and delivering complex projects
deep understanding and application of modern data processing technology stacks for example spark hadoop ecosystem technologies and others
deep understanding of streaming data architectures and technologies for realtime and lowlatency data processing
deep understanding of nosql technologies including column family graph document and keyvalue data storage technologies
understanding of how to architect solutions for data science and analytics such as productionizing machine learning models and collaborating with data scientists
understanding of agile development methods including core values guiding principles and key agile practices
understanding of the theory and application of continuous integrationdelivery
passion for software craftsmanship
a rich breadth of industry experience and background working across different organizations ranging in size from startups to large corporations
strong stakeholder management and interaction experience at different levels

theres no typical day or engagement for our senior data engineers heres what youll do


be the sme develop modern data architectural approaches to meet key business objectives and provide end to end data solutions
you might spend a few weeks with a new client on a deep technical review or a complete organizational review helping them to understand the potential that data brings to solve their most pressing problems
on other projects you might be acting as the architect leading the design of technical solutions or perhaps overseeing a program inception to build a new product
it could be much more about getting stuck into a delivery project where youre equally happy coding and tech leading the team to implement the solution
whatever your role the team always look to draw on your experience when things get tough and you often handle the difficult client conversations allowing the team to continue delivering without undue pressure
you have great relationships with our new business team and work collaboratively to support presales meet prospective clients and ultimately influence and shape our portfolio of work
you recognize that building your network with a client is absolutely key to enable you to perform in your role youll be drawing on all of your passion for technology handson experience and knowledge of latest big data and engineering best practices to help you gain the respect and credibility of those around you

a few important things to know

travel is required projects are almost exclusively on customer site so thoughtworkers need to be flexible and up for extensive travel most of our consultants travel every week and fly home for weekends we do our best to take peoples personal situations into account but we know its not for everyone
residing near one of our north america offices in chicago dallas new york atlanta or san francisco is preferable although not necessary

not quite ready to apply or maybe this isnt the right role for you

thats ok you can stay in touch with accessthoughtworks  httpswwwthoughtworkscomcareersaccessutmsourceapplyjobsutmmediumjdutmcampaignaccessthoughtworks  our learning community tick contact me about recruitment opportunities to hear about jobs in the future

lina",,NY,False,data_engineer
BI Data Engineer,"renew financial is the nation’s leader in affordable financing products for renewable energy and energy efficiency projects that will help move america toward a clean energy model we originated the property assessed clean energy pace model an innovative lowcost financing solution that helps homeowners make improvements that dramatically reduce their energy and water use  and repay on their property taxes
as a data engineer with a focus on data visualizations you will join our business intelligence team dedicated to empowering renew financial to make data driven decisions positioned in the information technology group you will work across various business units risk sales finops operations product government relations etc to create bi reports dashboards and improve existing reporting processes solid communication skills and building interdepartmental relationships are critical to success in this role your work here will directly contribute to a shared vision of selfservice data analytics
ideal candidate
passion for using data visualization tools to turn complex data sets into actionable insights
proven success in requirements gathering scoping projects and delivery timely results
sql is your second language you write sql in your sleep and have a keen eye for performance tuning
strong data analysis skills and kpi development
passionate about promoting data literacy and training the business on new tools and technology
tool agnostic you care about using the right tool for the right job
job responsibilities
 develop both operational and analytical reports
 translate business users’ needs into bi implementations
 design build and deploy tableau dashboards in the form of ongoing and adhoc reporting
 educate business users on tableau usage and best practices
 investigate data discrepancies working with data engineers and developers to identify root cause
 identify opportunities to bring data to life in newcreative ways
required skills and knowledge
2 years of experience using data visualization tools to develop dashboards and reports
proficient in sql
bachelors degree in computer science or related field stem degree
strong data analysis
proficient in tableau
familiarity with postgres aws github
knowledge of star schema data models
nice to have
scripting language such as ruby python r",,GA,False,data_engineer
Azure Data Engineer,"resolvit
bringing solutions that make business better
we are seeking an azure data engineer to be part of a creative forwardthinking team our success at deploying skilled highly knowledgeable experts has landed us on the inc 5000 list of america’s fastestgrowing companies four times – and we’re just getting started
as the azure data engineer you will develop sustainable data driven solutions with new data technologies to meet the needs of our organization and business customers you will build robust endtoend systems with an eye on the long term maintenance and support of the application you will also leverage reusable code modules to solve problems across the team and organization additionally you will
handle multiple functions and roles for the projects and agile teams
work with established standards across the team and organization
understand complex multitier multiplatform systems
contribute to building a framework of a significant complexity
work with internal team of data engineers both fulltime associates andor third party resources
what you’ll need to be successful
at least 5 years of coding or data warehousing or unstructured data environments experience
at least 2 years of experience with azure cloud technologies
at least 2 years of experience with big data technologies cassandra hbase spark hadoop hdfs avro mongodb zookeeper or similar
at least 2 years of experience with agile engineering practices
bachelor’s degree
strong problem solving and conceptual thinking abilities
excellent communication interpersonal and leadership skills
desire to be part of cutting edge high profile projects
a love for learning new technologies and mentoring junior analysts to raise the bar on your team
passionate about intuitive and engaging user interfaces
we currently have more than 100 open career opportunities across the country so be sure to mention the appropriate job code with any correspondence
about resolvit
resolvit is an international technology consulting firm with industryleading customers in the financial services high tech manufacturing retail life sciences and government sectors through its partnerships resolvit delivers highly impactful innovative solutions across five core areas infrastructure modernization application development services enterprise data management  analytics knowledge  content management and strategic staffing",,PA,False,data_engineer
Big Data Engineer -Spark,"who is blueprint

blueprint technologies is a group of solutionminded thinkers changing the face of consulting in bellevue wa we follow a mission vision and core values that allow us to function as a collaborative unit

what are our solutions

blueprint provides strategic and professional consulting services as well as technical delivery for companies of all sizes and market segments we bridge the gap between the segments for a complete solution for our clients allowing us to be a partner from idea to implementation

why you want to be a part of blueprint

working at blueprint will change the way you think about the typical consulting job we want you to be accountable and make decisions that positively impact the client our people are our solutions we work together and collaborate to make sure our offerings and execution are always superior we also have a great benefits package offering medical dental vision 401k pto and company events throughout the year

blueprint is looking for big data engineers to join us as we build cuttingedge technology solutions

note we are not able to sponsor visa candidates at this time must be able to work on a w2 basis

qualifications

experience with spark with knowledge of how spark and other big data tools work 3 years
experience with hadoop 2 years
experience with scala 3 years and java skills
experience with github andor other versioning tools
advanced experience with software development in an open source environment 5 years
ability to quickly learn new technologies application domains and adapt to changes
ability to develop simple elegant solutions to complex problems
ability to handle multiple competing priorities in a fastpaced environment

preferred qualifications

experience with pythonr andor functional languages like clojurehaskell 3 years
experience with cloud technologies preferably azure
experience with change data capturedata lineage preferred
experience with agile software development methodology and continuous delivery models
experience with team building and mentoring
bachelors or masters degree in computer science computer engineering or related discipline preferred

",,WA,False,data_engineer
Sr. Health Sensing Data Engineer,"our team is growing here is your opportunity to come and join an exciting engineering team responsible for building nextgeneration health sensors and features the human interface devices team is looking for talented and passionate engineers with expertise in data pipelines and infrastructure this is an integral role where you will help design develop and support high quality scalable data platforms and applications for analysis of machine user and sensor data

key qualifications
strong software development skills with proficiency in relevant languages such as python java
extensive experience with spark andor hadoop mapreduce
exposure to web frameworks such as django flask
familiarity with cloudbased infrastructure such as aws and docker
practical experience with sql and nosql databases mysql postgres mongodb cassandra hbase etc
creative and collaborative
description
as a senior data engineer in this central role you will own data pipelines work with the data engineering team to develop general use tooling and collaborate with the algorithm and qa teams to design and validate the pipelines and tooling your work will directly impact the development of features across multiple apple hardware platforms
additional responsibilities include
scaling our existing data pipelines
parallelization of data processing tools and frameworks and platform virtualization
supporting data collection and curation and handling large datasets
working closely with data scientists and algorithm engineers

education
bachelor or master degree in computer science 3 years of programming experience 1 year distributed computing with spark
apple is an equal opportunity employer that is committed to inclusion and diversity we also take affirmative action to offer employment and advancement opportunities to all applicants including minorities women protected veterans and individuals with disabilities apple will not discriminate or retaliate against applicants who inquire about disclose or discuss their compensation or that of other applicants",,CA,False,data_engineer
Principal Big Data Engineer,"req id 32803

at ntt data services we know that with the right people on board anything is possible the quality integrity and commitment of our employees are key factors in our company’s growth market presence and our ability to help our clients stay a step ahead of the competition by hiring the best people and helping them grow both professionally and personally we ensure a bright future for ntt data services and for the people who work here

ntt data services currently seeks a principal big data engineer to join our team in durham north carolina usnc united states us

primary responsibility
as a principal data engineer you must be an expert with big data technologies like hadoop hive hbase spark and various aws technologies
you will architect and drive the build out of next generation data platform
as a handson engineer you will influence all architecture decisions
you will build reusable code with the ability to scale with very large data volumes
everything you build will need to scale and perform
as a principal member on the team you will also mentor juniorsenior engineers on the team
define and lead the frameworks for compliance with data management standards for emerging technologies streaming platforms cloud integration etc
you will architect and drive the build out of next generation data platform
general responsibilities
build and lead highperforming agile teams focused on data engineering
be part of a core team leading migration to new data technologies for unstructured streaming and high volume data
overall accountability for ensuring teams adopt established data management frameworks to prevent data lakes from becoming data swamps
provide senior level technical consulting to application development teams during application design and development for highly complex or critical projects
as a handson engineer you will influence all architecture decisions
as a principal member on the team you will also mentor juniorsenior engineers on the team
job functions
provide technical leadership to build and implement data and big data solutions
articulate pros and cons of various technologies platforms and tools
demonstrated work experience with distributed scalable big data programming model and technologies such as hadoop hive pig etc
demonstrated handson experience with atleast one of the major hadoop distributions preferrably cloudera
deep technical expertise in hadoop eco system components
experience designing developing and implementing onlinemachine learning libraries
minimum experience

10 years of data engineering experience
8 years’ experience in dimensional data modeling etl development and data warehousing
5 years of experience in hadoop mapreduce hive pig spark and yarn
4 years of business experience leading analyses and initiatives with track record of business impact
cloud dev and migrationawsanalyticsdwredshift  1 year

travel need locals
degree bachelors in computer science or equivalent work experience

desirable skills
hadoopcloud developer certification
experience deploying applications in a cloud environment ability to architect design deploy and manage cloud based hadoop clusters
exposure to cloud infrastructure

this position is only available to those interested in direct staff employment opportunities with ntt data inc or its subsidiaries please note 1099 or corp2corp contractors or the equivalent will not be considered we offer a full comprehensive benefits package that starts from your first day of employment

about ntt data services

ntt data services partners with clients to navigate and simplify the modern complexities of business and technology delivering the insights solutions and outcomes that matter most we deliver tangible business results by combining deep industry expertise with applied innovations in digital cloud and automation across a comprehensive portfolio of consulting applications infrastructure and business process services

ntt data services headquartered in plano texas is a division of ntt data corporation a top 10 global business and it services provider with 118000 professionals in more than 50 countries and ntt group a partner to 88 percent of the fortune 100 visit nttdataservicescom to learn more

ntt data inc the “company” is an equal opportunity employer and makes employment decisions on the basis of merit and business needs the company will consider all qualified applicants for employment without regard to race color religious creed citizenship national origin ancestry age sex sexual orientation gender identity genetic information physical or mental disability veteran or marital status or any other class protected by law to comply with applicable laws ensuring equal employment opportunities to qualified individuals with a disability the company will make reasonable accommodations for the known physical or mental limitations of an otherwise qualified individual with a disability who is an applicant or an employee unless undue hardship to the company would result",,NC,False,data_engineer
Data Engineer,"job description
amazon lab126 is an inventive research and development company that designs and engineers highprofile consumer electronics lab126 began in 2004 as a subsidiary of amazoncom inc originally creating the bestselling kindle family of products since then we have produced groundbreaking devices like fire tablets fire tv fire phone and amazon echo what will you help us create

work hard have fun make history

the role
we are seeking a talented selfdirected data engineer to design develop implement test document and operate largescale highvolume highperformance data structures for our internal customers implement data structures using best practices in data modeling and etlelt processes gather business and functional requirements and translate these requirements into robust scalable operable solutions that work well within the overall data architecture analyze source data systems and drive best practices in source teams participate in the full development life cycle endtoend from design implementation and testing to documentation delivery support and maintenance produce comprehensive usable dataset documentation and metadata evaluate and make decisions around dataset implementations designed and proposed by peer data engineers evaluate and make decisions around the use of new or existing software products and tools mentor junior data engineers

the ideal candidate relishes working with large volumes of data enjoys the challenge of highly complex technical contexts and above all else is passionate about data and analytics heshe is an expert with data modeling etl design and business intelligence tools and passionately partners with the business to identify strategic opportunities where improvements in data infrastructure creates outsized business impact heshe is a selfstarter comfortable with ambiguity able to think big while paying careful attention to detail and enjoys working in a fastpaced team the ideal candidate needs to possess exceptional technical expertise in large scale data warehouse and bi systems with handson knowledge on sql distributedmpp data storage and aws services s3 redshift emr rds

specifically the data engineer will
design implement and support a platform providing ad hoc access to large datasets
interface with other technology teams to extract transform and load data from a wide variety of data sources using sql
implement data structures using best practices in data modeling etlelt processes and sql and redshift
build robust and scalable data integration etl pipelines using sql python and spark
build and deliver high quality datasets to support business analysis and customer reporting needs
interface with business customers gathering requirements and delivering complete data structures
basic qualifications
bachelors degree in computer science computer engineering business administration mathematics or a related field
3 years of industry experience as a data engineer or related specialty eg business intelligence engineer data scientist
experience in data modeling etl development and data warehousing
data warehousing experience with oracle redshift teradata etc
experience providing technical leadership and mentor other engineers for the best practices on the data engineering space
experience in continually improve ongoing reporting and analysis processes automating or simplifying selfservice support for customers
experience building data products incrementally and integrating and managing datasets from multiple sources
experience buildingoperating highly available distributed systems of data extraction ingestion and processing of large data sets
preferred qualifications
experience leveraging python r or matlab to manipulate data and set up automated processes as per business requirements
experience with big data technologies hadoop hive hbase pig spark etc
experience leading largescale data warehousing and analytics projects including using aws technologies – redshift s3 ec2 datapipeline and other big data technologies
strong ability to interact communicate present and influence within multiple levels of the organization
track record of manipulating processing and extracting value from large datasets
excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions
masters degree
amazon is an equal opportunity employer – minority  women  disability  veteran  gender identity  sexual orientation",,CA,False,data_engineer
Sr. Big Data Engineer,who we are aunalytics is a data science software and analytics service company with a mission to harness the power of data and use it to fuel the economic engine of growing companies communities and people we offer an endtoend cloud analytics platform that was designed to manage and automate data ingestion compute resources data set creation advanced data science and accelerated data interaction—allowing dramatically increased speed to analytical insights for businesses aunalytics also provides analytics solutions for specific business objectives with a focus on digital consumer enterprise and iot applications across a wide variety of industries we focus on providing indisputable value to our clients by acting as their trusted data and analytics partner and by creating powerful tools to help companies realize the full potential in their dataposition overview as a big data engineer you will be responsible for developing maintaining testing and evaluating big data solutions utilized within aunalytics you will be a member of the software team but work closely with our infrastructure teamessential duties  responsibilities implement support and maintain big data tools and frameworksassist in the development of deployment automation and operational support strategiesdeliver nearreal time and nonnearrealtime data and applications to a team of analysts and data scientists who create insights and analytics applications for our stakeholdersrequired skills understanding of modern data structures and reporting toolsexperience designingintegrating heterogeneous software systemsexperience building microservices using javascript nodejs expressjs or pythonresourceful in getting things done selfstarter and productive working independently or collaboratively – ours is a fastpace entrepreneurial environment with performance expectations and deadlinesability to learn quickly and contribute ideas that make the team processes and solutions betterability to communicate your ideas verbal and written so that team members and clients can understand themability to defend your professional decisions and organize proof that your ideas and processes are correctshare our values growth relationships integrity and true gritpreferred skills bs or equivalent in a computational discipline computer science applied mathematics engineering or related field preferredthree or more years of handson experience with big data systems such as hadoop apache spark apache drill apache alluxio and dockerexperience with large distributed data and systemsexperience developing and managing data warehouseswhats in it for youopportunity to work in the booming field of data science alongside some of the brightest minds in the industryopportunity to work with cuttingedge technology in a casual fun environmentopportunity to be a part of a local company committed to making a difference in our communitychance to work with a rapidly expanding tech companyflexible schedule and paid time offfree snacks and an unlimited supply of coffeesocial events such as happy hours game nights holiday parties birthday celebrations movie days ice cream sundae bars fancy coffee carts company softball team etccompetitive salary and benefits package including health vision dental and life insurancejob type fulltimework authorizationunited states required,,IN,False,data_engineer
Data Engineer,"atger noun rockstar of atg – selfmotivated entrepreneurial driver of change not afraid to challenge processes and get stuff done gsd collaborate take risks and problem solve oh and we really like office dogs and breakfast burritos

perks noun all the good stuff and more fully stocked kitchens competitive paid time off and medical benefits outdoor “walk and talk” meetings where you will solve global complex business problems – all while eating a breakfast burrito
advanced technology group atg is a leader in quotetocash advisory and implementation services to both midmarket and large enterprise brands seeking increased agility in the “everythingasaservice” economy through our entrepreneurial spirit results focused culture and innovative delivery model atg brings contemporary solutions to the way clients transform and manage their customer and revenue technology platforms leveraging decades of deep domain expertise in billing and hundreds of quotetocash implementations of the leading cloud and onpremise software atg helps clients realize their desired outcome faster

what does a data engineer do for atg
the atg data engineer’s primary role is to strategize implement solve and execute on data related solutions to support atg initiatives on a variety of platforms common activities may include creating data strategies data migrationconversions data mapping and data profiling the role will interact with the latest enterprise saas platforms within the monetization ecosystem individuals in the role will leverage their business analytical and technical skills to provide expert guidance on data strategies to our customers that are critical in solution implementations

what are some of the responsibilities of a data engineer
participate in discovery sessions with project teams to understand data requirements needed to support solution implementationswork collaboratively with a project and client team in an agile environment to support our cloud initiativesleverage system and process analysis skills to produce data strategies that create a seamless and uninterrupted experience for our clientscollaborate with clients to generate data mapping documents between target and source systemsleverage industry leading tools to extract transform and load data into source systems in an automated fashion to support data migrationsperform data profiling tasks to collect statistics trends impacts and summaries that lead to a structured and successful implementationprovide key insights based on data analytics to aid the client in drawing conclusions as to the business value and impact of their data and best approaches for migrating and transforming data to support new system architectureswork with project management to provide regular status updates to internal and external stakeholders

what are the minimum requirements to be a data engineerbachelor’s degree and 15 years’ experience in a data related position that includes the use of common database tool etl products and interacting with data within relational databases

what other skills knowledge and qualifications are needed to be a successful data engineer

demonstrated knowledge of etl extracttransformload concepts
indepth experience with sql and plsql
proficiency in objectoriented programming java c c andor scripting python perl php
experience working in cloud transformation projects within crm cpq andor finance systems
ability to effectively manage time and prioritize tasks
ability to work with ambiguity
capability to take on tasks with little direction and produce highvalue deliverables in a fastpaced environment
excellent verbal and written communication skills ability to work with technical and nontechnical users other departments and clients
experience working in an agile scrum environment desired
organization skills  ability to work in a highly dynamic environment with shifting priorities
the specific locations for the data engineer are missoula montana and kansas city missouri
the advanced technology group atg is a privately held professional management and consulting firm founded in 2000 and headquartered in overland park kansas our niche service offering centers on customer care and billingcrm expertise supporting our communications industry telecomcableconferencing based clients additionally atg’s management consulting practice focuses on working with our targeted clients from a program delivery perspective in providing business solutions through strategy process and programproject implementation assisting our clients meet their business critical programproject initiatives",,NY,False,data_engineer
Junior Data Engineer- ML and AI,"date may 22 2018
global artificial intelligence accelerator

ericsson overview

ericsson is world’s leading provider of communications technology and services our offerings include services consulting software and infrastructure within information and communications technology
using innovation to empower people business and society ericsson is working towards the networked society a world connected in real time that will open up opportunities to create freedom transform society and drive solutions to some of our planet’s greatest challenges

we are truly a global company operating across borders in over 180 countries offering a diverse performancedriven culture and an innovative and engaging environment as an ericsson employee you will have freedom to think big and the support to turn ideas into achievements continuous learning and growth opportunities allow you to acquire the knowledge and skills necessary to progress and reach your career goals we invite you to join our team

machine intelligence at ericsson

it will be practically impossible for human brains to understand how to run and optimize a 5g network machine learning ml and other artificial intelligence ai technologies will be vital for us to handle that complexity we are setting up a global ai accelerator in the us sweden and india with 300 experts to fasttrack our strategy execution
machine intelligence mi the combination of machine learning and other artificial intelligence technologies is what ericsson uses to drive thought leadership to automate and transform ericsson offerings and operations mi is a key competence to enable new and emerging business this includes development of models frameworks and infrastructure that we use to power our 5g networks and services we engage in both academic and industry collaborations to drive the digitalization of ericsson and the industry our global group develop state of the art solutions that simplify and automate processes in our products and services and create new value through data insights
ericsson is hiring junior data engineers to significantly expand its global ai accelerator team

job description
ericsson is looking for savvy junior data engineers to join our growing team of mi experts as a team member you will be evolving and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for cross functional teams you are an expert data pipeline builder and data wrangler who enjoys optimizing data systems and evolving them the data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data and models devops dataops architecture is consistent throughout ongoing projects you are selfdirected and comfortable supporting the dataops needs of multiple teams systems and products you will also be responsible for integrating them with the architecture used across the company the right candidate will be excited by the prospect of optimizing or even redesigning our company’s dataops architecture to support our existing and next generation of midriven products and solutions initiatives

your roles and responsibilities
assist with the creation and maintaining of optimal data and model dataops pipeline architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and cloudbased ‘big data’ technologies from aws azure and others
work with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
keep data separated and secure across national boundaries through multiple data centers and strategic customerspartners
create toolchains for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
work with data and machine learning experts to strive for greater functionality in our data and model life cycle management systems
support dataops competence buildup in ericsson businesses and customer serving units

what we would like to see
bs ms or phd degree in computer science informatics information systems or another related field
02 years experience using the following softwaretools
hadoop spark kafka etc
experience with relational sql and nosql databases including postgres and cassandra
experience with data and model pipeline and workflow management tools azkaban luigi airflow dataiku etc
experience with streamprocessing systems storm sparkstreaming etc
experience with objectorientedobject function scripting languages python java c scala etc
advanced sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of other databasesdatesources
experience building and optimizing ‘big data’ data pipelines architectures and data sets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and seek opportunities for improvement
strong analytic skills related to working with unstructured datasets
have built processes supporting data transformation data structures metadata dependency and workload management
working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores
project management and interpersonal skills
experience supporting and working with crossfunctional teams in a dynamic environmentlibf1
disclaimer the above statements are intended to describe the general nature and level of work being performed by employees assigned to this classification they are not intended to be construed as an exhaustive list of all responsibilities duties and skills required of employees assigned to this position therefore employees assigned may be required to perform additional job tasks required by the manager

we are proud to be an eeoaa employer mfdisabledveterans we maintain a drugfree workplace and perform preemployment substance abuse testing

ericsson provides equal employment opportunities eeo to all employees and applicants for employment without regard to race color religion sex sexual orientation gender identity marital status pregnancy parental status national origin ethnic background age disability political opinion social status protected veteran status union membership or genetics information ericsson complies with applicable country state and all local laws governing nondiscrimination in employment in every location across the world in which the company has facilities in addition ericsson supports the un guiding principles for business and human rights and the united nations global compact

this policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation training and development

ericsson expressly prohibits any form of workplace harassment based on race color religion sex sexual orientation gender identity marital status pregnancy parental status national origin ethnic background age disability political opinion social status protected veteran status union membership or genetic information

ericsson will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant however employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by ericsson or c consistent with ericsson’s legal duty to furnish information

employee polygraph protection act notice  employers are generally prohibited from requiring or requesting any employee or job applicant to take a lie detector test and from discharging disciplining or discriminating against an employee or prospective employee for refusing to take a test or for exercising other rights under the act for more information visit httpswwwdolgovwhdregscomplianceposterseppacpdf

ericsson is an equal opportunity employer and is committed to providing reasonable accommodation for qualified disabled individuals during the application and hiring process ericsson will make modifications or adjustments to the job application or interview process that will enable a qualified applicant to be considered for a position if you require an accommodation due to a disability please contact ericsson at hrdirectdallasericssoncom or 866 3742272 us or 877 3389966 canada for further assistance

primary country and city united states us   santa clara  rd",,CA,False,data_engineer
Big Data Engineer,"if you have experience with big data solutions you have a wealth of opportunities to grow your career how about an environment with extraordinarily talented peers how about a company offering a range of both big data products and professional services to expand your skills how about an organization working on cutting edge projects that many of the biggest companies simply cant execute on their own are you looking to join a startup where you can directly contribute to the establishment of one the next great high tech companies then kogentix now hiring juniortomidlevel big data engineers may just be a perfect fit

responsibilities
develops distributed applications to solve large scale processing problems utilizing various languages like java scala  shell etc
implements troubleshoots and optimizes solutions based on modern big data technologies like hadoop spark elastic search storm kafka etc in both an on premise and cloud deployment model
implements data architecture including data ingress in batch and real time from a broad variety of external systems data transformations to prepare data for analytics processing and data egress for availability of analytics results to visualization systems applications or external data stores
supports documentation change control and qa processes consistent with enterprise requirements
establishes strong teamwork with client technical resources and effectively communicates project status technical issue options and resolution and operational requirements to client stakeholders
qualifications
overall 23 years experience with minimum of 1 year on hadoop or a closely related technology
very strong serverside java experience especially in an open source dataintensive distributed environments
expert in the hadoop framework  java programming ie spark mapreduce pig hive kafka storm etc including performance tuning
implemented complex projects dealing with the considerable data size tb pb and with high complexity
good understanding of algorithms data structure and performance optimization techniques
experience with agile development methodologies like scrum
self motivated and has the ability to drive technical discussions
organized detail oriented able to work both independently and in a team
excellent problem solver analytical thinker and quick learner
strong verbal and written communication skills
broad understanding of most of the following with depth of expertise and experience in at least 1
o hadoop security kerberos ranger knox
o amazon emr and related technologies eg dynamodb kinesis s3
o data mining statistical modeling techniques and quantitative analyses
o data architecture master data management and governance
o kafka
o search capabilities such as elastic search
o nosql db such as cassandra and mongodb
certifications a plus amazon cloudera spark
masters  bachelor of computer science with focus on distributed computing",,,False,data_engineer
Data Engineer - MSP,"description
team daugherty is hiring a data engineer to join us in minneapolis the ideal candidate for this position is a problem solver with the ability to utilize insights creativity and perspective to drive business success for our clients

as a data engineer you will have the opportunity to

contribute to the creation and maintenance of optimal data pipeline architectures
collaborate and work closely with team to build data platforms
maintain and manage hadoop clusters in development and production environments
assemble large complex data sets that meet functionalnonfunctional business requirements
work with team members and functional leads to understand existing data requirements and validation rules to support moving existing data warehouse workloads into a distributed data platform
create custom software components eg specialized udfs and analytics applications
employ a variety of languages and tools to marry systems together
recommend ways to improve data reliability efficiency and quality
implement  automate highperformance algorithms prototypes and predictive models
we are looking for someone with

1 years of experience in a similar role
proven experience working with aws technologies such as redshift rds s3 emr adp hive kinesis snssqs and quicksight
familiarity with python r shbash and jvmbased languages including scala and java
familiarity with hadoop family languages including pig and hive
familiarity with high performance data libraries including spark numpy and tensorflow
proven ability to pick up new languages and technologies quickly
intermediate level of sql programming and query performance tuning techniques for data integration and consumption using design for optimum performance against large data assets within an oltp olap and mpp architecture
knowledge of cloud and distributed systems principles including load balancing networks scaling and inmemory versus disk
experience building data pipelines to connect analytics stacks client data visualization tools and external data sources
exposure to streamprocessing and messaging such as storm sparkstreaming kafka and mq
understanding of devops and cicd toolset such as jenkins gitlab ci buildbot drone and bamboo
some experience with programming languages such as scala java r and python
we offer members of team daugherty

excellent health dental and vision insurance
revenue sharing and a 401k retirement savings plan
life disability and longterm care insurance
little to no travel
robust career development and training
do you think you’re a good fit for team daugherty apply now and find out why working here satisfies the smart the talented and the curious",,MN,False,data_engineer
Data Engineer,"about freestar
freestar engineers cuttingedge monetization solutions for websites by combining industryleading technology data and massive scale we enable busy site owners to seamlessly maximize revenue while freeing themselves of the hassles of ad operations publishers then have more time to do what they do best create content

job description  responsibilities
as a member of the freestar data engineering team the data engineer is responsible for manipulating and transforming data to meet business needs for adhoc and permanent reporting and for productionalizing processes in a microservices architecture using python andor java the data engineer will write both code that fetches data from myriad sources restful and soap apis file systems ftp etc and that publishes data to api endpoints as well as etl processes data cleaning and the like

at freestar our technology stack is built on google cloud the data engineer should have experience working with cloud technologies and should have experience with big data storage and transformation technologies including largescale relational databases such as google bigquery or amazon redshift google cloud storage or amazon s3 and some exposure to streamingbatch processing technologies

reporting to our vp of data engineering the data engineer is responsible for the following


ingesting datasets to meet business needs writing and productionalizing etl processes
coding solutions to the business data needs including delivery of data through reports or endpoints as appropriate
testing and vetting outputs and working with stakeholders to ensure that data being produced is accurate and fully meets business needs
responding to adhoc reporting requests
working with frontend and other engineers to integrate data products into dashboards and user interfaces as needed

data engineer requirements

2 years python or java with a focus on data manipulation and transformation
2 years sql
at least one year writing and deploying code in a production environment
at least one year working with cloud technologies
experience working with big data datasets on the order of hundreds of millions to billions of records
bachelors degree in a relevant field cs engineering math economics etc or equivalent experience
experience building statistical models or similar algorithms is a plus

wed love it if you had experience with

spring boot
microservice architecture
kubernetes  docker
apache beam
apache kafka
google cloud platform  amazon web services

what you can expect in return

fulltime salaried position
medical dental and vision benefits
401k with company match vested immediately
the opportunity to be part of something big

freestar is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin age protected veteran or disabled status or genetic information

this role is not eligible for visa sponsorship",,NY,False,data_engineer
Data Engineer,"we are looking for a versatile data engineer to join our growing team this hire will be responsible for a variety of expansions and optimizations across the company’s entire data architectural stack

the ideal candidate should be familiar with modern data concepts including data lakes cloud data concepts etl and data wrangling and search engine speed data access the position will also support the software and data science teams on designing and building data initiatives in fast paced environment as well as driving strong standards across the data engineering group individuals must have the ability to be selfdirected at times and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing and contributing to the designdevelopment of our company’s future data architecture ideally this hire will act as a mentor for other data engineers

experience
total 8 years of database experience with 4 years in cloudbig data andor nosql databases as well as maintain relational structuresapplicant should be ambitious and agile enough to move with the everchanging landscape of data engineering including uptodate aws cloud services

preferred skillset
strong ability to navigate aws cloud services including s3 rds ec2 and some exposure to aws data services
a thorough understanding of the elk stack elasticsearch kibana and logstash including optimizations at the cluster index and document levels
intermediate linux administration
hands on experience developing applications that run on spark preferably pyspark andor vanilla python
hands on experience designing and developing nontrivial etl processes
intermediate nosql skills preferably mongodb
intermediate sql skills mysql postgres etc
experience using kafka both consuming and producing content andor other pubsub enterprise tools sqs

bonus
java andor c development experience a plusdocker container creation andor enterprise managementapache nifi

preferred qualifications
bachelors in computer science 8 years of database experience with 4 years in cloudbig data andor nosql databases",,MA,False,data_engineer
Data Engineer,"our client is a missionminded saas company headquartered in austin that is building a new product to improve the way they deliver their solution to clients this role focuses on the design development and deployment of our clients saas platforms enterprise datawarehouse  underlying data transformations applying a strong technical and data lifecycle understanding this engineer will partner with other developers data engineers data scientists and the devops teams to create data science platforms
responsibilities
 designing and developing schemas attributes facts advanced report design data aggregation and advanced report services development  using tools including web intelligence report services pentaho spoon and report services  providing welldocumented efficient and effective solutions to meet business needs  institutionalizing a data management culture to support the companys scale initiatives  mapping data elements and attributes into the enterprise data model  developing solutions with team members to implement defined and documented data requirements  learning new technologies and sharing your knowledge with the team  advocating for new features new technologies and processes  prototyping ideas for discussiondemonstration  providing guidance on data security compliance initiatives  participating in code reviews
required skills
 experience with agile development methodologies  working knowledge of microsoft sql server mysql andor postgresql  23 years experience in reportinganalytic role with a focus on data transformation etl and design  deep sql development skills  knowledge of dimensional database design  experience with pentaho spoon microsoft sql server integration services ssis or other enterprise data transformation tools  working knowledge of python and other automation technology frameworks is a plus  working knowledge of java is a bonus  experience with sap business objects is a plus  experience with sparx systems enterprise architect or other data modeling tools is desired  experience with big data technologies including amazon mapreduce hadoop cassandra sap hana microsoft hdinsight amazon redshift amazon glue and similar technology stacks",,TX,False,data_engineer
Data Scientist / Data Engineer,"first republic is an ultrahightouch bank that provides extraordinary client service we believe that oneonone interactions build lasting relationships we move quickly to serve our clients’ needs so that their financial transactions are handled with ease and efficiency client trust and security are paramount in our line of business ultimately our goal is unsurpassed client satisfaction which will lead to personal referrals – our number one source of new business we recognize that our competitive advantage starts with our people and our culture at first republic we work hard and move quickly as a very coordinated team if you are looking for an opportunity to grow and contribute in a fun fastpaced environment first republic is the place for you we have exceptional people focused on providing extraordinary service

the data scientistdata engineer will play a crucial role in our enterprise data and client insights edci group in this role you will help build the data infrastructure that will allow the team to conduct analyze and consult on business decisions the data scientistdata engineer must be comfortable with a fast paced environment where you may need to shift responsibilities depending on projectteam needs you will be exposed to a number of departments and executives in this role giving insight into various verticals in the bank we’re looking for someone who is willing to roll up their sleeves to help build the foundation so that you can create the reports and run analysis from a data science perspective
responsibilities
experience with analytics investment managementbanking experience is a plus
experience with python java etc
sql and experience with relational databases
experience building realtime data pipelines and dws
designing for the present and future
design and implement data modeling
develop solutions for real world enterprise wide problems that impact the business and customer
interact with various business groups and a variety of people across the bank to identify opportunities
partner with leadership and stakeholders to develop and execute various reporting packages and ad hoc requests
experience in machine learning andor artificial intelligence
work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions
use predictive modeling to increase and optimize customer experiences revenue generation ad targeting and other business outcomes
qualifications
programming experience in one or more of the following java python andor c c
writing highperformance reliable and maintainable code
good knowledge of database structures theories principles and practices
relational sql distributed sql and nosql databases including but not limited to mssql postgresql mysql memsql cratedb mongodb cassandra etc
fluent in writing shell scripts
knowledge and experience in statistical and data mining techniques
experience creating and using machine learning algorithms and statistics regression simulation scenario analysis modeling clustering decision trees neural networks etc",,CA,False,data_engineer
Sr. Data Engineer,"2500 a monthdescription
upsight is the world’s largest enterprisegrade user lifecycle management platform our mission is to transform the world’s data into valuable action upsight customers leverage our consolidated solution stack to learn about their users make informed decisions and take immediate action to positively impact kpis increase ltv and add value to their businesses we handle more than 500 billion data points and deliver over 14 billion targeted web and mobile communications every month
born of the 2014 merger that married playhaven’s marketing automation solution with kontagent’s omnichannel analytics upsight was built from the ground up to handle the challenges inherent in managing the world’s largest software portfolios the 2016 acquisition of fuse powered and their bestinclass ad optimization technology secured our place as the industry’s only one stop shop for enterprise technologists upsight’s battletested infrastructure has scaled to facilitate some of the largest digital product launches in history and our commitment to perfecting the industry’s only fullservice solution has afforded us the privilege of working with companies like electronic arts warner brothers activision and more
above all upsight values relationships our refusal to adopt a “onesizefitsall” approach has empowered us and our customers to build resilient partnerships that drive growth it’s a philosophy we aim to carry with us into the future as we look forward to leading our industry in the discovery and development of practical technologies for the digital enterprise market
about the role
upsight is looking for a sr data platform engineer who will work on a team of data platform engineers to scale and expand on upsight’s data platform and runs at optimal performance
what you’ll do
work in an agile development environment
write rocksolid code for a variety of data processing systems
work with our support team to debug customer issues
work handinhand with our devops team to horizontally scale upsight’s infrastructure to handle tens of billions of events per day
deepen your knowledge of big data infrastructure tuning production systems running at petabyte scale
about you
bachelor’s degree in computer science related field or equivalent experience
5 years of software engineering experience
excellent understanding of distributed systems and associated algorithms
skills for success
rock solid understanding of the hadoop ecosystem yarn hdfs zookeeper etc
experience with both batch and streaming data processing systems storm kafka
experience with bigdata sql engines eg hive mr tez spark
deep debugging and problem solving skills
attention to detail and focus on maintaining data quality
ability to place components into the context of a broader architecture and identify any issues at a systems level
ability to understanding scaling characteristics of a system and address any deficiencies before shipping code
solid understanding of linux and associated metrics and tunables
expert knowledge in java and the jvm scala experience a bonus
what you’ll get
an opportunity to make immediate impact
2500 flexible benefit program to be used towards a combination of vacation fitness mobile devices and education
snacks on snacks on snacks
catered lunches 3x per week
upsight welcomes and encourages applications from people with disabilities accommodations are available on request for candidates taking part in all aspects of the selection process",,OR,False,data_engineer
Data Engineer,"the data engineer is responsible for utilizing current and future data ingestion and data storage technologies to build manipulate enhance and utilize data to meet the needs of the global end user analytical community the position will implement the tools necessary to meet the data warehousing data lake and big data requirements of the organization the data engineer will be responsible for designing implementing and maintaining the enterprise data warehouse in alignment with the data and analytics vision and strategy the data engineer will collaborate with the architect team along with the technical team to implement creative and innovative solutions to solve complex data opportunities this role will build and maintain manual and automated data workflowspipelines this position will also be involved in automating the analysis processing and testing of our big data and iot storage platforms



role  responsibility


technology research
research select and pilot technologies for use including
insightful datadriven solutions that support a variety of business needs
data ingestion technologies to meet or exceed the needs of the analytics users
support keeping the technologies up to date by understanding the benefits of updated versions andor componentized replacement products
application development
design build and deliver innovative technical solutions to the analytical community and other project teams
integrate transactional systems with the enterprise data warehouse
create data structures to accommodate source data and allow efficient data consumption
create data ingestion processes to collect manipulate if necessary and load data into tables available for end users
develop data lake and big data storage capabilities
application support
design build and maintain data storage facilities including data warehousing data lakes and big data
maintain the enterprise data warehouse
enhance data structures to accommodate source data and allow efficient data consumption
maintain data lake and big data storage
enhance data lake to align with the needs of the analytical community
analytics strategy support
implement data requirements to align with the strategy for business intelligence and advanced analytics
understand big data technologies and the tools to implement
keep abreast of new bi and related technology and trends and assess when and if new technology is needed
implement the architectural vision initiatives and roadmap for effectively leveraging data



job requirement


bachelors degree in information technology or related field master’s degree in information technology preferred
minimum of 8 years’ experience including
4 years of industry experience with application support andor development or equivalent
4 years of industry experience with building or maintaining traditional data storage and etlelt technologies
3 years of industry experience working with newer data storage and data ingestion technologies and platforms including use of open source tools
solid knowledge of technology relevant for the domains
proven experience in it solution design data model design integration design servicecomponent design
proven experience identifying and managing technical risks
familiar with operational support models and project management methodologies
able to translate business problems into it solutions
analytical mindset and problem solver
excellent written and verbal communication skills in english
highly computer literate
willing to work with distributed and multicultural teams
travel 1024




the worldrenowned brands that make up doosan bobcat produce industryleading compact and heavy construction equipment attachments air compressors lighting systems generators and articulated dump trucks doosan bobcat is a part of the doosan group which employs 43000 people in 38 countries worldwide with people at the core of who we are we believe the growth of our people will lead to the continued growth and success of our worldclass company our team of dedicated employees is the backbone that allows us to provide construction equipment solutions that help our customers build the world of tomorrow wherever you find us you’ll hear the sounds of progress see the results of our people and feel the rhythm of transformation in everything we do
doosan is committed to a diverse workforce and is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to sex age race color religion creed citizenship status national origin disability marital status sexual orientation gender identity protected veteran status or any other status or characteristic protected by law individuals with disabilities who require a reasonable accommodation in the application process or who need assistance accessing the information on this website should call 7014764263",,ND,False,data_engineer
Big Data Engineer,"who is blueprint

blueprint technologies is a group of solutionminded thinkers changing the face of technology in bellevue wa we follow a mission vision and core values that allow us to function as a collaborative unit

what are our solutions

blueprint is a technology solutions firm that connects strategy product and delivery we help companies digitally transform we have a special focus in cloud and infrastructure data platform and engineering data science and analytics organizational modernization and customer experience optimization

why you want to be a part of blueprint

we are innovators motivators thought provokers and coffee drinkers our collective backgrounds bring diverse perspectives that enable us to consistently think differently our people are our solutions we want you to bring your biggest and best ideas to help positively impact our culture clients and the community around us we believe in the importance of a healthy and happy team which is why our benefits include full medical dental and vision coverage as well as paid time off 401k paid volunteer hours and tuition reimbursement

blueprint is looking for big data engineers to join us as we build cuttingedge technology solutions

basic qualifications

bachelors or masters degree in computer science computer engineering or related discipline
advanced experience with software development in an open source environment 5 years
experience with spark andor scala 3 years
experience with hadoop 24 years
experience with github andor other versioning tools
ability to quickly learn new technologies application domains and adapt to changes
excellent critical thinking and problemsolving skills
ability to develop simple elegant solutions to complex problems
excellent verbal and written communication skills team player
ability to handle multiple competing priorities in a fastpaced environment

preferred qualifications

experience with a distributed cloud preferably azure
experience with agile software development methodology and continuous delivery models
experience with team building and mentoring

flsa  job classification exempt fulltime position

department big data",,WA,False,data_engineer
Data Engineer,"job description
at annalect we work with clients to develop data driven marketing strategies powered by a connected system of technology tools consultants and digital activation drawing from the vast resources of our parent company omnicom we are positioned as the data and analytics experts for dozens of fortune 500 companies
our job is one of empowerment specifically empowering our clients to improve their business through advances in technology and data as the ad tech ecosystem continues to become more complex we are counted on to provide expertise on digital marketing technologies incorporate strategy and manage tracking of all digital marketing efforts but as our client roster continues to grow we’re going to need more help

position overview
we are looking for a data engineer to join our team of engineers primary work involves managing large ad tech related data sets and making them available for data scientists marketing analysts and data products via automated workflows work also includes building commandline and webbased tools to support teams using big data doing large scale data analysis projects and building data products

the ideal candidate would identify himher self as
an automation specialist who conceptualizes and builds automate systems for workflows
a cloudbased infrastructure builder who integrates the use of cloud services into workflows
a detail oriented developer who enjoys complex challenges and who anticipates and designs for external failures


experience required
building workflows to support data environments and data products
python bash and sql scripting
linux system administration and working at the linux command prompt
distributed data processing engines such as spark hive presto and drill
aws services such as batch ecs ec2 sqs s3 elasticache emr glue redshift and rds
schedulers such as airflow luigi and cloudwatch events
docker
git or other version control systems",,IL,False,data_engineer
Data Engineer,"about blue river

blue river technology serves the agricultural industry by designing and building advanced farm machines that utilize computer vision and machine learning to enable farmers to understand and manage every plant these machines help farmers to improve profitability protects the environment by reducing pesticide use and captures valuable plantbyplant data blue river is a pioneer in the agricultural robotics space and has developed the see  spray precision sprayer which applies pesticide only where needed and can reduce pesticide use 90 john deere  company with over 180 years of experience in designing manufacturing and distributing innovative products to farmers acquired blue river technology in the fall of 2017 as an independentlyrun subsidiary in partnership with john deere blue river has expanded rapidly and together both companies see many opportunities to apply advanced computer vision machine learning and robotics technologies to other areas in agriculture beyond spraying

blue river is based in sunnyvale ca and has over 80 team members with diverse experience including computer vision machine learning systems software autonomous vehicles and precision agriculture our working environment is fast paced and highly collaborative and employees are excited to use their talents to improve food production and protect the environment

position description
we are seeking a data engineer to design and maintain blue rivers cloud data lake platform this person will collaborate closely with engineering product and support to define local and remotely hosted infrastructure needs they will create and maintain data pipeline to store and manipulate data acquired at remote sites with highly limited connectivity

requirements

experience with large data sets
have deployed complex system on aws  gcp
java scala pythonjavascript nosql sql rdbms
track record of developing web apis
self motivated ability to work independently
experienced in data mining and visualization of large data sets
deep understanding of map reduce framework and related big data ecosystem components like hive spark sql dynmodbhbase etc

preferred qualifications

at least 4 years of experience with big data  analytics solutions – hadoop kafka mapreduce hive dynmodbhbase
solr or elastic searchspark aws emr knowledge of experience with nosql database a plus
experience with nosql such as elasticsearch and dynmodbhbase preferred
experience with nosql database schema design
working experience of etl and data visualization is plus
understand the different formats parquet protobuf
experience developing with webapp containers such as tomcatjetty etc
practical expertise in performance tuning and optimization bottleneck problems analysis
experience deploying systems to a cloud provider like aws or google compute engine

",,CA,False,data_engineer
Data Engineer,"data engineer269025
description

we are pioneers we were the first to break the sound barrier and design the first functional jetpack we were aboard nasa’s first lunar mission and brought advanced tiltrotor systems to market today we are defining the future of ondemand mobility at bell we are proud to be an iconic company with superb talent rapidly creating novel and coveted vertical lift experiences
the data engineer is a member of bell’s team of analytics experts this position is responsible for optimizing our data pipeline architecture as well as data flow and collection for cross functional teams on our v247 aircraft program this role will be working with data from disparate aircraft systems data and aircraft maintenance data focusing on maintainability and operations
the ideal candidate enjoys optimizing data systems and building them from the ground up

the data engineer will support our software developers and database specialists on data initiatives and will ensure optimal data delivery through ongoing projects this position supports the data needs of multiple teams systems and products this position is based at bell’s headquarters facility in ft worth tx
position responsibilities

build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and potentially aws big data technologies
create and maintain optimal data pipeline architecture
assemble large complex data sets that includes simulator and flight data flight systems data that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery and redesigning infrastructure for greater scalability
work with stakeholders to assist with datarelated technical issues and support their data infrastructure needs
create data tools for team members that assist them in building and optimizing our products and services
build analytics tools that utilize the data pipeline to provide insights into customer acquisition operational efficiency and other key business performance metrics
qualifications

education requirements

bachelor’s degree in computer science information technology statistics informatics information systems  or another related quantitative field  is required
masters degree in one of the above disciplines is preferred
position requirements

at least 10 years of experience in data engineering and in optimizing data pipelines architectures and data sets is required
experience with build processes supporting etl data extraction transformation loading data structures metadata dependency and workload management
a successful history processing and extracting value from large disconnected datasets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
experience with relational nosql and graph databases
experience with objectorientedobject function scripting languages python java c scala etc
experience supporting and working with crossfunctional teams in a dynamic environment
experience in application of best practices in software development including source code control objectoriented development and programming principles
preferred education skills and experience

experience with military aviation maintenance databases
knowledge of aircraft systems and aircraft maintenance procedures focusing on maintainability and operations
experience with mssql oracle postgres mysql and neo4j


don’t miss the chance to join a diverse inclusive environment where you feel a sense of belonging as a member of our global workforce you will collaborate with dedicated enthusiastic teams where unique experiences backgrounds and ideas combined with a strong passion for our products take us above and beyond flight

eeo statement
textron is committed to providing equal opportunity in employment to all applicants and employees regardless of race color religion gender age national origin military status veteran status handicap physical or mental disability sexual orientation gender identity genetic information or any other characteristic protected by law

this position requires use of information which is subject to the international traffic in arms regulations itar andor the export administration regulations ear nonus persons selected must meet eligibility requirements for access to exportrestricted information  the itarear defines a us person as a us citizen us permanent resident ie green card holder political asylee or refugee

pay transparency policy statement
the contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant however employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by the employer or c consistent with the contractor’s legal duty to furnish information
job field information technology
primary location ustexasfort worth
recruiting company bell flight
schedule fulltime
job level individual contributor
shift first shift
travel yes 5  of the time
job posting 09192018 112315 am
textron and its subsidiaries participates in everify we will provide the us social security administration ssa and if necessary the us department of homeland security dhs with information from each new employer’s form i9 to confirm work authorization",,TX,False,data_engineer
Big Data Engineer 10 years of experience Philadelphia PA,75  80 an hourcontractjob summaryrole big data engineering leadlocation philadelphia paduration 1 yearvisa status h1b gc citizen h4ead tnpassport number mandatory experience 10javascalaspark aws experienceoverall big data architect who has experience working on awsusing big data technology and customer’s business requirements design and document a comprehensive technical architecture  solutionin depth knowledge of big data ecosystem design implementationexperience working in a client deliver role in an on offshore modeldetailed knowledge of rdbms data modeling and sq data warehouse bi and etl toolsjob type contractsalary 7500 to 8000 hour,,PA,False,data_engineer
​Data Engineer,"the data operations department provides data management integration and reporting services for multiple external and internal consumers the data engineer will be responsible for all aspects of data management that support ccmcn’s production services candidate must have experience in microsoft sql database development data integration etl extract transform and load tools and methods analytics reporting and documentation

essential functions
provide development and maintenance support for data integrations between systems
provide development and maintenance support for the edw and supporting databases
provide automated solutions whenever possible and proactively suggest alternative solutions
assist in the development of new databases and associated processes as necessary
provide data analytics report development for specific projects as needed
develop data validation reports and analysis where applicable
develop technical documentation of data integrations and processes
communicate and collaborate with other team members and clients to develop innovative data solutions
utilize uptodate knowledge of database and data quality best practices to produce effective solutions
remain knowledgeable in healthcare data standards measures and code sets as well as applicable data privacy practices and legal requirements

required skills and experience
experience working in a microsoft sql server environment especially with ssis stored procedures and query development
knowledge of data warehousing best practices concepts and processes
strong analytical and problemsolving skills with demonstrated change management experience
demonstrated ability to set and meet project timelines and deliverables
effective interpersonal and communications skills with the ability to interact with various levels of personnel
must be flexible organized selfdirected able to prioritize multiple tasks and able to manage a full workload
experienced in microsoft office and microsoft operating systems
must be able to work in ccmcns main office and travel to all required meetings
fluency in written and spoken english

additional preferred skills
strong business and technical writing abilities
knowledge of healthcare data standards such as hl7 ccd ccr and claims data
knowledge of standard healthcare code sets like loinc icd910 cpt4 and snomed
knowledge of ihi triple aim clinical quality improvement and primary care operationsworkflow
ability to stay current on healthcare reporting requirements such as uds pqri nqf meaningful use and patient centered medical home
ability to attend conferences and workshops for further education to expand and improve management skills

the above statements are intended to describe the general nature of work being performed by personnel assigned to this classification they are not intended to be construed as an exhaustive list of all responsibilities duties and skills required of personnel so classified

ccmcn is an equal opportunity employer offering flexible benefits a casual work environment and a competitive salary doe

to apply
if interested in this position please send cover letter resume and salary requirements by email
please include the job title in the subject of the email

please send all application information to
savannah bermudez
re data engineer
email jobsccmcncom

no phone calls please",,CO,False,data_engineer
"Siri - Data Engineer, Data organization","play a part in the next revolution in humancomputer interaction contribute to a product that is redefining mobile and desktop computing create groundbreaking technology for large scale systems spoken language big data and artificial intelligence and work with the people who created the intelligent assistant that helps millions of people get things done — just by asking
the vision for the siri data organization is to improve siri by using data as the voice of our customers join us and impact hundreds of millions of customers across a plethora of apple of devices
the siri metrics platform team is responsible for building a highly available and scalable system to ingest process and analyze billions of events generated daily from devices and our services this system along with the data visualization tooling we’re building will allow our engineering teams to perform quick exploration with the overarching goal of improving the quality of siri
as a data engineer on the siri metrics platform team you will have significant responsibility and influence in improving siri by using data as the voice of our users you will develop large scale data pipelines and analytical solutions interface with our quality initiative leaders to ensure the system is meeting the needs and iterate as well as innovate based on observations and requirements gathering
successful candidates will have strong engineering and communication skills as well as a belief that data informed processes lead to better products

key qualifications
5 years of industry experience working with largescale and highthroughput systems
expert knowledge of one or more objectoriented programming languages scala java c
ability to leverage several scripting languages python ruby bash etc
thorough understanding of the hadoop ecosystem hbase hdfs hive mapreduce spark solr kafka

description
the siri metrics platform team is in a unique position to align our quality initiatives to a singular platform this will allow all performance reliability accuracy and usability metrics to utilize the same methodology for dashboardreporting creation and curation this platform will also empower our developers to do adhoc queries into their problem space in order to troubleshoot or validate the effectiveness of their code from a quality perspective
a successful candidate will have experience in largevolume data ingestion processing and analysis in near realtime
design implement and manage scalable data models and pipelines leveraged by all siri teams
build analytical solutions to enable data analysts to perform accurate and consistent analysis efficiently
develop and contribute back to open source projects supporting the platform
ensure the platform can handle all types of robust data exploration in realtime
partner with all siri teams and build features to enhance data analysis

education
bs degree in computer science or 5 years of programming experience or equivalent",,CA,False,data_engineer
Data Engineer,"who we are
calico is a research and development company whose mission is to harness advanced technologies to increase our understanding of the biology that controls lifespan and to devise interventions that enable people to lead longer and healthier lives executing on this mission will require an unprecedented level of interdisciplinary effort and a longterm focus for which funding is already in place

position description
great software engineering and data science are increasingly crucial to biology we are in the midst of an explosion in the quantity and quality of biological and medical data that are transformative to our understanding of biology and disease but the tools to store process and analyze these data are often primitive and in some cases dont yet exist calico is seeking an exceptional data engineer to join our computing group and be a part of changing that story

in this role you will work closely with computational and research scientists to define strategies and implement systems for modeling collecting storing and accessing diverse scientific data and metadata collaborating with other scientists and engineers you will design build and maintain databases and data warehouses that underpin our scientific endeavors and accelerate our ability to ask new sophisticated questions spanning multiple organisms data modalities and timescales you will not only build tools to support existing scientific workflows but also help set the vision for future data generation and collection efforts

if you are passionate about data passionate about biology and passionate about their intersection—this is the job for you

what youll do

work with computational and research scientists to understand common analysis use cases and data access needs
design strategies for data storage and integration across different data sources both internal and external for multiple use cases
implement document and maintain processing pipelines databases and data warehouse infrastructure
work closely with fullstack engineers to develop apis and guis for accessing and visualizing scientific data
set data engineering vision and drive both independent and collaborative software development projects endtoend
contribute to a range of projects from oneoff solutions to longterm complex systems
build out core infrastructure tooling and software development processes

position requirements

5 years working with contemporary etl tools and frameworks
3 years building pythonbased backend systems
fluent knowledge of sql
experience implementing restful apis graphql and other programmatic interfaces to complex multidimensional data
experience deploying highperformance data backends in the cloud with amazon web services heroku google cloud platform or a similar service
firm grasp on software testing and testdriven development
demonstrated success in owning projects endtoend including working with nontechnical stakeholders to define requirements and seek feedback

nice to have

worked with machine learning tools and infrastructure eg tensorflow and pytorch
built backends for highdimensional graph or network data
worked in biology or life sciences and have familiarity with databases and data types used by computational biologists
built software with technologies like elasticsearch graphql and google cloud platform

some projects you may contribute to

data warehouse—a system to extract transform and load public and private datasets into a single repository then making these data available for analysis visually with either offtheshelf or custombuilt guis
exploratory data visualization  analysis tools—apps to help scientists explore and understand diverse complex and multidimensional data
data platform—a modern react frontend and python backend application that our scientists use to manage and process experimental data

automation—software to ingest and transform data from custom highthroughput instrumentation",,CA,False,data_engineer
Staff Data Engineer,"evidation health is a new kind of health and measurement company that provides the technology and guidance to understand how everyday behavior and health interact the volumes of behavior data generated from wearables and smartphones has opened up new ways to analyze individuals’ behavior and health in real time with a virtual pool of 2 million research participants evidation health undertakes research for innovative biopharma and health care companies to transform how diseases are identified treated and monitored

we are seeking a staff data engineer to join our enterprise data engineering team as a senior data engineer you will be working on our data platform coding in python and react and using cuttingedge big data technologies such as apache spark airflow hadoop and jupyter to build out data pipelines data lakes fullstack applications and analytics tools that scale on the cloud to empower data scientists to gather insights from billions of data points to improve health outcomes

responsibilities
design scalable high performance solutions that continuously handle terabytes of data and enable data scientists to analyze data at scale
understand overall performance and design around improving data performance using different technologies algorithm efficiencies and infrastructure architecture
work with customers to understand their needs develop and deliver products that meet the customer’s needs in a timely manner
implement best practices and provide feedback to team members through peer reviews
qualifications
technical qualifications
8 years experience in data engineering or fullstack engineering with strong database skills
proficiency with at least one interpreted object oriented programming language python ruby java etc
proficiency building data pipelines with big data processing technologies spark hadoop kafka etc
experience with sql databases eg postgres mysql redshift and distributed datastores eg s3
distributing computing experience on the cloud aws google
professional competencies
strong written and verbal communication
work effectively in a collaborative and crossfunctional team environment
take personal responsibility for driving initiatives forward and continually improving the product
qualityfocus ensuring proper test coverage for all the code you write
benefits
health dental and vision benefits for you and competitive coverage for your family
relocation support
equity
flexible work hours
open vacation policy  take time when you need it
support for remote work when needed
relaxed work environment
your choice of computing equipment and gear
lots of opportunities for growth
opportunity to work on fascinating challenges that improve people’s lives


evidation health values diversity and is committed to equal opportunity for all persons without regard to race color creed religion marital status age national origin or ancestry political activity or affiliation physical or mental disability medical condition including genetic characteristics marital status sexual orientation gender identity sex or gender",,CA,False,data_engineer
Data Engineer,"navican genomics inc delivers precision cancer care all patients deserve access to precision cancer care  the right therapy at the right time to ensure better outcomes and reduced healthcare costs today many people don’t get the precision therapy they need and with the exceptional team of professionals we are building we believe we can do better based on proven processes developed through years of experience and clinical best practices of intermountain healthcare navican was created to transform advances in precision medicine into precision cancer care for patients everywhere that advanced therapies are available

expert prioritized therapy recommendations and experienced treatment navigators will simplify the path to drug and clinical trial access at the same time we’ll help patients and their caregivers navigate often frustrating administrative processes we’re driven by an impatience to make more precision therapy options available to more cancer patients if you have a passion to help people a desire to grow and you excel at what you do join us at navican and make a positive impact on the world

data engineer
navican is seeking a highly motivated data engineerin san diego to join our team and help in building out the data platform that powers our data driven products as part of the it team you’ll work closely with several departments providing expertise on data management
the data engineerwill play a key role in navican’s data management strategy and assist in curating and cataloging multiple sources of data used throughout navican for use in internal and external products in addition they will contribute in improving the data management processes and take on other duties as needed

primary responsibilities and duties

architect implement and maintain navican’s data platform
build robust and scalable data integration pipelines for etl and reporting using appropriate technologies
identify gaps and improvements to internal data management processes including automation sanitization and optimizing data delivery to customers
collaborate with internal customers in gathering requirements to develop reporting solutions and evolve the data platform to meet their needs
develop and deliver high quality data sets for analysis to bioinformatics data science and business analytics
assist in tool evaluation selection and integration with various other frameworks
collaborate with devops in establishing best practices around data security and access


compentencies and essential skills
knowledge of relational database concepts and the sql querying language
knowledge of common flat file data formats such as json xml and csv
knowledge of healthrelated data formats including hl7 fhir edi etc
knowledge of data concepts such as enterprise data warehouses data lakes and etl
knowledge of hipaa requirements  data management best practices related to the storage of health information
excellent interpersonal verbal and written communication skills
selfdriven with the ability to work independently and within a team
a strong sense of ownership and urgency
demonstrates navican’s values by acting with integrity respect and trust

education and experience
bachelor’s degree in computer science information technology or a related field
3  5 years of relevant experience in one of the following areas data engineering data analytics business intelligence or business analytics
experience building and optimizing data pipelines architecture and data sets
experience with a relation database such as postgresql mysql or mssql
experience with an object oriented or functional language such as python java r etc
experience with a cloud platform such as aws or azure and its respective data processing technologies
preferred experience ngs next generation sequencing and working with laboratory related agencies
preferred experience middleware platforms integrating multiple systems including emr lis and lims


navican is an eoeaa employer and offers competitive salary and benefits package",,CA,False,data_engineer
"Data Engineer, Analytics - Tableau","job description

captech data engineers collaborate between business operations and it services by offering expertise in evaluating understanding and leveraging client data to drive factbased decisions bi consultants help our clients effectively leverage reporting and data tools to build strong robust and dynamic systems that will serve the client’s longterm strategic goals our bi consultants enable our clients to make more informed and datadriven decisions to gain competitive advantages increase sales improve sales improve core business competencies and satisfy today’s escalating customer expectations
specific responsibilities for the data engineer include
design develop document and test business intelligence solutions using industry standard tools
create own and present documentationdesigns to fellow team members and clients
facilitate requirements gathering sessions with business and technical stakeholders to distill data and reporting requirements from business requests
coordinate design and development efforts with client stakeholders to ensure the solution delivered meets the business need and is consistent with approved architectural standards
performance tuning to ensure a responsive solution

qualifications

specific qualifications for the data engineer include
at least 5 years experience developing business intelligence solutions using tableau
experience with tools such as ssrs cognos microstrategy qlikview spotfire etc is a plus
familiarity with at least two different database platforms such as teradata oracle ms sql server or other platforms teradata and ms sql strongly preferred  extremely strong sql skills
dimensional data modeling skills
handson experience with etl development a plus
excellent interpersonal team management facilitation and communication skills must be able to communicate effectively at all levels of the client’s organization
additional information

we offer challenging and impactful jobs with professional career paths all captechers can keep their hands on technology no matter what position they hold our employees find their work exciting and rewarding in a culture filled with opportunities to have fun along the way
at captech we offer a competitive and comprehensive benefits package including but not limited to
competitive salary with performance based bonus opportunities
single and family health insurance plans including dental coverage
shortterm and longterm disability
matching 401k
competitive paid time off
training and certification opportunities eligible for expense reimbursement
team building and social activities
mentor program to help you develop your career

at this time captech cannot transfer nor sponsor a work visa for this position applicants must be authorized to work directly for any employer in the united states without visa sponsorship

candidates must be eligible to work in the us for any employer directly we are not open to contract or “corp to corp” agreements

captech is an equal opportunity employer

captech is a drugfree work place

candidates must have the ability to work at captech’s client locations

all positions include the possibility of travel
captech has not contracteddoes not contract with any outside vendors in its recruitment process if you are interested in this position please apply to captech directly",,NC,False,data_engineer
Data Engineer,"contractposition summary

very strong engineering skills should have an analytical approach and have good programming skills
provide business insights while leveraging internal tools and systems databases and industry data
minimum of 5 years’ experience experience in retail business will be a plus
excellent written and verbal communication skills for varied audiences on engineering subject matter
ability to document requirements data lineage subject matter in both business and technical terminology
guide and learn from other team members
demonstrated ability to transform business requirements to code specific analytical reports and tools
this role will involve coding analytical modeling root cause analysis investigation debugging testing and collaboration with the business partners product managers other engineering team

requirements
must have


strong analytical background
selfstarter
must be able to reach out to others and thrive in a fastpaced environment
strong background in transforming big data into business insights

technical requirements

knowledgeexperience on teradata physical design and implementation teradata sql performance optimization
experience with teradata tools and utilities fastload multiload bteq fastexport
advanced sql preferably teradata
experience working with large data sets experience working with distributed computing mapreduce hadoop hive apache spark etc
strong hadoop scripting skills to process petabytes of data
experience in unixlinux shell scripting or similar programmingscripting knowledge
experience in etl processes
real time data ingestion kafka

nice to have

development experience with java scala flume python
cassandra
automic scheduler
rr studio sas experience a plus
presto
hbase
sap hana
tableau or similar reportingdash boarding tool
modeling and data science background
retail industry background

education

bs degree in specific technical fields like computer science math statistics preferred

benefits
this opportunity is open to both fulltime and contract employees",,CA,False,data_engineer
Data Engineer,"responsibilities
owner of the core company data pipeline responsible for scaling up data processing flow to meet the rapid data growth at datalitical consistently evolve data model  data schema based on business and engineering needs implement systems tracking data quality and consistency develop tools supporting selfservice data pipeline management etl sql and mapreduce job tuning to improve data processing performance

experience  skills
extensive experience with hadoop or similar ecosystem mapreduce yarn hdfs hive spark presto pig hbase parquet proficient in at least one of the sql languages mysql postgresql sqlserver oracle good understanding of sql engine and able to conduct advanced performance tuning strong skills in scripting language python ruby perl bash experience with workflow management tools airflow oozie azkaban uc4 comfortable working directly with data analytics to bridge business requirements with data engineering

bonus
mpp database experience redshift vertica teradata experience with building tools to support selfservice pipeline experience with one of the messaging system kafka sqs kinesis and different data serialization json protobuf avro

our corporate office supports and offers a competitive benefits package including medicaldentalvision term life insurance paid vacationholidays 401k savings plan with company match

apply hrdataliticalcom",,TX,False,data_engineer
Data Engineer,"what if you could shape the future of work and be part of the team that creates the digital workforce of tomorrow by means of robotic process automation
in the beginning of the 20th century henry ford had a vision of creating assembly lines and facilitating mass production
100 years later uipath has a grand vision of liberating the human workforce from tedious boring repetitive tasks by means of software robots artificial intelligence and machine learning

heres what you would be doing at uipath

as a data engineer you will be responsible for building and maintaining the infrastructure for big data and ai lifecycle you will also be responsible for maintaining the algorithms developed by our data scientists and using a myriad of tools for production readiness of ai models you will be working on a crossfunctional team of product managers devops engineers machine learning engineers and software engineers for high impact shipping being a part of hypergrowth startup you are not afraid of getting your hands dirty and are expected to be a jack of all trades for all steps in the ml lifecycle right from tagging featurization training and benchmarking to experimentation monitoring and analytics

role  responsibilities
you will work with our team of experts in machine learning and software engineering to do the following

design and build large scale data ingestion storage and processing platform
build and maintain platform to for the complete machine learning lifecycle
qualification  educational requirements

post graduate  graduate in computer science or a related field
overall 4 years of experience in it industry with 1 years working on products built to handle big data in both cloud and onprem settings
experience of working on both sql  nosql databases
experience with objectoriented design coding and testing patterns as well as experience in engineering commercial or open source software platforms and largescale data infrastructures
experience with big data technologies like hadoop spark  kafka
experience in python data processing and parsing

preferred skills

experience of building platforms in cloud using aws azure or gcp
experience in offline batch processing andor online realtime stream processing systems
knowledge of machine learning and interested in working across our entire data science stack including model building data pipelining and performancescale analysis
benefits 

we are offering the possibility to work from home or flexible working hours in a nice office plus free daily premium catering healthcare plan
competitive salary a stock options plan and the unique opportunity of working with us to develop stateoftheart robotics technology are just a few of the pluses
we must have caught your attention by now if youve read so far so we must connect",,WA,False,data_engineer
Big Data Engineer,"description
big data engineer

location new york new york

about symphony talent

at symphony talent we connect an employer’s brand with bestfit talent through our integrated cloudbased suite of solutions symphony talent’s leadership staff and investors are dedicated to paving the future for forwardthinking organizations focused on sourcing nurturing and hiring the bestfit talent for great brands

at symphony talent we respect relationships with one another just as we respect our relationships with our clients partners and supporters integrity is ingrained in our core values and we are committed to an open and honest work culture our teams of creative thinkers are inspired to make a unique impact in this often complex market landscape we are committed to building an organization fueled by the likes and minds of those passionate for this industry

symphony talent is using data to revolutionize and disrupt the online recruitment marketing space our data management platform dmp is now ingesting thousands of gbs of data from our online marketing sources


display advertising

social advertising

email marketing

online job postings

career web sites


amongst many other things symphony talent will be using this data to produce the following

multi source attribution analytics

predictive analytics

client facing analytics  via our saas portal

integration with external vendors and clients google facebook twitter indeed etc
about the role

we are looking for a generalist engineer that will primarily be responsible for collecting storing processing and analyzing huge sets of data you will also be responsible for integrating the resulting output of the data processing to our internal analytics team our customer facing saas analytics platform as well as 3rd party vendors and clients over the course of time you will be the goto person for all things data related
requirements
responsibilities

implementing complex robust etl pipelines python bash aws hadoop redshift

writingusing apis for internalexternal data integration and ingestion python java nodejs

building monitoring services

writing testing and debugging online tracking tags javascript

contributing to our client facing saas analytics platform jasperreports server

contributing to our continuous development framework github jenkins aws

skills and qualifications

3 years of working with large complex sets of data

highly proficient in sql this is a mandatory requirement

competent working experience with at least 1 of the following languages

python

nodesjs

javascript

java


the entire platform runs on aws specifically aws linux while it’s not mandatory to have hands on aws experience having solid working knowledge and experience of the nix os is mandatory shell scripts

the following hands on experience will be highly desirable

hadoop hive spark udfs

managing infrastructure in aws

building and scaling machine learning frameworks

bi tool jasperreports server tableau qlik etc



symphony talent perks include

competitive compensation

great benefits package including a 401k plan and unlimited pto

open collaborative culture and flexible work hours

fun conveniently located office in midtown


if this sounds like an exciting next step for your career we’d love to hear from you

only candidates with proper permits to work in the united states can be considered symphony talent is an equal opportunity employer mfdisabilityveterans and committed to a drugfree workplace",,NY,False,data_engineer
Data Scientist / Data Engineer,"142000  181000 a year indeed est data scientist  data engineer san francisco ca
location san francisco california united states
fulltime
the new york times describes thunder as an ad engine to put mad men out of business were changing how digital ads are created and distributed by automating much of what people thought couldnt be done by computer our technology retrieves all relevant content about an advertiser across the web to intelligently design a beautiful set of ads for desktop tablet and mobile devices all in under a minute

the job

thunder is looking for a talented data scientist with a track record working with big data and distributed systems to manage a cuttingedge infrastructure used by the world’s largest digital advertisers we’re using big data in groundbreaking ways to uncover customer insights personalize customer experiences and fix digital advertising you will contribute as a key member of the product engineering team where you will be driving product and engineering innovation to better leverage thunders growing personal graph we are looking for a selfstarter who thrives with ambiguity and loves solving challenging problems

responsibilities

design and develop big data and realtime analytics solutions using industry standard technologies
collaborate with internal business and product teams to identify product features that can be powered by advanced data analytics
use various machine learning and statistical techniques to analyze data build models and identify requirements for operationalizing those models into production services
work with external customers on challenging data analysis problems


qualifications

ideal candidates will have handson operational experience building and operating largescale data analytics services and thrive working in a fastpaced startup environment

5 7 years of handson experience with using advanced statistics techniques and machine learning to build operational production services
strong understanding of machine learning recommendation systems predictive analytics and multivariate analysis
strong computer science fundamentals including data structures algorithms distributed systems and common design patterns
strong database and data engineering experience with handson experience building services that leverage a variety of database systems including sql redshift spectrum druid hadoop hive hbase spark kafka aws kinesis mongodb
bs or ms in computer science computer engineering mathematics statistics applied mathematics or related experience",161500.0,CA,False,data_engineer
"Sr. Data Engineer, Machine Learning","job description

machine learning big data near realtime scoring environment if these areas resonate with you then join us to work on extremely motivating challenge at amazon web services aws marketing we build and run custom machine learning models to solve challenging business problems at scale if you are a strong data engineer selfstarter and learner who is passionate about working with massive amounts of data to build stateofart system on aws platform then this is the right opportunity for you you will work with a team of highly skilled engineers and scientists to build the next generation ml platform using aws services as part of your job you will deal with large amounts of training data partner with scientists and help rapidly prototype new models that meet stringent performance requirements perform offline and online testing and push these models to production

as part of this role you will be required to
analyze and extract relevant information from large amounts of historical data to help automate and optimize key features and ml processes
establish scalable efficient automated processes for large scale data analyses model development validation and implementation
work closely with scientists and engineers to create and deploy new features
work closely with stakeholders to solve various business problems
about you
you are fascinated by the power of large scale systems and using machine learning algorithms to optimize decision making and youre looking for a career where youll be able to build to deliver and to impress you look at problems holistically and thrive on the intricate complexity of designing feedback loops and ecosystems you want to work on projects where you are implementing solutions to real problems that require creative solutions and deep understanding of the problem space you will partner with scientists and engineers to challenge yourself and others to constantly come up with better solutions youll be given an opportunity to own and drive initiatives  from customer facing features system innovation all the way down to the datasets that the backend services consume
basic qualifications
bachelors degree or higher in a quantitativetechnical field eg computer science statistics engineering
5 years of relevant experience in one of the following areas data engineering database engineering business intelligence or business analytics
5 years of handson experience in writing complex highlyoptimized sql queries across large data sets
5 years of experience in scripting languages like python etc
demonstrated strength in data modeling etl development and data warehousing data warehousing
experience with aws services including s3 redshift emr kinesis and rds
experience in working and delivering endtoend projects independently
preferred qualifications
masters in computer science mathematics statistics economics or other quantitative field
experience with building highperformance highlyavailable and scalable distributed systems
proven success in communicating with users other technical teams and senior management to collect requirements describe data modeling decisions and data engineering strategy
experience providing technical leadership for best practices on data engineering
masters in computer science mathematics statistics economics or other quantitative field
experience working with large volumes of realworld noisy data
a willingness to dive deep experiment rapidly and get things done",,WA,False,data_engineer
Data Engineer,"what we do

uptake helps industrial companies digitally transform with open purposebuilt software that delivers outcomes that matter built on a foundation of data science and machine learning our vision is to create a world that always works — one where the machines and equipment we depend on daily dont break and industrial companies are once again the creators of economic growth and opportunity

what youll do

as a data engineer on the data science team youll work with uptakes data scientists and product team to design and build data infrastructure in support of uptakes data science the tools you create will have lasting impact on model development and deployment performance and outcomes reporting as well as data monitoring the ideal candidate has strong analytic and technical abilities as well as the ability to be flexible and adaptive to rapidly evolving needs of the team

responsibilities


design and implement data warehouses realtime etl and batch processing of data to support modeling and reporting needs
work with data ingestion teams to develop data expertise and resolve upstream issues relating to data quality
define best practices and design for the management of data
partner with data scientists to build and maintain internal data processing and visualization tools
translate requests into replicable analytic reports using varying applications
create tools to serve data such as apis and packages

qualifications


required
bachelors degree in computer science information technologyinformation systems or a field related to a computational science or 2 years experience working as a data engineer
ability to write efficient sql queries
experience managing data etl processes and making data available through service applications and databases
1 years experience with nosql databases cassandra or elasticsearch preferred
3 years experience with programming languages python java r andor scala preferred
familiarity with a variety of data processing technologies eg spark kafka hadoop
excellent communication skills including a knack for clear documentation
experience with or knowledge of rest apis and making data available through microservices
experience using version control git mercurial svn etc for collaborative code development
preferred
ms or phd in computer science or other technical field
ability to architect data solutions
some knowledge of machine learning and data science processes
experience supporting data science and analytical efforts is preferred
some experience with frontend webdevelopment
experience defining and implementing apis
experience working with docker

why work here

we build and deliver then explore to build more curiosity and flexibility enable everything we do and we get stronger as we make each new industry smarter as a team we bring our diverse backgrounds beliefs and experiences to solve problems no one has yet to solve at a speed no one has yet to experience we support and challenge one another to bring out a new best in each of us and we might have a little fun along the way",,IL,False,data_engineer
BI & DW Data Engineer,"join a team recognized for leadership innovation and diversity
join a company that is transforming from a traditional industrial company to a contemporary digital industrial business harnessing the power of cloud big data analytics internet of things and design thinking you will lead change that brings value to our customers partners and shareholders through the creation of innovative software and datadriven products and services you will be responsible for the development and maintenance of the database infrastructure needed for successful analytic processing you will ensure that there is optimal use of technology to meet business requirements
join a highperforming team and distinguished talent pipeline
work within honeywell to identify opportunities for new growth and efficiency based on data analysis
build strong relationships with leadership to effectively deliver contemporary data analytics solutions and contribute directly to business success
25 data modeling

25 enterprise reporting solutions

25 technical analytic work

25 cross team collaboration



you must have
bachelors degree in computer science engineering applied mathematics or related field
we value
some experience with sql net applications or other programming languages
experience with ssis and general administrative data experience
experience with the techniques of cqitqm and statistical process control methodology
experience with visualization software tableau spot fire qlikview d3js
understanding of bestinclass model and data configuration and development processes
experience with agile scrum methodology
strong understanding of relational databases
conveys specific observable andor measurable expectations for each assignment and verifies understanding and agreement on deliverables and timeframes
consistently makes timely decisions even in the face of complexity balancing systematic analysis with decisiveness
due to us export control laws must be a us citizen permanent resident or have protected status exempt how honeywell is connecting the world
includes
1st shift
continued professional development

additional information
job id req162256
category information technology
location 9680 old bailes rd fort mill sc 297077539 usa
honeywell is an equal opportunity employer qualified applicants will be considered without regard to age race creed color national origin ancestry marital status affectional or sexual orientation gender identity or expression disability nationality sex or veteran status",,SC,False,data_engineer
Data Engineer,"uscgchl2eadh4ead only
no c2c
candidates will work on our w2
role data engineer
location houston texas ustx
salary 144k
client ntt data
primary functions participating in projects as a data lead  data engineer responsible for performing many different data related tasks to make data available for the designated business need
these tasks could include the following components
database and interface design creatingediting data models physical  logical data profiling data mapping data quality management
required advanced level of technical competencies
data modeling physical and logical erstudio diagrams data dictionary data map normalizedenormalize agile datadata manipulation tools such as ssms ssis toad access excel
 advanced database handling languages sql and variants  experience in data architecture specifically in a data lake environment
– ie data lake zones data modeling etc preferred beginner to expert
technical competencies  practical skill sets in bi and data visualization tools tableau
 knowledge of programming languages and some ability to write code eg python vba xml r  api development and mulesoft
 sap business object data services bods erstudio modeling preferred candidate should  strong communication and interpersonal skills with strong english proficiency
demonstrate critical thinking analytical skills and employ judgment to offer thoughtful concise input toward resolutions of problemsbe able to translate data requirements into business processes and reverse engineer business processes into data requirementscomprehension of devops and agile development and application to data centric architecture and solutionsminimum bachelor’s degree in engineering technology computer science or a related field with equivalent experience",,TX,False,data_engineer
Sr. Data Engineer,minimum qualifications bachelor’s degree in engineering computer science or related discipline36 years of experience as a software or data engineersoftware development experience in javaexperience building large scale data warehouses and etl data processing pipelinesexperience with big data technologies hadoop hive spark presto etchave successfully supported an enterprisescale web application in the cloudrdbms experience sql schema design and optimizationexcellent communication skills both written and verbalnice to have aws experienceexperience with python r and scalaexperience with reporting and analytic toolsexperience with nlp machine learning deep learningexperience with healthcare data and workflows eg hl7 fhirexperience with columnar data stores parquet orc redshiftnosql experience dynamodb cassandra hbase mongodbknowledge of infrastructure automation cloudformation terraformexperience with streaming data technologies kafka kinesis storm spark streamingjob type fulltime,,CA,False,data_engineer
Data Engineer,summary the data engineer is a part of an it team creating data warehouse solutions to support business strategies priorities and growth the data engineer is responsible for the design architecture creation and implementation of data and analytics environment including data lakes operational data stores data warehouse and data marts this individual is also responsible for selecting customizing and implementing data translation data mining and machine learning modules while ensuring a smooth integration with existing data this role also ensures business continuity requirements are met for all data and participates in disaster recovery planning testing and execution this position contributes in the planning forecasting and management of the it budget this individual consistently promotes and emulates our company values and our 5p’skey responsibilities  essential functions works with all functional teams to set up maintain and support the data warehouse and all data warehouse related tasks includes ssis ssas mdm and data martsresponsible for monitoring data warehouses setting up data warehouse and backup and recovery processesaids the technical team in setting database standards launching and implementing new data warehouse capabilitiesworks effectively with infrastructure and developers on performance tuning and optimization query optimization index tuning caching buffer tuning etchelps define and improve best practices for data and data warehouse activities and initiativeschampions change and innovation stimulating creativity and innovation in othersparticipates in business process redesign including identifying current state future state and gapsdrives the data warehouse technology direction and delivery through hisher understanding of the technical environment possibilities as well as limitsparticipates in the it steering committee meetings to ensure all data needs are understood for approved projectsparticipates on the business data governance team to ensure consistent business rules data quality and efficient data managementimplements and maintains data governance framework and processes to manage data assetsassists in defining and implementing development and integration standardsserves as a subject matter expert for all data source integrations translations and data loadsconsults with internal customers and partners to identify data sources data owners and data flowsensures detailed documentation such as data models data hierarchies and data flows are reviewed and kept up to dateensures that data flows are built to meet business service level agreementsparticipates in the evaluation and recommends solutions to meet data needs helps evaluate data sources that are targeted for possible integration into the systems or environment including additional tools and utilities needs to facilitatecritical success factors handson experience and demonstrated expertise in data warehouse technologyfamiliarity and experience with integrating data warehouse with vendor and other applicationsdemonstrated experience troubleshooting and resolving problems with ms sql server and other database enginesable to define and champion processes identify and avoid potential data errors to ensure data integrityperforms capacity planning and properly identifies required hardware software data warehouse configurationarchitecture needed to support application needsdesigns and implements core services processes and technologies to provide reliability high availability performance and scalability for creation access caching and lifecycle of data objects and entitiesutilizes toolsets to diagnose and resolve production issues for data warehouse based project rollouts or for post rollout supportselfmotivated and capable of working with infrastructure applications and business areas to align systems solutions with business requirementsable to manage the reporting needs of the business at the same time ensuring the data warehouse is kept responsivedemonstrated experience working in a large scale dispersed networking and communications environment and maintaining continuity of operationsaids in the setup design and maintenance of the data warehousedemonstrates technical skills and is trainedcertified in ms sql server ssis ssas and mdmworks with team to enhance processes review standards and support current and future platforms and applicationsparticipates in project definition and design activitieshelps conduct analysis and implement recommendations affecting data warehouse technical initiatives and helps prepare reviews and evaluate system documentation specifications test plans and proceduresparticipates in endtoend data warehouse and system testing and integrationassists functional teams in setting up maintaining and supporting data warehouses and all data and data warehouse related taskshelps monitor data warehouses set up database clusters and backup and recovery processesdesigns builds and supports data cubes data marts and etlconducts performance tuning and optimization query optimization index tuning caching buffer tuning etchelps define and improve best practices for data and data warehouse activities and initiativesdevelops and implements an enterprise data architecture strategyfacilitates strategic planning and development of architectural roadmapspartners with business on implementation and enhancement projectsdevelops and oversees data management standards data dictionary and meta data standards and incorporating industry standards for data managementunderstands industry direction best practices and technologies to discuss options with other team membersprovides logical and physical modeling and design servicespartners with endusers to developing monitoring and performance standardsdrives resolution of implementation and technical issues related to assigned projectsjob requirements bachelor’s degree in business information systems computer science or related discipline5 years of related projectindustry experiencedemonstrated competency in full life cycle of data warehouse development and support4  7 years professional experience in ms sql serverexperience working with functional teams on data model and schema design performance optimizations and data intensive tasks and architecture components3 years of experience with data warehouse administration support optimizations and monitoring3 years of design and development of extremely high volume high availability applications and systems2 years of experience writing etl jobs working with data cubesdata martsstrong experience developing and deploying triggers sql jobs data imports migrations transformations etcstrong understanding of microsoft vmware operating system storage solutions networking security and web serversexpert level skills in data modeling and design of logical and physical schemasability to communicate effectively and work cooperatively with development and infrastructure engineersdeep understanding of performance unit and load testing instrumentation and analysis strategiesbroad knowledge of common applications and technologies in internet computing including web servers app servers database servers load balancers etcexperience mentoring internal business partners on data managementhandson experience and demonstrated expertise in database technology specifically ms sql server 2012 and higherfamiliarity and experience with integrating the data warehouse environment with vendor solutions and other applicationsable to help troubleshoot and resolve problems with data warehouse implementations and projectsassists with identifying and avoiding potential data errors to ensure data integrityis familiar with hardware software database configurationarchitecture needed to support application needshelps design and implement data warehouse services processes and technologies to provide reliability high availability performance and scalability for creation access caching and lifecycle of data objects and entitieshelps utilize toolsets to diagnose and resolve production issues for project rollouts or for post rollout supportjob requirements preferred distribution industry knowledgeexperience administering disaster recovery plansappropriate ms sql server certificationjob type fulltimeexperiencedata warehouse administration support  optimizations 5 years preferredwriting etl jobs working with data cubesdata marts 2 years preferreddeploying triggers sql jobs data imports  migrations 1 year preferrededucationbachelors preferred,,MN,False,data_engineer
Data Engineer III,"overview
cures start here at fred hutchinson cancer research center home to three nobel laureates interdisciplinary teams of worldrenowned scientists seek new and innovative ways to prevent diagnose and treat cancer hivaids and other lifethreatening diseases fred hutch’s pioneering work in bone marrow transplantation led to the development of immunotherapy which harnesses the power of the immune system to treat cancer an independent nonprofit research institute based in seattle fred hutch houses the nation’s first cancer prevention research program as well as the clinical coordinating center of the women’s health initiative and the international headquarters of the hiv vaccine trials network careers start here

working with minimal supervision the data analyst iii will utilize a preapproved business intelligence tool or direct sql development to create reporting artifacts including but not limited to simple reports complex reports dashboards cubes data visualizations and data mining constructs in support of fred hutchinson cancer research center and the various consortium partner’s organizational goals

the data engineer iii reports to the manager of business intelligence data and analytics
responsibilities
gathering and documenting requirements from the user community and then translating those requirements into an analytics solution that meets the customer’s needs
produce highquality output reports analysis development consistent with team and industry best practices
participate in the design and development of dimensional data warehouse onboarding and access of data sources
analyze data to develop and implement standardized reporting formats procedures and processes
possess indepth knowledge of preapproved business intelligence tooltableau set functionality and options
possess knowledge on a wide range of possible reporting solutions and have sufficient discernment skills to select the most appropriate solution for each set of requirements
have an indepth understanding of the sql programming language
will serve as a liaison with the business community around the usage and deployment of reporting solutions and tools
conduct oneonone or small group training sessions in order to advance the adoption of analytical solutions
will participatelead code review sessions and will be expected to make updates as directed by the primary reviewer
will have an understanding of reporting within both a relational and a dimensional framework
respond to ad hoc requests for operational needs related to bi tools platform reports and other artifacts
participate in change control problem management and communication process
utilizing approved bi tools translate written requirement documents into appropriate reporting artifacts
develop adopt and evangelize reporting guidelines and standards
assist in preparing work estimates for assigned projects
meet required deadlines as outlined by project team and business partners
prepare documentation for deployment purposes and respond to any implementation issues as needed to ensure quality deliverable has been met
assist the data quality team in tracking downdebugging potential data quality issues
qualifications
minimum qualifications
bs in computer science engineering math or equivalent experience
minimum of 7 years professional database reporting development experience with business intelligence tools tableau preferred ms reporting services cognos business objects tableau software ms powerbi etc
minimum of 7 years sql development experience
minimum of 3 years technical leadership experience
experience working with both relational and dimensional models
experience developing a variety of different reporting artifacts parameterized reports cubes dashboards etc
sharp analytical abilities proven design skills and problem solving skills
enjoys working in a team environment and has a proven record of positive contributions to the work of the team
coordination and working knowledge of project management methodologies agilescrum time estimates and allocation
preferred qualifications

experience with microsoft sql server
experience gathering and documenting requirements
some past experience with analytical data management  reporting tools
expertise and knowledge of gathering and documenting analyticreporting requirements
expertise in architecting and developing access to data sources for scale
previous experience in delivering to end users reports andor extracts to support research andor clinical care
our commitment to diversity
we are committed to cultivating a workplace in which diverse perspectives and experiences are welcomed and respected we are proud to be an equal opportunity and vevraa employer we do not discriminate on the basis of race color religion creed ancestry national origin sex age disability marital or veteran status sexual orientation gender identity political ideology or membership in any other legally protected class we are an affirmative action employer we encourage individuals with diverse backgrounds to apply and desire priority referrals of protected veterans if due to a disability you need assistanceand or a reasonable accommodation during the application or recruiting process please send a request to our employee services center at escmailfredhutchorg or by calling 2066674700",,WA,False,data_engineer
Business Intelligence Engineer - BIE,"job description
sponsored products is amazons native advertising solution run a search in amazon and try to spot our sponsored native ads alongside with the organic results sponsored products uses automatic and keyword targeting capabilities to give merchants control over product merchandising on amazon by boosting the visibility of products when customers shop merchants can access the platform via self service capabilities and only pay when shoppers click on the ads even though this product started in 2012 it is growing rapidly and it has the potential of eventually becoming as large as other established cpc advertising publishers learn more about sponsored products here httpspamazoncom
our team of high caliber software developers statisticians and product managers use rigorous quantitative approaches to ensure that we target the right ad to the right customer at the right moment managing tradeoffs between monetization advertiser roi and customer relevance in order to accomplish this we leverage the wealth of amazon’s information to build a wide range of models set up experiments that ensure that we are thriving to reach global optimums and leverage amazon’s technological infrastructure to display the right ads in real time

as a data engineer with our team you will be working in a large extremely complex and dynamic data warehousing environment we are looking for someone with the uncanny ability to build efficient flexible and scalable data lakewarehouse and analytic solutions enabling identifying risks and opportunities the candidate should be able to use new technologies aws stack redshift emrspark and be able to implement solutions using these technologies to empower internal customers and scale the existing platform you should be expert at designing implementing and operating stable scalable low cost solutions to flow data from production systems into the data warehouse and into enduser facing reporting applications above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth

to succeed in this newly created role you will work closely with bi  product and business leaders in seattle you will have the opportunity to be mentored by top data engineers and you will work directly with bi peers

key responsibilities
design implement and support data warehouse infrastructure using aws redshift datalake technologies
create etls to take data from various operational systems and create a unified dimensional or star schema data model for analytics and reporting
use business intelligence and visualization software eg obiee tableau micro strategy etc to empower nontechnical internal customers to drive their own analytics and reporting
develop a deep understanding of our vast data sources and know exactly how when and which data to use to solve particular business problems
monitor and maintain database security and database software
support the development of performance dashboards that encompass key metrics to be reviewed with senior leadership
work with product managers and a growing global team to help in analyzing data and derive new insights that drive amazons sponsored product success
manage numerous requests concurrently and strategically prioritizing when necessary
basic qualifications

5 years of relevant experience with etl data modeling and business intelligence architectures
experience with big data solutions hadoop pighive or emrspark
experience in relational database concepts with a solid knowledge of star schema oracle sql plsql sql tuning olap big data technologies
experience building selfservice reporting solutions using business intelligence software eg obiee tableau server micro strategy etc
exceptional troubleshooting and problemsolving abilities
excellent written and verbal communications skills
demonstrated ability to work effectively across various internal organizations
preferred qualifications
experience with setting up infrastructure on aws
experience with scripting languages like python or unix shell scripts
experience with applied data science
experience with web technology to develop dashboards
demonstrated experience in dealing with senior management on addressing their reporting and metrics requirements
sspajobs sspasv

amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,WA,False,data_engineer
Data Engineer,"data engineer

locations new york ny – greensboro nc  chicago il – raleigh durham chapelhill nc

at deloitte digital – marketing  experience services xsp we are combining data programmatic decisioning and realtime delivery to build customer data platforms cdps complimented by a suite of clientspecific managed services

we’re growing fast and need brilliant data engineers like you to fuel our continuing innovation and help us scale along the way you’ll find exceptional growth opportunities limited only by your hunger for learning and ability to apply best practice methodology in our startuplike environment
work you’ll do

as a data engineer you’ll design implement and maintain a full suite of realtime and batch jobs that fuels our cutting edge ai to provide realtime marketing intelligence to our existing clients
you’ll develop test and deliver production grade code to help our clients solve their marketing challenges using cuttingedge bigdata tools you’ll also ensure data integrity resolve production issues and assist in the support and maintenance of our overall platform

as you grow your capabilities and learn how to build a platform that can ingest load and process billions of data points you’ll enjoy new challenges and opportunities to showcase your development skills by joining project teams to build innovative newclient platforms and execute highvalue strategic development projects with high visibility

your responsibilities will include
design construct install test and maintain highly scalable data pipelines with stateoftheart monitoring and logging practices
bring together large complex and sparce data sets to meet functional and nonfunctional business requirements
design and implements data tools for analytics and data scientist team members to help them in building optimizing and tuning our product
integrate new data management technologies and software engineering tools into existing structures
help build highperformance algorithms prototypes predictive models and proof of concepts
use a variety of languages tools and frameworks to marry data and systems together
recommend ways to improve data reliability efficiency and quality
collaborate with data scientists devops and project managers on meeting project goals
tackle challenges and solve complex problems on a daily basis

the team

advertising marketing  commerce

our advertising marketing  commerce team focuses on delivering marketing and growth objectives aligned with our clients’ brand values for measurable business growth we do this by creating content communications and experiences that engage and inspire their customers to act we implement and operate the technology platforms that enable personalized content commerce and marketing usercentric experiences in doing so we transform our clients’ marketing and engagement operations into modern datadriven creatively focused organizations our team brings deep experience in creative and digital marketing capabilities many from our digital studios

we serve our clients through the following types of work
crosschannel customer engagement strategy design and development
web mobile social physical
ecommerce strategy implementation and operations
marketing content and digital asset management solutions
marketing technology and advertising technology solutions
marketing analytics implementation and operations
advertising campaign ideation development and execution
acquisition and engagement campaign ideation development and execution
agile based designthinking usercentric empirical projects that accelerate results

qualifications

required
4 years of experience in software development a substantial part of which was gained in a highthroughput decisionautomation related environment
2 years of experience in working with big data using technologies like spark kafka flink hadoop and nosql datastores
1 years of experience on distributed high throughput and low latency architecture
1 years of experience deploying or managing data pipelines for supporting datasciencedriven decisioning at scale
a successful trackrecord of manipulating processing and extracting value from large disconnected datasets
producing highquality code in python
passionate about testing and with extensive experience in agile teams using scrum you consider automated build and test to be the norm
proven ability to communicate in both verbal and writing in a high performance collaborative environment
follows data development best practices and enjoy helping others learn to do the same
an independent thinker who considers the operating context of what heshe is developing
believes that the best data pipelines run unattended for weeks and months on end
familiar with version control you believe that code reviews help to catch bugs improves code base and spread knowledge

helpful but not required
knowledge in
experience with large consumer data sets used in performance marketing is a major advantage
familiarity with machine learning libraries is a plus
wellversed in or contributes to datacentric open source projects
reads hacker news blogs or stays on top of emerging tools in some other way
data visualization
industryspecific marketing data

technologies of interest
languageslibraries – python java scala spark kafka hadoop hdfs parquet
cloud – aws azure google

how you’ll grow

at deloitte our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day from entrylevel employees to senior leaders we believe there’s always room to learn we offer opportunities to help sharpen skills in addition to handson experience in the global fastchanging business world from onthejob learning experiences to formal development programs at deloitte university our professionals have a variety of opportunities to continue to grow throughout their career explore deloitte university the leadership center

benefits

at deloitte we know that great people make a great organization we value our people and offer employees a broad range of benefits learn more about what working at deloitte can mean for you

deloitte’s culture

our positive and supportive culture encourages our people to do their best work every day we celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them to be healthy centered confident and aware we offer wellbeing programs and are continuously looking for new ways to maintain a culture where our people excel and lead healthy happy lives learn more about life at deloitte

corporate citizenship

deloitte is led by a purpose to make an impact that matters this purpose defines who we are and extends to relationships with our clients our people and our communities we believe that business has the power to inspire and transform we focus on education giving skillbased volunteerism and leadership to help drive positive social impact in our communities learn more about deloitte’s impact on the world

recruiter tips

we want job seekers exploring opportunities at deloitte to feel prepared and confident to help you with your interview we suggest that you do your research know some background about the organization and the business area you’re applying to check out recruiting tips from deloitte professionals

as used in this posting “deloitte” means deloitte consulting llp a subsidiary of deloitte llp please see wwwdeloittecomusabout for a detailed description of the legal structure of deloitte llp and its subsidiaries certain services may not be available to attest clients under the rules and regulations of public accounting
all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin age disability or protected veteran status or any other legally protected basis in accordance with applicable law",,NC,False,data_engineer
Data Engineer (m/f) – Germany,"as a data engineer at simonkucher you will be responsible for large data management processes during client projects you will develop and automate robust processes to extract transform and load large scattered and unstructured data sets into clean and powerful analysis cubes which form a fundamental basis of our business recommendations in addition you will identify tackle and implement internal data process and technology improvements were looking for
data engineer mf – germany
for our office in bonn or cologne

your tasks
generate large multidimensional analysis cubes based on client data
validate data and ensure completeness correctness and relevance for meaningful analyses
develop and automate analytical tools based on the generated cubes to provide marketing sales and pricing insights
advise and support clients on how to model implement and automate robust etl processes
work with internal and external business and technology experts across the world
detect solve and implement internal process and technology improvements as well as create optimize and maintain new and existing data transfer channels
your profile
proven capabilities to build and maintain large and complex data sets
experience in structuring and automating etl processes based on scattered and unstructured data sources
experience with relational data management software and languages esp sql
extensive knowledge of analyticalbi software and languages eg tableau python r sas
familiarity with big data technologies eg nosql databases distributed file systems or stream processing technologies are a strong plus
sharp analytical and problemsolving mindset
proactive reliable attitude and enthusiasm for working in teams
fluency in english additional language abilities are a major advantage
master’s or bachelor’s degree business economics computer science or engineering preferred
what we offer
possibility to work in a new fastgrowing team comprised of young dynamic individuals
possibility to shape and implement new technologies within our organization and those of our clients
frequently changing project assignments no yearlong it implementation projects
a large variety of projects centered around sales marketing and pricing across different industries
highly international role and challenges
corporate culture led by our entrepreneurial spirit openness and honesty
simonkucher  partners
simonkucher  partners is a global consulting firm specializing in topline power® which encompasses strategy marketing pricing and sales our practice is built on evidencebased practical strategies for profit improvement via the top line simonkucher  partners is regarded as the worlds leading pricing advisor and thought leader

your personal contact
dorothea hayer
willybrandtallee 13
53113 bonn
tel 49 228 9843 351
email dorotheahayersimonkuchercom",,,False,data_engineer
Data Engineer (Media),"120000  145000 a yearas a data engineer working for one of the worlds most wellknown news organizations you will be working with newer technologies like spark gcpgoogle cloud etc sound interesting keep reading

what is the job

you will be an individual contributor moving large amounts of internal data into our data warehouse this will not be an architecture role

we are using google cloud platform after going through a number of different data storage solutions you should be someone looking to work with newer technologies and the cloud

we want to know what are visitors are interested in what they do on the site and what they like to do with our content therefore you will be helping to organize and store data from a variety of sources so we can put together an understanding of a single view of our visitors

what skills do we need


our biggest tools are python and spark so you should know these technologies
a cloud technology background aws is okay gcp preferred
a good background working in etl

who are we

we are a worldrenowned multimedia news information and entertainment company located in midtown manhattan near penn station we have a large portfolio of web properties and print outlets reaching tens of millions of people worldwide daily

compensation


120000  145000
generous paid vacation and pto
full benefits

whats in it for you

our office is located conveniently in midtown manhattan our headquarters is a stateoftheart naturally lit ecologically friendly workspace featuring a cafeteria coffee bar and access to all the major modes of mass transportation",132500.0,NY,False,data_engineer
Data Engineer,founded in 2001 qlarion is a dynamic and rapidly growing consulting firm focused on providing analytics and data management solutions to public sector and related organizations we are looking for smart wellrounded technologists that are passionate about helping our longterm clients use business intelligence and analytics to achieve their missionsqlarion offers a “life friendly” work environment that is both challenging and rewarding while our consultants develop cutting edge solutions for our clients we also encourage them to explore innovative ideas and technologies that complement our company’s vision qlarion provides career mentoring as well as defined technical and functional career paths that allow employees to become more empowered and prepares them for leadership roles each consultant has an annual dedicated training budget and opportunities for ongoing training and certifications to ensure they remain on the leading edgeqlarion provides an extensive package of large company benefits including healthcare vision dental 401k matching flextime and pto among othersqlarion is seeking an experienced wellrounded data engineer for the washington dc area the desired candidates must meet the requirements below and will be compensated based on their qualificationsbachelor’s degree in computer science engineering or related field3 years of experience configuring and supporting advanced analytical techniques in a multinode linux computing environment or multinode cloud computing environments ie highperformance computing environment3 years of experience in writing shell scripts eg bash to support configurations of advanced analytical toolkits on multimode environments3 years of experience supporting and tuning python code in a multinode computing environment experience in r or java preferredexperience utilizing gitbased code repositoriesexperience configuring natural language processing nlp toolkitsexperience configuring machine learning toolkits including but not limited to tensorflow keras and scikitlearnexperience using andor managing an anaconda python environmentexperience in writing queries and transformations with sqlexperience with the hadoop ecosystem to support highperformance computing environments preferredexperience working in an agile or scrumbased environment preferredstrong analytical skills and problem solving skillsmust possess excellent written and oral communication skillsresultsdriven with the ability to take initiatives handle multiple tasks and shifting priorities and meet deadlinesmust have a strong ability and desire to assimilate and apply knowledge as well as to spread acquired knowledge and experience to other team membersto learn more about qlarion visit our website at wwwqlarioncomqlarion will not accept resumes that are more than 5 pages longequal opportunity employer race color religion sex sexual orientation gender identity national origin age genetic information disability protected veteran status or any other legally protected group statusjob type fulltimeexperiencesupporting 3 years required,,DC,False,data_engineer
Data Engineer (Downtown),"100000  120000 a yearcontracta large health start up that specializes in streamlining health insurance claims and finding solutions to get patients money sooner just refactored their entire tech stack to make it more scalable
with that they are going to need skilled data engineers to make sure the terabytes of data being collected is pipelined into the proper channels for the data scientists and nontechnicalfolk alike to be able to utilize it so in addition to being skilled technically creating a system that can easily be accessed by anyone
check the required skills and if this is something that sounds exciting send me your resume and let’s talk
required skills  experience
around 3 years of python experience
spark for processing large repositories of data
comfortable with aws lambdas and server less architecture
understanding of web development django or flask
data ingestion
batch file processing
desired skills  experience
healthcare experience is a big plus
experience helping companies scale existing structures is a plus
automation is a plus
what you will be doing
tech breakdown
50 data ingestion
50 data pipelining
daily responsibilities
80 hands on
20 team collaboration
the offer
competitive salary up to 120kyear doe
you will receive the following benefits
medical insurance  health savings account hsa
401k
paid sick time leave
pretax commuter benefit


applicants must be currently authorized to work in the united states on a fulltime basis now and in the future
this position does not offer sponsorship
jobspring partners part of the motion recruitment network provides it staffing solutions contract contracttohire and direct hire across 10 major north american markets our unique expertise in today’s highest demand tech skill sets paired with our deep networks and knowledge of our local technology markets results in an exemplary track record with candidates and clients",110000.0,IL,False,data_engineer
"Software Engineer, Data","lime is a technology company that is changing how people get from point a to b via our fleet of shared limes electric scooters and limee eassist bikes were empowering our communities with new mobility options that are clean affordable and a ton of fun

as a data engineer at lime you will own the infrastructure that processes every single data point we collect were building an ondemand service that stretches into the physical world so you will be presented with a vast array of exciting openended data challenges you will lay the groundwork for how our entire organization runs data pipelines trains statistical models and turns analytical reports into concrete actions your work will directly drive many of our key business decisions youll be working alongside a group of engineers designers pms and operators from top schools and with experience building systems and apps at companies like facebook twitter uber and square

responsibilities
ensure system uptime for all of our data infrastructure ie our central data warehouse etl systems and realtime processing
democratize data within the organization by formulating and internally distributing best practices for building data pipelines
jump into at least one engineeringproduct unit to build data pipelines and produce actionable insights for that team
embrace your role as a founding member of our data infrastructure team
requirements
you have a degree in computer science from a top engineering school or equivalent technical background
you possess 2 years experience in the industry via internships or fulltime positions
you have experience working with big data technology like redshift snowflake hadoop or hive
you understand how to harness realtime data streams using technologies like aws kinesis kafka storm or spark
what we offer
opportunity to revolutionize transportation in your hometown with the leader in urban mobility solutions
a position that offers a variety of career and resume building experiences with the fastest growing startup of 2018
you will have the chance to scale with a rapidly growing organization with tons of opportunity for growth
play a role in the transformation of urban mobility and sustainability
work with a team of fun and motivated people
competitive salary and benefits
we here at lime strive to build a workforce comprised of individuals with diverse backgrounds abilities minds and identities that will help us to grow not only as a company but also as individuals lime is an equal opportunity employer",,CA,False,data_engineer
Sr. Big Data Engineer (Full-Time),note this position is open to fulltimew2 candidates only no ctcresponsibilitiesfull lifecycle application developmentdesign code and debug softwareperform software analysis risk analysis reliability analysisparticipate in software modeling and simulationintegrate new software solutions with existing systemsextract and reverse engineer existing codeperform regular status reviews of problemsissuesparticipate in the development or refinement of proactive services andor data repositoriesquery database to provide data extractsqualificationsrequired5 years of development experience in at least one of these languages java python or cexperience with restful api design and implementationexperience in workflow and bpmn development using activiti camunda etcexperience with data migration transformation and scriptingproficient understanding of code versioning tools such as gitability to work crossfunctionally with engineering and nonengineering teamspassionate about engineering quality testing automation and documentation of code and systems to ensure easy maintenance over a long periodexperience working on highvolume server softwareunderstanding and implementation of security and data protectionuser authentication and authorization between multiple systems servers and environmentsexperience with nosql databases such as dynamodbexperience with data frameworks such as hadoop hive pig and sparkdesiredexperience with mulesoft application developmentexperience in building highperformant scalable backend services in the cloud especially awspassionate about application scalability availability reliability and securityexposure to test driven development behavioral driven development frameworks and librariesexperience with collibra administration management working with apisexperience with anypoint apisabout galaxesolutionsgalaxesolutions is a global it services firm headquartered in somerset new jersey with over 2000 team members worldwide our downtown detroit office overlooks the beautiful campus martius park and is rapidly expanding to serve some of our largest and fastestgrowing clients within multiple industries including financial services gaming energy healthcare sports and entertainmentbe a part of an energetic and fastmoving team that delivers incredible innovative software systems galaxe’s software engineers take pride in software craftsmanship and a polyglot engineering approach to solving tough challenges galaxe’s application development teams are small 610 team members agile and leanfocused with a passion that goes beyond the workplace learn more at galaxecomequal opportunity employerveteransdisabledid 20188224job type fulltimeexperiencehandson java python or c development 5 years requiredwork authorizationunited states required,,MI,False,data_engineer
Data Engineer,"sql server dba data engineer

the data engineer will use smart technology to empower stakeholders enterprisewide to make the best decisions based on timely accurate and actionable information must enjoy working with sql server and big data technologies the data engineer will have the chance to work with the best data and massively parallel processing databases to speed analyses with broad exposure to the workings of teamhealth and critical thinking to tackle complex challenges when other teams need to know about providers productivity performance or other data insights they count on our data  analytics team

essential duties and responsibilities

part of a progressive technologyfocused team that is dedicated to identifying and delivering solutions to our customers and employees with smart technology and teamwork
embody our company values along with agile and lean software development principles
proactively engage in both internal and external learning opportunities
responsibility for the full development life cycle of the solution including detailed design code development code reviews unit testing buildtest support data quality monitors deployment activities and postdeployment support
build great leadership skills by managing and optimizing the eda team etls along with analytic operations jobstream definition and management parameters scheduling monitoring communication and alerting
juggle multiple project timelines simultaneously and estimate development duration and effort for all projects
communicate openly and candidly with your team leader and other teammates verbally and written
viewed as a mentor by others in and outside the team for technical solutions
hands on with big data management activities including acquisition ingestion transformation and data quality

qualifications  experience

bachelor’s degree preferred
at least 8 years experience of all 4 of the following bi disciplines data integration modeling analytics or reporting
10 years of sql experience with the ability to write complex sql statements while mentoring optimal code hygiene practices
closely involved in learning and teaching industry trends and practices along with your past experiences
a record of accomplishment of designing deploying and evolving etl solutions to meet business requirements via creating sql and ssis best practices for multiple platforms
proven analytical troubleshooting and problemsolving skills and ability to communicate well even to nontechnical users
built rock solid relational databases solutions along with designing implementing testing migrating deploying and managing etl solutions core functional etl processing extract transform and load
built solutions by leveraging advanced testing techniques and implemented proper audits alerts and notifications that proactively measures failures before they happen along with mentoring others to do the same
strong desire to teach and mentor other developers along with proven ability to work autonomously or in a team setting 
microsoft bi stack ssis ssas netezza and microstrategy is required
agile and big data experience is preferred

physical  environmental demands

job performed in a welllighted modern office setting
occasional liftingcarrying 10 pounds or less
occasional standingbendingstoopingreaching
moderate stress
prolonged sitting and
prolonged work at a computerpc

",,TN,False,data_engineer
Data Engineer I,"we invite you to explore a future with us at pra group a diverse and growing company that has a tangible impact on the global economy

position summary


proactively contributes in designing developing and evolving high quality usable and extensive data engineer solutions under supervision perform adhoc and routine tasking

working closely with other pra group data engineer software engineers and reporting to the manager data engineering the data engineer will engage internal customers at all levels develop adhoc and continuous enterprise level reports and contribute to new and existing analytical studies as a member of the enterprise data and analytics team this position will document key protocols procedures and system infrastructure as part of an ongoing data stewardshipgovernance effort of the data and analytics team
key responsibilities other duties may be assigned


employing various tools sql shell r python etc to complete data engineering requests
develop modify and implement enterprise level reports
assist in the documentation of new and existing data stores to assist in the administration and maintenance of the enterprise data governance program
assist in provide expertise on statistical and mathematical concepts used by the broader analytics team
assist with advocating evangelizing and building data driven solutions to help pra group meet our yearly net income goals

supervisory responsibilities
none


professional experiencequalifications
bachelor’s degree in math statistics computer science economics or related quantitative disciplines
1 years experience in the following
sql
github
unixlinux
strong written and oral communication skills
ability to effectively juggle multiple development administrative and support projects simultaneously

preferred
database
sql server
ssms command line tools bcp sql command etc
oracle 11g 12c
sqlplus
business objects
open source tools including but not limited to
r
python
data warehouse dimensional modeling concepts star snowflake schema
transactional entityrelationship modeling erm
dashboard report development

work environment
the noise level in the work environment is usually moderate as the employee works in a collaborative office environment in an individual work station using telephone and computer employee may be required to occasionally work evenings and weekends reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions



disclaimer
the above information on this description has been designed to indicate the general nature and level of work performed by employees within this classification it is not designed to contain or be interpreted as a comprehensive inventory of all duties responsibilities and qualifications required of employees assigned to this job


all qualified applicants will receive consideration for employment regardless of age race color sex gender religion national origin physical or mental disability citizenship or any other classes recognized by state or local law or any other characteristic protected under applicable federal state or local law we are a drug free workplace",,VA,False,data_engineer
"Data Engineer, Data Warehouse","at fitbit our mission is to help people lead healthier more active lives by empowering them with data inspiration and guidance to reach their goals

we started our journey in 2007—as a team of two with one big idea since then weve grown to over 1500 employees sold over 60mm devices and built a health and fitness community across the globe in fact the fitbit community has taken enough steps to walk from the sun to pluto offering awardwinning products a toprated mobile app and an easytouse online dashboard fitbit provides personalized experiences that help our users reach their goals with a reenergized focus on innovative devices interactive experiences and enterprise health we are transforming the way consumers and businesses see health  fitness

from your first steps as a fitbitter you will be at the forefront of developing new products our culture combines the spirit of startup with the perks of being public we offer a competitive benefits package and amazing perks like unlimited snacks friday happy hours onsite workout classes and a strong focus on a healthy worklife balance as part of our team youll have the opportunity to grow your career contribute your ideas to lifechanging products and services and—above all—have fun doing it

fitbits hq campus is located in the heart of san francisco with office locations in boston san diego and around the world think youve found your fit

what will you do

as a member of the data warehouse team at fitbit your primary responsibility will be development maintenance and operational stability of etl pipelines which feed the fitbit data warehouse this is an excellent opportunity for a recent graduate or experienced software engineer looking to get into the field of data engineering daytoday activities include


development of scalable resilient data pipelines in the cloud
upgrading legacy pipelines to leverage latest technologies
oncall duties to ensure data pipelines are meeting our slas

our ideal data engineer for the data warehouse team will have experience in most but preferably all of these skills and an interest in learning them all


development with sparkscala and python
etl best practices
database concepts relational and nosql including a working knowledge of sql
cloud environments aws google
linux environments

in addition an individual joining our team in any capacity must


take personal responsibility for driving initiatives forward
work effectively with stakeholders around the globe
display top notch written and verbal communication skills

we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,MA,False,data_engineer
Big Data Engineer,"required skills and experience

expertlevel java development experience including common backend frameworks
handson development with key aws technologies including aws batch aws step functions and aws lambda
aws certified developer or other aws certification
experience with highlyscalable and distributed databases and the key issues affecting their performance and reliability
experience using highthroughput message queueing systems such as aws sqs
familiarity with devops technologies including docker and common configuration management tools
an ability to periodically deploy systems to cloud environments such as aws
mastery of key development tools such as git and familiarity with collaboration tools such as jira and confluence or similar tools
overall 5 years of industry experience developing backend components with a recent focus on big data systems
bachelors degree or equivalent required masters degree preferred

job responsibilities

design and implement key components for highly scalable distributed data collection and analysis system built for handling petabytes of data in the cloud
analyze and support requirements from machine learning specialists focusing on the most important topics in the rapidly evolving automotive industry
move architecture and implementation through the automotive development pipeline from research to deployment in millions of cars on the road
work with architects from other divisions contributing to this analytics system and mentor team members on best practices in backend infrastructure and distributed computing topics

",,CA,False,data_engineer
"Data Engineer, Health","the communications research group at syneos health is looking for a data engineer with experience working with healthcare or media data sets you will build and manage databases and establish workflow pipelines that lead to api endpoints in support of data science tasks you will also manage code libraries automate database updates and build and validate new methodologies for data set qa

about us


syneos health communications is a network of pr communications branding and advertising companies that help bring new medical products to market
we are expanding the group that helps the company’s clients  biopharma companies  make better marketing decisions through advanced uses of data you will be instrumental in identifying the right approaches tools and methods as well as opportunities to put them to use

types of projects
among the bigger problems you will help solving is optimizing and plugging large historical data lakes into disjoint public and commercial data sets to build models for
identifying factors that influence patients’ adherence to a treatment regimen
ranking a list of physicians by the driving distance between their offices
creating the shortest route for a traveling salesman that will result in the largest number of conversions

it is meaningful and challenging work in a team of supportive and bright colleagues a lot of things will have to be invented and built from scratch you will not be bored
responsibilities
get things done
establish etl for both structuredunstructured data sources from internalexternal sources
manage and create performanceerroranalytics systems and processes for qa of all data sets
create dashboards and api data access tools for both technical and business users
manage and grow our network of data and research partners by finding and evaluating new suppliers and offerings

make us better
introduce best practices for database design processing and workflows
extend our capabilities by helping to build efficient and scalable frameworks
share your knowledge through training others evaluating new tech and building our documentation library
job requirements
we are looking for someone who has done similar work elsewhere you will need to be good at

data management
integrating data sources and schema design
querying troubleshooting and designing sql and nosql databases
working directly with a variety of stakeholders to evaluate project needs
working with common cloud data repositories aws and versioning systems git
building processing pipelines between remote data lakes and local data warehouse

analysis and optimization
making use of data visualization strategies for data qa to develop internal and end user dashboards js libraries and tableau or similar
identifying and maximizing data delivery methods specific to various enduser types

what it will take to succeed here

ship executing the daytoday tasks delivering projects on time and within parameters

background and training degree in informationlibrarycomputer sciences operations research physics engineering field andor relavent work experience

skills 23 years with sql nosql python or similar systems spark

independent problemsolving and grit willingness to own one’s work and confidence to push best practices

obsessive accuracy when it comes to numbers

drive identifying and pursuing the most impactful opportunities requires an entrepreneurial selfdirected attitude creativity and familiarity with the business context healthcare marketing

grow being able to solve problems of increasing complexity requires awareness of gaps in one’s own skills and knowledge and a motivation to fill them lots of selfdirected learning you will have access to whatever online tutorials textbooks and reference materials you need",,MA,False,data_engineer
"Data Engineer - Abu Dhabi, UAE","description
circinus seeks an experienced data engineer to manage process and protocol in a state of the art data analytics center in abu dhabi uae the data engineer will develop implement manage and improve data administration for a rapidly growing intelligence and analytics company with worldwide presence this is a fulltime position with flexible hours in abu dhabi occasional travel between uae and the us may be required this position includes companypaid housing and a comprehensive benefits package

the data engineer will work with a team of talented it professionals data scientist and data analysts to ensure the security and integrity of data and unhindered encumbered or delayed access to data by the analyst team as well as continuous access to data during continuity of operations coop events the data engineer is a direct report to the director of the analytics center in the uae because this is a small team the data engineer will be crosstrained and be expected to assist in performance of a range of other supporting functions related to it including enterprise cyber and anomaly detection

the data engineers responsibilities include

work with the circinus analytics architecture team to design implement enhance and optimize data ingest and etl
create design and maintain reusable datasets for analysis by data scientists and analysts
assess new data sources to better understand availability and quality of data
provide governance and best practices of data structures data integrity and querying
interpret business needs from requests and rapidly implement effective technical solutions
write sql queries to answer questions from the data science team
maintain source code repository of scripts sql python r and other data products dashboards reports etc
work with technology teams baqa dev and admin to understand data capture and testing needs
automate and improve creationmaintenance of reports and dashboards

requirements

programming skills in javascript python sqlnosql and db2 in both a windows and linux operating environment
database design and maintenance including designing new tables and relationships proper database normalization and tuning using database indices
etl extract transform load development including merging and normalizing related data sources
data visualization skills using javascript and other toolslanguages
technical skills in mvc frameworks web api design natural language processing nlp
must possess the ability to communicate clearly concisely and with technical accuracy in both oral and written modes
must be able to work effectively under time constraints and potentially changing priorities while maintaining a high level of attention to detail
must be able to work in a collaborative team environment
bachelors degree in engineering mathematics operations research or computer science or related technical field
current driver’s license and us passport

",,VA,False,data_engineer
Senior Data Engineer,"at skillshare we’re building a platform to connect curious lifelong learners everywhere our teachers and students are constantly interacting with the platform and with each other and the data we capture plays a huge role in driving business decisions and building an informed product as skillshare’s first data engineer you’ll build and own the home for this important data and create robust systems to support analytics and modeling needs

we’ll look to your strategic expertise reliable execution and sound judgment to lead our data warehousing efforts and instrumentation to ensure our team has consistent reliable access to the inputs they need this role is highly collaborative – you’ll work closely with engineers data scientists product leaders and data stakeholders across the company
what youll do
design build and own our data warehouse and the associated etl pipeline
ensure that we have robust instrumentation and logging by implementing key pieces as well as providing leadership to the team to disseminate best practices
collaborate with engineers to optimize queries that power our core application
what youll need to be successful
handson experience building and maintaining data warehouses from scratch
experienced with relational databases and queueing systems we use mysql redshift fluentd aws kinesis elasticsearch etc
passion for data and industry knowledge – you can make informed recommendations about the best tools for our needs and lead the implementation
strong communication skills – you’re a natural collaborator and can report out to stakeholders of all levels
ability to balance strategy and execution
why you want this job
impact harnessing and accessing the right data is at the heart of our growth and this role plays a key role in enabling us to do so
our mission we are building a learning ecosystem for the new economy and changing millions of lives for the better
our team we have a passionate smart team that is a lot of fun to work with
your life we take pride in our flexibility need flexible hours or work a day or two remotely no problem we trust you to do what you need to do
about skillshare

skillshare is an online learning community whose mission is to connect curious lifelong learners everywhere – and in so doing build a more creative more generous and more prosperous world today our community has grown to over 5 million members who come to skillshare to learn creative and entrepreneurial skills network with peers and even teach a class themselves we are backed by union square ventures spark capital amasia spero ventures and burda principal investments

we are an equal opportunity employer all applicants will be considered for employment without attention to race color religion sex sexual orientation gender identity national origin veteran or disability status
apply for this job",,NY,False,data_engineer
Data Engineer,"contractwe are committed to bringing passion and customer focus to the business


job summary

omnigon is looking for a data engineer to build maintain monitor and improve a real time scalable fault tolerant data processing pipeline


the data engineer will support the building of a redshiftbased data mart implementing etl processes and integrating with various marketing platforms sas salesforce and other systems


this is a remote contract position located in the united states



job requirements

4 years of data engineering or related experience
strong java andor scala experience
experience with aws services including s3 redshift emr lambda and rds
experience with stream processing using spark streamingstormbeamflink
experience with messaging systems such as kafka or kinesis
bs in computer science or a related field
excellent communication skills

nice to know
experience with nosql databases such as mongodb cassandra or dynamodb
experience with elasticsearch
experience with machine learning using mahoutdeeplearning4jspark ml

responsibilities
implementing etl processes
monitoring performance and advising any necessary infrastructure changes
defining data retention policies
collaborate with team members to help shape requirements

about omnigon

omnigon an infront sports  media company is a team of digital strategists artists and technologists working exclusively in the areas of consumer loyalty audience growth and digital content delivery since its founding in 2008 omnigon has established itself as a market leader focused on helping clients achieve returns on the strategic creative and technical investments theyve made omnigon headquartered in new york and with teams in los angeles london toronto kiev and st petersburg works with celebrated global brands including as roma pga tour nascar concacaf the united states golf association usga international champions cup stubhub under armour legends fox sports the german football association dfb and countless others


are you ready to contribute to transforming and enhancing every aspect of the sports industry unite your passion for sports with a rewarding career by joining our one team of talented highlymotivated and hardworking individuals please submit your online application now

infront is an equal opportunities employer",,CA,False,data_engineer
Big Data Engineer,"description
job summary

the job designs and engineers solutions associated with analytic data for the organization and working closely with the business analytic and it teams assists with the build and upkeep for these solutions this includes coding data ingestion transformation and delivery programslocic for analysts to access operational derived and external data sets expected deliverables will include coding of delivery frameworks to load and transform raw source data into enhanced analytic assets being a key resource for analytical and big data efforts working with architects analysts and data scientists as needed the incumbent is responsible for the operation and execution of projects related to big data or other analytic platforms works in a team to leverage experience in analyzing and delivering large data sets by using a variety of delivery tools to perform tasks ability to work in crossfunctional teams from different organizations both technical and nontechnical on projects provides guidance and education to junior level staff technologies such as but not limited to hadoop hive nosql spark python sas teradata oracle informatica

essential responsibilities
work closely with it architect and engineer solutions that provide views for the enterprise data hub or other analytic ecosystems this includes working with the appropriate teams building out the design and providing upkeep for the solution create high performance big data and traditional systems to be used with analytic applications
code test process and maintain data resources for the analytics organizations this will include working to maintain data sourcing transformation and delivery for key analytic platforms throughout the organization etlelt
work with alternative analytic data systems to incorporate them into the operational data flow for the analytics teams work with data science teams and strategic partners on capabilities of core platform this may include products purchased by the organization that must be ingested or modeledderived data maintained by analytic teams
responsible for delivery of assigned projects this may include providing guidance and junior contributors within team will attend meetings with customers as needed
assist with the establishment of standards and patters for high performance data ingestion transformation and delivery of data analytic needs keep current with big data technologies in order to recommend best tools in order to perform current and future work
other duties as assigned
education

required
bachelors degree in computer systems analysis computer engineering data processing healthcare informatics or management information systems
substitutions
none
preferred
masters degree management information systems healthcare informatics or computer engineering
experience

required
3  5 years in analytics
1  3 years in it application  hadoop
preferred any of the following
3  5 years in data warehousing
3  5 years in the healthcare industry
1  3 years in database administration
licenses and certifications

required
none
preferred
none
skills
sql
data warehousing
problemsolving
communication skills
analytical skills

language other than english
none

travel required
0  25

physical mental demands and working conditions

position type
officebased

teaches  trains others regularly
occasionally

travel regularly from the office to various work sites or from sitetosite
rarely

works primarily outofthe office selling productsservices sales employees
never

physical work site required
yes

lifting up to 10 pounds
constantly

lifting 10 to 25 pounds
rarely

lifting 25 to 50 pounds
rarely

disclaimer the job description has been designed to indicate the general nature and essential duties and responsibilities of work performed by employees within this job title it may not contain a comprehensive inventory of all duties responsibilities and qualifications required of employees to do this job

compliance requirement this job adheres to the ethical and legal standards and behavioral expectations as set forth in the code of business conduct and company policies",,PA,False,data_engineer
Quantitative Data Engineer,a leading quantitative investment company focused on computerdriven trading in global financial markets is searching for a talented quantitative data engineer to join the team the business is a team of researchers engineers and financial industry professionals using sophisticated statistical models to analyze data identify predictive signals and generate superior investment returns in a collaborative environment their investment teams each focus on their independent strategies while utilizing the firm’s proprietary stateoftheart technology and data platform to optimize their alpha research they are passionate about implementing scientific and mathematical methods to explore isolate and solve problems in the global financial markets they believe that career fulfillment and enterprise success converge when smart hardworking and intellectually curious people come together with a shared goal of innovation and the pursuit of excellencejob summary the quantitative data engineer will join a small high performing team focused on trading global markets in a completely automated fashion this role is an exciting opportunity for a strong technologist looking to get exposure to several aspects of quantitative trading with wide ranging responsibilities across data research infrastructure realtime trading and operations the team believes in rewarding people on merit and excellence not necessarily on experience work is fastpaced decision making is efficient and changes are quickly implementedresponsibilities design and maintain data pipelines that fuel research and production tradingbuild machine learning  dataoriented toolsdevelop and support applications for all aspects of an automated trading system  order handling risk operations reportinganalyze trading data to optimize and improve trade execution performanceday to day maintenance and monitoring of complex trading algorithms in a realtime environmentcommunicate with internal groups and external counter parties to solve trading issuesdynamically adapt to evolving business needscandidate attributes keen interest in quantitative trading and metrics driven decision makingdetail oriented and a passion for spotting trends in datadesire to tackle challenging problems under tough deadlinesother requirements strong programming skills in python c kdb good to havefamiliarity with vector programing and functional languagesbasic knowledge of statistics machine learningcomfortable on the linux command linepractical knowledge of operating system and networking basics2  5 years of work experience in a fastpaced environmenttakes pride in well documented systems and can communicate their work to the rest of the teamjob type fulltimeeducationbachelors required,,NY,False,data_engineer
Data Engineer,contractdata engineerduration 2 yearslocation rockville md andor baltimore mdclearance  ability to obtain a public trustsome local travelthe sr data engineers mission will be to guide this platform’s development so that it becomes the engine of a healthcarewide transition to valuebased care by enabling effective data sharing analytics performance transparency and valuebased paymentresponsibilities expected to provide hands on software development support for a large data warehouse project hosted in a cloud environmentprovide architectural guidance and oversight to projects within a teambe a mentor to junior and midlevel engineersenforce highquality coding standards and practices via reviews and by demonstrating this in their own workbe able to help others break down large team goals into specific and manageable tasksbe involved and supportive of agile sprint model of development helping to enforce the practice and the disciplineable to work efficiently and proactively across engineering teams to enable us to deliver on our goals of loosely coupled adaptable scalable solutionshave a good understanding of where their project fits into the larger goals for engineering and adapts their work so that the priorities of the systems they are creating match those of the organizationqualifications demonstrated expertise with java scala and pythonexperience software development in a team environmentexperience with one or more software version control systems eg git subversionexperience software development on a team using agile methodologyfamiliarity with devops tools and techniques eg continuous integration jenkins puppet etcexperience with cloud infrastructure eg amazon web servicesexperience with big data processing frameworks eg sparkpreferred experience with big data tools eg databricksvery strong sql skills experience with parquet filesexceptional communication and listening skills with the ability to break down problems and generate shared understanding across technical and nontechnical audiencesexperience in enterprise software or healthcarerelated domainspreferred knowledge of medicaid  medicare and databricks  notebookseducation bachelors degree in computer science statistics applied math or related fieldjob type contract,,MD,False,data_engineer
Data Engineer,"about capgemini

with almost 200000 people in over 40 countries capgemini is one of the worlds foremost providers of consulting technology and outsourcing services the group reported 2017 global revenues of usd 1578 billion together with its clients capgemini creates and delivers business and technology solutions that fit their needs and drive the results they want a deeply multicultural organization capgemini has developed its own way of working the collaborative business experiencetm and draws on rightshore® its worldwide delivery model learn more about us at httpwwwcapgeminicom rightshore ® is a trademark belonging to capgemini rightshore® is a trademark belonging to capgemini
 capgemini america inc is an equal opportunity employer encouraging diversity in the workplace all qualified applicants will receive consideration for employment without regard to race national origin gender identityexpression age religion disability sexual orientation genetics veteran status marital status or any other characteristic protected by law
this is a general description of the duties responsibilities and qualifications required for this position physical mental sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed whenever necessary to provide individuals with disabilities an equal employment opportunity capgemini will consider reasonable accommodations that might involve varying job requirements andor changing the way this job is performed provided that such accommodations do not pose an undue hardship



job responsibilities

job title data engineer
location charlotte nc
duties  responsibilities
the resources must have domain technical experience in delivering data
engineering solutions using data lake technology and experience working with
our it support team
experience with the following hadoop cdh relational databases and sql
etl development spark data validation and testing data warehousing
etlelt to the data lake using the data lake for data analysis hadoop tools
hive impala pig sqoop hue kafka etc python r java docker dakota
knowledge of cloud platform implementation azure or amazon knowledge of
data visualization tools is also a plus axa us uses tableau on multiple
platforms along with python visualization in the data lake using pandas and
bokeh packages
experience with collaborative development workflows eg microsoft vsts
relevant technical skills include applied mathematics statistics calculus
quantitative or statistical methods or techniques data mining informatics
machine learning data science programming computational algorithms
databases artificial intelligence natural language processing bayesian
inference markov logic java software engineering andor systems design
analysis
excellent written verbal and interpersonal skills a must as there will be
significant collaboration with the business and it",,,False,data_engineer
Data Engineer,position title data engineerexperience three to five years experience with data warehousingstatus full time employeejob location arlington virginiabusiness hours 900530 mfstart date immediatelysalary  commensurate with experiencetravel 0  5please include cover letter explaining pertinent data engineering experience resumes without cover letters will not be taken into considerationcompany overviewmorten beyer  agnew mba established in 1992 is an international consulting firm specializing in transaction advisory valuation and strategic analysis within the commercial aviation industry mba provides support to investment banks aircraft owners operators investors lessors and governments on their respective involvement with commercial aviation more information can be found at wwwmbaaeroposition descriptionyou will be part of a world class digital services team in the market intelligence group supporting data services and other product offerings of morten beyer  agnew and supporting a data warehouse process used by a global community of aviation professionals and the various groups as stakeholders internally the team is responsible for ensuring the health of the data warehousing efforts internally supporting reliability across the various systems high performance and high availability for the clientbasethe database engineer will report to the managing director on topics such as the development and organization of the databases assessment and implementation of new technologies and providing the it group with a longterm perspective on the relationship of database technology to the business opportunities facing the company to help achieve a stateoftheart environment that meets current and future objectives this will include providing technical support and administration of all database installations designing and schedulingqualifications  responsibilities – applicants should be able to address all the following criteria requirementsbachelors degree in computer science information systems or engineering3  5 years of handson database administration support and performance tuning experienceprior sdlc experience or experience in a startup or agile or dev ops environment is a plusadvanced working knowledge of sql and plsqlexperience with pentaho talend or any other etl tool preferredexperience with python bash or any scripting language  preferredknowledge of software development and user interface web applicationsan ability to understand frontend users requirements and a problemsolving attitudeexperience with freebsd linux dtrace go zfspackage building and upgrades in a production environment  mysql  postgresql 9x experience with gitunderstanding of virtualization and clustered environmentsinterest in aviation industryresponsibilitiesdatabase administration  install configure upgrade and migrate existing databases listed belowsolid knowledge of physical and logical database designset up highly available architectureautomate various dba tasksoptimize performance and monitor the data warehouse for integrity and solve outstanding issuesreview processes and identify areas of improvementtroubleshoot and optimize queries and performance bottlenecksdevelopment and maintenance of the database stored procedures views and functions in postgresql for hosted web applications  maintaining and updating etl process with various methods tools ie bashpythonpentahoworking closely with development team to partition requirement needs based on backendfrontend change requirementsanalysis and visualization of data using kpisdevelop technical and training manualsbenefitshealth insurance dental insurance longterm disability insurance life insurance flexible spending account fsa paid parking paidtimeoff pto 401k participation with company matching contributionjob type fulltimeexperiencedatabase administration 3 years requiredpostgresql 1 year preferredscripting 1 year preferredsql 1 year requiredshell scripting 1 year preferred,,VA,False,data_engineer
Systems Data Engineer,"description
perform data analytics extraction support the fundamental structure of applications and relational databases understands solutions that enables one to investigate analyze and provide comprehensive resolution for service requests by using applicable monitoring and troubleshooting tools and techniques provides ongoing systems and user support of one or more computer applications consults in system design build configuration and implementation within the appropriate tools used by the solution utilizes technical expertise to configure the system and solve client issues provide advanced design and maintenance of programs using visual basiccerner command languagesql creates scripts reports and data files supports financial applications including accounts payable materials management edi and general ledger
education associate degree in information systems or related discipline experience ten years as a systems analyst and programmer visual basic cclsql programming skills and relational database knowledge experience health care experience
experience
ten years as a systems analyst and programmer ten years advanced programming in visual basiccclsql skills and relational database required health care experience

schedule fulltime
shift day shift monfri 800 am430 pm
education
license or experience experience is preferred
location carolinaeast medical center
department information systems",,NC,False,data_engineer
Data Scientist/Engineer in NYC,"we are seeking a senior data engineerscientist to assist in improving our optimization algorithms in the same week you could work on userfacing interfaces and reports with frontend developers write code to import process and qc terabytes of new data and work with analysts and statisticians to ensure the validity of our processes a strong understanding of data structures algorithms and software design is a must

required skills

bachelor’s degree in computer science or a related field or 4 additional years of relevant work experience • a strong understanding of data structures algorithms and effective software design • significant development experience with a major modern language eg java scala python ruby cc etc • experience with a distributedparallel computing engine such as apache spark or hadoop • experience wrangling terabytes of big complicated imperfect data • significant experience working with structured and unstructured data at scale and comfort with a variety of different stores keyvalue document columnar etc as well as traditional rdbmses and data warehouses • comfort with version control systems eg git svn • excellent verbal and written communication skills must work well in an agile collaborative team environment
master’s in computer science or a related field • experience with big datatechnologies such as cassandra kafka hbase • basic understanding of statistics and experience with statistical packages such as r matlab spss etc • practical experience with supervised machine learning techniques • experience with aws products • experience writing unit and functional tests
we are unable to sponsor a visa at this time  must be us citizen no 3rd party candidates
best

miranda krayca
senior recruiter
comcentric inc
3039936873",,NY,False,data_engineer
Data Engineer,"yaptas mission is simple to give our customers confidence in travel to that end we are one of the world’s leading companies for fare transparency and cost savings we analyze billions of rates every month and turn all that data into meaningful notifications and reports we provide automated services for corporate travelers to save money by tracking prices on airline tickets and hotels and sending alerts when prices drop
we were recently named to deloitte’s fast 500 are highly profitable and have grown 400 in the past 4 years our team is fast paced and focused but we maintain a healthy worklife balance and have fun we value integrity flexibility accountability drive and collaboration
are you excited about the convergence of technology and travel do you want to be a part of a cohesive agile team do you fall asleep thinking about indexes transforms and solutions for streaming data ingest come help us build our cuttingedge data platform powering insights used by some of the biggest brands in the world
how you’ll succeed on the team
youre passionate about getting at data and creating high quality easy to consume views into that data
you continually improve by learning from others and you jump in when a teammate could use your help
you care about your customers and understand how your data contributes to the goals of the business
you have an agile mindset and are comfortable refining vague requirements
you can sense miscommunications among team members and do your part to improve understanding
you thrive in and contribute to a positive work environment where everyone shares constructive thoughts and suggestions
requirements must have experience to be eligible for consideration
minimum of 3 years of professional software development experience in a handson datacentric role in data engineering architecture streaming or warehousing is required
comfortable working with a mix of structured  unstructured data from a variety of sources is required
experience with at least one modern serverside language such as python java or similar is required
experience with at least one relational database technology mysql postgres ms sql etc is required
proficient with sql and schema design is required
preferred experience very helpful skills as they will be important in this role
familiarity with cloud services and infrastructure preferably aws
familiarity with columnar store databases vertica redshift snowflake etc
experience building out data ingest pipelines
experience building out or working within extract load transform  data lake architectures
experience with spark dataframes pandas a big plus
experience transforming partially or fully unstructured data into more easily queryable formats
experience tuning databases for performance
experience working in an agile environment such as scrum or kanban
knowledge of machine learning tools  concepts a plus
what we offer
fun collaborative environment
optional workfromhome wednesdays
competitive compensation and benefits package including medical dental and vision insurance
5 weeks of pto and 10 paid holidays total 7 weeks
401k
stock options
commuter benefits
stocked kitchens with coffee soda and snacks
regular team activities including mariners games ping pong tournaments movies etc
this position is based in pioneer square in downtown seattle candidates must be eligible to work in the us
we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,WA,False,data_engineer
Big Data Engineer,"overview
imagine a career where your creative inspiration can fuel big innovation immerse yourself in our award winning culture while creating breakthrough retail solutions that simplify the lives of customers worldwide

7eleven is expanding its social mobile and digital footprint with a full suite of products and services that are revolutionizing the industry at the newly formed digital center of excellence team we are looking to foster innovation by focusing on designing experiences for customer delight and test  learn methodologies the breadth and depth of these customerdriven innovations mean limitless opportunities for you to turn your ingenious ideas into reality at 7eleven

discover what it’s like to be part of a team that rewards taking risks and trying new things it’s time to love what you do
responsibilities
looking for individuals with an unmistakable passion for building elegant and intuitive data integration pipelines need to be opinioned and passionate about what you do both at a tech level and at a business level not afraid to challenge the norm
qualifications
35 years of experience in architecting and building enterprise scale systems is required
expertise with hdfsbased computing frameworks like spark kafka storm or similar are required
experience with r python shbash and jvmbased languages including scala and java hadoop family languages including pig hive high performance data libraries including spark numpy tensorflow or similar with the ability to pick up new languages and technologies quickly
ability to manually and programmatically interact with data stored in traditional relational databases as well as nosql databases like cassandra and mogodb
experience in hdinsights azure data lake azure data lake analytics and azure data factory is required
experience in cloud and distributed systems principles including load balancing networks scaling inmemory vs disk etcis required
marketing technologycrm functional expertise highly desired but not required
experience dealing with data in a retailmarketing organization preferred but not required
internal posting dates 0828  911",,TX,False,data_engineer
IT Big Data Engineer,"are you passionate about delivering building robust and scalable solutions using big data technologies do you have a curious nature always interested in how to innovate we’re looking for someone like that to help us
– build a data hub for applications supporting wma business
– analyze data on mainframe and big data platform
– build relationship and work closely with developers data modelers data stewards and data governance teams
youll be working in the wma it team in weehawken nj we are a team of open minded highly motivated and forward thinking professionals who care about strategy and quality you will be cooperating with multiple teams located in us and in india working on a strategic data architecture platform we are the central data hub for core wma data the single version of the truth providing data for downstream processing reporting and analytics all teams are highly skilled and capable in big data and etl technologies you will collaborate closely with the business the office of the cdo cto quality assurance and it professionals this initiative has a very high profile and is recognized to be a core component of our business strategy over the next three years you will be based in the ubs office in weehawken nj if you love data new technologies and innovation then this position is for you

you have

at least 10 years of it experience  of which 35 years of experience in a developer role in big data environment with hadoop distributions such as cloudera or hortonworks  who will play a major role in implementation of big data refinery for ubs wealth management organization
strong programming skills using informatica bdm scalaspark python sql
experience with hortonworks or cloudera hdfs hive hbase impala spark kafka flume pig etc
experience of developing streaming applications using scalaspark cassandra
hands on unix shell scripting experience
experience preferably with autosys jil

you are
– proactive keeping stakeholders well informed of development effort status
– comfortable working in dynamic environments with fastpaced deliveries and changing requirements
– expected to work interdependently collaborate negotiate
– skilled at recognizing system deficiencies and implementing effective solutions

dicetech
expert advice wealth management investment banking asset management retail banking in switzerland and all the support functions thats what we do and we do it for private and institutional clients as well as corporations around the world

we are about 60000 employees in all major financial centers in more than 50 countries do you want to be one of us
together that’s how we do things we offer people around the world a supportive challenging and diverse working environment we value your passion and commitment and reward your performance

keen to achieve the worklife agility that you desire were open to discussing how this could work for you and us

why ubs video
are you truly collaborative succeeding at ubs means respecting understanding and trusting colleagues and clients challenging others and being challenged in return being passionate about what you do driving yourself forward always wanting to do things the right way does that sound like you then you have the right stuff to join us apply now
ubs is an equal opportunity employer we respect and seek to empower each individual and support the diverse cultures perspectives skills and experiences within our workforce",,NJ,False,data_engineer
Data Engineer,"role summary
the data engineering team helps solve our customers toughest challenges making flights safer power cheaper and oil  gas production safer for people and the environment by leveraging data and analytics the data engineer will work with the team to create stateoftheart data and analytics driven solutions working across ge to drive business analytics to a new level of predictive analytics while leveraging big data tools and technologies

essential responsibilities
as a data engineer you will be part of a data engineering or crossdisciplinary team on commerciallyfacing development projects typically involving large complex data sets these teams typically include statisticians computer scientists software developers engineers product managers and end users working in concert with partners in ge business units potential application areas include remote monitoring and diagnostics across infrastructure and industrial sectors financial portfolio risk assessment and operations optimization

in this role you will

performs a variety of data loads  data transformations
working knowledge of methods for parsing formatting  transforming data into units consistent with analytical needs
demonstrates proficiency in implementation of logicalphysical data models that support mdm best practices
performs integration of multiple data sourceformats into master data load
proficient in the use of at least one etl tool
must have good communication skills  both oral and written

qualificationsrequirements
basic qualifications

bachelors degree in business computer science or in stem majors science technology engineering and math
fluent in relational database platforms and programming languages oracle sql server open source databases with minimum 5 years of experience as data
engineer
experience and understanding of microsoft azure dbms related services and virtual machines platforms
a minimum of 3 years of technical experience along with established credentials across disciplines and functions within a product

eligibility requirements

legal authorization to work in the us is required we will not sponsor individuals for employment visas now or in the future for this job
must be willing to work out of an office located in providence ri

desired characteristics
technical expertise

working knowledge of db technologies distributed systems automation oracle exadata sql server open source dbs
deployment  automation and configuration management tools dockerchefpuppet refactory and jenkins
understands the technology landscape up to date on current technology trends and new technology brings new ideas to the team and ability to analyze impact of technology choices
skilled in breaking down problems documenting problem statements and estimating efforts

leadership

demonstrates clarity of thinking to work through limited information and vague problem definitions
influences through others builds direct and behind the scenes support for ideas
proactively identifies and removes project obstacles or barriers on behalf of the team
shares knowledge power and credit establishing trust credibility and goodwill

personal attributes

selfmotivated able to work independently
excellent communication skills and the ability to interface with leadership with confidence and clarity
ability to work well with global teams including timezone flexibility manage multiple priorities across the technology stack
ability to identify quantify and resolve technical problems along with deep passion for learning

dtr

about us
at ge digital we are creating technology and solutions to enable social mobile analytical and cloud capabilities for the industrial internet the industrial internet is an open global network that connects people data and machines it’s about making infrastructure more intelligent and advancing the industries critical to the world we live in at ge we believe it’s about the future of industry—energy healthcare transportation manufacturing it’s about making the world work better ge offers a great work environment professional development challenging careers and competitive compensation ge is an equal opportunity employer employment decisions are made without regard to race color religion national or ethnic origin sex sexual orientation gender identity or expression age disability protected veteran status or other characteristics protected by law
ge offers a great work environment professional development challenging careers and competitive compensation ge is an equal opportunity employer employment decisions are made without regard to race color religion national or ethnic origin sex sexual orientation gender identity or expression age disability protected veteran status or other characteristics protected by law

locations united states rhode island providence

ge will only employ those who are legally authorized to work in the united states for this opening",,RI,False,data_engineer
Data Engineer,"data engineer

at gumgum our ad server produces over 50 tb of new raw data every day it amounts to 100 billion events per day that needs to be processed dealing with data at this scale is challenging in a number of ways we deal with number offtheshelf frameworks including spark kafka cassandra dynamodb redshift but often push them past their limits this team is responsible for providing critical ad reporting data for gumgum’s internal and external customers

as a data engineer you will be building and maintaining exciting systems services and data tools you’ll bring your experience with complex distributed systems passion for performance and optimization and ability to write highly scalable and fault tolerant code

responsibilities refining our data infrastructure technologies such as kafka spark druid fluentd to support real time analysis of data
 own the core data pipelines and scale our data processing flow build scalable systems with various aws  big data technologies lead technical discussions participate in code reviews guide the team in engineering best practices must be able to write quality code and build secure highly available systems
 work on gumgum’s proprietary reporting server work on various reports using groovy sql and java works on gumgum’s proprietary forecasting system
requirements at least a bachelors degree in computer science or equivalent 3 years of software engineering experience javascalapython experience with large scale distributed realtime systems with tools such as aws spark kafka hadoop familiar with various aws services serverless architecture and containers experience with high volume high availability production systems strong problem solving skills strong verbal and written communications skills

perks stock options 401k great medicaldental plans unlimited pto great coworkers monthly happyhours located in hotbed of tech startups just blocks from the beach",,CA,False,data_engineer
Data Engineer,"do you want to have an impact it starts with the data we absorb billions of data points a day and transform into a full resolution identity graph as part of an early stage team you will make an impact in creating a robust and scalable data platform to fuel drawbridge’s data needs you will architect and build powerful data pipelines that will enable business insights and efficient if you are a motivated individual that wants to work on bleedingedge technology making vast sums of data accessible to others weve saved you a seat on our team

about drawbridge
drawbridge is the leading digital identity company building patented crossdevice technology that fundamentally changes the way brands connect with people we use largescale ai and machine learning technologies to build democratized solutions for consumerfriendly identity our technology is driving the intersect between martech and other categories with applications including advertising personalization content management product recommendations authentication and risk detection we’re headquartered in silicon valley backed by sequoia capital kleiner perkins caufield byers and northgate capital and have been listed on cnbc’s annual disruptor 50 list of groundbreaking companies twice named one of fortune’s 50 companies leading the ai revolution and has been included on the inc 500 list of fastest growing companies in america for two consecutive years for more information visit wwwdrawbridgecom
what youll do
work with analytics and product management to ensure optimal data design and efficiency
identify and drive scalable solutions for building and automating reports pipelines and dashboards
partner with engineering teams to ensure data quality
build scalable data pipelines and create data models to support analysts and other stakeholders
what you bring to the table
knowledge of hadoop ecosystem and willingness to learn more spark hive presto pig… ect
experience with relational databases mysqlvertica redshift… ect
experience with etl design implementation and maintenance
experience with bi reporting  visualization tools knowledge of tableau is preferred
development experience with python
you are a proactive self starter with a willingness to learn and adjust in a fastpaced working environment
whats in it for you
contribute to a fastpaced highgrowth company that will challenge you and which was recently featured in forbes fortune techcrunch and adweek
have a huge impact in the hottest growth area in digital advertising
get rewarded with competitive pay benefits and preipo stock options
work with fun intelligent people in a great work environment
enjoy gourmet coffee free lunches sweet  salty snacks and keg
medical ppo and hmo options dental and vision coverage
flexible spending account fsa benefit
life and disability insurance
401k savings plan
attractive vacation sick gymhealth and holiday benefits
an excellent work culture of fun respectful open minds diversity and teamwork
the drawbridge “x” factor
sure we’ve got the usual requisite stuff like happy hours brownbag talks free lunches snacks and more but what sets drawbridge apart is the authentic sense of community we actually like hanging out together whether we’re working to move the company forward or getting to know each other a little better – in and out of the office our culture makes us excited to come to work and we know that this strength helps us attract talented individuals who go above and beyond if you’re different you’ll fit

as part of our dedication to the diversity of our workforce drawbridge is committed to equal employment opportunity without regard to race color national origin ethnicity gender protected veteran status age disability sexual orientation gender identity or religion or any other unlawful factor drawbridge complies with all applicable laws including those regarding consideration of qualified applicants with criminal histories such as the san francisco fair chance ordinance we are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our drawbridge participates in everify

note to recruiters and placement agencies drawbridge does not accept unsolicited agency resumes please do not forward unsolicited agency resumes to our website or to any drawbridge employee drawbridge will not pay fees to any third party agency or firm and will not be responsible for any agency fees associated with unsolicited resumes unsolicited resumes received will be considered the property of drawbridge",,CA,False,data_engineer
Data Enginner,"job description
are you passionate about data does the prospect of dealing with massive volumes of data excite you do you want to build data engineering solutions that process billions of records a day in a scalable fashion using aws technologies do you want to create the nextgeneration tools for intuitive data access

amazons finance technology team is seeking an outstanding data engineer to join the team that is shaping the future of the finance data platform the team is committed to building the next generation big data platform that will be one of the worlds largest finance data warehouse to support amazons rapidly growing and dynamic businesses and use it to deliver the bi applications which will have an immediate influence on daytoday decision making amazon has culture of datadriven decisionmaking and demands data that is timely accurate and actionable our platform serves amazons finance tax and accounting functions across the globe

as a data engineer you should be an expert with data warehousing technical components eg data modeling etl and reporting infrastructure eg hardware and software and their integration you should have deep understanding of the architecture for enterprise level data warehouse solutions using multiple platforms rdbms columnar cloud you should be an expert in the design creation management and business use of extremely large datasets you should have excellent business and communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions the individual is expected to be able to build efficient flexible extensible and scalable etl and reporting solutions you should be enthusiastic about learning new technologies and be able to implement solutions using them to provide new functionality to the users or to scale the existing platform excellent written and verbal communication skills are required as the person will work very closely with diverse teams having strong analytical skills is a plus above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive change

our ideal candidate thrives in a fastpaced environment relishes working with large transactional volumes and big data enjoys the challenge of highly complex business contexts that are typically being defined in realtime and above all is a passionate about data and analytics in this role you will be part of a team of engineers to create worlds largest financial data warehouses and bi tools for amazons expanding global footprint

responsibilities
design implement and support a platform providing secured access to large datasets
interface with tax finance and accounting customers gathering requirements and delivering complete bi solutions
model data and metadata to support adhoc and prebuilt reporting
own the design development and maintenance of ongoing metrics reports analyses dashboards etc to drive key business decisions
recognize and adopt best practices in reporting and analysis data integrity test design analysis validation and documentation
tune application and query performance using profiling tools and sql
analyze and solve problems at their root stepping back to understand the broader context
learn and understand a broad range of amazon’s data resources and know when how and which to use and which not to use
keep up to date with advances in big data technologies and run pilots to design the data architecture to scale with the increased data volume using aws
continually improve ongoing reporting and analysis processes automating or simplifying selfservice support for datasets
triage many possible courses of action in a highambiguity environment making use of both quantitative analysis and business judgment
basic qualifications
bachelor’s degree in cs or related technical field
6 years experience in dimensional data modeling etl development and data warehousing
experience with redshift andor other distributed computing systems
excellent knowledge of sql and linux os
sql performance tuning
server management and administration including basic scripting
basic dba tasks
solid experience in at least one business intelligence reporting tool
preferred qualifications
master’s degree in information systems or a related field
knowledge of big data solutions experience with hadoop hive or pig
experience with redshift and other aws services
excellent communication verbal and written and interpersonal skills and an ability to effectively communicate with both business and technical teams
knowledge of a programming or scripting language r python ruby or javascript
experience with java and map reduce frameworks such as hivehadoop
strong organizational and multitasking skills with ability to balance competing priorities
an ability to work in a fastpaced environment where continuous innovation is occurring and ambiguity is the norm",,WA,False,data_engineer
Business Intel Engineer I,"job description
amazon seeks an experienced business intelligence engineer bie to join a newly created enterprise risk management and compliance ermc team amazon has a diverse set of global businesses and each business has some level of compliance requirements across multiple areas including payments trade human resources tax social responsibility and others while the responsibility for maintaining compliance is with the individual business areas this team ensures each business has an effective ermc program with processes controls and selftesting in place to address their regulatory responsibilities this team also assists in risk ranking and mitigation of gaps identified throughout the organization

in this role you will own the root cause analysis for the transactions reported to the regulatory bodies for the denied party screening program by enterprise risk management and compliance ermc the root cause analysis will drive longterm strategic decisions for ermc on where to invest preventative technological resources you will need to collaborate effectively with internal stakeholders and crossfunctional teams to solve problems create operational efficiencies and deliver successfully against high organizational standards you should be able to apply a variety of tools data sources and analytical techniques to answer a wide range of highimpact business questions and present insights in a concise and effective manner this is a high impact role with goals that directly influence the bottom line of the business

responsibilities include but not limited to
apply analytics and data mining techniques to solve complex problems and drive business decisions
employ appropriate tools methodologies to discover patterns of risks gaps and help reduce reportable transactions to the regulatory bodies
solve analytical problems and effectively communicate methodologies and results
design and develop automated dashboards to monitor and highlight key trends drivers and anomalies
partner with operations tech  and compliance to quantify risks and opportunities for the improved screening
basic qualifications
babs in computer science engineering statistics mathematics finance or related field3 years’ experience as a bie data analyst data scientist data engineer or similar job function in a technology companydemonstrated strength in sql data modeling etl development and data warehousingadvanced skills in excel as well as any data visualization tools like quicksight tableau or similar bi toolsexperienced working in very large data warehouse environmentsadvanced knowledge of microsoft officepredominantly ms excel and ms sharepointknowledge of aws solutions such as redshift s3advanced ability to draw insights from data and clearly communicate them to the stakeholders and senior management
preferred qualifications
mba or master in computer science engineering statistics mathematics finance or related fieldexperienced supporting projects involving complex data sets and high variabilityexperienced conducting complex data analysis whatif scenarios ab testing etc and using ml modelsexcellent communication verbal and written interpersonal skills and ability to effectively communicate with both business and technical teamsexperienced handling confidential and sensitive datadesigned and developed data infrastructure to support business growth

amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,WA,False,data_engineer
Data Engineer,"the webbmason analytics data engineer helps our clients turn data into knowledge so they can make better decisions faster the data engineer will work with clients and other team members to analyze and help define requirements mine and analyze data integrate data from a variety of sources and participate in the design and implementation of reports algorithms and other data processing and analysis techniques the most fundamental role of the data engineer to is deliver highquality data pipelines for producing analyticsready datasets

data engineer responsibilities

deliver endtoend analytics projects including data ingest data transformation data science and data visualization
design and deploy databases and data pipelines to support analytics projects
clearly document datasets solutions findings and recommendations to be shared internally  externally
learn and apply tools and technologies proficiently including
languages sql standard and dbspecific python r sparkscala bash
frameworks hadoop spark aws
toolsproducts data science studio alteryx jupyter rstudio tableau powerbi
build compelling visualizations and dashboards that address the analytic needs of the endusercustomer
performance optimization for queries and dashboards
develop and deliver clear compelling briefings to internal and external stakeholders on findings recommendations and solutions
analyze client data  systems to determine whether requirements can be met
test and validate data pipelines transformations datasets reports and dashboards built by team
develop and communicate solutions architectures and present solutions to both business and technical stakeholders
provide end user support to other data engineers and analysts

requirements

expertise in sql and python other programming languages r scalaspark sas java etc are a plus
experience with data and analytics technologies including rdbms etl and bi
experience with hadoop or other big data technologies
experience with aws or other cloud technologies
experience with agile delivery methodologies andor jira
experience working on linux commandline
bs or higher in related field
master’s degree in related field

",,MD,False,data_engineer
Data Engineer (Boston),"quantumblack helps companies use data to drive decisions we combine business experience expertise in largescale data analysis and visualization and advanced software engineering knowhow to deliver results from aerospace to finance to formula one we help companies prototype develop and deploy bespoke data science and data visualisation solutions to make better decisions
who youll work with
our consultant data engineers work closely with our clients and our data scientists in order to curate transform and construct features which feed directly into our modelling approach
this would be a hybrid clientfacingtechnical role using cutting edge technologies whilst also being able to communicate complex intractable ideas to nontechnical audiences gathering clear requirements is a key part of this role and will define the technical strategy the team employs on the study
our projects cover a wide range of industries and may expose you to problem areas such as disease epidemiology athlete injury prediction or salesforce effectiveness optimisation and many more in order to gain insight from previously ignored and unconnected data you will need to extract information from vast array of different data sources such as data warehouses sql databases legacy applications unstructured data documents emails apis kafka endpoints and graph databases
what youll do
work with our clients to model their data landscape obtain data extracts and define secure data exchange approaches
acquire ingest and process data from multiple sources and systems into big data platforms
understanding assessing and mapping the data landscape
maintaining our information security standards on the engagement
collaborate with our data scientists to map data fields to hypotheses and curate wrangle and prepare data for use in their advanced analytical models
defining the technology stack to be provisioned by our infrastructure team
building modular pipeline to construct features and modelling tables
use new and innovative techniques to deliver impact for our clients as well as internal rd projects
mentoring and developing junior data engineers on engagements
requirements
strong experience with at least two of the following technologies python scala sql java
commercial clientfacing project experience is beneficial including working in closeknit teams
the ability to work across structured semistructured and unstructured data extracting information and identifying linkages across disparate data sets
good experience in multiple database technologies such as
distributed processing spark hadoop emr
traditional rdbms ms sql server oracle mysql postgresql
mpp aws redshift teradata
nosql mongodb dynamodb cassandra neo4j titan
a proven ability in clearly communicating complex solutions
have a strong understanding of information security principles to ensure compliant handling and management of client data
experience and interest in cloud platforms such as aws azure google platform or databricks
strong experience in traditional data warehousing  etl tools informatica talend pentaho datastage
exceptional attention to detail",,MA,False,data_engineer
"Senior Data Engineer, Apple Media Products","apple is seeking a highly skilled data engineer to join the data engineering team within apple media products amp home to apple music app store itunes and more has some of the most compelling data in the world we are looking for a talented engineer who is motivated by challenging problems and well versed with big data technologies this is a unique opportunity to join a focused team and work collaboratively with other groups to make a significant impact

key qualifications
experience in high level programming languages such as java scala or python
proficiency with databases and sql is required
proficiency in data processing using technologies like spark streaming spark sql or mapreduce
expertise in hadoop related technologies such as hdfs azkaban oozie impala hive and pig
expertise in developing big data pipelines using technologies like kafka flume or storm
experience with large scale data warehousing mining or analytic systems
ability to work with analysts to gather requirements and translate them into data engineering tasks
aptitude to independently learn new technologies
description
as a member of the data engineering team you will have significant responsibility and influence in shaping its future direction this role is inherently cross functional and the ideal candidate will work across disciplines we are looking for someone with a love for data and ability to iterate quickly on all stages of data pipeline this position involves working on a small team to develop large scale data pipelines and analytical solutions using big data technologies successful candidates will have strong engineering skills and communication as well as a belief that data driven processes lead to great products you will need to have a passion for quality and an ability to understand complex systems

educationbachelors degree or equivalent work experience in engineering computer science business information systems",,CA,False,data_engineer
Data Engineer with AWS,title data engineer with awslocation sanjose caposition fulltimenote aws expert responsibilities work closely with the business teams and translate business problems into analytical requirementswork with a team of people to design various components of the solution such as data movement storage computation  processing and insight deliverylead the deployment and maintenance of this platform and contribute to continuous improvementwork collaboratively using iterative methods design and code reviews and contributing ideas for business growth requirementsbachelors masters phd degree in math computer science information systems machine learning statistics econometrics applied mathematics operations research or related technical degreea minimum of 5 years’ experience in a related position as a technology architect providing technical leadership in handling for various types of business problems4 years of building data platforms for analytics advanced analytics in aws or azureexposure to traditional etls and in depth exposure to orchestrating pipelines in aws or azuredata modelling query optimization in mpp systemsable to design the technical architecture platforms selection develop  test solutions to address the client problems  requirementexperience in designing  developing data processing solutions  custom etl pipeline for varied data formatsknowledge on scalable processing frameworks rdbms  nosql platformsstrong fundamentals in hadoop sparkstrong individual planning and project management skills able to juggle multiple tasks and prioritiestrack record of delivering strong business resultsability to communicate technical architecture to business audiencethanks  regardsakthar pasha sr technical recruitercell  1 7327235773job type fulltimeexperienceaws 3 years requiredazure 2 years requiredbuilding data platforms for analytics advanced analytics 4 years requiredtraditional etls and in depth exposure to orchestrating pipe 3 years requiredstrong fundamentals in hadoop spark 2 years requirededucationbachelors required,,CA,False,data_engineer
Big Data and AI Engineer,"as a member of the pfizer analytics lab team a component of pfizer’s business technology organization the data engineer will join a team of highly collaborative data scientists  engineers dedicated to leveraging data and advanced analytics to create a healthier world this team member will contribute their dynamic perspective and knowledge to data engineering and advanced analytics inspire colleagues and peers to develop and implement critical data driven solutions within pfizer’s drug discovery efforts

specifically this group is focused on developing a set of capabilities designed to enable highly efficient exploration experimentation and rapid hypothesis generation based on internal public and commercially available datasets to continue supporting pfizer’s data driven forward thinking approach to data science

daytoday the data engineer will
build services and tooling around “scraping” databases loading logs fetching data from external stores or apis
automate data consumption from other source systems files etc
collaborate with other engineering cloud infrastructure  security and product management teams to understand requirements and develop highly scalable system designs and architecture
integrate new data management technologies and software engineering tools into existing structures
create custom software components and analytics applications
employ a variety of languages and tools to marry systems together
participate in the assessment of new technologies as well as identifying nextgeneration solution architectures
develop efficient analytic pipelines that include components related to data acquisition exploratory analysis feature engineering modeling and interactive storytelling
sharedownership of advancing teams data engineering capabilities through the ability to implement and execute on stateoftheart approaches
codevelop reusable components that will serve as the foundation for a scalable approach for pfizer’s analytic maturation
partner with other business technology teams to define and execute technology pocs using innovative technologies to advance pfizer’s analytic capabilities
directly engage with key business stakeholders director level
informal leadership of project teams comprised of associatesr associate level colleagues

qualifications

bachelor’s degree in computer science operations research physics applied mathematics statistics required
advanced degree in computer science operations research physics applied mathematics statistics or related field strongly preferred
5 years’ experience working as a dataml engineer
3 years working with semistructured and unstructured data
2 years working in a cloud based ecosystem preferably amazon web services
ability to thrive in a fastpaced multidisciplinary environment with the ability to effectively communicate with a diverse audience
ability to create technical examples prototypes and demonstrations based on rapidly changing data sets
excellent written and verbal communication skills

technical qualification
proven experience in at least two of the three following categories

data science  machine learning
expertise with generalpurpose statisticsmachine learning algorithms and at least one of the following subdisciplines natural language processing deep learning network analysis
expertise with the implementation of algorithms within python r or scala
expertise with model tuning validation and evaluation

data engineering
expertise with sql development database administration and performance tuning
expertise with data manipulation and extraction using modern programming languages java c c python scala spark etc
experience with unixlinux development – package management knowledge of filesystems performance monitoringtroubleshooting
experience with sourcing data from apis experience building apis is a plus
experience with a variety of data stores for unstructured and columnar data as well as traditional database systems for example elasticsearch mongodb cassandra hbase mysql postgres and vertica

machine learning engineering
experience building production implementations of data science and engineering pipelines
building and running high throughput realtime and batch data processing pipelines using spark flink storm kafka or equivalent technologies

eeo  employment eligibility

pfizer is committed to equal opportunity in the terms and conditions of employment for all employees and job applicants without regard to race color religion sex sexual orientation age gender identity or gender expression national origin disability or veteran status pfizer also complies with all applicable national state and local laws governing nondiscrimination in employment as well as work authorization and employment eligibility verification requirements of the immigration and nationality act and irca pfizer is an everify employer

sunshine act
 
pfizer reports payments and other transfers of value to health care providers as required by federal and state transparency laws and implementing regulations these laws and regulations require pfizer to provide government agencies with information such as a health care provider’s name address and the type of payments or other value received generally for public disclosure subject to further legal review and statutory or regulatory clarification which pfizer intends to pursue reimbursement of recruiting expenses for licensed physicians may constitute a reportable transfer of value under the federal transparency law commonly known as the sunshine act therefore if you are a licensed physician who incurs recruiting expenses as a result of interviewing with pfizer that we pay or reimburse your name address and the amount of payments made currently will be reported to the government if you have questions regarding this matter please do not hesitate to contact your talent acquisition representative

other job details
eligible for employee referral bonus
this position can sit in la jolla ca new york ny or collegeville pa


pfizer is an equal opportunity employer and complies with all applicable equal employment opportunity legislation in each jurisdiction in which it operates",,CA,False,data_engineer
Data Engineer - Center of Data Science Team,"new york life insurance company “new york life” or “the company” is the largest mutual life insurance company in the united states founded in 1845 new york life is headquartered in new york city maintains offices in all fifty states and owns seguros monterrey new york life in mexico

new york life is one of the most financially strong and highly capitalized insurers in the business the company reported 2016 operating earnings of 1954 billion total assets under management at year end 2016 with affiliates totaled 538 billion as of yearend 2016 new york life’s surplus was 23336 billion new york life holds the highest possible financial strength ratings currently awarded to any life insurer from all four of the major ratings agencies am best a fitch aaa moody’s aaa standard  poor’s aa source individual third party ratings report as of 81716

financial strength integrity and humanity—the values upon which new york life was founded—have guided the company’s decisions and actions for over 170 years

new york life the largest writer of retail life insurance in the us and a top player in annuities longterm care and mutual funds is seeking a data engineer in its center for data science and analytics

the center for data science and analytics is the innovative corporate analytics group within new york life we are a rapidly growing entrepreneurial department which aims to design create and offer innovative datadriven solutions for many parts of the enterprise we are aided by new york life’s existing business with a large market share in individual life insurance we have the freedom to explore external data sources and new statistical techniques and are excited about delivering a whole new generation of analytical solutions

in fact we are designing and will build one of the first multivariate modelbased continuous risk differentiations in the industry this model will incorporate current underwriting best practices including medical rules as features and add other data sources patternsideas and variables to essentially create a rating plan to support the next generation underwriting process at new york life this is just one of several projects with large business value geographic analytics on agents and customers application fraud detection agent success prediction and client prospecting analytics offline and online are other exciting examples of enormous incremental value from analytics our products will be implemented into realtime core business processes and decisions that drive the company eg underwriting pricing agent recruiting prospecting new product development
we work with data ranging from demographics credit and geo data to detailed medical data medical test results diagnosis prescriptions and social media information we have a modern computing environment with a solid suite of data sciencemodeling tools and packages and a large but manageable group of welltrained professionals at various levels to support you life insurance is on the verge of huge change this is a chance to be part of actually to drive the transformation of an industry
you will be part of data  platform subfunction team under center for data science and analytics the data  platform team services internally to data scientists who focus on statistical analysis
you will be part of a fast paced highimpact team who will work with an entrepreneurial mindset using some of the best of breed tools as part of our enterprise data hub hadoop using r spark and python
you will apply your data engineering skills to build pipelines workflows to gather cleanse test and curate datasets from oracle mssql server 3rd party data and create datasets in enterprise data lake hadoop which will be used by several teams of predictive modelers
you will perform proof of concepts and test out new software tools under the umbrella of data science but geared more towards data engineering
responsibilities
ingests merges prepares tests documents curated datasets from various novel external and internal datasets for a variety of advanced analytics involving multivariate models
utilizes data wranglingdata matchingetl techniques while to explore a variety of data sources gain data expertise perform summary analyses and curate datasets
functions as data expert contributes to analyticssolutions design and productizing decisions
collaborate with business leaders to understand business challenges and devise solutions by using business acumen and mining vast amounts of data to draw insights
can work independently with some supervision and be part of a collaborative team
work with project managers and scrum masters to provide milestones and stories
proactively and effectively communicates in various verbal and written formats with senior level member of the team and partner
actively participates in proof of concept tests of new data software and technologies shares knowledge within the team
follows industry trends and related dataanalytics processes and businesses attends conferences events and vendor meetings as needed

required qualifications
graduatelevel degree in computer science engineering or relevant experience in the field of business intelligence data mining database engineering programming
35 years of overall experience working in the field of data wrangling and programming with a minimum of 1 year experience with ingesting cleaning merging and applying necessary data wrangling logic in hadoop
1 years in writing complex sql queries in any of the following andor similar databases  oracle sql server db2 mysql
proficiency using python for all data related work such as numpy pandas pyspark
experience working with linux operating system
experience working with data visualization tools or packages
experience building exploratory data analysis reports such as histograms box plots pareto scatter plot using r python or a data visualization tool such as tableau and spotfire

preferred
understanding of statistical modeling concepts designs and analyticsbased products
any experience in using etl tools such as ab initio talend informatica pentaho
any experience working with data warehouses andor data marts
any experience in life insurance business

other notes
our technology stack is rstudio pro sas enterprise data hub using hortonworks hadoop data platform waterline trifacta r python spark pyspark sparkr linux

eoe mfdv

sf litk1
ef eftk1
eoe mfdv

if you have difficulty using or interacting with any portions of this web site due to incompatibility with an assistive technology if you need the information in an alternative format or if you have suggestions on how we can make this site more accessible please contact us at 212 5765811
based on revenue as reported by “fortune 500 ranked within industries insurance life health mutual” fortune magazine june 17 2016 see httpfortunecomfortune500 for methodology
total surplus which includes the asset valuation reserve is one of the key indicators of the company’s longterm financial strength and stability and is presented on a consolidated basis of the company

1 operating earnings is the key measure use by management to track company’s profitability from ongoing operations and underlying profitability of the business this indicator is based on generally accepted accounting principles in the us gaap with certain adjustments company believes to be appropriate as a measurement approach non gaap primarily the removal of gains or losses on investments and related adjustments

2 assets under management represent consolidated domestic and international insurance company statutory assets cash and invested assets and separate account assets and third party assets principally managed by new york life investment management holdings llc a wholly owned subsidiary of new york life insurance company",,NY,False,data_engineer
Data Engineer,"system1 is looking for engineers with production data experience to join data engineer team this team is the horizontal layer that supports business intelligence optimization machine learning and external  internal reporting we process and report on hundreds of millions of events and user attributes per day gathered from an extremely heterogeneous set of data streams
our bread and butter is python and postgresql but we also utilize a range of technologies including aws lambda sns sqs redis and dynamodb for caching and mapping as well as redshift kinesis and spark for large dataset munging and ad hoc analysis
the role you will have
create build and maintain a coherent and performant data architecture
prototype develop deploy and debug data ingestions and data management services
participate in peer code reviews and produce high quality documentation
construct queries and reports to guide architectural design business decisions and optimization algorithms
take projects through the full engineering lifecycle designing ticketing building testing deploying and debugging tools and products
help grow a team and work with a tight knit group of engineers and data stakeholders
what you will bring
bachelor’s in computer science or equivalent
3 years of experience with python development
3 years of experience working with large sql datastores postgresql redshift
understanding of nosql datastores like dynamodb and redis
experience with linux and the aws ecosystem
what we have to offer
free uberlyft to and from work every day
collegial and collaborative team with highly intelligent and motivated coworkers
crossteam lunches and demos to foster learning
unlimited paid sick time competitive pto and benefits package
daily catered meals and fully stocked kitchen
biweekly happy hour at various bars restaurants and venues across los angeles
biweekly onsite happy hour
catered dinner on tuesdays and thursdays
weekly fitness class with private trainer high intensity training yoga beach volleyball beach soccer ultimate frisbee
company parties and outings skyzone indoor skydiving medieval times karaoke etc",,CA,False,data_engineer
Financial Data Engineer,"interested in an opportunity to work in a robust challenging datafocused environment with an outstanding team of technical and research professionals at tgs financial data is at the heart of our business the financial data engineering role is mission critical  requiring uncommon reliability a passion for writing great software and tools experience working with a wide variety of data preferably financial data but not necessarily and the ability to support largescale production systems it’s an exciting challenging role that provides clear opportunities to contribute to the success of an exceptional organization
in addition to writing programs and working with data the successful candidate will work closely with our research team and is likely to interact with a variety of external resources such as data providers brokers dealers and software vendors
to be considered for this role you will need to demonstrate expertise in a number of the following general areas
programming experience developing data management tools andor applications using languages such as java perl python or cc
system tools experience with scripting languages perl python shell scripts etc and unixbased operating systems especially linux
production support  willingness and ability to support large complex production systems in an oncall or rotational capacity
analysis of large data sets experience developing programs to parse process analyze and comprehend large data sets
applications experience designing developing and maintaining software applications tools and systems
vendor interaction working with external resources to solve problems acquire data and improve relationships
financial data familiarity with financial terms and experience working with data from a variety of vendors and sources

about us

for over two decades the tgs team has built quantitative trading systems that have produced exceptional results across a range of financial markets we use scientific methods and engineering discipline to solve challenging problems and develop technology solutions our irvine office is as unique as our southern california location combining elements of high tech finance and applied research in a collegial atmosphere and beautiful workspace

as an employer we are small discreet and highly selective we look for talented people with proven track records of performance and achievement and are far more interested in aptitude and potential than expertise in any particular technology tool set or professional domain if youre inspired by the idea of working on interesting problems with talented colleagues we invite you to share your resume and explore the possibility of joining our team",,CA,False,data_engineer
Data Engineer,"job description
data engineer

who is spr

spr is a digital technology consultancy that develops elegant solutions to transform the way people do business we’re 300 strategists developers designers architects consultants thinkers and doers in chicago and milwaukee we work with 160 clients in 10 unique industries – everything from corporate finance and global logistics to local breweries and startups

we think about the end users and rigorously apply the latest technologies and frameworks to address our clients’ needs we enable companies to do more with data engage with other people build disruptive solutions and operate productively to do this we hire smart technologists and sharp business leaders who are excellent communicators and have an interest in working on multiple projects across industries

spr offers a great environment for employees to learn to build systems that make an impact and to tackle exciting challenges we operate in a fun casual work environment and have great benefits including competitive salary bonuses generous vacation time big fitness incentives and medicaldentalvision insurance

by joining the spr team you’ll be using your brain working hard and making an impact through your projects – and you’ll be rewarded for it

what is the position

as a data engineer at spr you must have experience building and operating data pipelines both streaming and batch utilizing both etl and elt architectures you will be building data pipeline solutions by designing adopting and applying big data strategies and architectures you must be experienced in largescale system implementations with a focus on complex data processing and analytics pipelines you must demonstrate an understanding of data integration best practices and expertise in data integration data transformation data modeling and data cleansing the data engineer must be able to demonstrate innovative approaches to complex problems which deliver industryleading experiences for our clients

professional qualifications

experience in designing and implementing innovative data integration solutions utilizing python with spark clusters
familiarity with architectural patterns for dataintensive solutions
expertise in realtime streaming and migrating batchstyle data processing to streaming and microbatch solutions
knowledge of the rdbms core principles set up tune design as well as newer unstructured data tools
familiarity with consulting and traditional application design
excellent written and verbal communication skills
display solid problemsolving abilities in the face of ambiguity
must be a handson individual who is comfortable leading by example
experience with agile methodology
possess excellent interpersonal and organizational skills
able to manage your own time and work well both independently and as part of a team

technologies we use

cloud azure aws cloud foundry heroku mesos dcos   rdbms sql server postgresql oracle db2 nosql mongo raven documentdb cassandra maria riak  python including databricks   big data cloudera  hortonworks hadoop distributions including hive pig sqoop spark  integration tools apache nifi cloudera streamsets azure data factory aws glue talend  elk elasticsearch logstash kibana  machine learning azure ml tooling tensorflow aws sagemaker scikitlearn  data visualization grafana kibana  microsoft powershell  aws sdk  fast data apache ignite  gridgain apache geodepivotal gemfire

education  experience

35 years of professional experience
ba or bs preferably in computer science engineering or sciencetechnologybased discipline

if this sounds like the kind of challenge you would be up for every day we would love to hear from you",,IL,False,data_engineer
Backend / Data Engineer,60000  100000 a yearstriiv is building the industrys leading wearable oem platform for the healthcare and group market we provide an endtoend solution  from the dataservices mobile applications to a family of wristworn devicesas a backenddata engineer at striiv you will design and build data processing systems and backend services on the google cloud platform that impact peoples lives worldwide helping them stay healthy you will working closely with other smart dedicated engineers and product managers shape our platform scaling and data processing and cloud service strategy write maintainable code and advocate for best practices and exceptional qualityan ideal candidate has bachelors degree in computer science or engineering or relevant experience experience working with backend technologies knowledge developing apis using python or java experience with a python web framework django flask webapp2 experience with database technologies and database design eg sql or nosql experience with google cloud platform such as app engine datastore bigquery pubsub dataflow or equivalent technologies on amazon web service experience with oauth 20 experience with version control using gitbenefits  perks competitive salary and equity options working with latest and greatest technology weekly free lunches unlimited snacks close to downtown redwood city and caltrain casual dress code wear the latest wearable gearstriiv is an industry leader of oem fitness tracking and smartwatch devices powering technology branded by walgreens acer and more striiv specializes in creating custom solutions for businesses interested in offering wearable technology striiv is located in redwood city ca and is an equal opportunity employerjob type fulltimesalary 6000000 to 10000000 yearwork authorizationunited states required,80000.0,CA,False,data_engineer
Senior Data Engineer,"major duties and responsibilities
",,TN,False,data_engineer
Senior Data Engineer,seeking a data developer for a contract role at a major investment bank in jersey city nj below is the job descriptionresponsible for the design development testing integration operation and support of infrastructure services that meet stated business requirements and adhere to coding best practices and architecture standardsadheres to architectural design standards risk management and security policies data management policies leading presentations in architecture review strategic technology directions best practice development eg estimating models mentoring less experienced team members code reviewsresponsible for all elements of software development lifecycledevelops integration elements data models application programming interfaces apisassists in the building of open 3rdparty software development kits sdksall interested and available data developers please apply nowjob type fulltimeexperienceapis 1 year preferredinvestment banking 1 year preferreddata development 1 year preferredkafka 1 year preferrednosql data stores 1 year preferredlocationjersey city nj preferredwork authorizationunited states required,,NJ,False,data_engineer
Data Engineer,"austin tx
novus is an innovative company that is changing the way the world invests we are a high growth disruptive technology firm bringing big data analytics to the alternative investment industry our platform enables investors to consistently maximize their performance potential through discovery of true investment acumen and risk proprietary industry insights and expertise and effortless data management and enlightenment

we are looking for a data engineer to join the team and play a critical role in the design and implementing of sophisticated financial data feeds that serve as the foundation of our platform

background

we operate in an industry in which over 120 trillion is invested annually on behalf pension  endowment  sovereign funds and private investors  family offices and yet the lack of data intelligence and insight results in much of that money being invested based purely on historic track record with little transparency into performance acumen and  or risk management this is our challenge and our purpose to help investors make better investments and in doing so we aim to provide the single network on which trusted professionals will engage promote and manage their business in short we want to help the world invest better and we need you

role

you will report directly to our vice president of engineering and be based in austin

the engineering team at novus is a fastpaced group of individuals who are passionate about improving the way the world invests the data engineer will work with vast amount of securities data from many sources and portfolio data from prominent hedge funds fund of hedge funds and some of the most sophisticated institutional investors

responsibilities around client data integration include

help lead a greenfield redesign and implementation of industryleading etl
lead and coordinate development efforts with our international team
applying industry best practices for database development
maintaining and performance tuning database code
culture

our culture is critical to us it’s how we push ourselves every day to do better than the day before we expect our team members to deliver on their responsibilities understand how each and every component of our company works to generate success and hold themselves and their colleagues accountable to the highest standards as a result we will enjoy talking to you if

you are excited to solve problems you haven’t seen before – “turning every page” to understand the domain
you can work independently – removing roadblocks and answering your own questions
you want to solve problems quickly – to satisfy your users to get feedback  iterate and to move onto the next problem
you want to make an impact
qualifications traits  experience
bs in computer science or related discipline from top university or college double major or minor in economics or finance a plus
experience with python is a huge plus
working experience with microsoft sql server version 2008 r2 or higher
working experience in building adhoc tsql queries stored procedures views and functions
working experience with etl
knowledge on definitions and parameters of financial instruments eg equities fixed incomes options futures swaps forwards etc is a plus
interest in investments andor the fund of funds and hedge fund industry",,TX,False,data_engineer
Data Engineer,"responsibilities
manage data warehouse plans for a product or a group of products
interface with developers product managers and product analysts to understand data needs
build data expertise and own data quality for allocated areas of ownership
design build and launch new data models in production
design build and launch new data extraction transformation and loading processes in production
support existing processes running in production
integrate external data sources into data pipeline
build api’s for internal and external consumption
define and manage sla for all data sets in allocated areas of ownership
qualifications
bsba in technical field computer science or mathematics
experience in the data warehouse space
experience in custom etl design implementation and maintenance
experience with a data integration tools eg ssis pentaho
experience with objectoriented programming languages eg python java c
experience with schema design and data modeling
experience in writing sql statements
experience in analyzation of data to help identify deliverables gaps and inconsistencies
experience with a visualization tools eg power bi tableau qlik
preferred qualifications
knowledge in python
knowledge in ssis
knowledge in mssql server 20142017
knowledge in power bi or sql server reporting services
experience in payment processing or clinical trials",,PA,False,data_engineer
Data Engineer,120000  160000 a yearcontractover 9 years of experience in development design testing and implementation with major focus on data warehousing database applications and business intelligence solutions using etl tools like ab initio informatica etcrequirement gathering and data analysis of all supporting systems designed informatica mappings and data flowsfull software development life cycle sdlc experience including analysis design and review of business and software requirement specifications development and testing as per the sdlc agilescrum methodologydesigned developed and tested etl processes in aws environmentworked on data ingestion encryption etcoptimized and refactored existing etl processes from sql server environment to aws environmentworked on aws redshift database distribution key sort key compression analysis in redshiftworked on the unloading into s3 bucketsworked on external hive tablesworked in sprit based releases and participated in scrum meeting and daily standup meetingsworked with bsa to understand requirements and prepared lld and hldprepared estimates for small modulesworked on servigistics toolcreated etl mappings using informatica power center to move information from multiple sources into a common target area such as data marts and data warehouseextensively worked in developing etl for supporting data extraction transformations and loading using informatica power centerinformaticametadata mangermm designing and developing metadata manager resources and loading into mm warehouse performed developer testing functional testing unit testing for the informatica metadata managerexcellent experience in implementing push down optimization in informaticadeveloped complex mappings in informatica from various transformations like router filter expression aggregator joiner update strategy using the informatica power center and idqworked on complex transformations like java and normalizerintegrated sales force sources into informatica power centerworked as developer for informatica migration from 96 to 101worked on sap etl tool bods and prepared reverse engineering sheetsdeveloped and maintained etl extract transformation and loading mappings to extract the data from multiple source systems like oracle sql server and flat files and loaded into teradataknowledge in business intelligence areas such as data integration data masking physical expertise knowledge improving performance worked on various scheduling tools like controlm autosys tivoli tws and espknowledge in business intelligence areas such as data integration data masking physical data modeling in teradataextensively worked on teradata indexes join strategies and performance tuning of long running teradata sql queriesexperience using nopi tables and multi value compression and temporal tablesjob types fulltime contractsalary 12000000 to 16000000 year,140000.0,TN,False,data_engineer
Microsoft SQL Server\BI Data Engineer,"requirements

4 years of experience
spoken english
dwh structures creation
develop and monitor ssis packages for etl processes
ssas cubes development both mdx and tabular
writing stored procedures
developing ssrs and powerbi reports
performing etl functions to migrate the legacy data to sql databases
masterdata management
mandatory skills

sql server 201220142016
ssis
ssrs
ssas
sql server agent
nice to have

math background for ml tasks
other relational andor nosql databases
different reporting tools like tableau qlikview
big data experience
c python",,TX,False,data_engineer
Data Engineer,"75  85 a daycontractas big data engineer you will work on building the next generation a top security analytics platform you will play a crucial role in building a platform to collect and ingest several billion and growing log events from the globally distributed security infrastructure and provide actionable insights to customers and security researchers


required skills  experience
4 years of experience in java development
excellent interpersonal technical and communication skills
ability to learn evaluate and adopt new technologies
bachelors degree in computer science or equivalent experience
candidates must be local
desired skills  experience
familiarity with hadoop  hive and other data processing frameworks such as spark kafka storm and elastic search
experience working with data processing infrastructure
experience with data serialization techniques and data stores for persisting events
what you will be doing
you will design and create multitenant systems capable of loading and transforming a large volume of structured and semistructured fast moving data
build robust and scalable data infrastructure both batch processing and realtime to support needs from internal and external users
the offer
competitive pay up to 90hour doe
contract duration 6 – 12 months
you will receive the following benefits
medical insurance  health savings account hsa
401k
paid sick time leave
pretax commuter benefit


applicants must be currently authorized to work in united states on a fulltime basis now and in the future
workbridge associates part of the motion recruitment network provides it staffing solutions contract contracttohire and direct hire across 11 major north american markets our unique expertise in today’s highest demand tech skill sets paired with our deep networks and knowledge of our local technology markets results in an exemplary track record with candidates and clients",,CA,False,data_engineer
Data Science Engineer,"reimagining healthcare requires a sensitivity towards understanding complex data problems and drawing substantiated insights that help build novel products that truly improve peoples lives our role in administering health plans puts us a position to dig into the most granular level of americas healthcare payment infrastructure this gives us control over our data quality which is key for getting specific and actionable insights

we are looking for a creative softwaredata engineer with a data science mindset this position requires strong foundation in building data centric algorithms at scale ideal candidate would have builtshipped production code using open source big data technologies hadoop spark airflow wtc this candidate should also be willing go beyond what is available in current open source frameworks and customize the these stacks if needed to make them better fit for business needs and contribute back to open source community besides engineering foundational infrastructure components you will also be building scalable datamining and machine learning pipelines you will be working very closely with rest of the data science team and collaborate with wider engineering teams at company level

we expect to see



strong data structures and algorithms background
developed scalable data pipelines
shipped at least one productservice
development experience in linux environment
distributed data computing experience you know how to parallelize computing across cluster of machines using modern stacks
written production code in any modern languages like c java python etc
comfortable with basic statistics
superb communication skills in both technical and nontechnical setting

nice to have



experience with big data technologies like hadoop spark airflow
relational database modeling and sql queries
familiar with aws services like ec2 emr etc or similar cloud computing environment
python development experience
experience with productionization of models developed in ml libraries like scikitlearn mllib tensorflow keras pytorch etc
experience with management of bi frameworks like tableau looker etc
interest in healthcare

collective health is a technology company working to create the healthcare experience we all deserve founded in 2013 our team of engineers designers product managers and actuaries are redefining the 1 trillion market of employersponsored health benefits with datadriven and peoplefocused products our complete health benefits solution helps great companies like activision blizzard palantir restoration hardware and pinterest take care of their people by harnessing the power of design and technology based in san francisco ca were backed by some of the best investors in silicon valley including google ventures founders fund nea and redpoint ventures for more information visit us at httpswwwcollectivehealthcom  httpswwwcollectivehealthcom 
we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,CA,False,data_engineer
Data Engineer,"tabula rasa health care– trhc is a family of companies that leverages technology to improve healthcare trhc works with providers and insurers to identify multidrug interactions and to reduce risk of medicationrelated problems we have developed the first multidrug interaction tool that identifies risk across a variety of safety factors and presents meaningful opportunities to mitigate that risk this technology can be used to assess safety at the individual patientlevel or to stratify medication risk at the populationlevel and can be embedded within any emr or other healthcare it system
tabula rasa health care is looking for a data engineer to work with it business analysts and application developers to define and program etl solutions the data engineer will be responsible for creating developing investigating mapping and testing the various data needs this position requires that the developer be an expert on data availability and quality have a strong understanding of the business requirements and the creativity to develop workable solutions for a wide range of customers
responsibilities
build and maintain sql server integration services ssis jobs
migrate ssis jobs over to new informatica environment
document etl processes programs and solutions
develop and test new etl processes
design and build data structures and processes to populate data warehouse tables
manage postproduction data quality monitoring
quickly identify and resolve data and migrationrelated production issues
acquire data from primary or secondary data sources and maintain data systems and integrity
develop procedures to enhance reporting and query capabilities to improve efficiency and accuracy
develop innovative approaches to manipulate data sets in a way that enables clients to see patterns and trends
work with key stakeholders to ensure integrity and proper integration for all sources of enterprise data
provide technical leadership in the area of big data systems development including data ingestion data curation data storage highthroughput data processing user access and security
stay current on big data trends and research various technologies as they become relevant
provide software coding leadership guidance and quality adherence in languages such as python java javascript react nodejs sql nosql etc
qualifications
education experience  training
a bs degree in computer science computer engineering other technical discipline or equivalent work experience
exceptional skills in relational database systems ms sql server mysql oracle
strong ability with dimensional data modeling and olap principles
3 years’ experience working with etl tools ms ssis packages ssms informatica
experience with nosql mongo couch and columnar databases a plus
knowledge of python will be a plus
handson expertise with application design software development and automated testing
prior experience with compliant eg hipaa 21 crf part 11 systems processes and operations development is preferred
ability to identify and diagnose etl and database related issues perform root cause analysis and recommend corrective actions
specific skills
solid understanding of data warehouse methodologies
high proficiency with sql mysql sql server oracle db2
excellent communication skills
working knowledge in software development life cycle
3 years of experience with big data componentsframeworks hadoop hbase mapreduce hdfs pig hive sqoop flume ozie etc
competencies
overall competency in business and technology
excited  motivated to learn new technologies
sense of urgency to attend to it leadership demands
responsive and prompt communication
customerservice oriented
excellent time management
excellent verbal and written communication skills
selfmotivated team player highly organized
attention to detail and accuracy of facts and documentation
ability to manage multiple priorities and work independently
ability to problemsolve and ability to follow through on tasks",,NJ,False,data_engineer
Data Engineer,"lirio is looking for a skilled data engineer to build a data pipeline and warehouse to support its data science team lirio is a communication and technology company that applies behavioral science and persona segmentation to optimize individualized communication at scale in other words we deliver the right message to the right person at the right time to drive the customer of one to take action this is an opportunity to join a hardworking team with the mission of truly impacting lives for the better

the data engineer will be responsible for building a data architecture from the ground up that will ingest internal and external data transform it when necessary and store it in an analyticsfriendly warehouse the data engineer will work closely with data scientists machine learning engineers and developers to understand the provenance of data information needed from the data and potential etl techniques an ideal candidate is comfortable with building systems from the ground up

core responsibilities
design build and maintain a scalable cloudbased data warehouse that provides standardized access to internal and external datasets
evaluate new data sources to understand requirements for acquisition parsing and transformation of the data via api or flatfiles
build automated data ingestion pipelines to continuously etl external data into a data warehouse
work with developers to capture valuable internal events and ingest into the data warehouse
work with data scientists to harden and automate feature extraction and feature engineering scripts
ensure that production data products have consistent access to input data
additional opportunities
feature engineering from unstructured or semistructured data
data acquisition
education  experience
an ideal candidate has

a bachelor’s degree or equivalent and proven work experience
demonstrated capability in data engineering
3 years of directly relatable experience
5 years of software engineering experience
expertise in
etl
data flow diagrams
workflow management platforms airflow luigi or similar
database schemas  normalization
matching storage technology to data size structure and use
python or java • sql db and nosql db technology particularly keyvalue
ability to work with multiple teams and internal customers
experience with cloud platforms preferably aws
the benefits
lirio is based in knoxville tennessee with support for remote employees for the right fit we offer competitive benefits including ample paid time off and health insurance among others we have a great culture comprised of people who are committed to delivering results we are growing and want great people to join our team

to apply please send resume and linkedin profile to talentlirioco and specify the position for which you are applying in the subject line",,TN,False,data_engineer
"Data Engineer – Data Warehouse, Analytics & BI","do you have strong product instinct and an appreciation for datacentric analytical products are you passionate about data and how data can be used in investing we are looking for people like you who can help us

gather requirements and scope out project details with relevant stakeholders
create and maintain optimal data pipeline architecture across different domains
coordinate with data quality team on business rule implementations and daytoday operations
fix defects and implement enhancements in existing pipelines
support data analysts in building dashboards and visualization models
identify inefficiencies in queries and etls and investigate solutions for performance tuning
work with business teams to assist with datarelated technical issues and support their data needs

evidence lab is one of the most innovative and highly regarded teams in ubs investment bank we thrive on innovation and work as a startup within a wellestablished and wellfunded investment bank we specialize in various analytical techniques including web harvesting geospatial social media market research and data science you will be joining a team of product managers and business analysts that sit within evidence lab that are helping to scale and grow the business you can learn more about evidence lab here

you have

bachelor’s degree in computer science cis  mis or related engineering or technical fields
outstanding sql python and plsql skills r and java knowledge is a plus
experience in enterprise data warehousing concepts data modeling architecture etc
working experience with cloudbased data solutions redshift azure data warehouselake hdinsight etc
working knowledge of message queuing stream processing and scalable ‘big data’ stores
proficiency in etl tools such as dataiku cask andor pentaho

you are

ready to join a fast growing team in a dynamic and challenging environment
relentless in pursuing new ideas and selfimprovement
problem solver with strong data analytical skills
a team player willing to learn  share solutions and best practices from your colleagues
able to manage multiple assignments simultaneously and follow up on unfinished business

dicetech dicepref
expert advice wealth management investment banking asset management retail banking in switzerland and all the support functions thats what we do and we do it for private and institutional clients as well as corporations around the world

we are about 60000 employees in all major financial centers in more than 50 countries do you want to be one of us
together that’s how we do things we offer people around the world a supportive challenging and diverse working environment we value your passion and commitment and reward your performance

keen to achieve the worklife agility that you desire were open to discussing how this could work for you and us

why ubs video
are you truly collaborative succeeding at ubs means respecting understanding and trusting colleagues and clients challenging others and being challenged in return being passionate about what you do driving yourself forward always wanting to do things the right way does that sound like you then you have the right stuff to join us apply now
ubs is an equal opportunity employer we respect and seek to empower each individual and support the diverse cultures perspectives skills and experiences within our workforce",,NY,False,data_engineer
Data Engineer - Core Data and Analytics,"samba tv recognized by inc magazine as one of the fastgrowing companies in the us and one of the most interesting adtech upstarts of the year by business insider is seeking to hire a software engineer to join our data engineering department

samba tv is uniquely positioned at the forefront of the tv revolution the way people discover watch and engage with television has fundamentally changed and were connecting the dots to help better understand audience trends and viewership habits for marketers

the core data and analytics team is one of several in the data engineering department our team is responsible for the data processing pipelines that produce key datasets consumed by our data scientists research analysts and external customers as well as power our analytics platform this team deals with data at scale — on a continuous basis we ingest process and ultimately make sense of incoming viewing data from millions of televisions

as a member of this team you will help architect build operate and maintain our data pipelines responsible for aggregating television viewing data and deriving metrics and insights that power a variety of our data products and offerings you will not only work on our pipeline jobs but you will also have the opportunity to help build out and further evolve our internal frameworks upon which we process and deliver data at scale

responsibilities


analyze and improve the efficiency scalability and stability of data collection storage and retrieval processes for our core systems
create and manage platformspecific apis
create new data processing systems as necessary to support our data scientists and research analysts
ultimately build robust highvolume production software

requirements


strong command of a programming language or two – while we code primarily in python we acknowledge that engineers with sound fundamentals can pick up new languages relatively quickly
excellent problem solving skills ability to interpret and analyze data is a must consequently mathematical inclination is a major plus
2 years of professional development experience building highperformance largescale applicationspipelines
solid foundation in computer science with strong competencies in data structures algorithms and software design
experience with hadoop spark or similar technologies is desirable
experience with running production systems on aws is also a plus

",,CA,False,data_engineer
Data Engineer with AWS,60  63 an hourcontractjob summaryjob functions  responsibilitiesprovide data engineering on modern cloudbased and legacy data processing technology stacksbuild data pipelines data validation frameworks job schedules with emphasis on automation and scalecontribute to overall architecture framework and design patterns to store and process high data volumesensure product and technical features are delivered to spec and ontimedesign and implement features in collaboration with product owners reporting analysts  data analysts and business partners within an agile  scrum methodologyproactively support product health by building solutions that are automated scalable and sustainable – be relentlessly focused on minimizing defects and technical debtqualifications and skills5 years of experience in largescale software development with emphasis on data analytics and highvolume data processing3 years of experience in data engineering development2 years of experience implementing scalable data architectures2 years of experience with aws and related services eg ec2 s3 dynamodb elasticsearch sqs sns lambda airflow snowflakeexperience in datacentric programming languages eg python go ruby javascript scalaproficiency with etl tools and techniquesknowledge of and experience with rdbms platforms such as ms sql server oracle db2 ims mysql postgres sap hana and teradataexperience with participating in projects in a highly collaborative multidiscipline team environmentwork settingsrequires frequent sitting and walkingavailability to work “oncall” 24 hoursday for emergenciesposition could be required to minimal traveling up to 20educationmasters or bachelors degree in computer science or a related fieldjob types fulltime contractsalary 6000 to 6300 hourexperienceaws 1 year required,,WA,False,data_engineer
Data Engineer,"appzen has developed the world’s first artificial intelligence ai solution for business process automation appzen’s ai for business solutions uses patentpending natural language processing computer vision and machine learning algorithms to analyze data and automate functions our technology is used to automate business processes for both small and large enterprises including fortune 50 organizations the machine learning based technology automatically detects accidental and intentional fraud providing realtime compliance to irs rules fcpa regulations and general company policies

we are looking for a data engineer to help expand and build out our data infrastructure and pipelines data engineers at appzen work on architecting data pipelines to analyze and process streams of data throughout our system both in offline and online contexts you will also work with data scientists to productionize machine learning models and the pipelines that build them
requirements
3 years experience in engineering or data science
experience writing production quality python code
knowledge in databases schema design querying optimization sql postgres
knowledge in offline batch processing andor online realtime stream processing and queueing systems
interested in working across our entire data science stack including model building data pipelining and performancescale analysis
nice tohaves
experience using systems like apache spark airflow or other data processing tools
knowledge in aws tooling such as rds sqs kinesis and s3",,CA,False,data_engineer
Senior Data Engineer,"elasticiti is an analytics solutions company dedicated to the media industry our clients are top media brands who need to innovate on multiple large datasets to inform their strategy and tactics
the ideal candidate has a strong aws skillset and is well rounded enough to interface effectively with business users
job functions
build an understanding of data sources and downstream systems
liaise with key stakeholders to understand requirements business definitions and the potential value of different data sets
support design implement and document solutions for loading piping and exposing data from multiple sources
support and build wellengineered data systems to support analytical needs using aws 
assure accuracy of data processing and outputs through consistently high software development skills adherence to best practice thorough testing and peer reviews
habitually approach problem solving with creativity and resourcefulness carefully evaluate risks and determine correct courses of action when completing tasks
skillsabilities
demonstrable professional experience designing building and maintaining data systems and processes using aws big data platform
demonstrable handson professional data analytics skills using python sql java is a plus
excellent verbal and written communications skills with the ability to clearly present ideas concepts and solutions
demonstrated willingness and ability to effectively work with various team members when gathering requirements delivering solutions and eliciting suggestions and feedback
extremely quick learner both in terms of new technical skills and acquiring domain knowledge
experience
must have  4 years hands on big data sparkhive experience
experience 4 years working in python development environments for data wrangling and analytics
expertise using cloudbased systems and services to acquire and deliver data via apis and flat files
extensive handson experience working with data using sql
extensive handson experience working with aws s3 emr redshift glue
education
bachelors degree in computer science or closely related discipline",,NY,False,data_engineer
Data Engineer,"data engineer
requisition id 1810310

description

responsibilities include but are not limited to the following implement best practices for data engineering develop processes and documentation extract and prepare data for analysis develop and revise model code understand data path from source to destination troubleshoot connectivity and data integrity issues prepare and manage infrastructure servers databases etc for data storage coordinate with nov software engineers product engineers data scientists and other data users to define and configure datavault tag lists prepare reliabilitycentered equipment maintenance templates including tag lists and analytical models for deployment to rigs coordinate efforts with field engineers and nov crossfunctional teams to ensure that rigs have the proper hardware software and network to collect data develop code for automating data processing pipelines perform other workrelated tasks as required


qualifications

a minimum education of bachelors in computer science engineering or related field is required
a minimum of 2 years of experience specifically in data engineering is required
experience with programming language is required ex python r batch scripting java step7
experience with data processing is required ex hadoop cassandra spark
excellent written and verbal communication skills
experience in the following areas preferred
o reading control systems documentation
o data acquisition
o data integrity
o data management osisoft pi system strongly preferred microsoft sql mongodb
o revision management git stash
o data science platform domino
o data visualization grafana tibco spotfire microsoft power bi
o server network installation configuration and troubleshooting
drilling data analysis experience preferred
candidates must be highly selfmotivated and work well as part of a fastpaced collaborative team

job science
schedule fulltime
shift day job
job posting",,TX,False,data_engineer
Data Engineer,contractdata engineer job descriptionlocation based in austin txtravel  020about us we are the premier data science and machine learning firm we are scientists innovators and strategists we bring tangible value to our clients through mathematics applied science and machine learning we transform information into intelligence and intelligence into initiative we formed to address the need across industries to solve complex problems with a specialized approach valkyrie has honed that approach for many clients with impactful innovative outcomes simply put we help our clients make the right decisions craft the right initiatives and answer the right questions through applied sciencedata engineer position the data engineer is the right fit for a motivated engineer that is excited to be part of a growing business interested in artificial intelligence and is passionate about data infrastructure as an engineer you will be assisting in developing data set processes for data modeling mining and production the right candidate will have strong experience architecting systems for collecting storing processing and analyzing data and has demonstrated datawrangling excellence in collaboration with data scientists you will be a part of efforts to improve data reliability efficiency and quality as well as researching opportunities for data acquisition and new uses for existing data the right candidate for this role will leverage knowledge of largescale processing systems to enable innovation in data science and machine learningdata engineer qualifications bachelor’s or master’s degree in stem science technology engineering math or related field4 years of professional database and distributedcomputing experience3 years’ experience with aws athena lambda airflow kinesis andor firehose preferred5 years of strong experience in designing constructing installing testing and maintaining highly scalable data management systemsextensive knowledge on databases and engineering practicesexperience with various databases sql postgresql mongodb andor neo4jstrong python programming skills including numpy scipy pandas and scikitlearnetl development and spark experience is a plusstrong skills and experience in effective collaboration and technical problem solving within multidisciplinary teamsexperience in a client facing role is a plusperks competitive compensationtremendous growth potentialhealthcare dental hsaflexible hours work from home as neededonsite gym  poolparkingopen pto  sick timestocked kitchen with healthy snacks drinks coffee etclots of team events including happy hours catered lunches and other fun outingsdog friendly officejob types fulltime contractexperienceaws 2 years requiredlocationaustin tx preferredwork authorizationunited states required,,TX,False,data_engineer
Big Data Engineer,"global video game publisherdeveloper headquartered in rockville md seeks a big data engineer this position works within the enterprise bi team and is responsible for the development of the big data platform for enterprisewide reporting the big data engineer will be supporting a broad range of data pipelining needs from all facets of the business including ecommerce financial and game event data

the incumbent will have at least 2 years of previous experience partnering with both technical and business teams to facilitate implementation across the enterprise the big data engineer will facilitate the creation of data pipeline processes to move data from enterprise data sources such as relational databases and log files

responsibilities
work within the enterprise bi team supporting the creation of data pipeline processes for ingesting data at large scales
work directly with data modelers enterprise architect and analysts ensuring that business requirements are being met
directly work with the data engineers and data modelers to understand the source and target structures
coordinate with the analysts and report developers to ensure data can be easily digested by business intelligence tools
be able to straddle differing subject areas such as in game vs business data sources

requirements
2 years of experience with a major programming language c java scala python etc
comfortable working with structured semistructured and unstructured source data
understanding of amazon web services especially data related components
a strong communicator and is comfortable interfacing directly with differing customers across the organization in addition to the bi team
working experience with the scrum development framework

preferred skills
apache spark experience a major plus spark rdds spark dataframes spark sql
sql skills – able to query data sources and generate results from complex structures
a clear understanding of both row and columnar storage databases
experience working within the videogamemmo industry is desired though candidates from outside of the industry are also welcomed
understanding of the free to playmicrotransaction business model is a plus
a personal interest in video gaming is a plus",,MD,False,data_engineer
Data Engineer,contractdescription the data center network engineer assists in the installation team in maintaining our key role of being a valued and trusted technology employee through effective installation and support of data routingswitching wireless and network security products in a large application centric infrastructure frameworkresponsibilities data center engineer position in large aci environmentdesign implementation and support of network architectures primarily ciscoinstall and configure network solutions using routers switches and security devicesinstall and configure software systems that support the network infrastructure such as network monitoring systems log monitors dns servers and firewallstroubleshoot network errors and performance problemsdocumenting procedures and changes related to design installation and supportexperience in hardware provisioning installation configuration maintenance and troubleshootingability to handle complex problems effectively identify key issues and generates multiple solutionsunderstand client needs identify root causes of problems and develop and implement creative and pragmatic solutionscreate asbuilt documentation and provide knowledge transfer to customers upon completion of the installation and configurationrequirements desired skills and experienceaci experience a mustcisco certifications ccnp route switch ccna data center or ccnp data centernexus rs 9k7k5k2kcatalyst switching experience 9k6k4k3k2kprogrammability experience preferred eg python ansible and json scriptingjob type contractexperiencenexus rs 9k7k5k2k 5 years requiredaci 5 years requiredpython ansible and json scripting 4 years requiredlicenseccnp route switch requiredccna data center requiredcnp data center required,,TN,False,data_engineer
Data Engineer,"70000  76000 a yearhydromax usa is looking to add a data engineer to the team the ideal candidate will show enthusiasm towards building and maintaining distributed data systems initially this role will be focused on the set up of a new big data analytics production environment which will eventually merge with existing infrastructure the ideal candidate possesses advanced understanding of data storage and usage at large scale after the initial deployment of a production environment this role will translate data science algorithms into production ready services and help support production data systems our team includes some of the brightest minds in the industry and we hope to add you to our roster
duties
develop deploy and manage distributed systems in a production environment
turn data science algorithms into production pipelines
design scripts for data management
support analysts and developers in query optimization
work with developers to establish new data services
tune analysts’ queries for optimized performance
containerize developer created applications for deployment
build and maintain external data ingress and egress protocols
requirements
bachelor degree in a technical field or equivalent experience in a related position
3 years of experience with data systems
advanced understanding of sql
1 years of experience building data pipelines
fluency with one or more coding languages java scala and python preferable
experience with apache spark or similar big data platforms
familiarity with rest endpoints
preferred qualifications
master’s degree in a technical field
experience working with spatial data
formal education in mathematics
experience building containerized applications kubernetes or docker
experience deploying and using distributed systems nosql apache kafka apache airflow presto…etc
familiarity with the linux terminal
benefits health dental and vision insurance 401k company matching up to 5 after year 1 paid personal time off pto and paid holidays profit sharing

eoe we are an equal opportunity employer and do not discriminate against otherwise qualified applicants on the basis of race color creed ancestry religion orientation age sex marital status national origin disability genetic information handicap or veteran status
qualifications",73000.0,KY,False,data_engineer
Big Data Engineer,"our customer is one of the worlds largest technology companies based in silicon valley with operations all over the world on this project we are working on the bleedingedge of big data technology to develop high performance data analytics platform which handles petabytes datasets we are looking for an enthusiastic and technologyproficient big data engineer who is eager to participate in design and implementation of a topnotch big data solution to be deployed at massive scale

responsibilities
participate in design and development of big data analytical applications
design support and continuously enhance the project code base continuous integration pipeline etc
write complex etl processes and frameworks for analytics and data management
implement largescale near realtime streaming data processing pipelines
work inside the team of industry experts on the cutting edge big data technologies to develop solutions for deployment at massive scale
requirements
strong knowledge of scala
indepth knowledge of hadoop and spark experience with data mining and stream processing technologies kafka spark streaming akka streams
understanding of the best practices in data quality and quality engineering
experience with version control systems git in particular
desire and ability for quick learning of new tools and technologies
what will be a plus
knowledge of unixbased operating systems bashsshpsgrep etc
experience with githubbased development processes
experience with jvm build systems sbt maven gradle

what we offer
work in the bay area with terrific customers on large innovative projects
highenergy atmosphere of exponentially  successfully growing company
a very attractive compensation package with generous benefits medical dental vision and life 401k and section 125 pretax offerings pop and fsa plans

about us
grid dynamics is the engineering services company known for transformative missioncritical cloud solutions for retail finance and technology sectors we architected some of the busiest ecommerce services on the internet and have never had an outage during the peak season founded in 2006 and headquartered in san ramon california with offices throughout the us and eastern europe we focus on big data analytics omnichannel services devops and cloud enablement",,CA,False,data_engineer
Principal Data Engineer,"movable ink powers meaningful experiences in email and on the web for the biggest brands in the world data is at the heart of these experiences  we are collecting many terabytes of data each quarter and all of it must be partitioned and aggregated for many different use cases

the principal data engineer will be responsible for all data access patterns across the business data scientists will want access to the billions of events tracked across our customers web sites each day data analysts will want connect that usage back to configuration data in our relational database the product itself will need to aggregate this constant flood of data in real time

fastforward one year heres what you will have accomplished


supported data initiatives in three different products using a combination of stream processing messaging queues and batch etl
become an expert in our existing storage technologies and our use cases to suggest and implement enhancements
enabled the data science team by providing them with the tools and the dataset they need to be effective
connected product data to business data for adhoc analysis with bi tools
performed a cost analysis for moving from a unified data storage approach to regional isolation
partnered with information security to define and implement recommend procedures for data storage and access

experience

youve done a lot of work with big data tools such as spark storm hive hadoop etc
youve implemented storage mechanisms for highthroughput workloads
youre comfortable in aws and have run production systems there

",,NY,False,data_engineer
Data Engineer I,"description

job purpose
the data engineer i is responsible for processing structured and unstructured data validating data quality and developing and supporting data products the data engineer also plays a role in agile planning providing advice and guidance and monitoring emerging technologies

key responsibilities
gathers and processes raw structured semistructured and unstructured data using batch and realtime data processing frameworks
understands and enforces appropriate data master management techniques
ensures data quality and implements tools and frameworks for automating the identification of data quality issues
work with internal and external data providers on data validation providing feedback and making customized changes to data feeds and data mappings
understands the challenges that the analytics organization faces in their daytoday work and partner with them to design viable data solutions
recommends improvements to processes technology and interfaces that improve the effectiveness of the team and reduce technical debt

qualifications
knowledge experience  qualifications
working experience in design development and implementation of highly scalable highvolume software systems and components clientfacing web applications and major internetoriented applications and systems
working experience with relational databases and knowledge of query tools and statistical software is required including but not limited to sql management studio  sql integration services sql database services sql job agent sql server data tools sql reporting services sql analysis services tabular power querym
working experience with batch and realtime data processing frameworks
working experience with data modelling data access and data storage techniques
working experience with business intelligence tools and platforms
working experience with data quality tools
working experience with application lifecycle methodologies eg waterfall agile iterative


about cox automotive
cox automotive inc makes buying selling and owning cars easier for everyone while also enabling mobility services the global company’s 34000plus team members and family of brands including autotrader® clutch technologies dealercom® dealertrack® kelley blue book® manheim® nextgear capital® vinsolutions® vauto® and xtime® are passionate about helping millions of car shoppers tens of thousands of auto dealer clients across five continents and many others throughout the automotive industry thrive for generations to come cox automotive is a subsidiary of cox enterprises inc a privatelyowned atlantabased company with revenues exceeding 20 billion wwwcoxautoinccom
cox is an equal employment opportunity employer  all qualified applicantsemployees will receive consideration for employment without regard to that individual’s age race color religion or creed national origin or ancestry sex including pregnancy sexual orientation gender gender identity physical or mental disability veteran status genetic information ethnicity citizenship or any other characteristic protected by law
statement to all thirdparty agencies and similar organizations cox accepts resumes only from agencies with which we formally engage their services please do not forward resumes to our applicant tracking system cox employees cox hiring manager or send to any cox facility cox is not responsible for any fees or charges associated with unsolicited resumes

organization cox automotive

primary location usincarmel11799 n college ave

employee status regular

job level individual contributor

shift day job

travel no

schedule fulltime

unposting date ongoing",,IN,False,data_engineer
Data Engineer,"requisition id 25606

there are currently more than 20000 objects in earths orbit some of these objects are operational satellites performing critical civil scientific and military missions tracking monitoring controlling and defending these satellites is of key national interest the information integration and decision support group develops the mission critical decision support tools needed to perform key functions such as rapid event detection and dynamic scheduling of assets in order to develop courses of action for the space operator the decision support tools are driven by integrating information from various sensors sources and systems

the focal point of the groups activities resides in its lexington bmc3 testbed lc3t facility it provides a realtime framework environment to ensure interoperability of several serviceorientedarchitecture soa systems to evaluate and operationalize the contributions of new sensors and sources and to develop and assess the performance of new decision support algorithms using live data

we are seeking a data engineer to help us build the next generation automated decision support tools in the lc3t facility these tools will help the space operator understand the behavior of objects in space and the intent of this behavior this engineer will be working with a team to create the end to end design as well as development and deployment of new capability tools developed in the lc3t are commonly used in space operations today

qualifications bs in electrical engineering physics applied mathematics or similar technical field with 0  3 years is required experience with java sql and nosql databases data analytics such as pattern recognition  change detection is highly desired
position will require candidate to acquire and maintain a secret clearance





mit lincoln laboratory is an equal employment opportunity eeo employer all qualified applicants will receive consideration for employment and will not be discriminated against on the basis of race color religion sex sexual orientation gender identity national origin age veteran status disability status or genetic information us citizenship is required",,,False,data_engineer
Sr Data Engineer - APIs for Test/Measurement Platform,"description
the data science and engineering team at target is a hypergrowing dynamic and collaborative team data engineers work closely with data scientists to create valuable insights using voluminous data collected from internal and external systems on a largescale business operations are empowered with these insights to achieve target’s strategic initiatives while providing worldclass shopping experiences

use your skills experience and talents to be a part of groundbreaking thinking and visionary goals with target’s data science and engineering team in sunnyvale as a sr data engineer you will take the lead as you work on

designing and implementation

ownership of all technical aspects of software development for assigned application
utilize the data structure and algorithms to make the system more efficient
support ongoing refactoring of code utilize visualization and other techniques to fasttrack concepts and deliver continuous improvement
analyze monitor and optimize for performance
write code and unit tests work on api’s automation and testing
produce and maintain highquality technical documentation
scope of work

will gain new knowledge from upcoming research and applying it to design and development
develop deep understanding of tieins with other systemsplatforms within the supported domains
share the gained knowledge with other team members through interactive sessions
identify opportunities to adopt innovative technologies
works with product owners and principal data engineers to prioritize features for ongoing sprints and managing the list of technical requirements based on new known defects and issues
provides continuous support for design development and application availability
requirements

2 years of experience in developing software applications including analysis design coding testing deploying and supporting of applications
bs degree in computer science applied mathematics statistics or area of study related to data sciences and data mining
understand applicationsoftware development and design in an agile environment
collaborative personality able to engage in interactive discussions with the rest of the team
inquisitive on big data technology current on new ideas and tools
good understanding of data structures and designing of algorithms
good understanding of basic mathematical concepts and ability to grasp complex mathematics
should know at least one programming language ie java python cc
preferred qualifications

experience with hadoop stack map reduce kafka pig hive hbase cassandra yarn andor bdas scalaspark
extensive experience designing and developing api’s in large scale environments
experience working on projects facilitating true cicd jenkins drone etc
exposure to devops tools and culture ie kubernetes docker spinnaker jenkins git etc
awareness of new and emerging big data technologies
qualifications",,CA,False,data_engineer
"Director, Data Science/Engineering",150000  200000 a yeartech team extension is looking for a director of data scienceengineering for one of our high growth clients adtech experience is a huge plusthe data engineer  science director will lead a team responsible for designing and improving our big data infrastructure the team is also responsible for providing various advanced mathematical solutions for largescale problems in other areas of our system we process a few billion events daily and the amount of data we process is growing rapidly we believe in being smart innovative pragmatic polished and efficient and are looking for people that fit those values this role reports to our ctowhat you’ll do develop various predictive models to help solve various big data problemsadapt  improve various parts of the our big data infrastructurestack to handle the above modelswork with various team members to help improve areas which deal with high volume low latency problems using various statisticalmathematical modelswhat you’ll need good background and experience with statistical and other advanced math problem solvingproven experience writing advanced algorithms on top of big data infrastructureknowledge in a variety of nonsql big data open source products such as spark hadoopetcprogramming experience ideally in python scala java or r but we are open to other experience if you’re willing to learn the languages we useknowledge of machine learning libraries and such as spark mllib mahoutscikitlearntheanovowpalwabbit h2o orxgboostand ability to apply machine learning at scaleknowledge of data mining and natural language processing is a plusability to operate in an agile entrepreneurial startup environmentexcellent teamwork skills with an ability to reach out and use team strengths to get the work done with minimal supervisiongood communication skillsyou must be motivated driven and passionate about programming and technologyjob type fulltimesalary 15000000 to 20000000 yearexperiencedata mining 4 years preferredpython 3 years preferrednatural language processing 1 year preferredbig data 3 years preferredjava 3 years preferred,175000.0,CA,False,data_engineer
Scientific Data Engineer,"the data analytics and visualization group httpdavlblgov has an immediate opening for a scientific data engineer

the data engineer will work on development and applied research in the area of data modeling management and analysis in the area of neuroinformatics applications the position is in support of a research project funded by the national institutes of health nih that aims to develop methods for standardization sharing and analysis of neurophysiology data the overall objectives for this position are to develop new methods and software tools that enable scientific knowledge discovery using high performance computational platforms and advance the stateoftheart in dataintensive analysis this positions will be part of an experienced team conducting rd in the areas of dataintensive highperformance analysis visualization and data management the candidate will be working as part of a multidisciplinary team composed of computer scientists mathematicians and experimentalcomputational neuroscientists

the scientific data engineer will

design implement and maintain hpc ready software tools for querying and visualizing complex multidimensional neurophysiology data and design implement and maintain software tools for creating and running parallel data intensive analysis workflows
develop methods for tracking provenance of analyses of experimental data and develop capabilities for integrating standardized data with webbased data archives
ensure and exercise software development best practices around version control and continuous integration and deployment
work closely with the community of developers of the neurodata without borders httpswwwnwborg open source data ecosystem and work closely with neuroscientists from institutions such as ucsf and the allen institute for brain science to develop new capabilities of the neurodata without borders ecosystem

minimum qualifications

bachelor’s degree in a field with an emphasis on mathematics andor computer science or equivalent experience and at least 2 years of related experience designing and developing software for data modeling or analysis
demonstrated capability with programming languages such as cc python java
demonstrated capability with version control systems such as git mercurial or svn
experience developing complex software solutions
experience testing large code bases
experience contributing to communitydriven open source software
demonstrable experience in one or more of the following areas data modeling data management data query machine learning visualization

additional desired qualifications

master’s or phd in computer science or related field with 5 or more years of professional experience designing and developing scientific data modeling or analysis software
demonstrated capability with parallel libraries and environments such as mpi openmp cuda pthreads opencl openacc
demonstrated capability with cicd systems such as travisci cirlceci or appveyor
experience working in shared compute resources eg clusters
experience working with relational andor nonrelational database systems eg mongodb postgresql mysql redis
experience working with hdf5
experience developing rest apis
experience with the neurodata without borders data standard and pynwb

notes

this is a full time 2year term appointment with the possibility of extension or conversion to career appointment based upon satisfactory job performance continuing availability of funds and ongoing operational needs
the level of the position will depend upon the applicants demonstrated skills knowledge and abilities
fulltime mf exempt monthly paid from overtime pay
salary is commensurate with experience
this position may be subject to a background check any convictions will be evaluated to determine if they directly relate to the responsibilities and requirements of the position having a conviction history will not automatically disqualify an applicant from being considered for employment
work will be primarily performed at lawrence berkeley national lab 1 cyclotron road berkeley ca

berkeley lab lbnl addresses the world’s most urgent scientific challenges by advancing sustainable energy protecting human health creating new materials and revealing the origin and fate of the universe founded in 1931 berkeley lab’s scientific expertise has been recognized with 13 nobel prizes the university of california manages berkeley lab for the us department of energy’s office of science

equal employment opportunity berkeley lab is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability age or protected veteran status berkeley lab is in compliance with the pay transparency nondiscrimination provision under 41 cfr 6014 click here to view the poster and supplement equal employment opportunity is the law",,CA,False,data_engineer
Principal Big Data Engineer,"in addition to the responsibilities listed below this position is responsible for planning designing and building database systems that are stable recoverable and integrated with other available technology stacks for the purpose of efficient secure data utilization this includes understanding the interoperability between databases and other dependent technology stacks performance scalability stability capacity planning etc possessing indepth knowledge in one dependent technology stack eg windows admin networking storage etc negotiating with other engineering platform partners and consulting as 2nd level technical expert on specific platforms this role also requires familiarity with at least one other dbms platform in addition to specialty and administrative skills in at least one other platformsome of the unique challenges this position will face include database considerations for a large corporate enterprise and a high degree of complexity and nonuniformity


essential responsibilities

conducts or oversees businessspecific projects by applying deep expertise in subject area promoting adherence to all procedures and policies developing work plans to meet business priorities and deadlines determining and carrying out processes and methodologies coordinating and delegating resources to accomplish organizational goals partnering internally and externally to make effective business decisions solving complex problems escalating issues or risks as appropriate monitoring progress and results recognizing and capitalizing on improvement opportunities evaluating recommendations made and influencing the completion of project tasks by others

practices selfleadership and promotes learning in others by building relationships with crossfunctional stakeholders communicating information and providing advice to drive projects forward influencing team members within assigned unit listening and responding to seeking and addressing performance feedback adapting to competing demands and new responsibilities providing feedback to others including upward feedback to leadership and mentoring junior team members creating and executing plans to capitalize on strengths and improve opportunity areas and adapting to and learning from change difficulties and feedback

as part of the it engineering job family this position is responsible for leveraging devops and both waterfall and agile practices to design develop and deliver resilient secure multichannel highvolume hightransaction onoffpremise cloudbased solutions

provides consultation and expert technical advice on it infrastructure planning engineering and architecture for assigned systems by assessing the implications of it strategies on infrastructure capabilities

provides some recommendations and input on options risks costs and benefits for systems designs

leverages partnerships with it teams and key business partners to troubleshoot complex systems

serves as a functional expert and collaborates with architects and software engineers to ensure functional specifications are converted into flexible scalable and maintainable system designs

translates business requirements and functional and nonfunctional requirements into technical specifications that support integrated and sustainable designs for complex or high impact infrastructure systems by partnering with business analysts to understand business needs and functional specifications

ensures system designs adhere to company architecture standards

builds partnerships with counterparts in various it teams eg database operations technical support throughout system development and implementation

serves as a technical expert for project teams throughout the implementation and maintenance of assigned enterprise infrastructure systems by defining and overseeing the documentation of detailed standards eg guidelines processes procedures for the introduction and maintenance of services

mentors other technical resources throughout infrastructure systems development

reviews and validates technical specifications and documentation for complex or multidimensional solutions

leads the development and modification of solutions by identifying technical solutions to business problems

collaborates with business leaders solutions and lead enterprise architects to review business drivers and establish a foundation for enterprise systems planning

reviews benchmarking results and provides information to support current and future infrastructure needs and projects to it leadership provides preliminary conclusions

benchmarks and evaluates it trends and technologies to identify opportunities and considerations that impact roi

makes recommendations on resources required to maintain service levels and meet new demands

guides and drives physical architecture design for new initiatives",,CA,False,data_engineer
Data Architect / Data Engineer / Data Analyst / Business Ana...,"job description
midlevel position participating in data conversion data cleansing data integrity solutions as well as generating user documentation for our application there is opportunity to attain high visibility to our clients and become entitled to bonus participation based on performance and contribution great opportunity to acquire oil and gas experience as well as client service skills
assists in the compilation analysis and manipulation of massive sets of data in order to convert raw data into meaningful information in client systems this responsibility requires exemplary skills in sql ms excel and ms access skills are also valued
defines processes and procedures associated with unique client requirements for data management and reporting
researches and recommends innovative approaches for project execution recommends areas for improvement in internal processes along with possible solutions and provides status reports to stakeholders and addresses issues as appropriate
participates with team in problem resolution regarding systems and procedures assists team or supervisor with special consulting projects to identify client data anomalies and provide business solutions
documents procedures using text and workflow diagrams and screen shots from application develops and maintains installation and configuration procedures provides documentation for institutional workflow processes associated with application
responsible for the provisioning of application access accounts create modify and remove user accounts or permissions as required
ensures systems documentation follows best practices is uptodate accurate and tested maintains inventory of equipment software subscriptions troubleshoot user computer and application issues coordinate with client it personnel for implementation and troubleshooting recommends policies and procedures which govern the applications
performs other duties as assigned and works under minimal supervision with some latitude for independent judgment
qualificationsknowledgeexperience required
requires bachelors degree in computer science information systems finance accounting or related curriculum must possess strong customer service and interpersonal skills additional skills talents and languages

data warehousing solutions
indepth knowledge of database architecture
systems development
etl spreadsheet and bi tools
data modeling
communication  visualization
data apis
database systems sql etc
math stats machine learning
sql xml c r python",,OK,False,data_engineer
Data Engineer,"data engineer

 at medispend we are on a mission to transform and simplify how the life science industry complies with global healthcare industry regulations medispend global compliance solutions are recognized market leaders fully integrated within a firstmover born in the cloud technology platform we’re gearing up for the next phase of growth looking to onboard hungry humble and smart people who thrive on solving business problems with innovative technology read on to see what’s different about this opportunity and begin to visualize how you will advance your career by joining our team

check this out

get to know the regulatory compliance and healthcare entity data domain
work with “big data” architects to create analytic data structures
use modern data wrangling tools and techniques to inspect and transform data
participate in the renaissance of the functional programming paradigm within the industry’s hottest data transformationanalytics framework
learn and practice the tricks to working with data at scale
 a day in the life

you are a data engineer at medispend you practice etl and elt you create data transformations to standardize three aggregate spend transaction files into a standard format you build innovative algorithms to detect duplicate healthcare providers you figure out that a particular file won’t load properly because there are missing delimiters you build custom crosswalks that transform client specific data to standardized formats you build a set of routines to create a set of denormalized data structures that will enhance analytic execution speeds you help build operational metrics to report on data quality and volumes you aid the product team to mine for client data inconsistencies

what you bring to the table
you’re a professional with a great blend of practical experience education and achievement you’re efficient at getting your points across in written and verbal mediums you are passionate about working with data exposure to the healthcare data domain is a plus but not required

significant experience with etlelt tools and platforms is expected we’re a java shop so cloveretl pentaho talend experience helps if you’ve used modern data wrangling tools like paxata tamr or trifacta even better spark experience is a plus you should be efficient with at least one programming language such as java scala or python sql skills are a given knowledge of data storage systems which include traditional rdbms oracle postgresql mariadb analytic data stores vertica greenplum redshift presto and object stores aws s3 openstack swift helps also
you’ve been in the trenches delivering commercial applications requiring data accuracy you have contributed to the development of repeatable modern data processing pipelines

your move

growth story startup feel life science domain passionate technologists and born in the cloud

looking for fulltime employees only",,NH,False,data_engineer
Data Engineer,"data engineer  downtown boston  6590k

a stable healthcare company reinventing the primary care system
in downtown boston is looking for a data engineer to join their growing team this
is a midsize company but the data team is small so they are looking for someone
who thrives in a team environment some additional details on this position

requirements
contribute to the full life cycle of etl
processes

12 years’ experience with sql relational
databases python

strong communication skills are a must

past experience working in the healthcare
industry

pluses
experience with looker tableau ssis
matillion talend

benefits
health dental insurance

20 days pto

tuition reimbursement

equity",,,False,data_engineer
Lead Data Engineer - High Performance Computing,"description
lead data engineer – high performance computing
target edabi enterprise data analytics business intelligence is revolutionizing the way how target retail uses data located in sunnyvale ca it’s just across the street from the local train station in the heart of silicon valley originally opened in 2014 the sunnyvale office is now home to more than 100 team members who work to make target a more modern datadriven retail company to learn more view this article httpscorporatetargetcomarticle201611meettargetsunnyvale
team introduction
the highperformance computing group at target edabi not only aims to enable teams at target to stream filter transform and analyze highbandwidth data in realtime but also provide tools for data analysts and other team members to analyze and take action on their data streams
what will you be doing
the highperformance computing engineer will design and develop parallel computing algorithms for solving very large machinelearning problems on heterogenous platforms including vector engines avx512 fpgas and other types of supercomputing hardware platforms
principal dutiesresponsibilities
design and develop parallel computing algorithms
manage lifecycle of hpc products from inception to deployment
requirements
ms or phd degree in computer science electrical engineering or computer engineering
ability to analyze systems at all levels
ability to make decisions based on strict scientific analysis
outstanding communication skills
ability to create innovate think outofthe box
understand applicationsoftware development and design
collaborative personality able to engage in interactive discussions with the rest of the team
indepth understanding of computer processor architecture
ability to create new solutions beyond available open source code
ability to explain strengths and weaknesses of generally available open source such as hadoop spark storm flink we do not use these open source solutions but it is important to know understand how they fail in achieving supercomputing performance levels
indepth understanding of sharedmemory multiprocessor multicore programming
indepth understanding of parallelization paradigms
experience in designing and developing largescale realtime systems
deep understanding of operating system kernels
deep understanding of machinelevel architecture and programming
deep understanding of computer performance benchmarking latency throughput
highperformance linear algebra libraries
expertlevel knowledge of c or c
some familiarity with tensorflow or similar
conceptual understanding of opencl verilog fpga development cuda
qualifications",,CA,False,data_engineer
Data Engineer,"the challenge
the data engineering team is building the next generation of data infrastructure we work with cuttingedge big data technologies to power the most efficient secure and performant data ecosystem to power live experiences operating at the base of eventbrites infrastructure we feed data to analysts customers engineers and the platform alike our core foundation is modular and strong we hope you can help us extend its use across the company as we explore and implement new technologies

the team
the data engineering team is charged with building and maintaining all streaming and batch data pipelines across the company we also support and empower analysts engineers and data scientists with the tools they need to create a datadriven product and power datadriven decision making we are pragmatic and meritocratic we work hard we play hard we are strongly connected to each other eventbrite engineers perform frequent demos of the code we ship we also hone our skills through code reviews and tell the world about it on eventbrite’s engineering blog we value community we believe in the power of live experiences and we regularly host free events with top technical speakers learn more about the team from some of our engineers here
the role
we are hiring someone to help us build a scalable reliable secure and highly performant data platform youll help reinforce and extend the infrastructure that powers the use of data at eventbrite from infrastructure development to data analysis to etl jobs you will need a broad range of bigdata engineering skills the team has strong and versatile engineers you will grow we hope to grow with you

tech stack
our primary stack includes usual suspects in big data engineering spark hadoop presto spark sql hive spark streaming kafka mysql redis aws yarn ansible terraform python git and more
the skill set
13 years of experience building high quality software in python java or scala
1 years of working experience in rapid product development building data infrastructure etl or mapreduce jobs
working knowledge of sql and relational database design and modeling approaches and techniques for extracting transforming loading and integrating data
understanding of data engineering data science machine learning business analytics and the relevant technologies that support them
familiarity with a serverside framework such as django express rails or net
excellent customer service skills
outstanding verbal written presentation and facilitation skills in particular a demonstrated ability to effectively communicate technical and business issues and solutions to multiple organizational levels
ability to teach and mentor engineers with a variety of skill levels and backgrounds
strong analytical and problem solving skills and attention to detail
bonus points
bachelor’s degree or higher in a technical field csmathstatsengineering
passionate about live entertainment and eager to help build eventbrite into the world’s leading event technology platform
about eventbrite
eventbrite is the world’s largest ticketing and event technology platform powering millions of live experiences around the globe we build technology that allows anyone to create share find and attend events of all kinds music festivals marathons conferences hackathons political rallies fundraisers gaming competitions— you name it we power it meet some of the team

is this role not an exact fit
sign up to keep in touch and we’ll let you know when we have new positions on our team

eventbrite is a proud equal opportunityaffirmative action employer supporting workforce diversity we do not discriminate based upon race ethnicity ancestry citizenship status religion color national origin sex including pregnancy childbirth or related medical conditions marital status registered domestic partner status caregiver status sexual orientation gender gender identity gender expression transgender status sexual stereotypes age genetic information military or veteran status mental or physical disability political affiliation status as a victim of domestic violence assault or stalking or other applicable legally protected characteristics

flsa status exempt

please read our applicant privacy notice to understand how we process your personal information when you apply for a job with us",,TN,False,data_engineer
Data Engineer,"job description

this role works as a member within decision sciences of consumer banking group at first national bank of omaha the principle purpose of this position is to conduct assignments to support initiatives related but not limited to the following

perform data import wrangling and visualization on very large datasets data validation and integration from multiple sources including sql and nosql databases

end to end programming support of machine learning initiatives including coding testing and code validation

assist automating production code optimizing model efficiency improving quality assurance and deploying model into production on big data platform

visualizing data in a way that tells a story

work independently and collaboratively within the team to help to achieve the desired outcomes of an analytical project

job qualifications
basic qualifications

minimum of 3 years of working experience in data science

must have a master’s degree in computer science management information system statistics or other related stem fields

strong working knowledge in computer programming languages including r sql and python

experience with data visualization tools eg r shiny markdown microsoft visual studio powerbi

depth of knowledge in leveraging latest big data toolsplatforms ie machine learning techniques deep learning highlypreferred experience in bigdata computation such as hadoop spark and mapreduce

demonstrate excellent oral and written communication skills

demonstrate the ability to handle stress meet deadlines and work with minimal supervision

demonstrated experience working in multidisciplinary teams",,NE,False,data_engineer
Data Engineer,"digital pharmacist is a rapidly growing digital health company that powers technological communication and adherence solutions for 7500 pharmacies national pharmacy wholesalers hospital systems and pharmaceutical brands millions of patients use the companys products every month the company is headquartered in austin texas with offices in newark new jersey digital pharmacist is the official digital partner of the national community pharmacy association and a winner of the 2017 austin alist awards
the role
own all of the data infrastructure the data lakewarehouse and etl jobs
architect data patterns to support our organization’s needs
maintain security of hipaa data while using it to power business decisions and analytics as well as other customer facing systems
build a robust comprehensive data architecture to support the goal of building tools to utilize large sets of data to help improve medication adherence and promote patient health
qualifications
bs in computer science or engineering or equivalent experience
2 years of etldata engineering work
3 years of professional software engineering
experience working with relational and nosql databases
experience working with engineers and business analysts to solve data needs
experience working with a data pipeline and etl jobs
preferred
experience with big data frameworks spark emr etc
experience with airflow luigi pinball or equivalent batch job managers
experience working with cloud infrastructure
experience with bigquery redshift vertica cassandra or others
experience consuming and building restful apis
why work with us
stock options
401k plan
dogfriendly workplace
three weeks of pto plus holidays
paid medical dental and vision plan
breakfast taco mondays and a fully stocked kitchen for snack breaks daily
free orange theory and yoga classes",,TX,False,data_engineer
Customer Data Engineer I - ObjectRocket,"objectrocket is a young company with big goals we want to build the next generation of database as a service and we need your help we need folks who want to build something that hasnt been done yet is hard yet fantastically rewarding

we are located in the heart of beautiful downtown austin tx austin is highly regarded as a wonderful place to live work and play its the live music capital of the world and has a serious night life

objectrocket has a fast paced and exciting culture we are a small team and move quick we are building something quite amazing and look to be leaders in our field and community we are growing like crazy we need more help

we own the entire stack hardware and software so that means you’ll need to find and resolve issues at all levels to do this successfully you’ll be switching hats often from systems administrator resolving a configuration problem on a machine to dba digging into production datastores to identify issues to software developer troubleshooting customer code you’ll have the opportunity to work with a broad range of technologies in particular hadoop mongodb elasticsearch and redis additionally you’ll be responsible for owning the full customer experience this includes communication with customers via our ticketing system and phones working complex problems and owning issues through to resolution

you’re a seasoned systems administrator and technical jack of all trades with topnotch people skills looking to join a fastpaced team building huge things you prefer an agile work environment and possess the selfmotivation to thrive in it your written communication skills are the stuff of legends

you have an uncanny ability to solve issues with technologies you’ve never seen before after a few minutes of research you are above all a problem solver

qualifications
tenured linux knowledge with centos rhel andor ubuntu
functional virtualization knowledge with kvm xen andor openvz
prior training or experience installing configuring and optimizing hadoop mongodb andor redis
indepth knowledge of bashshell scripting and working knowledge in at least one other language
python or java preferred
excellent written communication skills
ability to learn new technologies quickly
passion for collaboration

nice to haves

working knowledge of storage tech such as ssds raid and lvm2
nagiosicinga and new relic experience
experience administering web and application servers running apache nginx and gunicorn
active in the technical and open source community eg participating in blogging tweeting and social coding are all very desirable
database administration experience with other nosql solutions eg hbase and elasticsearch
knowledge of postgresql cassandra andor other rdbms technologies
experience with the hortonworks sandbox environment",,TX,False,data_engineer
Big Data Engineer,"what youll do
we need a selfmotivated and highly curious individual that is excited to work with everevolving groundbreaking technology in the big data field you will apply a variety of big data technologies to the security space to ingest transform index aggregate correlate provide apis visualize and enable a spectrum of organizations across cisco
who youll work with
as a member of the threat intelligence platform team youll be part of a highly empowered collaborative group whos passionate about using data to help secure cisco enable security products and cultivate security research
who you are
you are a selfstarter who loves to dig into data and who your teammates trust to throw challenging problems in your direction as a result you help make data much easier to understand and consume for others and have managed to pivot to new technologies rapidly
at minimum we expect you to have
bs in computer science or related technical degree
active proficiency with python git and test automation
minimum 3 years of experience on big data platform ex hadoop spark kafka clickhouse nifi
experience with crafting and managing data pipelines
devops mindset with experience on agile team
strong technical writing and communication skills
excellent problem solving and decisionmaking skills
the following would be beneficial but not required
experience with containerization specifically docker  kubernetes
experience with sql and linux
security experience
splunk dashboards reports and alerting
why cisco
at cisco each person brings their unique talents to work as a team and make a difference yes our technology changes the way the world works lives plays and learns but our edge comes from our people
we connect everything securely– people process data and things – and we use those connections to change our world for the better
we innovate everywhere from launching a new era of networking that adapts learns and protects to building cisco services that accelerate businesses and business results our technology powers entertainment retail healthcare education and more – from smart cities to your everyday devices
we benefit everyone we do all of this while striving for a culture that empowers every person to be the difference at work and in our communitiescolorful hair don’t care tattoos show off your ink like polka dots that’s cool pop culture geek many of us are be you with us wearecisco
cisco is an affirmative action and equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion gender sexual orientation national origin genetic information age disability veteran status or any other legally protected basis
cisco will consider for employment on a case by case basis qualified applicants with arrest and conviction recordslikm1",,NC,False,data_engineer
Big Data Engineer: ML Platform,"job description
are you passionate about data does the prospect of dealing with massive volumes of data excite you do you want to be part of team building a new machine learning platform that processes billions of records a day in a scalable fashion using aws technologies

amazons finance technology team is seeking an outstanding big data engineer to join the team that is shaping the future of the finance machine learning platform the team is committed to building a largescale machine learning platform solving complex and ambiguous problems in the finance space to service customers such as payments treasury and finance operations amazon has culture of datadriven decisionmaking and demands data that is timely accurate and actionable

our ideal candidate thrives in a fastpaced environment relishes working with large transactional volumes and big data enjoys the challenge of highly complex business contexts that are typically being defined in realtime and above all is a passionate about data and machine learning
basic qualifications
bachelors degree or higher in an analytical area such as computer science physics mathematics statistics engineering or similar
demonstrated ability in data modeling etl development and data warehousing
coding proficiency in at least one modern programming language eg python java scala
experience with big data technologies hadoop hive hbase pig spark etc
preferred qualifications
industry experience as a data engineer or related specialty eg software engineer business intelligence engineer data scientist with a track record of manipulating processing and extracting value from large datasets
experience buildingoperating highly available distributed systems of data extraction ingestion and processing of large data sets
experience building data products incrementally and integrating and managing datasets from multiple sources
query performance tuning skills using unix profiling tools and sql
experience leading largescale data warehousing and analytics projects including using aws technologies – redshift s3 ec2 datapipeline and other big data technologies
experience providing technical leadership and mentor other engineers for the best practices on the data engineering space
linuxunix including to process large data sets
experience with aws services
some experience leveraging python r or matlab to manipulate data and set up automated processes as per business requirements
strong ability to interact communicate present and influence within multiple levels of the organization
masters degree
excellent communication skills to be able to work with business owners to develop and define key business questions and to build data sets that answer those questions
previous experience with distributed or load balanced system design and development
strong verbalwritten communication and data presentation skills including an ability to effectively communicate with both business and technical teams

amazoncom is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,WA,False,data_engineer
Data Engineer,"
design access and implementation of extensive databases and analytical tools
recognize trends and put puzzles together that are relevant to understanding value creation in the intersection of data sets
formulate and apply mathematical modeling and other optimizing methods to develop and interpret information that assists management with decision making and policy formulation
collect and analyze data and develop decision support software services and products
develop and supply optimal time cost or logistics networks for program evaluation review and implementation
gather and process raw data at scale including writing scripts web scraping and calling apis
perform validation and testing of models to ensure adequacy and reformulate models as necessary
collaborate with management to identify and solve operational problems to clarify management objectives

– present the results of mathematical modeling and data analysis to management and other endusers


scrub noisy datasets using programming language sql python r matlab c as well as statistical software
use understanding of how structured and unstructured data sets intersect to provide creative solutions
develop code to predict correlation between number of operating rigs in us and oil prices
use tsql to analyze data an build correlation models
develop automated well production forecast model using tsql to load data into python implementing pandas numpy and scipy modules to analyze data and predict well production for every well in us
perform database management by automating data update processes and building stored procedures and tablefunctions for various users
write code for automated data scraping and data download assignments using python and selenium module

requirements
this position requires a bachelor’s degree in mathematics or computer science followed by six months of experience as a software developer using python

contact
applicants interested in this position should mail their resume to

justin carlson – vp  managing director research

east daley capital

5161 e araphaoe road

ste 411

centennial co 80122",,CO,False,data_engineer
Data Engineer,"the job

akili interactive is looking for a data engineer to join our development teams in boston ma or larkspur ca just north of san francisco you will help develop the data infrastructure that supports our data science business intelligence and data integration initiatives and you will be an integral part of the broader effort to launch of our digital therapeutic products that combine rigorous scientific validation with engaging video game mechanics

you will join during the early stages of building new mobile applications web applications event streaming pipelines and supporting api services our stack is scala play lots of docker postgres elasticsearch several aws services and javascript ideally wed like someone whos comfortable with these technologies but were always excited to meet great engineers who can quickly learn new technologies

heres what it entails


participate in technical discussions with other engineers architects partners and colleagues to discuss application and platform solutions
serve as a hands on software engineer using the language and tools best suited to solve the problem
establish expertise in our existing data infrastructure
develop data storage and pipeline infrastructure to support data science business intelligence and data integrations
be handson with cloud deployments load balancing cicd provisioning and security of the production and staging environments
ship clean well crafted code

heres what you need


bachelors degree or masters degree in computer science
4 years experience as a data engineer
hands on experience using amazon web services aws sdks  such as sqs s3 sns rds lambda
strong understanding of scala or expertise in java with a desire to learn scala
strong understanding of both relational and nosql databases
experience working in a containerized infrastructure deployed in the cloud
avid user of open source projects and enjoy constant learning
enjoy both analytical and handson work to solve problems
able to focus on a problem to completion with a strong attention to detail

its great if you also have


experience as a backend software engineer developing services and apis
hipaa experience
continuous integration and development
agile development
written technical documentation samples or links to open source projects github projects or documentation you have written that you are able to share

akili  the company

akili interactive wwwakiliinteractivecom  httpwwwakiliinteractivecom  is pioneering the field of digital therapeutics combining scientific and clinical rigor with the ingenuity of the tech industry to develop novel digital medicines designed to treat cognitive dysfunction and brainrelated conditions

akilis flagship product aklt01 in pediatric adhd is now under review by fda for clearance following akilis recent filing akili previously announced positive topline results of a multicenter randomized doubleblind controlled pivotal study evaluating the safety and efficacy of aklt01 if cleared by fda aklt01 would be the first prescription video game to treat a medical condition and the first prescription digital medicine for children with adhd the product is based on technology developed at ucsf that was featured as the cover article  httpwwwnaturecomnewsgamingimprovesmultitaskingskills113674  in nature under the headline game changer

akili was founded by leading neuroscientists and toptier game design veterans to create gaming experiences that are designed to directly treat cognitive deficiency and improve symptoms associated with medical conditions across neurology and psychiatry akili has partnerships with top pharmaceutical companies and has received recent recognition in major media outlets including the wall street journal cnbc fast company and the verge",,CA,False,data_engineer
Data Engineer,"as a data engineer at amne you’ll join a young growing team as we build the world’s fastest and simplest home transaction experience
responsibilities will include
building data infrastructure and backend services to support userfacing and internaluse applications
identifying researching and analyzing new data sources
developing and maintaining rest apis for amnes backend services
managing and developing etl pipelines to ensure and improve the accuracy quality and usability of data across amnes infrastructure
improving and maintaining industryleading home valuation models and methodologies using millions of realestate transactions and complementary data sets
collaborating with software engineers product managers and product designers
maintaining development best practices including test coverage continuous integration ab testing and documentation
becoming a domain expert in realestate
required skills and abilities
strong python programming skills including experience with numpy scipy pandas and scikitlearn
familiarity with common python web frameworks flask django etc
experience with the aws ecosystem s3 elastic beanstalk ec2 etc and application deployment
ability to write clean reusable and productionready code
ability to translate complex dataoriented challenges into solutions for business objectives and vice versa
welldeveloped sql skills preferably including experience with postgresql and postgis
desirable skills and experience
experience with apache airflow
previous experience with continuous integration tools eg circleci travisci etc
previous gis experience
programming experience in nodejs is a plus
we’re looking for individuals who bring
experience with databases statistics web services algorithms and python
strong communication skills
experience building modular scalable cloudbased systems
an interest in learning new technologies and taking the lead on the integration of new technologies into amnes stack
a willingness to learn new technologies and a whateverittakes attitude towards building the best possible home buying and selling experiences for our users
amne is currently hiring for our austin office amne team members are thoughtful listeners fast learners results driven selfmotivated selfaware and selfdisciplined",,TX,False,data_engineer
Data Engineer-Data Analyst,"data engineer
duration  6 months c2h
only w2 consultants
phone  inperson
owings millmd

job description

the data engineer is an accomplished technical leader proactive customerfocused advocate a team player with substantial software engineering experience preferably with some experience within the healthcare industry the data engineer must have handson experience with data security and knowledge of hipaa expert determination the ideal candidate will have an advanced understanding of data discoveryanalysisclassification data masking data transformation and sqldata modelling the candidate must demonstrate the ability to evaluate cutting edge technologies and overcome technical challenges in a fast paced environment the data engineer will play a key role of migrating three enterprise applications into a consolidated application which leverages devops cloud computing and data lake  big data technologies

job duties
design develop implement and maintain code information architecture and conceptual models to support data deidentification effortdevelop data  metadata policies and proceduresreview and evaluate database performance risk and financial analysis feasibility studiesinvestigate and repair application defects regardless of component including platform business logic data process logic or database sql and data modelingall other duties as assigned or directed
qualifications
bachelors of science or higher in computer science or related field8 years of systemsapplication analysis  design experience5 years of combined experience data masking tools eg dataguise privacy analytics or etl talend or informatica
 preferred experience with phi data deidentification anonymization  masking

technical skills
excellent knowledge of relational databases postgresql oracle including sql  stored proceduresexcellent knowledge of rules engines particularly used for complex data masking operationsbasic knowledge of unixlinux commands especially in processing data filespreferred experience with attd and associated technologies fitnesse dbslim junitpreferred experience with delivering code using continuous integration and continuous delivery cicd best practices and devops jenkins pipelines docker groovy ansiblepreferred experience with aws or other cloud platforms
other
us citizen or legal right to work in the united states without sponsorship

thanks and regards

sindhuri
direct  2018154942
sindhurigajulasiarptechcom",,MD,False,data_engineer
Data Science Engineer,"120000  177000 a year indeed est sp global ratings is looking for an experienced data science engineer to join data engineering team within chief data office a team of data and technology professionals who define and execute the strategic data roadmap for sp global ratings the successful candidate will participate in the design and build of sp ratings cloud based analytics platform to help develop and deploy advanced analyticsmachine learning solutions

the team
you will be an expert contributor and part of the rating organization’s data services team this team who has a broad and expert knowledge on ratings organization’s critical data domains technology stacks and architectural patterns fosters knowledge sharing and collaboration that results in a unified strategy all data services team members provide leadership innovation timely delivery and the ability to articulate business value be a part of a unique opportunity to build and evolve sp ratings next gen analytics platform

our hiring manager says
if you are an individual that brings demonstrated experience of delivering big data projects as a data science engineer this is an excellent opportunity i am looking for someone with sound technical knowledge can be handson worked on transformational initiatives and can drive results

responsibilities
design and develop efficient and scalable data pipelines between enterprise systems and analytics platformwork closely with data science team and participate in development and deployment of machine learning models and feature engineering pipelinesprovide technical expertise in the areas of design and implementation of ratings integrated data facility with modern aws cloud technologies such as s3 redshift emr hive presto and sparkbuild and maintain a data environment for speed accuracy consistency and ‘up’ timesupport analytics by building a worldclass data lake environment that empowers analysts to determine insights into revenue and power products across the organizationwork with the machine learning engineering team to build a data eco system that supports ai products at scaleensure data governance principles adopted data quality checks and data lineage implemented in each hop of the datapartner with the chief data office enterprise architecture organization to ensure best use of standards for the key data domains and use casesbe in tune with emerging trends big data and cloud technologies and participate in evaluation of new technologiesensure compliance through the adoption of enterprise standards and promotion of best practice  guiding principles aligned with organization standards
experience  qualifications
bs or ms degree in computer science or information technology8 years of experience as data engineer at an innovative organization4 years of handson experience in implementing data lake systems using aws cloud technologies such as s3 redshift emr hive presto and sparkexpert managing aws services ec2 s3 route 53 elb vpc cloudwatch lambda in a multi account production environmentexperience with machine learning frameworks such as tensorflow  pytorch h2o scikitlearn theano caffe or spark mlib is an added advantageexposure to r sparkr sparklyr or other r packages is a plusexperience in constructing fast data staging layers to feed machine learning algorithmsexperience in building data apis to consume analytic model outputfamiliarity with machine learning model training and deployment process is a plusexperience with development frameworks as well as data and integration technologies such as python scala or informaticaexpert knowledge of agile approaches to software development and able to put key agile principles into practice to deliver solutions incrementallymonitors industry trends and directions develops and presents substantive technical recommendations to senior managementexcellent analytical thinking interpersonal oral and written communication skills with strong ability to influence both it and business partnersability to prioritize and manage work to critical project timelines in a fastpaced environmentfinancial services industry experience",148500.0,NY,False,data_engineer
Healthcare BI / Data Engineer,"the role

were looking for a business intelligence engineer to help design and build the data environment that supports the iora health vision as a key member of our business and clinical intelligence bci team you will be responsible for designing implementing and maintaining operational data stores and data warehouses which form the foundation for innovative applications that directly impact the quality of care delivered to our patients you will be passionate about quality data clean architecture effective collaboration and continuous learning you will be happy to get your hands dirty while building towards a bigger vision you will serve as the resident data architecture and informatics expert and you will be instrumental in building the systems and culture of an innovative company that is working to transform health care positively and directly impacting the lives of our patients every day

responsibilities


be a key contributor to the design implementation automation and documentation for iora etl processes
as a member of an agile team design implement and document data infrastructure for iora healths data warehouse
develop key reports and dashboards using looker to provide reporting analysis and analytics insights

required skills


12 years experience with relational databases and sql
12 years experience building reports and dashboards using bi tools such as tableau or looker
12 years experience building data pipelines and etl processes using tools such as ssis or talend
excellent verbal and written communication skills
working knowledge and curiosity required to debug and analyze complicated system

preferred skills


experience with redshift
experience with matillion  ssis  talend
experience with looker  tableau

we believe in building a diverse team and we strive to make our office a welcoming space for everyone we encourage talented people from all backgrounds to join us help us restore humanity to healthcare

about iora

iora health is transforming health care starting with primary care we created a highimpact relationship based care model that particularly benefits adults on medicare and those who might need more attention our care model changes everything  the team outcomefocused payment customer service and the technology that supports our care

we know that when you invest in relationships with people you can help them live happier and healthier our patients get a team that respects and listens to them we get paid to keep our patients healthier and it works  we are successfully improving the lives of our patients while lowering costs",,MA,False,data_engineer
BI Data Engineer,"contractabout us
we are a growing company with a solid customer base excellent compensation and benefits and a collaborative yet flexible work environment if you enjoy challenging projects using new technologies to deliver innovative business solutions and youre interested in working for an entrepreneurial company we may have a home for you

bi data engineer


ptp is seeking an experienced bi data engineer to join our team of qualified diverse consultants this position is located in sacramento california

the bi data engineer position requires strong business and technical skills responsibilities include data modeling batch processing data matching data search and duplicate record checking it also includes integrating data quality tools in a microsoft environment excellent communication skills and working as part of an integrated team are critical

tasks and responsibilities

assist with the design development implementation and support of the customer’s business intelligence and business analytic biba platform’s data architecture including assessment of the clients current model and offer suggestions to improve performance data handling and development process efficiencies
lead developer to integrate new data quality components within the clients biba platform
develop and support of detailed dimensional data models
develop detailed multidimensional ie olap databases in conjunction with team members
provide etl design development implementation and support of the customer’s business intelligence  business analytic data for the warehouse
assist and guide customer technical staff in extracting data from the source system into the data warehouse staging area ensuring data validation data accuracy data type conversion and business rule application
prepare documentation as part of the knowledge transfer process which will enable the customer’s technical team to continue with the ongoing maintenance and operations of the biba system
design develop refactor and support web service calls to stored procedures to consume data
mandatory qualifications
a bs degree in information systems computer science or software engineering related field
experience with microsoft sql server 081214 ssis ssas ssrs pps including experience with customer systems that have over 15 million record updates daily
experience developing and calling web service apis
experience with microsoft visual studio 2010 and team foundation server 2010
experience with data requirements gathering and analysis
experience with integrating data quality tools from companies such as experian trillium informatica etc
experience with data requirements gathering and analysis
familiarity with multidimensional olap databases
experience translating dimensional data models into physical data structures
familiarity with data management and database administration concepts principles and processes
experience working as a bi data engineer on at least one project involving the design development implementation and deployment of a bi software solution using the microsoft bi toolset for this requirement the amount of experience gained on each project must have been at least six fulltime equivalent months
experience working as a bi etl developer on at least one it project involving the design development implementation and deployment of a bi software solution relatively large in size and complexity over 15 million records
desired qualifications
experience with government technology projects
excellent verbal and written communication skills and the ability to interact professionally with a diverse group including executives managers and subject matter experts technical and nontechnical

salary is doe and is extremely competitive we are able to offer relocation assistance to the right candidate",,CA,False,data_engineer
Data & Analytics- Data Engineer,"data engineer consultant
as a data engineer for slalom consulting youll work in small teams to deliver innovative solutions on amazon web services azure and google cloud using core data warehousing tools hadoop spark event stream platforms and other big data related technologies in addition to building the next generation of data platforms youll be working with some of the most forwardthinking organizations in data and analytics
who are you
you’re a smart collaborative person who is passionate about technology and driven to get things done
you’re not afraid to be bring your authentic self to work
you embrace a continuous learner mentality
what technologies will you be using
everything it’s about using the right technologies to solve problems and playing with new technologies to figure out how to apply them intelligently we work with technologies across the board
why do we work here
each of us came to slalom because we wanted something different we wanted to make a difference we wanted autonomy to own and drive our future while working with some of the best companies in san francisco leveraging the coolest technologies at slalom we found our people
what does our recruitment process look like
our process is highly personalized some candidates complete their process in one week others can take several weeks or even months deciding to take a new job is a big decision so regardless how long or short the process may be for you the most important thing is that you find your dream job
qualifications
bachelor’s degree in computer engineering computer science or related discipline
57 years relevant experience
understand different types of storage filesystem relation mpp nosql and working with various kinds of data structured unstructured metrics logs etc
4 years of experience working with sql
experience with setting up and operating data pipelines using python or sql
2 years of experience working on aws gcp or azure
experience working with relational databases
strong analytical problemsolving ability
great presentation skills
great written and verbal communication skills
selfstarter with the ability to work independently or as part of a project team
capability to conduct performance analysis troubleshooting and remediation
experience working with data warehouses such as redshift bigquery and snowflake
exposure to open source and cloud specific data pipeline tools such as airflow glue and dataflow",,CA,False,data_engineer
Data Engineer,"data engineer

lake trust’s business intelligence team is a cornerstone to achieve future business objectives this team will be primarily responsible for supporting the business intelligence  analytics objectives of lake trust credit union we are seeking a data engineer to perform a key role on this team solving problems through the use of extracting information from data

what you’ll do

the data engineer will work on implementing complex data projects with a focus on collecting parsing managing analyzing large sets of data to turn information into insights using multiple platforms the data engineer will make the appropriate data accessible and available for use by lake trust he or she should be able to decide on the needed hardware and software design needs and act according to the decisions the data engineer should be able to develop prototypes and proof of concepts for the selected solutions some of the tools used will be microsoft sql server alteryx designer and server r microsoft powerbi and azure the data engineer role requires creativity with a high attention to detail and drive for data accuracy if you enjoy working within an agile team this may be a great role for you

essential functions
ability to solve problems with data
discovery of data across many different systems data sources and data types
have strong sql querying skills
ability to profile data to measure quality integrity accuracy and completeness
poses data preparation and blending for reporting and visualization purposes
have experience with the cataloging of data sources
handson experience on all aspects of data warehousing and schema
to be proficient in designing efficient and robust etl workflows
helping to streamline a better data supply chain for analytics that goes from experimentation into production
working with cloud computing environments
tune solutions to improve performance and enduser experience
document requirements and resolve conflicts and clear ambiguities
work in teams and collaborate with others
contribute to group knowledge sharing platforms and best practice
perform other duties and responsibilities as required or assigned

knowledge skills and abilities
high attention to data accuracy
ability to work in an agile team
critical thinking to ask questions determine best course and offer solutions
complete work independently
act as a change agent
continuous improvement mindset
ability to understand the big picture
effective analytical and decisionmaking skills
strong interpersonal skills to build relationships and communicate effectively with managers staff and vendors
strong written and verbal communication skills
teamwork skills within the department and on project teams
demonstrated ability to work effectively in a fastpaced complex and dynamic business environment
effectively provide open and honest feedback via performance reviews and 11 conversation
enjoy being challenged and to solve complex problems on a daily basis
proven ability to support a strong membercustomer service culture
demonstrated and dynamic analyticalproblem solving skills
proven effective communication and collaboration

what you’ll bring

babs data analyticscomputer scienceinformation or similar degree is required
four years job related experience is preferred
data warehouse architecture experience is required
handson experience writing sql code is required
building reporting semantic layers and bi dashboards is preferred
handson etl experience is required
sql server integration services is preferred
microsoft sql andor oracle querying is required
experience with microsoft power bi alteryx designer and microsoft azure preferred

what you’ll get

we know that pay and benefits are important and we’ve really got that covered but we also know that those are not the only things that you need to decide if this is the place for you join our team of lake trusters and you’ll enjoy
working with an energetic team focused on making our members wildly successful
an opportunity to work with others that have your back every step of the way
opportunities to make a difference both inside and outside of our walls
being treated like you are more than the work you do",,MI,False,data_engineer
Data Engineer 3,"data engineer iii

in the hospitality industry people matter

thats why here at choice were always looking for exceptional people  people who will challenge us make our team stronger smarter and more complete people who know how to roll up their sleeves and tackle the job at hand who go the extra mile to get the job done  and done well

at choice we are looking for employees to connect the world through the power of hospitality  and we offer support training and a collaborative workplace atmosphere that makes us a great place to bring together people brands and technology that enable success

who are we looking for maybe its you

the role…
the data engineer iii is a technical leader in the department responsible for development of solutions using all commonly used tools by the team and leading others to complete projects through technical guidance this person will play a critical role to support the analytic data development efforts of the ongoing dap data analytics platform project

this role requires expert skills in building datasets in bigdata environments such as cloudera this role requires strong skills in etl programming and application development using java scala python and other data science languages and programs such as r experience using etl tools such as syncsort dmxh is a plus

the data engineer iii also drives and leads the team in the following areas
design reviews
production release reviews
code repository management
documentation

in this individual contributor role the data engineer iii handles the most complex projectsassignments and helps drive the strategy for business intelligence data development and data visualization under limited direction from management and in alignment with choice business strategy and the department’s objectives

this role ensures all yearly key program initiatives are supported

what you will do…
completes dap analytics data development  etl projects big data
completes application development projects
researches and completes development of leadingedgefuture technology solutions
manages and supports the departments infrastructure apps tools code bases performance
attends leads and ensures the occurrence of design reviews production release reviews and code reviews
maintains knowledge of future technologies and industry practices related to existing technologies used in the department
drives risk mitigation activities including creation of backup strategyprocess disaster recovery process code repositories and documentation on wiki sites

skills you have…

education
bachelor’s degree in computer science information technology or related field from a fouryear college or university or one to two years related experience andor training or equivalent combination of education and experience relevant industrytechnologyapplication certification is preferred

experience
5 years relevant experience in business intelligence data development and data visualizations or equivalent technical environment

knowledge
exceptional knowledge of business intelligence data development and data visualization tools and solutions
exceptional knowledge of database management system technologies and tools
strong knowledge of application development techniques using java

skills
expert proficiency in
data visualization tools such as tableau desktoptableau server
etl and data development tools such as syncsort dmexpress
advanced proficiency in
application development using java
programming languages such as sql or 4gl
expert proficiency with reporting tools analytic tools query tools and interfaces
advanced proficiency in data warehousing concepts and database technologies
exceptional analytical skills
exceptional verbal written and listening communication skills
data integration experience including ability to design document develop and test data integration processes from data analyst specifications
prior experience on analysis and resolution of data quality and integration issues
demonstrable experience implementing big data solutions using current technologies
experience in data formatting cleaning up the data understanding of schemas and metadata
practical skills with efficient file movement inside of big data platform
experience with large scale  1tb raw data processing and etl
ability to design architect and code
demonstrable experience on hadoop ecosystem including hdfs spark sqoop flume hive impala map reduce sentry navigator hadoop data ingestion using etl tools eg nifi kafka talend pentaho informatica dmxh and hadoop transformation including mapreduce scala
demonstrated experience and knowledge of relational sql databases such as vertica clouderaimpala informix sql server oracle and ability to write sql commands with expert level sql skills for data manipulation dml and validation informix vertica sql server oracle
working knowledge or experience with tableau to create reports and dashboards is desired
working knowledge or experience with business objects xi business objects web intelligence is a plus
ability to code in either python or r for data analytics is a plus
exceptional knowledge sharing skills such as creating userfriendly documentation and instructions and professionally responding to requests in audits
exceptional interpersonal skills and demeanor
excellent leadership skills such as planning and prioritizing the use of limited resources promoting a sense of team developing good relationships with peers and customers and dealing appropriately with ambiguity
proficient in the use of ms office applications such as outlook word powerpoint and excel

abilities
ability to lead and motivate others and to drive results
ability to provide after hours support as needed
ability to work effectively in a teamoriented environment both independently and collaboratively
ability to uphold choice’s values  performance principles of collaboration performance excellence sense of urgency openness to new ideas inclusion  diversity integrity customer focus and respect




must be able to uphold choices values  performance principles of accountability collaboration performance excellence sense of urgency innovation inclusion  diversity integrity  trust customer focus and respect",,AZ,False,data_engineer
Big Data Engineer,"at springml we are all about empowering the ‘doers’ in companies to make smarter decisions with their data our predictive analytics products and solutions apply machine learning to today’s most pressing business problems so customers get insights they can trust to drive business growth we are a tight knit friendly team of passionate and driven people who are dedicated to learning get excited to solve tough problems and like seeing results fast
your primary role will be to design and build data pipelines you will be focused on designing and implementing solutions on hadoop spark pig hive in this role you will be exposed to google cloud platform including dataflow bigquery and kubernetes so the ideal candidate will have a strong big data technology foundation and bring a passion to learn new technologies if you believe you have these skills please email your resume to infospringmlcom


required skills
47 years python and java programming
35 years knowledge of javaj2ee
35 years hadoop big data ecosystem experience
35 years of unix experience
bachelors in computer science or equivalent
duties and responsibilities
design and develop applications utilizing the spark and hadoop frameworks or gcp components
read extract transform stage and load data to multiple targets including hadoop hive bigquery
migrate existing data processing from standalone or legacy technology scripts to hadoop framework processing
should have experience working with gigabytesterabytes of data and must understand the challenges of transforming and enriching such large datasets
additional skills that are a plus
c perl javascript or other programming skills and experience a plus
production supporttroubleshooting experience
data cleaningwrangling
data visualization and reporting
devops kubernetes docker containers",,CA,False,data_engineer
"ETL Developer (SQL, Big Data)",85000  125000 a yearare you a data engineer that loves working with very large data sets are you skilled in using hadoop pig hive java or python to integrate large data sets into meaningful assets that can be used by the business for analytics if you answered yes to any of the question above please read onthe business intelligence team needs data engineers to help us architect and build robust data solutions that can be used by the data science  applied analytics teams as well as the analysts throughout the business the role requires you to collaborate with both technical and nontechnical folks so unfortunately you won’t be able to speak techie all the time however you will be involved in a variety of projects allowing you to grow your knowledge and skills beyond what you thought was possiblewe spend a lot of time and effort architecting building and automating our solutions so hopefully it’s no surprise that we take data quality very seriously we’ll ask you to use your jedi engineering skills on data quality efforts from time to time it’s fun and a great way to learn our datawhat you will be doingtransforming large complex data into business assets that serve both the enterprise business intelligence team and analysts throughout the organizationproviding appropriate data for a given analysis this would require you to work with data modelersanalysts to understand the business problems they are trying to solve and create or augment data assets to feed their analysisexplore and recommend innovative solutions to complex problems how cool is thatensure our data assets meet our data quality standards it’s importanthave fun in a fast paced energetic environmentwhat you need5 years of relevant employment experienceteradata experience we’re looking for power users not administratorsstrong sql we mean really strong we want you to be excited about sql scripts that are hundreds of linesexperience transforming large datasets into consumable assets for selfservice analytics and reportingexperience designing implementing and supporting data martsmust be familiar with linux systems including basic shell scriptingdesign develop and maintain data aggregation summarization jobs ie automationyou need to be flexible to changing priorities and comfortable in a fast passed dynamic environmentknowledge of amdocs andor csg billing systems a plusgood generalist experience is a plus ideally working with all layers in the technology stack if you’re “good” in various technologies we should talkjob type fulltimesalary 8500000 to 12500000 year,105000.0,PA,False,data_engineer
Data Engineer (Data Science Group),"about us

our ambitious goal of helping innovators build a better world with data started in 2009 today we are one of the fastest growing enterprise companies in history exceeding 1b in revenue at the end of 2017

the world is experiencing a technological revolution driven by ai machine learning virtual reality quantum computing and selfdriving cars  all of which require large amounts of data and put pures technology literally in the drivers seat our solutions deliver realtime secure data to power critical production devops and modern analytics in multicloud environments with a satmetrix nps score in the top 1 of b2b companies worldwide our customerfirst culture and commitment to innovation build a fastgrowing company that employees customers partners and investors love for more information on our business check out the corporate fact sheet  httpswwwpurestoragecomcontentdampurestoragepdfpurestoragefactsheetpdf 

our team
puritans come from various backgrounds and we thrive off of challenging the norm this cross pollination of backgrounds led to numerous ground breaking ideas and has helped us build one of the most reliable and easy to use storage systems in the industry ​we strive to hire the best and brightest people who excel in a cutting edge fast paced collaborative and transparent environment we are seeking enthusiastic individuals to solve real world problems while having fun along the way

summary
davenport  patil have written in the harvard business review article entitled data scientist the sexiest job of the 21st century that the role requires a highranking professional with the training and curiosity to make discoveries in the world of big data
pure storage is looking for an experienced data engineer with a strong programming background coupled with excellent analytical and communication skills to join us in building up a data science practice our charter is to partner with it to create a marketing data lake on pure storage technology that enables the ingestion and blending of many disparate sources both structured and unstructured for predictive analytics and operational reporting this will be the platform for nextgen business decision support focusing on the use of statistical techniques for sales and pipeline forecasting new customer acquisition propensitytobuy prediction for program targeting rules for crossupsell segmentationclassification realtime analytics and media mix optimization

what you will be doing
the data engineer will join a growing data science community in pure storage and report directly to the senior director data science as part of the marketing group the data scientist will blend both structured and unstructured data and team with statisticiansmathematicians to use the latest datamining and data visualization techniques to craft actionable models and insight in order to provide a sustainable competitive advantage for pure storage
the candidate must have a formal education in an area related to computer science and be exceptionally interested in lifelong learning to keep pace with the latest techniques and technology related to big data analytics while having the skill to manipulate large disparate datasets from a wide range of sources
the ability to identify synthesize and communicate technical and analytical findings and business recommendations to a nontechnical audience is critical

what you bring to the team


graduate degree in computer science or a related technical field required
25 years experience data experience
excellent knowledge of database systems and architectures big data programming languages and machine learning experience in working in sales and marketing analytics a plus graduate degree in computer science or a related technical field required
excellent knowledge of database systems and architectures big data programming languages and machine learning experience in working in sales and marketing analytics a plus
programming experience in sql andor python for data manipulation necessary
familiarity with data visualization programming languages such as javascript in addition to software such as tableau r shiny chartio or spotfire beneficial
familiarity with big data technology such as spark kafka hadoop and hive
ability to program in r base sas andor python to implement machinelearning techniques a plus
excellent interpersonal skills collaboration creativity and communication all key to success
if a career in data science with a company that is at the center of the big data renaissance sounds like a good fit for you please reach out to us to get in on the cutting edge of big data analytics

pure creates opportunities for your development and career growth

at pure we believe that each puritan is a leader contributing to the success of our business regardless of role we offer an assortment of learning options available to all puritans including workshops on leadership management career development and more were here to change the world and we hope you join us

popular perks

pure offers an unlimited vacation policy free lunches meditation rooms free yoga classes and employee resource groups to inspire all of our employees to maintain mind and body wellness through our pure good foundation we also offer numerous volunteer opportunities for employees to give back not only to the bay area but across the globe

pure is committed to equality

pure is proud to be an equal opportunity and affirmative action employer we do not discriminate based upon race religion color national origin sex including pregnancy childbirth or related medical conditions sexual orientation gender gender identity gender expression transgender status sexual stereotypes age status as a protected veteran status as an individual with a disability or any other characteristic legally protected by the laws of the jurisdiction in which you are being considered for hire if you need assistance or an accommodation due to a disability you may contact us at taopspurestoragecom  taopspurestoragecom ",,CA,False,data_engineer
Big Data Engineer (S&P Global Ratings),"sp global ratings is looking for an experienced big data engineer to join data engineering team within chief data office a team of data and technology professionals who define and execute the strategic data roadmap for sp global ratings the successful candidate will participate in the design and build of sp ratings cloud based analytics platform to help develop and deploy advanced analyticsmachine learning solutions

the team
you will be an expert contributor and part of the rating organization’s data services team this team who has a broad and expert knowledge on ratings organization’s critical data domains technology stacks and architectural patterns fosters knowledge sharing and collaboration that results in a unified strategy all data services team members provide leadership innovation timely delivery and the ability to articulate business value be a part of a unique opportunity to build and evolve sp ratings next gen analytics platform

our hiring manager says

if you are an individual that brings demonstrated experience of delivering big data projects as a data engineer this is an excellent opportunity i am looking for someone with sound technical knowledge can be handson worked on transformational initiatives and can drive results

responsibilities
design and develop efficient and scalable data pipelines between enterprise systems and analytics platform
work closely with data science team and participate in development of feature engineering pipelines
provide technical expertise in the areas of design and implementation of ratings integrated data facility with modern aws cloud technologies such as s3 redshift emr hive presto and spark
build and maintain a data environment for speed accuracy consistency and ‘up’ time
support analytics by building a worldclass data lake environment that empowers analysts to determine insights into revenue and power products across the organization
work with the machine learning engineering team to build a data eco system that supports ai products at scale
ensure data governance principles adopted data quality checks and data lineage implemented in each hop of the data
partner with the chief data office enterprise architecture organization to ensure best use of standards for the key data domains and use cases
be in tune with emerging trends big data and cloud technologies and participate in evaluation of new technologies
ensure compliance through the adoption of enterprise standards and promotion of best practice  guiding principles aligned with organization standards
experience  qualifications
bs or ms degree in computer science or information technology
5 years of experience as data engineer at an innovative organization
3 years of handson experience in implementing data lake systems using aws cloud technologies such as s3 redshift emr hive presto and spark
expert managing aws services ec2 s3 route 53 elb vpc cloudwatch lambda in a multi account production environment
experience with machine learning libraries and frameworks tensorflow  mllib is an added advantage
exposure to r  sparklyr  and other r packages is a plus
experience with development frameworks as well as data and integration technologies such as informatica python scala
expert knowledge of agile approaches to software development and able to put key agile principles into practice to deliver solutions incrementally
monitors industry trends and directions develops and presents substantive technical recommendations to senior management
excellent analytical thinking interpersonal oral and written communication skills with strong ability to influence both it and business partners
ability to prioritize and manage work to critical project timelines in a fastpaced environment
financial services industry experience",,NY,False,data_engineer
Sr. Data Engineer,"the individual will be principally responsible for overseeing a team of dispute resolution investigators and administrative support staff to ensure their work is completed with high quality and within the time lines established in our policies and procedures

this team is responsible for handling the review of an insuredservicer appeal to a prior decision to rescind coverage the team is accountable for an independent investigation of each appeal based upon the loan underwriting and policy requirements and providing a timely and reasoned response to the insuredservicer including any new documentation provided by the insuredservicer

in conjunction with the avpdru the individual provides training and acts as a mentor to newly hired employees and is available to assist in guiding all of the employees in the direction of handling the customer appealsrebuttals among their existing responsibilities will include counseling existing staff on performance and quality standards organizing and leading escalation calls with our key customers lead special projects with our client advocate group at radian on key accounts specific to a customers’ rescissions of claims this individual will also partner with it department and risk analytics to identify enhancements to dru functionality in investigations db and to develop accurate reporting to support dru’s surveillance management ability


the individual will be principally responsible for overseeing a team of dispute resolution investigators and administrative support staff to ensure their work is completed with high quality and within the time lines established in our policies and procedures

this team is responsible for handling the review of an insuredservicer appeal to a prior decision to rescind coverage the team is accountable for an independent investigation of each appeal based upon the loan underwriting and policy requirements and providing a timely and reasoned response to the insuredservicer including any new documentation provided by the insuredservicer

in conjunction with the avpdru the individual provides training and acts as a mentor to newly hired employees and is available to assist in guiding all of the employees in the direction of handling the customer appealsrebuttals among their existing responsibilities will include counseling existing staff on performance and quality standards organizing and leading escalation calls with our key customers lead special projects with our client advocate group at radian on key accounts specific to a customers’ rescissions of claims this individual will also partner with it department and risk analytics to identify enhancements to dru functionality in investigations db and to develop accurate reporting to support dru’s surveillance management ability


eeo statement
radian complies with all applicable federal state and local laws prohibiting discrimination in employment all qualified applicants will receive consideration for employment without regard to gender age race color religious creed marital status sexual orientation national origin ethnicity ancestry citizenship genetic information disability protected veteran status or any other characteristic protected by applicable federal state or local law

if you are a person with a disability and need assistance in the application process please send an email message to recruitmentradianbiz",,PA,False,data_engineer
Senior Data Engineer,"knowledge is our product and data is our platform we need engineers who look at a data set and want to unlock the answers it holds inside engineers who look at a data set and think about how to make sure it is correct engineers who look at a data set and want to make infrastructure to help build it better faster and stronger

as a data engineer you will work closely with oncologists and statisticians to build software that will help our customers discover novel insights into their data you will design our data infrastructure and use it to develop extensible robust data and analytics pipelines tools visualizations and services for accessible and flexible data analysis you will learn more than you ever thought possible about how cancer is treated in the real world and your work will directly support oncology research and publications

about you

you hold a bs ms or phd in computer science or related field
you have 2 years work experience
you have experience with languages like python c java or c
you are passionate about performance reliability and scalability of systems
you are inspired by our mission to improve cancer research through technology
you seek simple approaches to complex problems
you like science and or medicine just because its cool

bonus points if you have any of the following

have a good understanding of relational databases like postgresql mysql or mssql
have real passion for data and a strong understanding of statistics
have developed distributed data processing systems against large heterogeneous data sets
have taken a leading role in delivering complex software systems all the way to production
you almost decided to go to med school

",,NY,False,data_engineer
Data Engineer,"overview
tista science and technology corporation a cmmi maturity level 3 company focuses on delivering information technology and professional services to federal and state agencies tista is an inc 500 company a recipient of the 2010 top 100 servicedisabled veteranowned businesses from diversity business recognized in washington technologys fast 50 list of the fastest growing small businesses in government contracting in 2012  2013 recognized as the top 25 fastest growing small technology companies by the washington business journal in 2014  2015 and selected as the veteran owned company of the year in 2014 by the montgomery county md dept of economic development

tista science and technology corporation is seeking data engineers to join our growing team using groundbreaking cloud and big data technologies these data engineers will collaborate with data scientists from prominent ivy league institutions to identify user needs find solutions and take our products from concept to launch we have mid senior and lead roles available
responsibilities
build data pipelines using apache spark scala python apache airflow etc
collaborate with user experience and engineering teams in the planning of new products
write unit tests and get close to 100 code coverage
work on aws – s3 for storage ec2 and emr for processinganalysis
follow agile methodology for the software development
identify problems and propose resolutions
qualifications
 6 year of engineering experience focus on backend development andor data engineering
 indepth programming knowledge with java python and scala
 experience with spark hadoop or hive
 strong experience with aws including ec2 ebs redshift emr elb sns rds cloudformation and more
 experience with tools like maven jenkins git
 able to perform as an effective member of a geographically dispersed team across multiple timezones

education
bachelor’s degree in computer science or closely related field
clearance
must be eligible to obtain a public trust
location
rockville md

here at tista science and technology we value our veterans and encourage all to apply

tista is an equal opportunity  affirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex national origin disability or protected veteran status",,MD,False,data_engineer
"Data Engineer, Visualization","by clicking the “apply” button i understand that my employment application process with takeda will commence and that i agree with takeda’s privacy notice privacy policy and terms of use

job description
are you looking for a patientfocused company that will inspire you and support your career if so be empowered to take charge of your future at takeda join us a data engineer visualization in our cambridge ma office
here everyone matter and you will be a vital contributor to our inspiring bold mission as a data engineer visualization working in the data engineering and emerging technologies team a typical day will include

objectives
 as a data engineer you will be tasked with creating an ecosystem to have the right data to ask the right question at the right time
 apply advanced techniques to complex problems in rd and other organizations
 for this specific role there will be a focus on visualization of data
 work directly with the data science in rd at takeda along with other advanced analytics organizations across the company
 apply advance techniques in structured partly structured and unstructured data across different partner organizations
 implement solutions for both big data and difficult to structure data sets
 maintain uptodata knowledge on modern data technologies explores new platforms and beta tooling
 independently use own judgement to identify data requirements and influences the design
 influence new computer science platforms to design analyze and implement complex and new data driven solutions that impact the company
 provide leadership to complex data analysis uses and explores data languages tools and software to best construct data for predictive modeling tests the model trains data to deploy the modeling within a complex rd medical mathematical environment and a large complexity of it systems and data
competences educational and skills
required
bachelor’s degree in computer science or data science
2 years’ experience or relevant project  coursework
uptodate specialized knowledge of data wrangling manipulation and management of technologies
ability to manipulate voluminous data with different degree of structuring across disparate sources to build and communicate actionable insights for internal or external parties
possesses strong communication skills to portray information
experience with rapid ui prototyping
experience with tableau or qlik
experience with r or python ui tools r shiny ggplot seaborn matplotlib …
ability to work in an agile environment with high quality deliverables
experience with two of the following languages java scala r or python
experience with ui frameworks like r understanding of web services as well as json formats
working knowledge of sql and relational databases
experience with one of the following nosql datastores cassandra mongodb neo4j …
experience with concepts of hadoop and spark
preferred
experience with tableau r shiny pandas and ggplot
additional languages chef r javascript
experience with multiple nosql datastores cassandra mongodb neo4j …
experience with data formats including parquet orc or avro
understanding of aws s3 ec2 redshift emr athena
experience with a rapid ui tools ex tableau
lijv1",,MA,False,data_engineer
"Data Engineer II, Scientific Computing",strength through diversityground breaking science advancing medicine healing made personalrole and responsibilities the data engineer ii will focus on data collection movement storage transformation processing and storage of big data the incumbent will work with both current etldata warehousing and future big datastreamingpipeline architectures the focus will be on choosing optimal solutions to use for these purposes then implementing maintaining and monitoring them always keeping in mind the overarching goal of accelerating translational research and improving clinical carefacilitate data collection from a variety of various sources getting it in the right formats assuring that it adheres to data quality standards and assuring that downstream users can get that data quickly and with a common standard interfaceensure that data streamspipelines are scalable repeatable and secure and can serve multiple users within the institutedevelop as a core member of an agile team using agile tools and methodology work closely with other team members including application developers database developers and data scientistsresponsible for creating the infrastructure that provides insight from raw data and handles diverse sources of data seamlesslyenable big data and batchrealtime analytical solutions that leverage emerging technologiesadditional responsibilities include developing prototypes and proof of concepts for the selected solutions and implementing complex big data projects with a focus on collecting parsing and managing large sets of data using multiple platforms to allow for research and data science initiativestranslate business requirements into modern data pipeline solutions create centralized documents and diagrams of all solutionscreates a data catalog store of all metadatadesigns and implements monitoring backup and disaster recovery of data systemsapproaches all relationships with a worldclass customer service approach maintains a customerfocused approach with users to provide solutions that are scienceresearchdrivenresponsible for the integrity and security of data in all forms of storage throughout the data architecturework with other it professionals through mount sinai effectively comply with the institutional review board and hipaa to follow all applicable policies and proceduresassists in the development of standards and procedures affecting data management design and maintenance documents all standards and proceduresprovides presentations and training to other team members in the aboveextremely flexible attitude willing to work with multiple types of technologies and languages with an open mind and without technology bias continuous interest in updating skill sets and knowledge of trends in the big data technology spacerequirementsbachelor’s degree in computer science or a related discipline advanced degree preferred with the following experience4 years relevant professional development experience preferably in a linux environmentproficiency with python development flexible to learn another language as needed  scala java andor c knowledge is a strong plusexperience with sql and nosql databases such as oracle ms sql server postgresqlmysql and mongo db or similar such as cosmosdb or dynamodbexperience in restful service development preferably with node js django and phpfamiliarity with the big data technology space and the ability to leverage a wide variety of open source technologies and tools knowledge of hadoop spark kafka and other big data technology stacks and streaming tools or related cloud service technologies on azure or awsexperience with configuration management software – ansible preferred puppet or chef or an equivalent awsazure infrastructure as code experience also experience with version control gitexperience with installation and configuration of big data software and technology or equivalent cloud service technologies on azure or awsexperience working in an agile methodologyexperience as a plus working knowledge of cloud architecture and implementation on azure or aws is a big plusexperience with serverless computing eg aws lambda or azure functions creating vms cloud security and other cloud services is also a big plusexperience with microservices and soa is a plusknowledge of healthcare data hl7 and mirth are also a big plusstrong skills in data structures datafile formats algorithms and objectoriented designexperience working with jira is a plusstrength through diversitythe mount sinai health system believes that diversity is a driver for excellence we share a common devotion to delivering exceptional patient care yet we’re as diverse as the city we call home culturally ethically in outlook and lifestyle when you join us you become a part of mount sinai’s unrivaled record of achievement education and advancement as we revolutionize medicine togetherwe work hard to acquire and retain the best people and to create a welcoming nurturing work environment where you can develop professionally we share the belief that all employees regardless of job title or expertise can make an impact on quality patient careexplore more about this opportunity and how you can help us write a new chapter in our storywho we are over 35000 employees strong the mission of the mount sinai health system is to provide compassionate patient care with seamless coordination and to advance medicine through unrivaled education research and outreach in the many diverse communities we serveformed in september 2013 the mount sinai health system combines the excellence of the icahn school of medicine at mount sinai with seven premier hospital campuses including mount sinai beth israel mount sinai beth israel brooklyn the mount sinai hospital mount sinai queens mount sinai roosevelt mount sinai st luke’s and new york eye and ear infirmary of mount sinaithe mount sinai health system is committed to the tenets of diversity and workforce that are strengthened by the inclusion of and respect for our differences we offer our employees a highly competitive compensation and benefits package a 403b savings plan and much morethe mount sinai health system is an equal opportunity employer we promote recognition and respect for individual and cultural differences and we work to make our employees feel valued and appreciated whatever their race gender background or sexual orientationeoe minoritieswomendisabledveteransjob type fulltimeexperiencelinux 4 years requiredpython 4 years requiredsql 4 years requirededucationmasters requiredlocationnew york ny requiredwork authorizationunited states required,,NY,False,data_engineer
Lead Data Engineer,"bluestem brands inc has a fulltime opportunity for a lead data engineer in eden prairie minnesota

the lead data engineer uses smart technology to provide timely accurate and actionable information to empower stakeholders enterprisewide to make the best decisions

this position requires a bachelors degree or equivalent in information technology computer science computer information systems electronic engineering or a related field and 7 years related progressive postbaccalaureate experience

must also have each of the following
1 3 years of demonstrated experience leading a team of technical resources on complex projects

2 5 years of demonstrated experience in working with data warehousing which includes designing and building enterprise data warehouse solutions for different business subject areas and

3 6 years of demonstrated experience with technical data analysis data quality responsibility for complex analysis deliveries and sql experience with the ability to write complex sql statements

employer will accept experience gained concurrently

please apply online at wwwbluestemcom

eoe

required skills

required experience",,MN,False,data_engineer
Data Engineer Senior,"under minimal supervision the data engineer senior accepts and validates all student level data for assigned projects in order to ensure data integrity combines several sources of data to be used for reporting test results the data engineer senior also provides input and support into internal products and systems that affect data in the company follows established protocols and standards when performing tasks this senior position also uses prior experience and expert judgment to make decisions on how contracts should be executed participates in and recommends process improvement projects may mentor junior staff members on the execution of projects works in consultation with other team members to find solutions to nonstandard complex situations additional responsibilities include the following
validate and accept student level data including student demographic and test data from various sources and provided in various formats
perform cleanup activities to data per specifications created
perform documentation of data processing specifications to ensure common understanding of processes and procedures used on a project
participate in project meetings in order to ensure data integrity issues are discussed and resolved
develop code and process to support validation cleanup transformation and delivery of student data
provide data support to internal products and systems
provide input into the development of internal products and systems
develop appropriate quality assurance steps to be implemented on projects to ensure data accuracy
provide support to team members on projects as needed
mentor junior team members
attend cross functional team meetings to contribute to solution definition for new projects or other complex situations


qualifications
bachelor’s degree and five 5 to eight 8 years related experience in sql development or an equivalent combination of education and experience
comprehensive knowledge of microsoft sql server or an equivalent database software
sql programming of complex views stored procedures functions and scripts
strong understanding of the fundamentals of developing userfacing reports and forms
experience with visual studio and c preferred
sas programming or experience in similar software such as r or spss is a plus
experience with etl tools is a plus
working knowledge of microsoft office required",,NH,False,data_engineer
Data Engineer,summaryas a member of our data team your role is critical in powering the datadriven culture at gaia you will be working in a collaborative team environment in order to understand the needs of all stakeholders in the business and build corresponding data products to meet them you will be working within an aws python spark hive and airflow stack in order to transform our data warehouse into a scalable data lake you are selfmotivated ambitious and come to work with a great attitude every day you live to make information accessible and beautiful for those who need itresponsibilitiescollaborate with data engineers data scientists software engineers data analysts and business stakeholders in order to power all of the data needs across the businessconsume ingest and transform raw largescale event streams of databuild maintain monitor and optimize etl data pipelineshelp design implement and enforce production requirements and data governance protocolscontribute to the design and construction of business critical kpis dashboards and reportsevangelize the proper use of data and datadriven decisions across the companyqualificationsbachelor’s degree in computer science math a related discipline or equivalent work experience2 years of software development experience ideally with python or scala1 years of experience working with distributed big data tools like spark and hivean extremely strong command of sql and comfort with database design and architecture principlescomfort working with data in both structured and unstructured formsexcellent analytical problemsolving and communication skillsthe ability to gather stakeholder requirements and translate them into tangible next stepsstrong familiarity with an affinity for our content is a prerequisite to applyingmembership in gaia is strongly preferredmust be able to work in our office in louisville coloradous citizenship or an existing work visa is requirednice to have experience with airflow andor other data pipeline toolsexperience with database administration preferably mysql andor postgresqlfamiliarity with eventdriven architecturecomfort within the aws data lake ecosystemexperience with bi tools like domo looker or tableaumore about gaiaat gaia we believe when enough of us wake up everyone wakes up gaia nasdaq gaia headquartered in louisville colorado is a global digital video streaming service and online community that provides curated conscious media content to its subscribers in over 120 countries as the world’s largest subscription video ondemand svod provider of transformational media dedicated to empowering you in body mind and spirit we have a unique opportunity to drive meaningful change in our world through streaming content that awakens and transforms with over 7000 titles of exclusive video content we serve 100’s of thousands of subscribers every day over 90 of our videos are available for streaming exclusively on gaia through most devices connected to the internet and 80 of the views are generated by content produced or owned by gaia our applications include gaiacom ios tvos android and roku as well as select content on comcast verizon and amazon we are a young rapidly growing public company that offers a fastpaced entrepreneurial working environment with plenty of opportunities to take risks and achieve outcomes previously thought to be unobtainable our opportunity is to become the undisputed global leader in the delivery of conscious mediathis opportunity expands our community of creative openminded conscious living enthusiasts that make up our employee base  a strong established team of professionals some of the perks of working collaboratively with a team dedicated to sharing this mission aside from sharing the values of growth personal responsibility creativity and innovation comes with access to the onsite olympic quality gym and complimentary yoga and fitness classes a beautiful solarpowered orchard campus complete with hiking and running trails and labyrinth and an onsite café which serves breakfast and lunch daily including a full service espresso bar featuring locally roasted coffeefulltime employees are offered alternative and traditional medical benefits including preventative coverage as well as dental vision 401k life insurance and morewe are having an impact – want to join usjob type fulltimeexperiencesoftware development 2 years preferreddistribute big data tools like spark and hive 1 year preferrededucationbachelors preferredwork authorizationunited states preferred,,CO,False,data_engineer
Data Engineer II,"summary of major responsibilities
the data engineer ii will provide technical expertise perform data analysis and be an expert of the data generated by business systems and used to drive decisions they will build meaningful effective and performant data visualizations and reports serve as a point of contact for production support and issue resolution and analyze troubleshoot and tune performance
essential duties and responsibilities
provide expertise in data analysis management and visualizations
expand and improve existing tableau dashboards and reports create new ones
debug data issues in dashboards reports data warehouses operational data stores and other disparate data sources
share knowledge of advanced tableau features like data blending parameters and calculated fields
improve monitoring automated testing and deployments
be a resource for providing insight recommendations and assistance with technical and nontechnical questions
monitor and recommend enhancements to the technical architecture to keep pace with changing business demands and scale
stay informed of technology industry trends and solutions with ability to analyze for possible application in our environment
promote the role and capabilities of it to enhance the professional development of all staff through example recommendation and accommodation
qualifications
minimum requirements
bachelor’s degree in computer science information systems or related field or equivalent professional experience
5 years of experience designing and developing reports and dashboards using a reporting tool preferably tableau
5 years of experience developing bi reports preferably in a data warehouse environment
experience working with sql for data exploration debugging and performant data access
ability to query disparate data sources including relational structures oltp systems and dimensional data models
experience creating data visualizations designing and developing dashboards
experience developing bi reports preferably in a data warehouse environment
ability to translate business requirements to technical specifications
proven ability to work in a fastpaced crossfunctional team environment
adaptable open to change and able to work in ambiguous situations and respond to new information or unexpected circumstances
excellent interpersonal and communication skills ability to operate in a cross cultural and complex matrix environment and ability to build consensus across functions
desired experience
developing dashboards and reports on data from sales call center and custom software applications
tableau ideally including performance optimization
microsoft edwbiolap technologies sql server ssrs ssis
etl
physical requirements
ability to work in an office setting operate telephony devices and a computer
lijk1

exact sciences is an equal employment opportunity employer all qualified applicants will receive consideration for employment without regard to age color creed disability gender identity national origin protected veteran status race religion sex sexual orientation and any other status protected by applicable local state or federal law applicable portions of the company’s affirmative action program is available to any applicant or employee for inspection upon request",,WI,False,data_engineer
Data Engineer,"cspring is seeking a data engineer to join our team in indianapolis in at cspring you truly do make a difference be heard work on challenging assignments improve your community and join a growing team that will both challenge you and value your contributions when you join cspring you become part of our ohana – or extended family and our most valuable asset you are not just another “resource” as is the case with many other consulting or staffing firms
if you possess the qualifications listed below please apply for this position and a member of our recruiting team will contact you directly your information will remain confidential and you will never be submitted for a position without your approval
you will be a member of the data team responsible for delivering highvalue bi solutions to support strategic business needs this person will be working on new development creating a new data  insight platform for our client to enable insight based decisions this is a highly innovative and dynamic environment
responsibilities
implement a highperformance next generation data platform
work with a team to identify design and build appropriate dataset and linkages for complex data
refactor legacy data platforms to integrate with the next generation data platform
implement data quality infrastructure and processes
implement data infrastructure for emerging data classes
contribute to the team’s growing set of development platforms tools processes and promote industry standard best practices
identify analytics tool guidelines and standards for performing required data preparation analysis visualization and reporting
provide business and architectural context to show how the analytics tools fit within the overall infrastructure and highperformance data architecture
organize deliver and ensure data integration support of a corporate computing capability
qualifications
35 years of experience with large scale data technologies such as hadoop spark machine learning etc
knowledge of informatics analytics computational science service management delivery
knowledge of toolsets and capabilities utilized by expert data scientists and modelers
java c
knowledge of perlpython and unix scripting
nosql and rdbms databases
hadoopbased tools hive hbase mapreduce mongodb cassandra
data modeling and elt  etl
data analytics and visualization
solid communication skills and team player


cspring offers a comprehensive compensation training and benefits package including paid time off ppo and hsa medical insurance options dental vision std ltd life insurance and ira match for more information about cspring please visit our website at httpwwwcspringcom
unsolicited resumes from third party recruiting firms will not be accepted or considered for this position",,IN,False,data_engineer
Big Data Engineer,"who we are
we’re america’s largest mortgage lender closing loans in all 50 states jd power ranked quicken loans “highest in customer satisfaction in primary mortgage origination” for the past eight consecutive years 2010 – 2017 the company was also ranked highest in the nation for client satisfaction among mortgage servicers by jd power for four consecutive years 2014 through 2017 each year the company was eligible there’s a simple reason we’ve been so successful we care about the people we work with

if you’re tired of stuffy bureaucratic workplaces then you’ll be delighted to find something different here we strive to make a creative fun and collaborative environment you simply won’t find anywhere else quicken loans was named 1 in essence magazine’s first ever list of “best places to work for african americans” in 2015 weve been on computerworlds best places to work in it list for 13 years running hitting 1 the last five years we were also ranked 14 in fortune magazine’s list of 100 best companies to work for in 2018 remaining in the top30 for the past 15 years
what youll doneed
the big data engineer develops the etl processes designs structured data models from unstructured data sets and integrates data in hadoop with a sql server data warehousing environment

responsibilities

collaborate with other engineers architects quality assurance and product owners on solving new and existing technical issues
work with or without complete business requirements or specifications
work directly with technology partners
assist with delivery estimates
maintain ownership of assigned projects
requirements

bachelor’s degree in computer science or equivalent experience
5 years of development experience in java python or c
experience with restful api design and implementation
experience in workflow and bpmn development using activiti camunda bpm etc
experience with data migration transformation and scripting
proficient understanding of code versioning tools
passionate about engineering quality testing automation and documentation of code and systems to ensure easy maintenance over a long period
experience working on highvolume server software
strong verbal and written communication skills and a strong attention to detail
what’ll make you special

master’s degree
experience in building highperformance scalable backend services in the cloud
experience with nosql databases such as amazon dynamodb
experience with data frameworks including hadoop hive pig and spark
exposure to testdriven development behaviordriven development frameworks and libraries
experience with collibra administration management and working with apis
experience with anypoint apis
experience with mulesoft application development
what youll get
excellent benefits package that includes a 401k match medicaldentalvision insurance and much more
opportunities to participate in professional and personal development programs including personal empowerment coaching leadership training and ongoing personal growth training
other incentives contests and rewards including trips event tickets cash prizes and more
why were different

corporate politics not your strong suit the anticorporate culture of quicken loans gives our team members the initiative to build solutions together and grow both personally and professionally at quicken loans we’re in the business of putting roofs over our clients’ heads but we certainly aren’t putting ceilings on our team members’ careers if you’re interested in working in a place with a philosophy that’s truly different apply today

quicken loans is an equal opportunity employer

disclaimer quicken loans received the highest numerical score in the proprietary jd power 2010 – 2016 primary mortgage origination studies and the 2014 – 2017 primary mortgage servicer studies 2016 origination or sales based on 5182 total responses and measures the opinions of customers who originated a new mortgage or refinanced within the past 12 months surveyed in july – august 2016 2017 servicing based on 7374 total responses and measures the opinions of homeowners on their mortgage servicing company surveyed in march – april 2017 your experiences may vary visit jdpowercom

quicken loans is the 1 online lender based on the ranking of quicken loans in comparison to online residential mortgage lenders included in the inside mortgage finance top 50 mortgage lenders report from q2 2017",,MI,False,data_engineer
Predictive Analytics Data Engineer,"parttimewhat is the opportunity
this role is within a technology team focused almost exclusively on the needs of municipal sales and trading desk the role will be focused on development and delivery of predictive analytics platforms to transform processes and optimize technologies in aiding decisions
what will you do
employ the existing and develop new machine learning algorithms that can find predictive patterns in large multimodal data
provide innovative solutions for business problems eg by translating complex commercial problems to machine learning problems
be an active member of teams that provide the business with aifirst apps and datadriven insights and strategies
participate in lead and create crossfunctional projects and training performs qualitative and quantitative assessments of all aspects of models including theoretical aspects model design and implementation as well as data quality and integrity
analyzes complex data and associated quantitative analysis
uses quantitative tools and techniques to measure and analyze model risks and reaches conclusions on strengths and limitations of the model
prepares and analyzes detailed documents for validation and regulatory compliance using applicable templates

what do you need to succeed
musthave
masters degree in mathematics statistics economics computer science operational research physics and other related quantitative fields
scientific expertise and applied experience in machine learning ideally a combination of excellent academic research and highimpact commercial projects
in depth understanding of common machine learning algorithms eg for classification regression and clustering
in depth knowledge of advanced statistical theories methodologies and inference tools eg hypothesis testing generalized linear models additive models mixture models nonparametric models
proven track record in some of the advanced topics such as bayesian inference hierarchical models deep learning gaussian processes and causal inference
advanced programming skills in python and their related data processing machine learning and visualization libraries
practical experience in preparing data for machine learning eg using sql andor nosql technologies
integration of machine learning algorithms with bigdata platforms eg spark and highperformance computing ecosystems
excellent written and oral communication skills

nicetohave
programming in c andor java
deployment of algorithms as real time  highly available services
integration with frontend systems eg html5 native mobile apps
employing machine learning in collaborative commercial settings eg using devops methodologies and tools such as github ideally in collaboration with product development teams
experience of working with engineering and design  product teams

what’s in it for you
we thrive on the challenge to be our best progressive thinking to keep growing and working together to deliver trusted advice to help our clients thrive and communities prosper we care about each other reaching our potential making a difference to our communities and achieving success that is mutual
a comprehensive total rewards program including bonuses and flexible benefits competitive compensation
leaders who support your development through coaching and managing opportunities
ability to make a difference and lasting impact
work in a dynamic collaborative progressive and highperforming team

about rbc
royal bank of canada is canada’s largest bank and one of the largest banks in the world based on market capitalization we are one of north america’s leading diversified financial services companies and provide personal and commercial banking wealth management insurance investor services and capital markets products and services on a global basis we have over 80000 full and parttime employees who serve more than 16 million personal business public sector and institutional clients through offices in canada the us and 37 other countries for more information please visit rbccom

inclusion and equal opportunity employment
rbc is an equal opportunity employer committed to diversity and inclusion we are pleased to consider all qualified applicants for employment without regard to race color religion sex sexual orientation gender identity national origin age disability protected veterans status aboriginalnative american status or any other legallyprotected factors disabilityrelated accommodations during the application process are available upon request

job summary
city jersey city
address 30 hudson street
work hoursweek 40
work environment office
employment type permanent
career level experienced hireprofessional
pay type salaried
position level pl07
required travel 025
exemptnonexempt exempt
people manager no
application deadline 11242018
req id 173449",,NJ,False,data_engineer
Sr. Data Engineer,fractal analytics is a strategic partner to fortune 500 companies and helps them to leverage big data analytics and technology to drive smarter faster and more accurate decisions in every aspect of their businessour big data capability team is hiring data engineers who can produce efficient  functional codes to solve complex analytics problems if you are an exceptional developer and who loves to push the boundaries to solve complex business problems using innovative solutions then we would like to talk to yourequirements overall 36 years of workexperienceability to perform etl operations on both onprem and cloud based technologiesdeep familiarity with hadoop hive spark and programming in javascalapysparkintegration and testing of data of models in development and production environmentsmedium proficiency and experience in implementing aiml codes in distributed node environment such as nlpjob type fulltimeexperiencehive 2 years requiredaws 1 year requirednatural language processing 1 year requiredhadoop 2 years requiredjava 2 years requiredspark 2 years requiredscala 2 years required,,CA,False,data_engineer
Data Engineer,"null
data engineer

tenx commercial is the cre marketplace that is a force multiplier for sellers buyers and brokers tenx precisionmatches assets accelerates close rates and streamlines the entire transaction process with more than 55 billion in sales and increasing daily leveraging desktop and mobile technology tenx allows people to safely and easily complete real estate transactions entirely online we bring quality assets to the market and attract prospective investors from around the world by virtue of our bestinclass marketing and scalable technology platform buyers and seller are able to conduct transactions in an efficient manner
tenx empowers consumers investors and real estate professionals with unprecedented levels of flexibility control and simplicity – and the convenience of transacting properties whenever and wherever they want as real estate continues to move online tenx is uniquely positioned at the forefront of this dramatic industry evolution
httpswwwtenxcom

the role
data and our ability to leverage it is seen and championed as a key competitive advantage from our ceo on down we are looking for a top tier data engineer to work with our data science team on building out proprietary tools and models around our customer and asset data both internal and external sets you will be working on key projects that have board level visibility
responsibilities
play a leading role in designing developing and implementing big data databases hadoop graph mysql nosql mongodb that contains multiple data sets from both internal and external sources
lead the setup of data pipelines of new internal and external data sets into the database
work with data scientists to help dedupe and fuzzy match data
work with software engineers on developing apis
experience
undergraduate degree ideally a masters in a relevant quantitative subject math statistics computer science engineering economics etc
5 years’ experience in data engineering including 2 years in a modern data stack environment specifically the hadoop stack 3 years python experience relating to data engineering
experience with iterative agile methodologies and use of supporting tools like jira confluence and git
experience in the following will be a plus
spark
kafka
clickstream data
machine learning
streaming data
elastic search
containers docker
fuzzy matching  nlp
ability to understand business problems and translate them into data science requirements
understanding and familiarity with
hadoop and all the related stack pig hive hbase etc
sql skills and sql databases
strong oral and written communication skills and be able to communicate complex technical knowledge in meaning terms
ability to work in a fastpaced environment and fluidly adapt to changing priorities
must be passionate about getting to the root cause of issues and driving to whys
proven ability to obtain buyin partner with the data science team including demonstrated ability to partner with functional leaders toward common goals
welldeveloped analytical and interpersonal skills with ability to draw conclusions and communicatepresent them confidently and effectively to broad audiences including senior leadership
high energy and passion about solving business needs through data
organized structured thinker with ability to handle multiple assignments remain calm under pressure and digest information from multiple disparate parts
continuous improvement mindset
not afraid to challenge conventional thinking or analyseslies1",,CA,False,data_engineer
Data Engineer,"at hasbro we embrace the unique skills experiences talents and perspectives of our global workforce which combined with our culture of curiosity and innovation generates the best ideas we live our values of community passion integrity and creativity and we’re committed to giving our 5000 employees opportunities to build their individual capabilities balance work and home deliver excellence through team work and thrive personally this enables us to deliver results in all aspects of our business

position summary
as a data engineer you will work with partners in it and stakeholders across the organization to enable datadriven decisions your primary responsibility will be to expand the usable pool of data available for conducting analysis you will also help execute the roadmap for analytics within hasbro and scope plan and execute strategic analytics projects to help hasbro’s brands achieve profitable growth

a day in the life as a data engineer

write routines and build data pipelines to ingest clean and prepare data for analysis develop views and aggregated datasets that can be easily loaded into analytical tools
support analytics projects and conduct analysis leverage descriptive and exploratory techniques text analytics and statistical methods to help answer business questions prepare results and communicate findings to stakeholders projects may be small onetime requests or larger ongoing programs
expand hasbro’s data model by incorporating hasbro internal and external thirdparty data identify data sources and catalog metadata understand relationships between datasets maintain and update data model as new data sources are identified
advise on appropriate infrastructure and tools for data storage ingestion preparation and maintenance understand how business requirements map onto infrastructure needs and toolset
support architecture plan to accommodate existing and future datasets create business processes for onboarding new data sources

what youll bring

24 years of experience in data engineering analytics consulting or a related dataquantitative field
bs in a quantitative field eg comp sci engineering economics advanced degreemba a plus
intermediate experience with a scripting language like python preferred r scala c unix shell javascript
intermediate to advanced sql skills must be able to design and optimize queries and create data structures
experience developing in aws google cloud or azure azure preferred
exposure to data preparation tools eg alteryx informatica teradata tamr
handson experience with next generation data storage tools and methods eg nosql hadoop spark as well as associated data modeling tools
knowledge of statistical package like r sas spss matlab knime rapidminer a plus
excellent written and verbal communication skills – experience working with business stakeholders and senior leaders
strong project management capabilities able to coordinate multiple projects and prioritize a variety of incoming requests",,RI,False,data_engineer
Senior Data Engineer,"
why do we want you



you are an ambitious driven developer looking to play a central role in the design development and implementation of cutting edge highlyscalable applications based on large amounts of unstructuredstructured data youre passionate about open source and big data technologies you find yourself thinking about complex cuttingedge systems in the shower you want the opportunity to collect parse manage analyze and visualize large data sets to extract meaningful knowledge and you dream of working with nosql database technologies and fun emerging data science techniques as part of a small team of experts you have a strong desire to contribute to important endeavors to address critical needs of fortune 500 companies


responsibilities



work with an amazing team to design and develop modern distributed big data processing and analysis systems
utilize primarily open source development tools and code frameworks eg git storm
define and manage development tasks within an agile team
utilize unit tests and deploy code to live systems
work closely with customers and incorporate feedback into development activities
gracefully accept criticism when you make a lessthanstellar lunch recommendation


skills  qualifications


must have

5 year software development in a professional setting
strong functional language experience clojure or scala preferred
programming with scripting languages eg python perl bash etc
proficient in unixlinux environments we work on macs and deploy to ubuntu on aws
strong knowledge of programming structures and algorithms
excellent oral and written communications skills

nice to have

distributed faulttolerant architectures storm experience preferred spark or hadoop ok
working with nosql databases and json data elasticsearch preferred
working with messagingqueueing systems rabbitmq preferred
working with sql databases and largescale data integration mysql preferred


about signafire


founded in 2013 signafire is best known for its industryleading fusion and content analysis technology which enables companies to fuse access and analyze data at an unprecedented speed and scale initially developed for intelligence agencies and special operations forces signafires technology has evolved to help companies in any industry find identify and accurately turn data into actionable insights across nearly any public or private databases

signafire is currently in a period of high growth and is expanding our technology teams to create and develop new products and enhanced features we are looking for ambitious intelligent and innovative candidates to help us continue to grow",,NY,False,data_engineer
Data Engineer,"you will love chesterfield and wed love to have you
civic pride and making a difference are just two reasons to join the chesterfield county team want to help chesterfield achieve the vision of being an extraordinary and innovative community in which to live learn work and play

chesterfield county is the fourth largest local jurisdiction in the state of virginia and is a recognized leader across the country for being innovative delivering highquality results and embracing new technology the center for digital government has recognized chesterfield as one of the top five counties of our size over the past several years awards and recognitions for innovative business solutions and openness and transparency of information are received annually chesterfield it teams have performed well at the governor of virginias datathon challenge the past three years earning the coveted governors cup last year

our data goals
evangelize the concept of data as an asset
formulate insights that foster innovation
enable effective decisionmaking through shared county data
unleash the capability of data science to empower business users
 data engineer role
advanced sql queries
metadata management
complex data modeling
cloud data architecture
efficient data integrations
innovative data analytics
data mining techniques
data governance
qualifications  experience
bachelors degree in information systems computer science mathematics statistics or related field from an accredited university or college advanced degree preferred
at least six years progressive work experience in data focused roles ten years preferred
experience with microsoft technologies including sql server ssis ssas ssrs power bi and azure cloud services preferred
proficient with advanced statistical techniques and concepts such as regression and distributions
building skill in variety of machine learning techniques such as clustering and decision tree learning
advanced experience in developing custom data models algorithms data integration data cataloging and metadata management
 skills  knowledge
advanced analytical and problemsolving skills
expert skills in database query language and semantic modeling
expert skills in data analytics reports visualizations and dashboards
drive to learn and master new data technologies and techniques
highly skilled on processes related to project life cycles software development life cycles requirements gathering testing methodologies and source control
be dependable and have a good respect for diversity
excellent communication team building and interpersonal skills with a customerfocused approach
embrace values of building trust staying agile and focusing on innovation
preemployment drug testing and fbi criminal background check required this position is subject to working in high security areas governed by the us department of justices criminal justice information services cjis security policy and therefore requires successfully passing a more stringent criminal background check must be a us citizen or have been a lawful resident of the us for the past ten years must maintain personal mobile technology as a condition of employment
 
shift

monday  friday 830am  500pm
 
work location

information systems technology",,VA,False,data_engineer
Big Data Engineer,"who are we
pixalate helps digital advertising ecosystem become a safer and more trustworthy place to transact in by providing intelligence on “bad actors” using our world class data our products provide benchmarks analytics research and threat intelligence solutions to the global media industry we make this happen by processing terabytes of data and trillions of data points a day across desktop mobile tablets connectedtv that are generated using machine learning and artificial intelligence based models
we are the world’s 1 decision making platform for digital advertising and don’t just take our word for it  forrester research consistently depends on our monthly indexes to make industry predictions


what does the media have to say about us
harvard business review
buzz feed
forbes
nbc news
cnbc
business insider
adage
adage
cso online
mediapost
mediapost
the drum
mediapost
mediapost


how is it working at pixalate
we believe in small teams that produce high output
slack is a way of life short emails are encouraged
fearless attitude holds high esteem
bold ideas are worshipped
chess players do really well
titles don’t mean much you attain respect by producing results
everyone’s a data addict and an analytical thinker you won’t survive if you run away from details
collaboration collaboration collaboration
what will you do
support existing processes running in production
design develop and support of various big data solutions at scale hundreds of billions of transactions a day
find smart fault tolerant selfhealing cost efficient solutions to extremely hard data problems
take ownership of the various big data solutions troubleshoot issues and provide production support
conduct research on new technologies that can improve current processes
contribute to publications of case studies and white papers delivering cutting edge research in the ad fraud security and measurement space
what are the minimum requirements for this role
bachelors masters or phd in computer science computer engineering software engineering or other related technical field
a minimum of 3 years of experience in a software or data engineering role
excellent teamwork and communication skills
extremely analytical critical thinking and problem solving abilities
proficiency in java
very strong knowledge of sql and ability to implement advanced queries to extract information from very large datasets
experience in working with very large datasets using big data technologies such as spark bigquery hive hadoop redshift etc
ability to design develop and deploy endtoend data pipelines that meet business requirements
strong experience in aws and google cloud platforms is a big plus
deep understanding of computer science concepts such as data structures algorithms and algorithmic complexity
deep understanding of statistics and machine learning algorithms foundations is a huge plus
experience with machine learning big data technologies such as r spark ml h2o mahout etc is a plus
what do we have to offer
located in sunny palo alto and playa vista ca the core of pixalate’s dna lies in innovation we focus on doing things differently and we challenge each other to be the best we can be we offer
experienced leadership and founding team
casual environment as long as you wear clothes we’re good
flexible hours yes we mean it  you will never have to sit in traffic anymore
free lunches you name it we’ve got it
fun team events
high performing team who wants to win and have fun doing it
extremely competitive compensation
opportunity pixalate will be what you make it",,CA,False,data_engineer
Data Engineer,"job title data engineer
reports to head of upstream data – americas

location houston tx usa

company
for the past 40 years wood mackenzie has established its reputation as a trusted source of intelligence enriching lives by empowering clients with unique insight on the world’s natural resources

now as part of the verisk analytics family that legacy is even stronger aligning with the world’s leading data analytics company extends our ability to help clients overcome the toughest challenges with our unique analysis and advice

we will continue to build on the power of our existing approach to assess and value individual assets and companies allowing our clients to pursue the most promising opportunities

together we inspire and innovate the markets we serve – providing invaluable intelligence that informs the strategic decisions that will ultimately shape the future direction of our global natural resources

role purpose
wood mackenzie seeks an experienced professional to play a key role in improving and growing our us upstream supply chain research coverage your team will source oilfield service ofs supply and demand data and craft proprietary models to derive detailed cost estimates and forecasts to complement our core upstream research offerings working as part of the wood mackenzie l48 upstream research team you will be at the forefront of our upstream analysis and engage with clients at a senior level you will be expected to contribute and make an impact from day one

team profile
the americas upstream data team leads the ingestion processing curating and analysis of data that underpins our products and supports our extraordinary research we are a global leader in commercial analysis within the energy sector and the completeness integrity and quality of our datasets are critical to maintain this position this is an exciting opportunity to join a team comprised of data analysts engineers and scientists working together to demonstrate greater value from our data

main responsibilities
maintain data and systems used to deliver content to clients andor internal partners
execute the operation of business processes including data gathering collation and formatting
understand the implications of system changes tools and processes that are used in the team and the impact of making changes for internal partners and clients
create and maintain the documentation of data processes databases data tools and models according to policies procedure and standard methodologies
follow set procedures to complete regular data processes and analysis ensuring completeness accuracy and integrity of data
collect and compile industry data on a regular basis from various sources to maintain and supplement our data platform
create new ways to visualize and analyze our data for both internal tools and commercial products
form a good understanding of data domain business activities and client requirements from the organizations products and services
ensure integrity of our own sourced data
develop new processes to improve the transformation and curation of our data
develop good working relationships with research and data colleagues to provide data support or process changes
knowledge  experience required
minimum of bachelors degree required in related field of study
experience in working with data and demonstrate an affinity with numbers
understanding of how web scraping methods can be implemented
additional skills desired but not required include python r vba kapow xml html json c arcgis sql aws kibana elasticsearch kafka
a knowledge of the upstream industry would be advantageous
experience of using ms office suite including excel
understanding of data visualization tools such as spotfire powerbi tableau quicksight
accuracy and attention to detail
process driven
information gathering
team working and communication
time management and organizational skills
efficiency focused
core competencies
accuracy and attention to detail
process driven
information gathering
team working and communication
time management and organizational skills
efficiency focused
wood mackenzie core values
wood mackenzie is a place where we are committed to supporting our people to grow and thrive we value different perspectives and aspire to create an inclusive environment which encourages diversity and fosters a sense of belonging

wood mackenzie values each individuals contribution and helps them reach their full potential while sustaining an organisational culture of health and wellbeing

our core values are
respect for the individual
integrity
passion
persistence
confidence with humility
excellence
teamwork
we understand the importance of bringing your whole self to work and to achieving balance between work family and other life commitments we are open to considering flexible working arrangements to enable the greatest spectrum of talent to contribute to wood mackenzies success

eeo statement
unsolicited resumes submitted to wood mackenzie by any external recruitment agency via internet email fax or us mail become the property of wood mackenzie and we are not responsible for any fees associated with those resumes

in compliance with the civil rights act of 1964 and 1991 the age discrimination in employment act of 1967 section 504 of the rehabilitation act of 1973 the americans with disabilities act of 1990 and all other relevant federal and state laws the policy of this company prohibits discrimination in employment because of race color religion national origin sex gender identity andor expression age veteran’s status disability genetic information or any other group protected by law applicants are considered for all positions without regard to race color religion national origin sex gender identity andor expression age veteran’s status disability genetic information or any other group protected by law

if you are a qualified individual with a disability or a disabled veteran you may request a reasonable accommodation if you are unable or limited in your ability to use or access woodmaccomcareers online as a result of your disability you can request reasonable accommodations sending an email to hrenquirieswoodmaccom

wood mackenzie is an equal opportunity employer mfvd and a member of everify

httpwwweeocgov",,TX,False,data_engineer
Sr. Data Engineer,"nyse wrk partners with our customers to provide differentiated paper and packaging solutions that help them win in the marketplace westrock’s 45000 team members support customers around the world from more than 300 operating and business locations spanning north america south america europe asia and australia learn more at wwwwestrockcom
sr data engineer  norcross ga
3169 holcomb bridge rd jefferson plaza
norcross georgia 30071
united states


the opportunity
this role will have an emphasis on data engineering practices and will be part of a center of excellence team leading the evaluation and implementation data engineering technology tools and frameworks leveraging the integration platform and cloud services supporting our integrations investments the efforts will help drive the strategic vision for eai and b2b integrations within westrock

how you will impact westrock

establish best practices in integration technologies and developing selfservicing tools
lead a technical team of data engineers delivering a wide array of eai and b2b solutions that use cutting edge technologies
guide the organization in efficient data and resource management best practices with cloud based integration services


what you need to succeed

at least 6 years of general software and data engineering experience
at least 4 years of experience building and maintaining integration platforms and services
hands  on experience in the following domains

enterprise architecture frameworks
processes methodologies standards products and frameworks applicable to support enterprise wide integrations
business systems and applications analysis and defining requirements for applications supported by webmethods servicesbpmscafterracotta in memory caching
security concepts such as oauth sso and attribute based access control and master data management concepts in supply chain management
user interface and user experience technologies including mobilefirst architectures
developing and supporting complex interfaces between internal business systems using various adapters file based mechanisms batch and realtime processing

developing and supporting complex interfaces between internal business systems and external partners
technologies and ecosystem supporting b2b integrations with good understanding of tools applications and frameworks in a typical supply chain management system that includes document exchange interacting with third party service providers customer related web interfaces and selfservice tools
analysis and reporting
experience providing solutions that provide insights into the transaction processing through analysis and reporting with hands on experience with trading networks
good understanding of reporting requirements for various business needs and costs allocation

operational experience with rdbms sql server oracle mysql etc data stores
experience in java programming language
strong software engineering skills including full agile software development lifecycle including design implementation unit testing techniques and able to participate in peer review
ability to identify problem root cause quickly and provide solutions with pros and cons
communicate effectively with product owner project manager and team members to ensure commitments dates and expectations are delivered
must be a selfstarter with good interpersonal skills and the ability to manage multiple tasks meet deadlines and adapt to changing project requirements
education bachelors degree in computer science or similar

what we offer
corporate culture based on integrity respect accountability and excellence
comprehensive training with numerous learning and development opportunities
an attractive salary reflecting skills competencies and potential
a career with a global packaging company where sustainability safety and inclusion are
business drivers and foundational elements of the daily work

westrock company is an equal opportunity employer committed to creating and maintaining a diverse workforce minoritiesfemales disabledveterans",,GA,False,data_engineer
Data Engineer,"we are looking for an experienced data engineer to join our growing data warehouse team you will be responsible for profiling analyzing processing and loading the vast amounts of payment data we have the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys the challenge of precisionbased quality and highthroughput performance engineering you will be part of a small team that works on data initiatives to deliver information products to our business intelligence community you will be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing our existing architecture and reshaping it to leverage the nextgeneration cloudnative tools

essential duties and responsibilities

 collaborate on design and maintain optimal data pipeline architecture
analyze and process large complex data sets to meet functional and nonfunctional business requirements
assist team to build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and related ‘big data’ technologies
deliver quality of work via unit testing
 ensure performance of code meets nonfunctional requirements
work with stakeholders including the management product data and design teams to assist with datarelated technical issues
responsible for engaging with production support staff and remediating chronic andor critical production support issues
responsible for monitoring more junior developer and contracted staff
qualifications

 minimum required qualifications for consideration
bachelor’s degree in computer science or information systems
 minimum 4 years experience designing and coding data pipeline programs particularly in a data warehousing or analytics environment
 experience with informatica talend or an equivalent etl tool
 advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
 strong analytic skills related to working with structured and unstructured datasets
 build processes supporting data transformation data structures metadata dependency and workload management
 a successful history of manipulating processing and extracting value from large disconnected datasets
excellent verbal and written communication skills
preferred qualifications
 
experience in a highvolume highthroughput data processing environment
 experience with aws cloud services ec2 rds s3 redshift glue athena
 experience with python is a plus
 knowledge of financial andor payment systems
 experience with source code version control

at wex we reward innovation hard work and excellence

benefits include
401k plan
adoption assistance
bonus plan
dental insurance
dependent life insurance
employee assistance program
employee referral award program
expedition  wex’s sabbatical program
extended parental leave
flexible spending accounts medical and dependent
health insurance
life insuranceadd
on site fitness facility in south portland location
pet insurance
paid time offpto
short and longterm disability programs
tuition reimbursement
vision

equal opportunity employervetsdisability
primary location usmesouth portland
schedule fulltime
job information technology  corp",,ME,False,data_engineer
Data Engineer,"as a data engineer you will use your technical capabilities to enable data driven decisions to inform financial and operational insights across the fossil group you will deliver insights that will inform and drive key business decisions and partner with business teams to structure problems extract and analyze data and present findings and recommendations to our leadership teams

specific responsibilities include
collaborating with internal business clients to identify and develop enterprise scale analytic algorithms on large data sets
acquiring curating and cleaning data from a wide variety sources both public and private
developing and maintaining etl pipelines and workflows
selecting and integrating big data tools and frameworks to support the business’ analytics needs
provisioning and maintaining cloud based databases and cloud computing environments
ability to draw conclusions from data and recommend actions
continuing to grow knowledge of data engineering tools and processes
your skills
aligning with fossil’s core values we are looking for someone who
develops strong partnerships across our organization
brings a positive serviceoriented approach to work
is driven by creating unique and efficient solutions for business challenges
can articulate thoughts clearly as well as listen to and considers others’ ideas
is passionate about their contribution to fossil
has a great time at work and encourages others to do the same
required skills and experience
babs degree in computer science mathematics or related technical field or equivalent practical experience a masters degree in computer science mathematics or related technical field is a plus
experience architecting and developing endtoend enterprise scale big data analytical solutions in serverless environments such as google cloud platform
experience with cloud dataflow bigquery hadoopspark and tableau
experience implementing etl processes in big data analytical solutions using a variety of sources text databases json xml etc
23 years of experience in statistical and database languages eg python r advanced sql
23 years of experience working with big data data mining or machine learning data visualization to draw actionable insights
3 years of experience programming in java and unix shell scripts
23 years of experience with agile and scrum development
familiar with apache beam sdk
working knowledge of basic financial concepts pl margins pricing etc
prior experience in financial modeling is a plus
excellent oral and written communication skills including the ability to communicate complex findings in a structured and clear manner to a nontechnical audience",,TX,False,data_engineer
Senior Data Engineer,"company overview
at proofpoint we have a passion for protecting people data and brands from today’s advanced threats and compliance risks we hire the best people in the business to
build and enhance our proven security platform
blend innovation and speed in a constantly evolving cloud architecture
analyze new threats and offer deep insight through datadriven intel
collaborate with customers to help solve their toughest security challenges
we are singularly devoted to helping our customers protect what matters most that’s why we’re a leader in next generation cybersecurity—and why more than half of the fortune 100 trust us as a security partner

the role
proofpoint is seeking a senior data engineer to work on the cloudmark security platform for mobile we are on a mission to delight our customers and partners by helping them achieve their business goals
we are a creative and datadriven team focused on continuous learning about our customers’ needs and behaviors we care deeply about customer experience and cherish the insights we uncover through experimentation analysis and prototyping
your daytoday
as a senior data engineer you will help shape the continued development of the cloudmark security platform for mobile solution you will split your time between working with the team in our san francisco office and travelling to work onsite with our mobile carrier customers onsite you will be deploying and integrating the solution and doing data analysis in splunk and elk to train the platform for optimal performance in the customer’s messaging environment you will bring valuable customer insights and realworld experiences back to product management and the rest of the development team to help evolve the solution and keep it the best in the industry
you will work alongside the mobile solution product manager and other development team members to design and build solutions in a fast collaborative process we will iterate quickly operate on evidence and evolve as we learn you are biased towards action pragmatism and results
deploy and integrate the cloudmark security platform for mobile solution into mobile operator environments
perform data analysis using operational intelligence tools and scripting tools including splunk elk python perl and golang to optimize and train the mobile solution for specific environments
iterate on product ideas and work with product management to help shape the direction of the solution
build rapport trust and credibility with customers delivering presentations on the product results
produce customer facing documentation
assist with building test harnesses and test plans
produce customer facing reports using splunk and elk
 what you bring to the team
bs degree in cs data science statistics or related fields or equivalent level of industry experience
minimum 710 years of experience in a software related field development testing data analysis solutions architect etc
experience in data analysis using splunk elk loggly or similar analytical tools
experience with linux system and application administration
ability to write scripts needs to perform integration tasks
presales solutions architect or consulting experience is useful – particularly implementation experience in carriers or large enterprises
experience in a technical role in the antispam cybersecurity andor messaging space is a plus
knowledge of networking topology tcpip protocol network configuration and components firewalls routers proxies etc and mobile protocols such smpp or messaging protocols such as smtp sms mms or rcs is very useful
strong technical presentation and communication skills both verbal and written is essential
ability to work both independently and in a team environment
ability to gather requirements and interact effectively with both customers and team members
ability to travel up to 50
why proofpoint
as a customer focused and driventowin organization with leading edge products there are many exciting reasons to join the proofpoint team we believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation as we continue to grow and expand globally we understand that hiring the right people and treating them well is key to our success we are a multinational company with locations in 10 countries with each location contributing to proofpoint’s amazing culture
livw1",,CA,False,data_engineer
Data Engineer,"data engineer
navigator works with clients across the country serviced by offices in columbus headquarters atlanta baltimore boston cleveland and phoenix
submit your resume knowing that our breadth of services require new recruits all the time

we are looking for an experienced data engineer to join our growing team of analytics experts this resource will join our consulting organization with a focus on optimizing data and data pipeline architectures as well as optimizing data flow and collection for cross functional teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up the data engineer will support our analytics project teams on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products

responsibilities for data engineer

create and maintain optimal data pipeline architecture
assemble large complex data sets that meet business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and hadoop ‘big data’ technologies
build analytics tools that utilize the data pipeline to provide actionable insights
work with executive functional and technical stakeholders regarding datarelated technical design development and architecture initiatives
create data tools for analytics and data scientist team members
qualifications for data engineer

advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
experience building and optimizing ‘big data’ pipelines architectures and data sets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
strong analytic skills related to working with unstructured datasets
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores
strong project management and organizational skills
experience supporting and working with crossfunctional teams in a dynamic environment
willingness to travel


we are looking for a candidate with 2 years of experience in a data engineer role who has experience using the following softwaretools

experience with big data tools hadoop spark kafka etc
experience with relational sql and nosql databases
experience with data pipeline and workflow management tools
experience with objectorientedobject function scripting languages python java scala etc


education

bachelor’s degree
navigator management partners llc is an equal opportunity employer it is the policy of navigator management partners to provide equal opportunity to all employees and applicants to provide equal opportunity for advancement of employees and to administer its business in a manner that does not discriminate against any person because of age race creed color religion sex national origin ancestry disability status veteran status sexual orientation gender identity or expression genetic information marital status citizenship status or any other basis as protected by federal state or local law",,OH,False,data_engineer
Data Engineer- Project Hire,"the data engineer will ensure the smooth functioning of processes to ingest thirdparty data into internal data systems as well as manage delivery of data to api endpoints or data repositories the engineer will have responsibility for both data ingest and delivery the engineer typically will be responsible for data transformation scripts and oversight of one or more data qa pipelines per client requirements the data engineer may work with client or provider systems to write specifications detailing the type and expected quality of data deliveries the data engineer will also with work with systems engineering product development solutions engineering and data entry teams as needed to assess and meet needs
highly knowledgeable about industry data management strategies and practices such as acid compliance data backuprestore and data encryptionaccess ability to write data transformation scripts in at least one common scripting language such as groovy python or javascript functional competence in java familiarity with w3c standards for linked data and related technologies such as triple stores rdf sparql and shacl is strongly preferred bachelors degree in computer science or information systems or 5 years’ experience with corporate data management systems in highcompliance contexts
the data engineer for the data technology team manages and operates systems to acquire and deliver content data to client systems within disney the data engineer’s primary responsibility is to maintain the systems that ensure data meets internal and client specifications and is delivered ontime the data engineer will work as part of a data technology team with the senior staff data engineer and the data quality engineer 588472",,CA,False,data_engineer
Data Engineer,"about the role
audley travel is now seeking a data engineer to play a pivotal role in our digital analytics team in this role you will be responsible for the creation and management of client  marketing data sets across the audley journey further enabling advanced data science and analytics you will collaborate closely with our digital marketing analysts data scientist and marketing channel owners to scope build and visualize extensible data sets to better our client communication strategies
basic qualifications
exceptional problem solving skills
strong attention to detail and managing deadlines
bachelor’s degree in computer science or related field
strong understanding of relational database systems both row  column oriented
experience with several aws features
preferred qualifications
experience creating data models and data city planning
experience migrating data infrastructure and workflows into the cloud
solid knowledge of software development methodologies such as agile
what’s in it for you
as a data engineer you will be a crucial piece of a brand new client acquisition strategy you will have the ability to work with key stakeholders and the freedom to think independently and be creative in your efforts in addition we offer a comprehensive benefits package where we cover 100 of the cost of medical dental and vision and match your 401k contribution we find though that the real benefit to a career at audley turns out to be the people
about audley travel us inc
audley connects discerning travelers to a more rewarding travel experience in nearly 80 destinations around the world each of our country specialists has firsthand knowledge of the best guides food lodging and local secrets in a specific region of the world having lived or traveled there extensively this allows them to tailor each journey to a client’s individual travel style and interests the local knowledge and personalized service creates a streamlined and stress free planning experience
our carefully curated experiences candid advice and level of service including personalized travel packs go above and beyond client expectations
audley travel group is an equal employment opportunityaffirmative action employer we are committed to the policy of providing equal employment opportunities without regard to race color religion sex sexual orientation gender identity veteran status disability or national origin
this employer participates in everify the employer will provide the social security administration ssa and if necessary the department of homeland security dhs with information from each new employees i9 to confirm work authorization",,MA,False,data_engineer
Data Engineer,we are seeking an experienced data engineering consultant with a proven track record for high quality and impactful deliveryresponsibilities advise enable and assist software data architects data engineers product and business owners to evolve fast data architectures and design technical solutionsenable our clients to successfully design and implement software solutions mainly through pairing mentoring code and architecture reviews etcassist in creating and maintaining tools and templates for professional services engagements such as methodologies perspectives training and other enablement materialsability to travel 25 of the timethis is much more than a coding position  we are looking for a true consultant and technology leader with an advanced technical backgroundqualifications enjoy being a fast learner and being a part of a fastmoving and evolving technical environmentare an advocate and evangelist of stack and related technologies; scala or java spark kafka hdfs mesosphere dcos or kubernetes and optionally platforms for microservices including akka lagom and playhave significant experience in big data batch and streaming architectures and concepts including deployment monitoring and operationshave experience in distributed architectures and functional programming conceptshave a consulting background and experience working directly with clientshave excellent written and verbal communication skills in englishare skillful at interacting and working with people in a leadership role; working with a selforganized lean and agile team to mitigate key project technical risks managing effort and ensuring qualityare dedicated to helping clients produce high quality solutions and dedicated to best practices such as automated testing performance testing code reviews continuous integration and continuous deploymenthold at least a bachelors degree or equivalent experiencehave specific experience one or more of the following data engineering and architecture areasiot solutionsspark hadoop big datafast data systemsmentoring and leading software teamsjob type fulltimeexperiencehadoop big datafast data systems 2 years preferredscala or java spark kafka hdfs mesosphere dcos 4 years requiredbig data batch and streaming architectures and concepts 3 years requirededucationbachelors requiredlanguageenglish preferredwork authorizationunited states required,,CA,False,data_engineer
Data Engineer,"r183245 data engineer
job description

your next adventure at vmware is only a click away

at vmware we are committed to helping our people grow professionally our talented employees exemplify our shared values and continue to drive our company to new heights
if you see a position that might be right for you we encourage you to apply and continue to be a part of our epic2 community
vmware the global leader in virtualization and cloud infrastructure delivers customerproven solutions that accelerate it by reducing complexity and enabling more flexible agile service delivery

are you looking for a high energy team where you can make a direct contribution to envisioning and architecting next generation data analytics platform are you looking to join a company with a vision to imagine design and create a better world who is also recognized as top places to work for in silicon valley

vmware data team is looking for a data engineer to help build on next generation near realtime bi platform based on sap hana and hadoop you will be responsible for building and enhancing the solutions on the existing platform based on the business needs in partnering with fellow developers and business groups

responsibilitiesunderstand the business capabilityrequirements and transform them into robust design solutionsperform hands on work using python able to write complex sql’s understand api and be able to consumewrite api’s as neededperform report development using enterprise tools such as tableau sap bobj and other open source reporting platformsperform hands on work using sap hana hadoophawq sdislt informatica to build next generation nearrealtime data analytics platformintegrate data sets from difference sources using informatica python sap sdisltprotect data integrity and accuracy perform root cause analysis of issues that hinder the data quality work with data source owner to increase quality and accuracy of the source datahelp data consumers to correctly understand and use the databuilding reports based on the business need

qualifications5 years of experience in as a bidata engineer handling large volumes of dataexcellent knowledge of data warehouse technical architecture infrastructure components etlelt and reportinganalytic toolsexpertise in writing advanced sql queriesexperience working with informatica sap sdisltexpertise in sap hana hivehadoophawqworking knowledge of bi reporting tools like bobj and tableau is a plusexperience in python scriptingfamiliarity with amazon web services aws redshift is a plusstrong analytical and troubleshooting skillsexcellent verbal and written communication skillsbachelor’s degree in computer science statistics mathematics engineering or relevant field

eeo statement
vmware is an equal opportunity employer committed to the principles of equal employment opportunity and affirmative action for all applicants and employees equal opportunity and consideration are afforded to all qualified applicants and employees in personnel actions which include recruiting and hiring selection for training promotion rates of pay or other compensation transfer discipline demotion layoff or termination vmware does not unlawfully discriminate on the basis of race color religion sexual orientation marital status pregnancy gender identity gender expression family medical history or genetic information citizenship national origin or ancestry sex age physical or mental disability medical condition veteran status military status or any other basis protected by federal state or local law ordinance or regulation vmware also makes reasonable accommodations for disabled employees consistent with applicable law further it is the policy of vmware to maintain a working environment free of all forms of harassment",,CA,False,data_engineer
Data Engineer (Education),"90000  110000 a yearare you a data engineer who wants to utilize your talents to help foster the leaders of tomorrow do you want your work for a nonprofit to help society if yes read on

whats the job

as a data engineer on our team you will be tasked to take the lead on building out data pipelines from the ground up using python

the data youll be shaping will help improve and track academic performance across our array of awardwinning educational facilities with the goal of creating the infrastructure to double our capacity you will be processing the data with spark  aws

this is a position where youll have a lot of insight into how we move forward as a team we are very feedbackdriven and value professional growth if you feel it can be done better youll be able to take ownership on steering us in that direction

who are we

we are an awardwinning educational system founded in nyc changing the game on how education can develop our leaders of tomorrow

we have grown rapidly since our inception and are looking to double to outreach soon

what are we looking for


data pipeline background using python
experience with spark aws
someone who wants to take point on projects

compensation


80100k
robust full benefits package medical dental vision

whats in it for you

if helping develop the leaders of tomorrow isnt enough we also offer a robust benefits package medical dental vision 20 days pto etc

you will be in an environment that allows for ownership on how we are going to move forward you will be a key figure in shaping our direction",100000.0,NY,False,data_engineer
Data Engineer,"thirdlove is looking for a data engineer to provide technical leadership and handson development of our data driven projects this role will lead the charge for selecting and implementing the right technologies and infrastructure for data warehousing analytic reporting recommendation engines and analytics engines based on business requirements and best practices

the job


identify database requirements by interviewing stakeholders evaluating existing systems and analyzing department applications and operations
recommend document and implement database systems data architecture schema design security backup and disaster recovery
master of etlelt
relational data modeling including denormalized dimensional modeling star and snowflake schema design
work closely with engineers to design and maintain scalable data models
develop document and maintain enterprise etl processes
be the expert on endtoend data flow for the enterprise
develop an enterprise reporting and data warehouse solution to track business metrics
implement systems for tracking data quality and consistency
work with the tech team to establish data standards ensure standard adherence and maintain data quality
collaborate with business and product stakeholders to develop clear business objectives kpis and measurements
programmingscripting of tools for task automation

the qualifications


3 years experience in data warehousing and business intelligence
expertise in etl eg ssis ansible informatica sap owb or scripts
prior experience working with data processing platform
proven ability to work with varied forms of data infrastructure including relational databases
experience with configuring and deploying databases on aws
experience with creating frameworks to extract data via apis
expertise with various database platforms sql nosql onprem cloud
scripting and programming in one or more of the following php net python r javascript
ability to write analyze and debug sql queries
experience with nonstructured data eg free form json xml images audio video
experience with data visualization data mining and preferably statistical tools
good understanding of the big data technology trends
a master of all trades mentality and an ability to embrace new challenges regularly
able to take individual ownership of a project from start to finish
excellent critical thinking problem solving and analytical skills
excellent communication skills and the ability to work effectively with others
bs or ms degree in computer science or a related technical field

the perks


comprehensive health benefits
401k plan
equity
subsidized lunches
quarterly product allotment
wellness benefits including inoffice massages visits

thirdlove® is empowering women to feel comfortable and confident in their everyday lives we make bras that fit perfectly feel incredible and look stellar

were a rapidly growing team over 250 today and doubling in size this year based in san francisco with offices in chico ca and argentina were funded by tier 1 investors and are disrupting a 100 billion global market were one of the fastest growing consumer brands in the country and known as the brand to catch victorias secret

our culture is collaborative fastpaced and datadriven with a strong focus on designing beautiful products and creating a seamless user experience instead of using standard industry molds we developed proprietary halfcup sizes based on real womens measurements and created a fit finder® quiz that removes the hassle in finding the best size to date over 9 million women have taken our easytouse fit finder® quiz

five core values drive all of the work we do

every day is a new day learn from the past but keep moving forward stay positive and optimistic
make it happen be proactive be thoughtful about the how
defy conventions question the status quo ask why be nimble and embrace change
were stronger together give your full attention share information and help others learn and develop
put customers first make every interaction count listen to respect and delight customers

if you want to impact millions of people each and every day and you share these values wed love to connect

thirdlove is an equal opportunity employer and values diversity at the company we do not discriminate on the basis of race religion color national origin gender gender identity or expression sexual orientation age genetics marital status veteran status or disability status",,CA,False,data_engineer
Engineer - Big Data,"an engineer is part of a key team of nordstrom technology professionals that applies scientific mathematical and social principles to design build and maintain technology products devices systems and solutions these technology products and solutions provide amazing customer experiences while meeting the needs of the business the data engineer will focus on leading the design and development of business intelligence etl and database solutions the ideal candidate is creative customerdriven and has a passion for supporting ecommerce bi products

a day in the life
possesses deep proficiency of engineering best practices
support the development and evolution of our data warehouse and bi platform
partner with the bi manager data and bi engineers program managers and analysts on building a bestinclass suite of tools and reporting mechanisms to bring the most salient insightful data more directly into key business functions
coding proficiency in at least one modern programming language eg python java scala
experience with big data technologies hadoop hive presto pig spark etc
design and implement modernized etl and data processing solutions through modernized cloud based solutions s3 redshift etc and deprecate legacy onpremise solutions oracle etc
develop data integration solutions leveraging multiple disparate sources
continual performance tuning and capacity planning for future growth potential
provide a constant flow of new and innovative ideas into the bi roadmap
integrates broad working knowledge in related disciplines to create integrated technical innovations solutions for complex business situations
serves as lead resource for dealing with challenging technical issues
makes decisions which influence and impact the success of crossteam initiatives
works with larger team to drive to resolution on complex engineering problems
accountable for resolving specific issues within a particular area application technology or system
some exposure to working cross discipline and driving solutions for moderately complex business situations
leads endtoend engineering support for projects and problems of complex scope and impact within practice
viewed as trusted engineering resource
makes decisions which require understanding of both internal and external impacts to teamproject

you own this if you…
4 years professional experience
2 years of experience writing advanced sql data modeling building etl solutions performance tuning of bi queries and data mining from multiple sources
2 years of experience in analytics olap tools and engineering automated solutions
2 years of experience in bi reporting technologies such as microstrategy or tableau
2 years of experience coding proficiency in at least one modern programming language eg python java scala
2 years of experience with big data technologies hadoop hive hbase pig spark etc
cloud computing experience eg aws azure is a major plus
bachelor’s or master’s in computer science engineering or equivalent














we’ve got you covered…

our employees are our most important asset and that’s reflected in our benefits we listen to what’s most important and continue to evolve our offering to support both our employees and their families

beyond strong health retirement and time off benefits nordstrom is proud to offer
commuter benefits
100 paid parental leave
charitable giving and volunteer match
merchandise discount
nordstrom stock purchase plan

a few more important points

the job posting highlights the most critical responsibilities and requirements of the job it’s not allinclusive there may be additional duties responsibilities and qualifications for this job

nordstrom will consider qualified applicants with criminal histories in a manner consistent with all legal requirements

applicants with disabilities who require assistance or accommodation should contact the nearest nordstrom location which can be identified at wwwnordstromcom 
© 2018 nordstrom inc  nordstrom careers privacy policy

current nordstrom employees to apply log into workday click the careers button and then click find jobs",,WA,False,data_engineer
Principal Data Engineer,"lendkey is solving a complex challenge – to improve lives with lending made simple – by helping financial institutions compete in the digital age and provide a delightful customer experience while providing borrowers with the simple transparent digital borrowing experience they have come to expect and desire lendkey works with hundreds of credit unions and banks to conduct their education finance and home improvement loan programs
we are looking for an experienced engineer and data architect to help us build out our data warehouse and technical data structure across the firm our data capabilities and culture are still in early stages so this is an opportunity to build a data platform from the ground up
what you’ll do
partner with the product and engineering teams to develop scalable extensible systems
be the driving force behind the roadmap to normalize all of our transactional data disparate systems and transfer of data in way that creates a flexible and scalable data solution
develop data governance policies  appropriate structures to ensure adherence to those policies
ensure that solutions work well within our current code environment that technical data initiatives are aligned effectively with development staff and work to understand how other tiers in the technology stack influence data quality including apis orms object relational mapping and user interface
responsible for managing the full lifecycle of the data warehouse solution including the architecture design development implementation and support of the data warehouse
participate in creating the data design of all transactional data stores across business units and technology stacks
work with end users to translate business questions and requirements into applications that employ the appropriate reporting tools
assist in monitoring and troubleshooting system performance reliability availability and recoverability of all data stores
requirements
what we’re looking for
culture fit
strong desire to work for a missionbased organization that emphasizes the importance of providing exceptional customer service and adherence to our core values truthful at all times helpful to teammates clients and customers present committed  engaged to their teams and work driven to be courageous to make an impact and diligent  conscientious in executing every element of work
technicalbusiness experience
bachelor’s degree in computer science or related field
10 years overall experience working in development and enterprise data architecture
experience and background in building data platforms for financial services
minimum 5 years of experience with enterprise data architecturedesign
minimum 5 years of experience in software development with deep experience in objectoriented functional objectfunctional language and one of the major sql relational datastores we are a sql server and mysql shop
deep expertise in relational and dimensional data modeling and database design skills
experience in leadership roles a plus
handson experience with data management and movement platforms like hadoop kafka and airflow
ability to investigate complex business problems develop effective recommendations negotiate andor present solutions and resolve problems in a highly professional and tactful manner",,NY,False,data_engineer
Data Engineer,"contractomnigon is looking for a data engineer to build maintain monitor and improve a real time scalable fault tolerant data processing pipeline

the data engineer will support the building of a redshiftbased data mart implementing etl processes and integrating with various marketing platforms sas salesforce and other systems

our preference is that this person is onsite in los angeles however we will accept candidates who can frequently travel onsite this is a contract position

responsibilities


implementing etl processes
monitoring performance and advising any necessary infrastructure changes
defining data retention policies
collaborate with team members to help shape requirements

requirements


4 years of data engineering or related experience
strong java andor scala experience
experience with aws services including s3 redshift emr lambda and rds
experience with stream processing using spark streamingstormbeamflink
experience with messaging systems such as kafka or kinesis
bs in computer science or a related field
excellent communication skills

preferred


experience with nosql databases such as mongodb cassandra or dynamodb
experience with elasticsearch
experience with machine learning using mahoutdeeplearning4jspark ml

about omnigon

omnigon is a team of digital strategists artists and technologists working exclusively in the areas of consumer loyalty audience growth and digital content delivery since its founding in 2008 omnigon has established itself as a market leader focused on helping clients achieve returns on the strategic creative and technical investments theyve made omnigon headquartered in new york and with teams in los angeles london toronto kiev and st petersburg works with celebrated global brands including fox broadcasting verizon the pga tour fc bayern munich as roma the german football association dfb ironman nascar world rugby the united states golf association and countless others",,CA,False,data_engineer
Data Engineer,"are you passionate about solving challenging problems
do you thrive being a critical part of an elite team of likeminded people
how would you like for your next career move to take you to the next level
if any of this sounds appealing look no further
job description
design and build robust and scalable solutions for managing structured and unstructured data using traditional databases postgresql sql server etc massively parallel processing mpp databases and nosql hadoop spark etc tools
work with business users and the data operations group to develop automated etl routines to ingest disparate sources of data into sql databases
orchestrate server environments on the data platform with tools such as puppet and ansible
develop tools to support a team of data architects data analysts and data scientists
basic qualifications
5 years software development experience with languages such as python java rust and scala
2 years python experience
3 years experience with sql database design and querying
3 years experience with using linux systems from the command line
desired skills
ansible
hadoop ecosystem
apache
open source development via github


so what does novetta do
we focus on three core areas cyber entity and multiint analytics our products are focused on processing and analyzing vast amounts of data in these core areas our services are focused on helping our customers move from complexity to clarity at novetta we bridge the gap between what our customers think they can do and what they aspire to achieve
our culture is shaped by a commitment to our core values
integrity we hold ourselves accountable to the highest standards of integrity and ethics
customer mission success customer mission success drives our daily efforts—we strive always to exceed customer expectations and focus on mission success beyond contractual commitments
employee focus we value our employees and demonstrate our commitment to them by providing clear communications outstanding benefits career development and opportunities to work on problems and technical challenges of national significance
innovation we believe that innovation is critical to our success – that discovering new and more effective ways to achieve customer mission success is what makes us a great company
get a referral bonus for the great people you know with our amazing referral program you could be eligible to win outstanding rewards for referring qualified new hires to novetta

novetta is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to sex gender identity sexual orientation race color religion national origin disability protected veteran status age or any other characteristic protected by law",,DC,False,data_engineer
Data Engineer,"overview
sentry insurance is seeking a data engineer at our stevens point wisconsin headquarters the individual filling this position is responsible for under broad supervision gathering and assessing business information needs and preparing system requirements the person will perform analyses development and evaluation of data requirements in a data management environment which includes data design database architecture metadata repository creation and data consumption methods the individual will use data mining and data analysis tools and will review and validate data loaded into the data repositories for accuracy the person will participate in the detailed identification and development of program and data repository specifications and the design development and implementation of new and existing programs and systems
what it takes
bachelor’s degree in computer science information systems or a related field and five years of progressive data engineering experience sentry will also accept individuals with a master’s degree in computer science information systems or a related field and three years of progressive data engineering experience
as part of the 5 years bachelor’s degree or 3 years master’s degree of data engineering experience required the individual must have
2 years’ experience with business intelligence tools and systems specifically business objects analysis services and tableau
2 years’ experience with scheduling and workload automation tools including at least one year with zena
2 years’ experience with sql and powershell scripting
2 years’ experience using java and apache kafka to create pipeline data messaging solutions
2 years’ experience with informatica power center and power exchange and
2 years’ experience with agile methodology and jira

what youll receive
there is a reason why sentry made forbes’ list of america’s best midsize employers in 2017 and 2018 at sentry we recognize there are many factors that contribute to your overall satisfaction both at work and in your personal life so we provide a perfect mixture of compensation benefits company culture and resources to ensure your everyday happiness below are some benefits that you’ll receive
competitive compensation to reward you for your hard work every day
generous paidtime off plan for you to enjoy time out of the office
401k plan with a dollar for dollar match on your first eight percent plus immediate vesting to help fund your future
group medical dental vision and life insurance to encourage a healthy lifestyle
pretax dependent care and health expense reimbursement accounts to ease taxes on health spending
extensive worklife resources to lend a helping hand
volunteer time off so you can dedicate time to the community
sentry foundation gift matching program to encourage charitable giving
how you’ll apply
if you are interested in joining sentry’s team select the one position that you are most interested in being considered for and complete your online application details if you have applied with us before you will only need to provide your email address and password if this is your first time applying you’ll need to create an account please upload your resume directly in addition to completing your online application details
who you’ll want to contact
laura kaczmarski at 7153466373
laurakaczmarskisentrycom
about sentry
all of us at sentry—more than 4000 associates—have various talents skills and backgrounds we work together to deliver on our promises to our policyholders every day we’re proud to offer a full line of property casualty and life insurance products to help protect businesses cars homes lives and retirement income

our headquarters is in stevens point wisconsin with claims and service offices located throughout the united states from sales to claims and information technology to marketing we enjoy a rewarding and challenging work environment with opportunities for ongoing professional development and growth

our bright future is built on a long track record of success we got our start in 1904 and have been helping businesses succeed and protect their futures ever since because of the trust placed in us we’re one of the largest and financially strongest mutual insurance companies in the united states we’re rated a by am best the industrys leading rating authority

get ready to own your future at sentry opportunities await
equal employment opportunity
it is our policy that there be no discrimination in employment based on race color national origin religion sex disability age marital status or sexual orientation",,WI,False,data_engineer
Senior Big Data Engineer,"location
new york new york
shift
day united states of america
description
join the information technology team at new york’s 1ranked hospital

this is your opportunity to provide world class technology solutions that will directly impact the quality of a patient’s life at new york presbyterian hospital information technology is at the forefront of our patient experience joining our team will give you the opportunity to develop your career while creating solutions and services that will improve the welfare of others if growing your career in technology while creating solutions that improve the lives of others inspires you then a career at new york presbyterian hospital awaits you

the senior big data engineer will be assisting in the configuration and implementation of batch and streaming data processes related to ingesting data cleaning and transforming it on a big data platform you will be responsible for documenting work and management of clusterservices the senior big data engineer will assist in the monitoring and maintenance of the data processes deployed in production

required criteria
bachelor’s degree in computer science
minimum 3 years of work related experience
minimum 3 years of experience in software development preferably with java excellent understanding of object orientated concepts
minimum 2 years’ experience with at least one scripting language python scala linux shell preferred
minimum 2 years of experience with a hadoopmap reduce preferably hortonworks or cloudera worked with hive and kafka
minimum 1 year experience with nosql database such as hbase preferred cassandra or mongodb
preferred criteria
master’s degree
minimum 1 year of experience in tuning hadoop cluster to improve performance and enduser
minimum 1 years of experience with workflow tool and data processing platform oozie and impala
strong sql skills preferred
familiarity with graph databases a plus
familiarity with search indexes such as lucenesolr a plus
familiarity with statistic tools such as r sas etc a plus
familiarity with spark a plus
enjoy being challenged and solving complex problems
able to work in a team and collaborate with other teams to define requirements and remove ambiguities
join a hospital where employee engagement is at an alltime high enjoy competitive compensation along with benefits such as tuition reimbursement hospital retirement contributions and financial planning assistance start your lifechanging journey today

1 in new york americas best hospitals 20172018  usnews  world report
2018 best places to work employees choice  glassdoor
2018 employees choice top ceos  glassdoor
2018 “america’s best employers”  forbes
2018 150 best places to work in healthcare  beckers healthcare
2018 toprated work places best hospitals  indeed
discover why were 1 in new york and a best employer at nyporgcareers

newyorkpresbyterian hospital is an equal opportunity employer",,NY,False,data_engineer
Data Engineer - Analytics,"data engineer  analytics  18123100

hillrom is a 27b leading worldwide manufacturer and provider of medical technologies and related services for the health care industry including patient support systems safe mobility and handling solutions noninvasive therapeutic products for a variety of acute and chronic medical conditions medical equipment rentals surgical products and information technology solutions hillroms comprehensive product and service offerings are used by health care providers across the health care continuum and around the world in hospitals extended care facilities and home care settings to enhance the safety and quality of patient care

description

the qara engineer  metrics will manage key corporate metrics to drive business decisions and implement sound datadriven business solutions with an emphasis on quality system compliance the primary function is to lead hillrom’s global efforts to collect analyze and track the resolution of key data related to entity quality and performance indicators by interfacing with key business partners across the corporation the incumbent will manage a dashboard of key performance indicators for executive management that provides consistent timely analysis and publication of quality and key performance indicator metrics trend analysis will be performed to identify and mitigate critical quality issues along with the corresponding level of risk the incumbent will promote a culture that quality matters to everyone in the corporation

essential duties and responsibilities – other duties may be assigned
manage the evaluation of quality systems to determine how metrics and measures can be used to drive business decisions
provide leadership to monitoring and analyzing key elements of quality performance to identify product and process quality trends quality system integrity and compliance with internal as well as external standards and guidelines intervene when necessary to implement solutions and drive continuous improvement
lead the quality improvement program for hillrom including identifying stateoftheart quality standards and practices quality system planning and implementation and influencing strategic planning
manage defined kpi’sother metrics to identify process efficiency and improvement items
coordinate executive management review and quality scorecards
recommend goals and objectives for quality performance as part of annual and long range business plans
manage a set of best practices on what hillrom should consider when defining quality system outcomesbest practices based on proven successes within the medical device industry
lead the review of quality process issues and determine the best solution approach using a combination of people training transformation process updates service improvements or technology changes
provide oversight to the development of queries and reports from various data sources and data warehouse activities
ensuring standardization harmonization and reuse of information across the global corporation
support the escalation process when compliance issues cannot be resolved at the local level
provide training and support to department staff and business users on the use of metrics
indhr

qualifications

must possess sound knowledge of analytical data interpretation and trending tools
must be articulate in both verbal and written communication skills including strong questioning and listening skills and ability to look beyond obvious answers and understand the impact on other areas
ability to understand and apply mathematical concepts especially as they relate to statistics and trending
ability to define problems collect data establish facts and draw valid conclusions
proven presentation skills are required
must be adept at independent decisionmaking
strong leadership skills strong interpersonal skills and the ability to deal effectively with system users is required
strong data analysis skills and creativity in identifying new opportunities and evaluating alternatives is required
the proven ability to prioritize and manage multiple projects and meet deadlines is required
must have the capability of developing effective working relationships with staff at all levels in the organization
willing to travel 510 as business responsibilities require

education andor experience
bachelors degree in a business or technical discipline or relevant experience
knowledge of quality systems business process management and process improvement is preferred
experience in statistical analysis is required the ability to understand and apply data to the business is extremely important
experience with the creation and ability to influence business processes using kpis and metrics is required
must be capable of working on several projects concurrently under tight deadlines and be able to prioritize to meet organizational goals with attention to regulatory requirements
demonstrated proficiency with microsoft systems excel powerpoint word access project sharepoint cognos bi minitab sap and jd edwards is preferred

hillrom is an equal employment employer fmdisabilityvetsexual orientationgender identity

job quality

primary location united statesindianabatesville

other locations united statesillinoischicago il

schedule fulltime

travel yes 10  of the time

posting entity hillrom",,IN,False,data_engineer
Python Robot Data Engineer,"at bossa nova we create service robots for the global retail industry our robots’ mission is to make large scale stores run efficiently by automating the collection and analysis of onshelf inventory data we drive autonomously through aisles navigating safely among customers and store associates if we were a self driving car we’d be operating at level 5 autonomy
oh we should add it’s real happening today you can meet our robots in some of the world’s biggest retailers
position python robot data engineer
location pittsburgh
you’ll be joining our data engineering team as a data engineer you’ll be responsible for the movement of various forms of data off our robots to the cloud youll write python code that is deployed on field robots and used for logging monitoring and remote troubleshooting you will work daily with roboticists
required
2 years professional experience with python
python data structures and best practices
strong linux skills ubuntu
writes organized code with appropriate exception handling and logging
designs code to handle degraded or constrained network conditions
understanding of http network requests and responses
understanding of tcp with ability to troubleshoot network issues
ability to write technical documentation and comment code
ability to write test suites
desire to collaborate with domain experts
nice to have
experience with containers
production experience working with cloud
configuration management of some form ansible chef etc
test automation",,PA,False,data_engineer
Software Engineer - Data Flow,"facebooks mission is to give people the power to build community and bring the world closer together through our family of apps and services were building a different kind of company that connects billions of people around the world gives them ways to share what matters most to them and helps bring people closer together whether were creating new products or helping a small business expand its reach people at facebook are builders at heart our global teams are constantly iterating solving problems and working together to empower people around the world to build community and connect in meaningful ways together we can help people build stronger communities — were just getting started
facebook is seeking an experienced software engineer to join the warehouse product infrastructure team the warehouse product infrastructure team builds large scale logging data processing and analytics at facebook our stack serves all facebook products to monitor and make critical product decisions we handle everything from facebook scale logging across client and server to metrics computation to unified pipeline management across streaming batch and machine learning workloads we are looking for candidates who share a passion for tackling complexity and building platforms that can scale through multiple orders of magnitude and for enable facebook analytics to be fast and high quality this position is fulltime and is based in our office in seattle wa
responsibilities

design core backend or frontend software components

code using primarily php hack python scala or java

interface with other teams to collaborate in transforming the landscape

conduct design and code reviews

analyze and improve efficiency scalability and stability of various system resources

design and implement a workflow language for efficient data processing and machine learning
minimum qualifications

4 years software engineering experience or coding experience in c c java

2 years coding experience in php hack python java or c

2 years experience building logging infrastructure metrics infrastructure or pipeline management
preferred qualifications

experience working directly with data engineer or data scientist teams

experience working with product team in logging instrumentation on both client and server side

experience working on data modeling from logging to analytics

experience building metrics computation or consumption framework

experience extracting and implementing analytics patterns",,WA,False,data_engineer
"Software Engineer, Data","112000  142000 a year indeed est we’re on a mission to understand and structure the world’s medical data starting by making sense of the terabytes of clinician notes contained within the electronic health records of the world’s largest health systems
we’re seeking exceptional data engineers to work on data products that drive the core of our businessa backend expert able to unify data and build systems that scale from both an operational and an organizational perspective
as a data engineer you will
develop data infrastructure to ingest sanitize and normalize a broad range of medical data such as electronics health records journals established medical ontologies crowdsourced labelling and other human inputs
build performant and expressive interfaces to the data
build infrastructure to help us not only scale up data ingest but largescale cloudbased machine learning

we’re looking for teammates who bring
experience building data pipelines from disparate sources
handson experience building and scaling up compute clusters
excitement about learning how to build and support machine learning pipelines that scale not just computationally but in ways that are flexible iterative and geared for collaboration
a solid understanding of databases and largescale data processing frameworks like hadoop or spark you’ve not only worked with a variety of technologies but know how to pick the right tool for the job
a unique combination of creative and analytic skills capable of designing a system capable of pulling together training and testing dozens of data sources under a unified ontology

bonus points if you have experience with
developing systems to do or support machine learning including experience working with nlp toolkits like stanford corenlp opennlp andor python’s nltk
expertise with wrangling healthcare data andor hipaa
experience with managing largescale data labelling and acquisition through tools such as through amazon turk or deepdive",127000.0,CA,False,data_engineer
Data Engineer,"position summary

we are currently seeking a data engineer who will assist in the design and implementation of a hospitalbased clinical datawarehouse system your role will be to support existing software and integrate new data sources with a focus on efficiency and availability etiometry has the world’s largest collection of pediatric intensive care unit monitoring data and the volume and data types are continually increasing the data sets provide numerous storage and normalization challenges but can offer important insights into the efficacy of existing treatments and reveal new and innovative patient management strategies

responsibilities

interface with software stakeholders to understand infrastructure and user requirements
develop and support etiometry’s datawarehouse solution both for clinical personnel and internal research staff
build test and deploy software and database upgrades into a production environment
utilize and improve etiometry’s clinical data cleaning tools and techniques which include data extraction deidentification and clinical measure normalization  cleaning
design and implement requirements for company research
basic qualifications

bs in computer science systems engineering or a similar technical field with relevant work experience
an understanding of data model design database schemas and optimizing database applications
a breadth of understanding of database technologies including both relational and nonrelational solutions
experience manipulating large data sets of timeseries and intermittent data
experience using version control software
desired qualifications

experience designing and developing database access layers for schemas that contain multiple databases containing unique data types and access requirements
experience working with python as a primary development language with an emphasis on data management and processing
experience with mysql and mongodb
experience producing software for a clinical setting that utilizes clinical patient data eg labs physiologic signals and administrative data
an understanding of clinical or any datadriven research from a data aggregation and methodologies standpoint study design subject protections and statistical analysis
experience with agile software development methodologies and continuous integration and delivery
contact us

if you are interested in this opportunity please email careersetiometrycom with your resume",,MA,False,data_engineer
Mission Link Data Engineer,"mission link data engineer268726
description
we are pioneers we were the first to break the sound barrier and design the first functional jetpack we were aboard nasa’s first lunar mission and brought advanced tiltrotor systems to market today we are defining the future of ondemand mobility at bell we are proud to be an iconic company with superb talent rapidly creating novel and coveted vertical lift experiences


the data engineer is a member of bell’s team of analytics experts this position is responsible for cleaning and analyzing aircraft sensor data from many types of aircraft the ideal candidate is an enthusiastic clean coder who enjoys designing and programming systems to analyze store and display data the data engineer works on a small team of developers and uses aircraft data to provide value to internal and external customers this position is based at bell’s headquarters facility in ft worth tx
position responsibilities
find explore and implement value from aircraft datalink the data analysis to customer usecases and valuehelp design and optimize data presentationextract transform and load data into relational database systemsdesign and maintain database schema and stored procedurescontribute to a clean and maintainable codebasereview data and code with peers

qualifications
education

bachelors degree in engineering or computer science

experience

at least 5 years of experience in data analysis is requiredexperience with objectoriented programming in python java c scala etc experience in coding with python 3x is preferredexperience with ms sql server – administration design programmingknowledge of aircraft systems and aircraft maintenance procedures is preferred
experience in linux ubuntu suse or others – command line shell scriptingexperience supporting and working with crossfunctional teams in a dynamic environmentexperience in application of best practices in software development including source control objectoriented development and clean programming principles

don’t miss the chance to join a diverse inclusive environment where you feel a sense of belonging as a member of our global workforce you will collaborate with dedicated enthusiastic teams where unique experiences backgrounds and ideas combined with a strong passion for our products take us above and beyond flight


eeo statement
textron is committed to providing equal opportunity in employment to all applicants and employees regardless of race color religion gender age national origin military status veteran status handicap physical or mental disability sexual orientation gender identity genetic information or any other characteristic protected by law

this position requires use of information which is subject to the international traffic in arms regulations itar andor the export administration regulations ear nonus persons selected must meet eligibility requirements for access to exportrestricted information  the itarear defines a us person as a us citizen us permanent resident ie green card holder political asylee or refugee

pay transparency policy statement
the contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant however employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by the employer or c consistent with the contractor’s legal duty to furnish information
job field information technology
primary location ustexasfort worth
recruiting company bell flight
schedule fulltime
job level individual contributor
shift first shift
job posting 09192018 101052 am
textron and its subsidiaries participates in everify we will provide the us social security administration ssa and",,TX,False,data_engineer
Data Engineer Grad Intern,"internshipdata engineer grad intern  00049974
description

do you want to help analyze data and do the analysis needed to contribute to solving our nation’s most critical problems do you want to be mentored by engineers and scientists that are experts in their fields do you want to join over 300 other interns for a summer full of learning networking and fun

mitre’s people are committed to tackling our nations toughest challenges we are different from most technology companies we are a notforprofit corporation chartered to work for the public interest with no commercial conflicts to influence what we do the rd centers we operate for the government create lasting impact in fields as diverse as cybersecurity healthcare aviation defense and enterprise transformation were making a difference every day—working for a safer healthier and more secure nation and world

our workplace reflects our values we want you to come as an intern and then join us upon completing your degree so that you can experience the gratifying work our competitive benefits exceptional professional development opportunities and a culture of innovation that embraces diversity inclusion flexibility collaboration and career growth
key function what do mitre data analytics  operations research  statistics  math interns do
mitre’s data analytics operations research  statistics  math interns help strengthen our sponsor’s effectiveness by using data analytics statistical analysis and modeling and simulations methods to drive analyticallydefensible decisions they apply advanced analytical and mathematical techniques to solve complex decision problems—those with multiple alternatives that require quantitative analysis to confidently select the best one analysts use high performance computing cloud computing big data analytics and data visualization tools and techniques to improve system designs to assist in making difficult policy and acquisition decisions to maximize operational effectiveness and efficiency and to achieve the highest quality engineering solutions

qualifications

required qualifications
completed bs undergraduate degree in computer science or equivalent technical degree and currently pursuing graduate degree in computer science or equivalent technical degree

candidate will have also have strong capabilities in the following areas

software design development java c and scripting perl pythondata engineering managing massive data volume and velocity information cleansing  refinement information models  architecturesdeep working knowledge of specific tools and technologies eg dbms etldesign techniques and tradeoff analysis for scalability availability extensibility redundancy load balancingcloud computing and virtualizationservice oriented architectureweb servicesinformation assuranceattribute based access controlinformation managementinformation exchangeinterface specificationagile development and agile acquisition
must have good analytical written presentation and interpersonal communication skills and leadership experience must possess a strong aptitude to work in a researchfocused program


primary location united statesvirginiamclean
work locations washington 22102
job sw eng comp sci  mathematics
this requisition requires a clearance of none
travel no
job posting jul 3 2018 102304 am",,VA,False,data_engineer
Data Engineer (Tableau Admin),contracthione of our esteemed client is open for a job position of data engineer tableau admin a 6 months contract position in sunnyvale cabelow are the details of requirement if interested please share your resumethe requirement is for a classic data engineer with primary skills on the infrastructure tableau server admin cloud deployments and data visualization the project management skill is secondary and preferable to have as the candidate needs to selfmanage the whole data life cycle the resource is not required to create etl jobs but enables other team members to do it in a selfdriven mode as part of selfservice bi platform team so strong knowledge on full data life cycle is requiredsenior data engineer tableau server adminlocation sunnyvale caduration 612 months tableau server administration cloud deployments and data visualizationetl experience informatica hadoopsparkscriptingdevelopment experience python sqldata engineering user trainingconsulting softwareproduct architectureverbal  written communication customer focus teamworkcollaboration eye for automationthanks and regardsvishal sharmavings technologiesmaking technology cheaper and more efficientjob type contract,,CA,False,data_engineer
Data Engineer III,contractw2 only 12mos aaeoe this is not an entry level position 23 yrs professional exp neededresponsibilitiesour team enables seamless execution so they can make radically better things to bring the best of the client to everyonewe organize information and data through the management and creation of centralized tools processes programs and analysis for the senior leadership team business units and functions to land excellent productsin this role you will enable data driven decision making within the central chief of staff teamour team handles multiple core processes for the business product development process and schedule headcount planning and the annual planning process okrs staples key metrics for senior leadership team within this role you will have a chance to impact each of these areas by leveraging your analytical skills business judgement and excellent communicationassist on the creation of the spreadsheetbased headcount planning tool that willunify the approach our teams use for headcount planningsignificantly reduce planning burden on teamsdramatically improve ability to visualize org needsautomatically calculate gaps in the orgspecify which products and functions drive those gapsenable scenario exploration to understand how roadmap or timing changes impact resource needscreate dashboards with headcount analysis that includes but is not limited to frontend development to create a webbased central tool for the headcount planning trix above  peeps entry for allocationcreating visualizations for headcount plan targets vs actuals scenario planning trendsprojectionsautomating headcount allocation data visualization gohwpapeepsimplementation of headcount modeling for new products based on complexitylead ad hoc quantitative analysis and research deep divesqualifications 2 years of working experience in an analytical role with proficiency in sql appscriptjavascript experience and spreadsheet modeling experience with visualization tools eg tableau effective problemsolving statistical and business judgment skills with the ability to translate quantitative analysis into a business recommendations excellent project management presentation and communication skillsjob type contractexperiencedata engineeringanalytics 3 years preferred,,CA,False,data_engineer
Big Data Engineer,contractskill set hdfs spark hive mapreduce scala java linux spring svngit hbaserules based engine lucy hands on knowledge is a plusamerican express experience is a plusjob type contract,,AZ,False,data_engineer
Senior Data Engineer,"coursera is scaling a global platform to provide universal access to the world’s best education and we’re motivated by the passion and mission to transform lives through learning our platform has reached over 35 million learners worldwide and we have partnered with 170 elite universities  industry partners around the globe with over 2900 courses in our catalog we offer courses specializations certificates and degrees to meet the needs and goals of the diverse learners who come to coursera

several years ago we began hosting accredited online masters degrees provided by our university partners which provide a more convenient lowercost “stackable” means of earning credentials comparable to their traditional oncampus counterparts we also launched coursera for business partnering with over 1000 companies around the world to provide access to curated skill development for their employees

at coursera our data engineering team is unique with the goal to democratize data and empower our internal and external users with data to build and enhance next generation of learning experience we are responsible to model and build our foundational core data lake that feeds our key data solutions we build analytical products to serve our partners and customers with key insights we believe the next generation of teaching and learning is personalized accessible and efficient  reaching a world of learners who need it  and that with our scale data technology and talent we are best positioned to make that vision a reality

we’re looking for a talented and driven senior data engineer with a keen eye for data our ideal candidate is an independent analyticallyminded individual with strong data modeling and software engineering skills who shares our passion for education in this role you’ll directly work with crossfunctional teams to design develop and deploy data solutions
you personally exhibit a conviction that the world needs coursera to be wildly successful and alignment to our core values
betterment a tireless pursuit to drive results
boldness take risks and act decisively
deep honesty invite and offer candid feedback in order to learn change and grow
solidarity recognize that we are part of something bigger than ourselves and are committed to our mission
your responsibilities
architect scalable data models and build efficient and reliable etl pipelines to bring the data into our core data lake
design build and launch visualization and selfserve analytics products that empower our internal and external customers with flexible insights
be a technical leader for the team guide technical and architectural designs for the major team initiatives mentor junior members of the team
build data expertise and partner with data scientists and product engineers to define and standardize business rules and maintain highfidelity data
define and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently
work crossfunctionally eg product managers engineers business teams to support new product and feature launches
your skills
5 years experience in a datarelated field including data engineering data warehousing business intelligence data visualization andor data science
strong software engineering skills and at least one scripting language eg python
proficient with relational databases and sql
familiarity and experience with big data technologies eg hive spark presto preferred
ability to communicate technical concepts clearly and concisely
independence and passion for innovation and learning new technologies
if this opportunity interest you you might like these courses on coursera 
data warehousing for business intelligence specialization",,CA,False,data_engineer
Senior Data Engineer,"as the senior data engineer youll be joining a team of passionate engineers designers and product managers together we answer business questions through data

blue bottle coffee is growing presenting us with exciting opportunities to solve interesting challenges and help create solutions to serve our production teams our retail teams and hq teams youll create impact that you can see and taste working on all parts of the data stack
you will
build maintain and troubleshoot etl pipelines for several data sources
work with business partners to build data specs
establish best practices around etl and other data services
build microservices to augment or supplant more involved etls
build automated testing performance evaluations monitoring tools and dashboards
design experiments analyze data visualize results and present findings
work with and build apis fromfor other microservices and outside services
evaluate and when necessary rebuild existing etls
you are
deeply collaborative comfortable jumping in and working closely with a group of different stakeholders excited to share knowledge and welcome support
constantly learning and eager to iterate hungry to build better software and are constantly finding better ways
able to take over someone else’s code and know when refactoring is needed
able to breakdown complex problems into solvable pieces of work
vigilant about test coverage and code quality
curious adaptable and versatile able to create compromises in situations where there is not one right answer
not shy about making estimates and are always trying to get better at it
a leader not just senior in title
you have
3 years of production experience with data engineering
3 years of experience with cloud infrastructure
ability to model data and write sql
familiarity with testing a data application integration testing and processes that rely on cicd
familiarity with machine learning
a few benefits we offer
medical dental and vision coverage for all fulltime employees and their dependents starting on their first day of work
401k plan
paid time off and parental leave
annual conference budget
free drinks at any of our cafes and a complimentary bag of beans to take home each week
discounts on any blue bottle food items and merchandise
blue bottle is an equal opportunity employer we value an open mind dedication to work and a collaborative spirit we hire based on these qualities a job’s requirements our business’s needs and an applicant’s qualifications we do not tolerate discrimination or harassment of any kind—in the hiring process or in the workplace

we comply with the ada and consider reasonable accommodation measures that may be necessary for eligible applicantsemployees to perform essential functions if you have a disability or special need that requires accommodation please contact us at careersbluebottlecoffeecom

we may refuse to hire relatives of present employees if doing so could result in actual or potential problems in supervision security safety or morale or if doing so could create conflicts of interest

we will consider for employment qualified applicants with arrest and conviction records

we participate in everify we will provide the federal government with employees’ form i9 information to confirm authorization to work in the us we will only use everify once an employee has accepted a job offer and completed the form i9",,CA,False,data_engineer
Data Engineer II,"responsibilities
work within the structure of an agile  scrum development team
experience at working within all levels of the software development lifecycle from requirements through development and post production support
able to work within a fast pace release cycle using automated devops  ci technologies
expected to produce quality code in a timely fashion with high emphasis on testing using bdd and other automated unit testing practices
adhere to continuous practices to improve and meet code quality standards through code reviews and compliance with patterns practices and standards set forth on various projects
work well with other developers analysts and managers to understand business and technical requirements in order to develop friendly intuitive solutions that are easy to use while making practical sense of complex data
enthusiastic about learning and adapting to new technologies quickly
required skills
experience in full stack server side web development sql dal middle tier routes controllers apis
experience with the laravel php framework
experience in full stack client side web development
various js frameworks angular jquery etc
html5 css3 and preprocessors including responsive concepts such as bootstrap  flexbox etc
exposure in developing mobile based application as either native or in responsive web technologies or pwa’s
strong experience in oop in many languages both server side desktop and browser client is a necessity php python javascript
experience with restful api’s ajax  json  cors
experience with using git as a code repository  version control system
strong core understanding and experience in multitiered development patterns such as mvc mvvm etc
strong experience in multiple database concepts olap  oltp relational data and data warehouse concepts oracle plsql and sql server tsql
experience in other data persistence solutions nosql document db concepts
firm understanding of presenting complex data in a visually simplified reporting manner
experience in working in posix based environments oracle linux  rhel specifically
working with linux shell scripts is a plus
an understanding of web based networking concepts specifically an advanced understanding of http

qualifications

minimum requirements

college degree in a technical or a related field and 24 years professional level experience or 6 years professional level related technical experience or an equivalent combination of education and professional level related technical experience required",,AR,False,data_engineer
SOFTWARE DATA ENGINEER : 18-03932,"contractakraya is looking for a software data engineer for one of our client in oakland ca if the job description below is a fit please apply directly or call sushil at 4088162465 if this position is not quite what you’ re looking for visit akrayacom and submit a copy of your resume our team will get to work finding you a job that is a better match at one of our many clients

primary skills pythonjavascala spark aws redshift sql airflow
duration cth or direct fte
contract type w2 or c2c

responsibilities
design and build robust data pipelines using scripting in spark airflow python and sql
design data warehousedata marts in aws redshift and other databases as appropriate
use optimization techniques in data load and query processing
validate and build audit balance and control of missioncritical data pipelines
develop cool viz using tableau and other open source viz tools as needed
identify best data sources among multiple sources to use for data pipelines to improve trust in data
fix bugs work collaboratively with team members
what you bring to the team
masters or equivalent in csengineering or another comparable discipline
you have at least 6 years of technical experience and strong data warehouse  data modeling skills
need a person who can write high quality python code or java or scala along with spark
very strong skills in python sql spark redshift airflow aws
familiarity with agile methods we use agile tools
experience with reporting tools like tableau is a plus
team player agile highly accountable curious willing to learn implement and teach
ability to juggle multiple responsibilities and deliver to timelines
experience in the consumer lending industry required
bonus points
experience with open source tools such as kafka is a plus
experience in any jvm based language


please apply directly with your updated resume or call sushil at 4088162465

about akraya
akraya inc is an awardwinning staffing firm that works with many of the leading technologybased companies around the world we have been ranked as one of the “ best staffing firms to temp for” by staffing industry analysts on multiple occasions and are a preferred staffing vendor within numerous staffing programs please visit akrayacom to search through all",,CA,False,data_engineer
Python Developer/Data Engineer,"job title

data engineer


reports to

chief technology officer


location

jersey city



company

verisk maplecroft’s datadriven solutions enable multinational companies to identify and manage the key political human rights economic and environmental risks impacting their operations supply chains and investments

as part of the verisk analytics family we are aligned with the world’s leading data analytics organisation together we aim give our clients the insight they need to make better datadriven decisions through unrivalled analysis and advice

team profile

the technology team at maplecroft is responsible for designing developing and running the infrastructure and products that drive the company maplecroft is a datadriven company and the technology team sits at the heart of what we do were a small but capable team that values independent thought critical thinking and pragmatism

role purpose

this will be the first hire in a new data science team reporting into the cto we need someone to work with people and data sources across the business to consolidate aggregate and make sense of various types of data ranging from website analytics to structured api feeds from vendors to web crawls a few example projects that the successful candidate would work on are

1 customer engagement reports  dashboards to support the sales  marketing team pulling data from google analytics and our cms  entitlement databases to show who is or isn’t accessing what content

2 usage metrics for the research teams to better understand how customers are consuming their content using similar data to 1

3 using web scraping tools to assist research analysts with their work by aggregating and annotating a variety of news sources

4 working with data scientists in our analytics team to help them gather and process structured and unstructured data sets in support of their work

5 working with the software engineering and infrastructure teams to turn pilot projects from around the business into production applications

knowledge  experience

key skills are python programming and a working knowledge of range of databases we aren’t looking for a web developer though someone with that background would be well suited to the role specific technologies you will be expected to work with include
python
mysql
postgresql
elasticsearch
apache airflow
various http apis

 minimum 3 years professional experience

key competencies

issue identification problem solving  analysis
communication
planning implementation and control
building and maintaining relationships
collaboration
continuous improvement


maplecroft core values

maplecroft is a place where we are committed to supporting our people to grow and thrive we value different perspectives and aspire to create an inclusive environment which encourages diversity and fosters a sense of belonging

maplecroft values the contributions of each individual and helps them reach their full potential while sustaining an organisational culture of health and wellbeing

our core values are
respect for the individual
integrity
passion
persistence
confidence with humility
excellence
teamwork

we understand the importance of achieving balance between work family and other life commitments we are open to considering flexible working arrangements to enable the greatest spectrum of talent to contribute to our success

eeo statement

unsolicited resumes submitted to wood mackenzie by any external recruitment agency via internet email fax or us mail become the property of wood mackenzie and we are not responsible for any fees associated with those resumes

in compliance with the civil rights act of 1964 and 1991 the age discrimination in employment act of 1967 section 504 of the rehabilitation act of 1973 the americans with disabilities act of 1990 and all other relevant federal and state laws the policy of this company prohibits discrimination in employment because of race color religion national origin sex gender identity andor expression age veteran’s status disability genetic information or any other group protected by law applicants are considered for all positions without regard to race color religion national origin sex gender identity andor expression age veteran’s status disability genetic information or any other group protected by law

if you are a qualified individual with a disability or a disabled veteran you may request a reasonable accommodation if you are unable or limited in your ability to use or access woodmaccomcareers online as a result of your disability you can request reasonable accommodations sending an email to hrenquirieswoodmaccom

wood mackenzie is an equal opportunity employer mfvd and a member of everify

httpwwweeocgov",,NJ,False,data_engineer
Data Engineer (Spark),"130000  170000 a yearour client is looking for a savvy data engineer well versed in moving many tb of data per hour you will be working to design and create low latency data processing pipelines

required
scala spark hadoop
kafka redis nosql akka
java or python
etl pipeline development
high throughput data volume
why work here
generous salary and bonus package
unlimited pto
401k
free snacks breakfasts coffee
medical dental vision benefits",150000.0,NY,False,data_engineer
Big Data Engineer,"oath ad platforms is our unified ad tech solution for both advertisers and publishers our innovative ad tech gives one stop access to oaths trusted data high quality inventory and demand creative ad experiences and industryleading machine learning at global scale


the yahoo gemini team is developing nextgeneration technologies to enrich advertiser and user experience with ever growing and interesting data challenges we work on all yahoo user data  building the data pipelines and statistical data models to process billions of events and making machine learning work

we are looking for worldclass funloving big data engineers to join our team where you will have the opportunity to help develop low latency and large scale data systems you will analyze requirements investigate optimal software solutions architect design implement and test those solutions

minimum job qualifications

handson experience in developing scalable data solutions
proficiency in hadoop spark hive hbase and oozie technologies
handson experience in realtime query engines druid presto preferred
solid understanding of data structures and algorithms
strong in java and pig
good skills and experience in linux xml json rest
experience with faulttolerant system design and highperformance engineering
experience with machine learning algorithms andor statistical methods is preferred
able focus and deliver results in a fast paced and entrepreneurial environment
strong analytical and problem solving skills
bsms degree in computer science or industry relevant field



oath is proud to be an equal opportunity workplace all qualified applicants will receive consideration for employment without regard to and will not be discriminated against based on age race gender color religion national origin sexual orientation gender identity veteran status disability or any other protected category oath is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment please let us know if you need a reasonable accommodation to apply for a job or participate in the application process


currently work for oath please apply on our internal career site",,CA,False,data_engineer
Data Engineer,"contribute to the definition and refinement of processes and procedures for the data engineering practice work closely with data scientists data architects and other it and business counterparts to identify capture collect and format data from the external sources internal systems and the data warehouse to extract and profile features of interest contribute to the evaluation research experimentation efforts with batch and streaming data engineering technologies in the context of data projects assigned work with data engineering related groups to inform and showcase capabilities new techniques within data engineering assist the data architects in implementing the data architecture roadmap and related data projects
basic qualifications
problem solving aptitude
data mining and profiling proficiency in various techniques
sql knowledge
basic knowledge of data storage technologies relational big data nosql
familiarity with etl and data ingestion techniques
tableau or similar reportinganalyticsdashboarding ui tool experience
desired skills
strong communication and facilitation skills
strong interpersonal skills
presentation skills
learning agility in picking up business processes specific to aerospace and defense
knowledge of data modeling
knowledge of devops and agile methodologies
ability to work as part of a team to solve business process and data problems
basic qualifications
problem solving aptitude
data mining and profiling proficiency in various techniques
sql knowledge
basic knowledge of data storage technologies relational big data nosql
familiarity with etl and data ingestion techniques
tableau or similar reportinganalyticsdashboarding ui tool experience
lockheed martin is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex pregnancy sexual orientation gender identity national origin age protected veteran status or disability status
as a leading technology innovation company lockheed martin’s vast team works with partners around the world to bring proven performance to our customers’ toughest challenges lockheed martin has employees based in many states throughout the us and internationally with business locations in many nations and territories

join us at lockheed martin where we’re engineering a better tomorrow",,TX,False,data_engineer
Data Engineer - ETL/Data Modeling,contractdata engineer – long term contract or contract to hirewe need a data engineer to help our client on a contract and possibly contract to hire role in this role you will be working with a small team of data engineers to ultimately impact how our client makes crucial decisions this opportunity will suit candidates who enjoy working in a small team and enjoy seeing the impact of their workthis is a contract role and can either be a longterm contract position or a contract to hire rolekey technical requirements for the data engineerat least 5 years of experience with netezza or similar mpp toolsome data modeling experiencestrong sql skills ie writing queries joins etcpreferred technical skills for the data engineerexperience building custom etl’sany experience with new cloudbig data technologies like hadoop emr etcif youre interested in this role please email dave wilson at david  primeteampartnerscomprime team partners is an equal opportunity employer prime team partners does not discriminate on the basis of race color religion national origin pregnancy status gender age marital status disability medical condition sexual orientation or any other characteristics protected by applicable state or federal civil rights lawsjob type contractexperienceetl 2 years requirededucationbachelors requiredwork authorizationunited states required,,WA,False,data_engineer
Data Engineer,contracttitle data engineerlocation san jose ca locals only in person interview must no exceptionsrequired experienceskills 46 years of hands on experience integration engineer kafka storm javapython db utiltiesscripting batchstreaming etl experiences direct experience in building high volume data pipeline working with highly available systems handson  agile infrastructure hw fundamentals for installationsresolving osproduct conflictsjob type contractlocationsan jose ca requiredwork authorizationunited states required,,CA,False,data_engineer
Big Data Engineer,job summarytitle big data engineerlocation plano tx  75024w2 onlyresponsibilities and duties8  years of professional experience3 years of experience with big data technology and analytics3 years of experience in etl and elt data modelingexperience working with traditional warehouse and correlation into hive warehouse on bigdata technologiesexperience setting data modeling standards in hiveproficiency in using query languages such as sql hiveexperience with streaming stacks like nifi spark and pysparkexperience working with elk stack or solar indexingunderstanding of data governance bigdata security like kerberos rangerknowledge of setting standards around data dictionary and tagging data assets within datalake for business consumptionunderstanding of big data tools eg nosql db hadoop hbase and api development consumptionunderstanding of data preparation and manipulation using datameer toolknowledge of soa iaas and cloud computing technologies particularly in the aws environmentexperience with hadoophive spark and scoop highly desirableexperience in one or more languages eg python or java groovyexperience with data visualization tools like tableau power bijob type fulltimeexperiencedata modeling 3 years requiredbig data technology 3 years required,,TX,False,data_engineer
Staff Data Engineer - Streaming / Metadata,"

about the role


if youre passionate about building large scale data processing systems and you are motivated to make an impact in creating a robust and scalable data platform used by every team come join us you will jump into an early stage team that builds the data transport collection and orchestration layers you will help shape the vision and architecture of weworks next generation data infrastructure making it easy for developers to build datadriven products and features you are responsible for developing a reliable infrastructure that scales with the companys incredible growth your efforts will allow accessibility to business and user behavior insights using huge amounts of wework data to fuel several teams such as analytics data science sales revenue product growth and many others as well as empowering them to depend on each other reliably you will be a part of an experienced engineering team and work with passionate leaders on challenging distributed systems problems



about the team


data is at the core of our business providing insights into the effectiveness of our products and enabling the technology that powers them we build and operate the platform used by the rest of the company for streaming and batch computation and to train ml models were building an ecosystem where consumers and producers of data can depend on each other safely we thrive to build high quality systems we can be proud to open source and an amazing experience for our users and ourselves we regard culture and trust highly and are looking forward to welcoming your contribution to the team


responsibilities



to architect and design large scale data infrastructure in production performance reliability monitoring
youll design implement and debug distributed systems
thinking through longterm impacts of key design decisions and handling failure scenarios
building selfservice platforms to power weworks technology
focused on team over individual achievements
building software incrementally and make consistent progress
you love to learn mentor and teach others
youre empathetic you build longlasting relationship characteristic of highly efficient teams
you keep uptodate with the latest developments in the field


requirements



5 years programming experience with java scala haskell javascript
2 years experience in stream processing with flink spark storm or beam
experience with one or more of the following technologies
distributed logging systems kafka pulsar kinesis etc
batch processing spark hadoop …
idl avro protobuf or thrift
mpp databases redshift vertica …
query execution columnar storage push downs hive presto parquet 
workflow management airflow oozie azkaban 
cloud storage s3 gcs 
understanding of distributed systems concepts and principles consistency and availability liveness and safety durability reliability faulttolerance consensus algorithms
eager to learn new things and passionate about technology
experience with contributing to open source software a plus
experience with the following cassandra dynamodb rocksdbleveldb graphite statsd collectd a plus


about wework


wework technology is bridging the gap between physical and digital platforms providing a delightful flawless  powerful experience for members and employees we build software and hardware that enables our members to connect with each other and the space around them like never before

we augment our community and culture teams through the tools we build we believe theres a macro shift toward a new way of working—one focused on a movement towards meaning and purpose wework technology is proud to be shaping this movement

we are a team of passionate fearless and collaborative problemsolvers distributed globally with one goal in mind  to humanize technology across the world

we are an equal opportunity employer and value diversity in our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,CA,False,data_engineer
Healthcare Data Engineer,trinisys is looking for a healthcare data engineer to join our fastgrowing team this position will extract transform and load healthcare data into trinisys clearview® and epic cerner athena allscripts and other ehr  emr systems the successful candidate will possess solid sql skills in a variety of dialects ms mysql aws aurora and oracle experience working with healthcare data is required and indepth knowledge of at least one emr systems will be a factor in candidate selectionan inc 500 award winning company trinisys revolutionizes the way businesses collect and process information clients have drastically reduced the time and cost involved in acquiring data from paper and the web with trinisys’ innovative data capture software the trinisys integration engine enables companies to automate complex business processes and get data to the systems they use every dayhere’s your opportunity to be a part of a growing company that values individuals and their contributions the trinisys team is a tightly‐knit collaborative group of creative enthusiastic and thoughtful people trinisys offers an impressive benefits package great flexibility and an amazing working environmentwhat you’ll be doingextracting transforming and loading healthcare data to support data archiving and migrations between ehremr systemsanalyzing client requirements developing extraction and transformation plans and implementing those plansusing your judgment to recommend alternatives when appropriateworking as part of an agile team and contributing to the team on a proactive basiswhat’s in it for youbeing part of an expanding company recognized nationally for its growth by inc 500 and best place to work by the nashville business journal sharpening your skills as a member of one of the most talented organizations in nashville working in a laidback collaborative and fun environment unmatched benefits including healthdentalvision disability and life insurance plus a 401k with a company contribution and much morewhat you need to qualifybachelor’s in computer science computer engineering information systems or related fieldminimum of three 3 years of programming andor systems analysis experience are preferredbackground in technologies such as clientserver relational database management systems objectoriented and distributed object development a plusstrong technical skills around data access and transformation must have the ability to write complex sql queries firsthandminimum two years programming experience in jsp javascript and sqlexperience with hibernate and spring or similar frameworksexperience reverse engineering systemssuperior ability to analyze and manipulate clinical dataability to write technical specs and create diagrams such as data flow diagramsexperience with financialrevenue cycle data is a plussoft skillsmust have above good communication skillsmust feel comfortable communicating to groups and defending technical decisionstenacious problem solver with a consuming curiosity and facility with intellectual abstractionsphysical demandsthe physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job reasonable accommodations may be made to enable individuals with disabilities to perform the essential functionsthe employee is frequently required to reach with hands and arms the employee is occasionally required to stand walk and stoop kneel crouch or crawl the employee must occasionally lift andor move up to 10 pounds specific vision abilities required by this job include close vision distance vision and ability to adjust focuswork environmentthe work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions the noise level in the work environment is a quiet professional officetrinisys is an equal opportunity employerjob type fulltime,,TN,False,data_engineer
Data Engineer/Operations Research Analyst,"company name kroger general office
position type employee
flsa status exempt
line of business research  development
see what life is like at kroger technology
at httpswwwkrogercomlivekt

additional technology information
the operations research team and data science team is a worldclass data science team this team is dedicated to solving krogers biggest problems the team combines data science and data engineering skills to provide fullstack data science support to multiple highprofile initiatives we collaborate with multiple business partners including rd operations merchandising finance and hr to deliver stateoftheart data science solutions the team is looking for data engineers that are focused on datarelated tasks such as sourcing data ensuring data is clean and high quality administering etl workflows managing databases system administration and providing operational support to the team if interested the candidate could also have the opportunity to learn data science skills such as modeling simulation forecasting and machine learning and may transition into more of a data science role over time

position summary
the operations research analyst 1 will create detailed analysis operational recommendations and decision support tools through intense mathematical analysis collaboration with subject matter experts model design and development in order to maximize the benefit to the kroger co this position will provide assistance to operation research analysts and senior analysts on large projects collaborate with crossfunctional teams to deliver sustainable continuous improvement
essential job functions
assist in the initial definition of the problem statement and data requirements
understand and translate operational complexities
design and develop models to visualize the problem
assist in the creation of measurement systems to track project success and goal attainment
perform extensive analysis of the problem and outline possible solutions
test possible solutions utilizing operations research tools and techniques these techniques and tools include but not limited to mathematical optimization quantitative decision support simulation linear programming dynamic programming regression analysis cluster analysis queuing theory statistics forecasting data mining and project management
draw conclusions from previous tests in order to create new hypotheses
work independently and accountable for multiple concurrent projects while delivering accurate and appropriate findings
publish findings and recommendations to project team management and operations research peers
collaboratively develop plans to implement suggested improvements and confirm the plans are realized
create sustainable control plans for improvement efforts
participate in the approval of project closures and formal transition to the process owners
complete other assigned work as necessary
key contributor in the process improvement engineering activities within a crossfunctional design team collaborate in developing sustainable processes and solutions that drive manufacturing supply chain and instore efficiencies eliminate nonvalueadded activities and enhance our internal and external customer experience
consult with subjectmatter experts to develop potential business and technology solutions advise on impact to business processes
establish and maintain relationships throughout the enterprise with division associates manufacturing vendors logistics and storelevel personnel to understand document and define business strategies and processes current and future state
must be able to perform the essential functions of this position with or without reasonable accommodation
minimum position qualifications
bachelors degree babs degree in engineeringsciencesquantitative discipline or equivalent
minimum of 2 years experience with data collection and analysis
strong analytical and problem solving skills balanced by the ability to apply common sense
strong mathematics and statistical background
effective organizational skills and solid team background maintained through effective communication skills
the ability to travel independently as required
desired previous job experience
experience analyzing complex sets of data and developing recommendations andor publishing findings
experience in computer programming data visualization andor mathematical analysis
experience in retail supply chain andor manufacturing a plus
education level none
required certificationslicenses none
position type fulltime
shifts mfield4
states alabama alaska american samoa arizona arkansas california colorado connecticut delaware district of columbia federated states of micronesia florida georgia guam hawaii idaho illinois indiana iowa kansas kentucky louisiana maine marshall islands maryland massachusetts michigan minnesota mississippi missouri montana nebraska nevada new hampshire new jersey new mexico new york north carolina north dakota northern mariana islands ohio oklahoma oregon palau pennsylvania puerto rico rhode island south carolina south dakota tennessee texas utah vermont virgin islands virginia washington west virginia wisconsin wyoming
keywords

jobs at kroger at kroger we hire people who have a passion for helping others and who want to build a relationship with our customers no matter what stage of your career you can build your future at kroger we look for people who want more aspire to be more and work hard to achieve their goals our focus on keeping the customer first is what makes us successful as the largest traditional grocery chain in the us and one of the worlds largest retailers we employee nearly half a million associates across 35 states we offer many opportunities not only in our stores but in manufacturing logistics marketing finance human resources and many other fields

company overview
kroger family of companies employs nearly half a million associates who serve customers in 2782 retail food stores under a variety of local banner names in 35 states our family of companies also operates 2268 pharmacies 274 fine jewelry stores 1489 supermarket fuel centers and 38 food production plants in the united states kroger is dedicated to our purpose to feed the human spirit™ by serving america through food inspiration and uplift and creating zerohungerzerowaste communities by 2025 careers with the kroger co and our family of companies offer competitive wages flexible schedules benefits and room for advancement",,OH,False,data_engineer
Watson Health - Data Engineer,"job description
the ibm’s watson health business unit is now looking for talented individuals ready to usher in the next era of healthcare we live in a moment of remarkable change and opportunity the convergence of data and technology is transforming healthcare and life sciences organizations in every way


position data engineer
location cambridge ma boston or raleigh nc

job description
are you passionate about data and want to work with data scientist to solve realworld problems the ai data curation team develops and operates a data platform to ensure the utmost quality of our datasets that are used for training the next generation of ai solutions to enhance clinical decision making we’re looking for a senior data engineer to help design develop and manage elastic and highlyavailable data platform for the large volume of medical datasets

essential responsibilities
design and develop scalable data infrastructure for a large volume of medical data structured and unstructured from various sources in batch mode and near realtime
develop data ingestion integration transformation pipelines and manage data warehouses
work with data scientist to develop toolsautomation and build analytics capabilities to expedite the use of data for ai training purposes
develop tools to analyze large data sets and perform data verification data integrity and quality check
responsibilities will vary from developing and maintaining new data sets data warehouse development and generating reports on data usage access controls and performing data integrity checks
all team members are expected to contribute broadly with an agile and growth mindset

required professional and technical expertise
undergraduate degree in computer science or related field of study for software development
8 years of experience in building data platform data engineering or software engineering
software engineer skills in one more language java python data manipulation sql
experience in designing and building efficient and scalable solutions for big data
3 experience working with agile methodologies and cloud technologies
experience working with medical data and knowledge of any one or more of the following hl7 fhir dicom pacs vna emr epic cerner data anonymization
strong communication negotiation and consensus building skills when dealing with stakeholders and team members

preferred professional and technical expertise
have developed statistical models machine learning algorithms

required technical and professional expertise

undergraduate degree in computer science or related field of study for software development
8 years of experience in building data platform data engineering or software engineering
software engineer skills in one more language java python data manipulation sql
experience in designing and building efficient and scalable solutions for big data
3 experience working with agile methodologies and cloud technologies
experience working with medical data and knowledge of any one or more of the following hl7 fhir dicom pacs vna emr epic cerner data anonymization
strong communication negotiation and consensus building skills when dealing with stakeholders and team members


preferred tech and prof experience

have developed statistical models machine learning algorithms

eo statement
ibm is committed to creating a diverse environment and is proud to be an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion gender gender identity or expression sexual orientation national origin genetics disability age or veteran status ibm is also committed to compliance with all fair employment practices regarding citizenship and immigration status",,MA,False,data_engineer
Customer Success/Data Engineer,"80000 a yearsales engineer  customer success engineer  data engineer
leading edge data analytics saas provider is hiring for a sales engineer  data engineer to work in their customer success department if you enjoy working in a closeknit collaborative environment where everyone cares about each other and in turn the success of the company  then apply now

skills

strong customer focus with a solutionoriented attitude and mindset
excellent sql skills able to write sql code
background working with complex data sets and familiar with various reporting tools and products
familiar with various public cloud systems amazon aws microsoft azure google cloud
prior experience working for a startuplike environment

compensation  perks

salary ranging up to 80k depending on experience
medical  dental  vision
snacks unlimited coffee tea and other beverages
catered breakfast and happy hour team outings
casual and collaborative work environment

",80000.0,MA,False,data_engineer
Data Engineer - Operations,"about mapr technologies
mapr technologies a provider of the industry’s leading data platform for ai and analytics enables enterprises to inject analytics into their business processes to increase revenue reduce costs and mitigate risks mapr addresses the data complexities of highscale and missioncritical distributed processing from the cloud to the edge iot analytics and container persistence global 2000 enterprises trust the mapr data platform to help them solve their most complex ai and analytics challenges amazon cisco google microsoft sap and other leading businesses are all part of the mapr ecosystem for more information visit wwwmaprcom

data engineer operations
data engineers will report into mapr’s professional services organization mapr data engineers are responsible for delivering a variety of engineering services to mapr customers throughout north america assignments will vary based on the candidate’s skills and experience typical assignments may involve cluster sizing installation configuration health checks performance tuning data migration security and automation mapr’s growing customer base includes most of the fortune 50 companies which makes the work assignments technically challenging yet rewarding this role provides a significant opportunity to learn and apply big data technologies and solve related complex problems mapr data engineers report to the director of data engineering located at company headquarters in san jose ca
responsibilities
master the mapr converged platform including maprfs maprdb binary and json tables maprstreams and the hadoop ecosystem products and maintain proficiency and currency as the technology evolves and advances
achieve and maintain proficiency with mapr cluster and hadoop framework sizing installation debugging performance optimization cluster migration security and automation
achieve proficiency with mapr db binary and json tables sizing performance tuning and multimaster replication
achieve proficiency with mapr streams sizing performance tuning and multimaster replication
assist the sales team sales rep and sales engineer in positioning and selling mapr service products and service offerings
work closely with mapr sales in scoping and estimating customer professional service projects
write deliver and present formal sow’s statement of work
deliver sow content in formal handson onsite customer engagements and ensure the ontime delivery and quality of mapr professional service engagements
be a technical voice to mapr’s customers and technical community via blogs hadoop user groups hug’s and through participation at leading industry conferences
stay current in best practices tools and applications used in the delivery of professional service engagements
requirements
5 years experience administering any flavor of linux
strong scripting skills bash or python preferred
familiarity with commercial it infrastructures including storage networking security virtualization and systems management
devops background and familiarity with either ansible puppet or chef
proficiency in basic java or scala programming preferred but not required
2 years in a customer facing professional services software delivery role
bachelors degree in cs or equivalent experience
familiarity with hadoop and the hadoop ecosystem framework a significant advantage mapr is willing to train otherwise promising candidates
strong verbal and written communication skills are required
ability to professionally manage multiple priorities with minimal supervision and deliver on schedule
willingness to travel about 70
the ideal candidate will have anyall of the following
rhce certification bash or python scripting automation using ansible puppet or chef basic knowledge of hadoop hive or spark",,CA,False,data_engineer
Data Engineer,"sharpspring is seeking a talented data engineer to join our engineering team in gainesville fl our team is a group of dedicated individuals working to provide the best service possible to our customers using the most innovative solutions sharpspring provides excellent benefits and an engaging workplace with talented friendly coworkers
the data engineer will be responsible for the code and processes required to extract transform and load data into a data warehouse or data store and should possess knowledge of schema design concurrency api design mapreduce and aggregation this role represents an opportunity to directly shape and impact a newly created team within our business and bring fresh ideas to the table regarding our longterm data strategy
as a key member of our data team you’ll work across departments to assist with the provisioning analysis and interpretation of business intelligence data as it relates to the adoption of our flagship saas platform while also working alongside our development team to provide centralized access to data we use for realtime reporting inside of our application
you’ll also be responsible for evaluating the available ecosystem of big data tools and will advise our senior technical staff members regarding what tools best fit the needs of our organization upon completing our initial assessments of these tools you’ll assist with the implementation and deployment of the solutions we collectively decide upon

responsibilities
extract data from multiple data sources such as sql mongodb google analytics and other platform apis and load them into a centralized data warehouse to facilitate unified reporting
assist with the creation of dataflow pipelines–or a comparable technology–to regularly aggregate and summarize data sets for consumption by our application and other business intelligence tools
use scientific methods to work alongside other departments such as finance customer success and marketing to understand trends and key performance indicators affecting the health of our business
assist our product and development teams with data needs as they relate to our product development
create dashboards inside of sisense and disseminate reports across the organization
maintain data feeds for dynamic spreadsheets and other ad hoc reporting tools
provide consultation regarding big data toolsets and storage solutions
administer and maintain our data infrastructure
the person
degree in computer sciences mathematics statistics or a similar discipline
5 years of professional industry experience as a software engineer
experience with the design and operation of large distributed systems
expert in a programming language such as python or golang and their respective standard data processing libraries
strong working knowledge of relational databases and sql
extensive experience with at least one queueing system such as activemq sqs etc
rigor in high code quality automated testing and other engineering best practices
high level of comfortability with command line tools and data pipeline processing from a terminal
knowledge of build systems and version control systems such as git
strong background in statistical modeling methods
basic business acumen customer empathy and a team player attitude
excellent spoken and written communication skills
enjoys a fastpaced work environment and the challenges it brings
selfstarter with the ability to work independently take initiative and learn new skills",,FL,False,data_engineer
Data Engineer,"insidesalescom offers the sales industry’s first comprehensive sales acceleration platform that creates high performance sales teams with breakthrough technology and increases the revenue of their customers’ worldwide by applying our machine learning and innovative technology our product is pure technology supported by a predictive machine learning engine
insidesalescom is growing incredibly fast and is funded by some of the top venture capital firms as well as by salesforce and microsoft we have high expectations and have attracted great leaders who have enjoyed a similar ride elsewhere and are excited to be here
joining a fast growing company is a great way to accelerate your career we’re transforming how sales is done applying technology to revolutionize and modernize want to bet on your career and learn a lot come join us
engineering for scale
insidesalescom builds for the cloud deploying as a software as a service saas platform we have a portfolio of seven products and a large amount of data helping to provide automation insights and intelligence to sales organizations around the world you’ll learn about building a large scale platform of distributed microservices using cutting edge technologies you will learn how to build and scale data pipelines and data structures required for insidesalescom to continue to innovate and grow
we need you if you
 love a challenge – the best technology problems are those tackling really hard business and scaling problems
 delight in building scalable fast robust and elegant software in modular components
 are proud in producing high quality solutions and iterate until they are truly awesome
 learn constantly about new technology challenges and lessons from your mistakes
 cooperate in a team environment where you can learn from your peers and they can learn from you
many job descriptions read like a shopping list for the impossible at the core we’re looking for great software engineers technologies change but great minds transition that said the following set of qualifications are relevant and useful to the problems we’re solving
position responsibilities
 work closely with product owners senior engineers designers programmers and qa to deliver industryleading solutions
 responsible for constructing solutions based on customer requirements
 contribute to the implementation of major features and components from requirements and designs
 contribute to the creation of functional and technical specifications
 responsible for contributions in technical design task estimation implementation automated testing debugging and deployment
 participate as a productive member of an agile team of engineers
 produce high quality testdriven software
 assist in planning costing designing and testing
 communicate well with product managers customer support and other team members
 promote established standards processes procedures and tools throughout the software development life cycle
 work with large sets of data building systems to facilitate flow management and consumption of the data
 requirements
 bachelor’s or master’s degree in computer science or engineering or equivalent andor the ability to show us that you are a great engineer
 1 year of software development ideally with experience with data structures and pipelines
 a demonstrable track record of building great software
 oop web and services experience all the skills to build great distributed and complex systems
 database experience – both sql and nosql mongodb cassandra etc
 experience with queuing technologies including rabbitmq or kafka
 core knowledge of cloud services like aws or azure
 experience in building services and applications across some combination of nodejs go scala python c java
nice to haves
 history of working in small agile teams iterating to build great solutions
 ability to work in a linux environment
 web development skills in javascript preferably with react or angularjs
insidesalescom offers competitive compensation generous benefits including a matching 401k program healthcare insurance and reimbursement accounts as well as a gym membership and ongoing training  education programs",,UT,False,data_engineer
Senior Data Engineer,"senior data engineer

ww is looking for candidates to help change people’s lives we are a global wellness technology company inspiring millions of people to adopt healthy habits for real life we do this through engaging digital experiences facetoface workshops and sustainable programs that encompass healthy eating physical activity and positive mindset by drawing on over five decades of experience and expertise in behavioral science we build communities in order to deliver wellness for all to learn more about ww and jobs with a purpose visit httpwwwwwcomuscorporatecareers

collecting data from many unique sources we are strongly positioned to derive deep knowledge on our member’s behaviors using this data we can provide improved  personalized experiences for users as well as providing insights to the executive team that will drive the evolution of our company

to help us achieve our goals we are seeking data engineers to join our team
description
uniquely positioned to lead the way in the exciting healthtech industry ww is rebuilding most of our core experiences and embracing modern engineering practices and techniques
collecting data from many unique sources we are strongly positioned to derive deep knowledge on our member’s behaviors using this data we can provide improved  personalized experiences for users as well as providing insights to the executive team that will drive the evolution of our company
as we rebuild many of our core experiences we are seeking talented people who are excited to join our team this is a rare opportunity to join a company embracing a modern technology culture where you will have the ability to improve people’s lives in a very meaningful way and have a major impact on ww offerings to our members as reliance on health and wellness awareness increases you can be part of the team that is leading the way

to help us achieve our goals we are seeking data engineers to join our team

some of the opportunities this role has to offer include
work closely with our data scientists to help build complex algorithms that provide unique insights into our data
build data pipelines that clean transform and aggregate data from many different sources
develop models that can be used to make predictions
build complex functions that answer questions for the business
model data at rest and enable powerful data analysis
enable machine learning natural language processing and other data science methods within ww
work with engineers across the organization to identify data quality issues in source systems and help keep the data clean
provide solutions that help share data with the enterprise
be an advocate for best practices and continued learning
you should have
experience with a cloud data platform such as gcp or aws
if gcp big query cloud dataflow cloud dataproc pubsub
if aws redshift emr datapipeline rds lambda and kinesis
experience programming in scala python or java
experience building data pipelines using apache beam or apache spark
experience with some of the following data stores big query redshift postgres cassandra or mongo
it would be great if you also have
experience with real time streaming solutions such as kinesis pubsub or kafka
large scale data modeling from a modern big data perspective
experience producing and consuming event driven data
experience working on a data team building functions models and complex algorithms
we hire only the best people here are the benefits to being topnotch
the opportunity to work with some of the best innovators in the industry
generous healthcare coverage
401k with company match
paid time off
paid parental leave
tuition reimbursement
wellness allowance
profit sharing
ww is an equal opportunity employer ww does not discriminate on the basis of sex race color creed national origin marital status age religion sexual orientation gender identity gender expression veteran status or disability

any offer of employment is contingent upon the satisfactory results of reference and background checks",,NY,False,data_engineer
Data Engineer,"in order to apply for a position at lumeris you must create an account using your email address and a password of your choosing this account will allow you to receive notifications each step of the way through the job application process with these updates you’ll never have to wonder where you are in the process additionally we can easily send pertinent documents to you for your review once you create the account you may apply to any position you feel is a good fit without having to reenter information thank you for your interest in lumeris


position
data engineer


position summary
this is an exciting opportunity to join a firstclass technology team who is developing accountable delivery solutions for the healthcare industry the datab engineer will be responsible for developing analytical data solutions focused on healthcare cost and quality analytics the candidate will participate in all phases of the development lifecycle from initial requirements gathering and design through to coding and testing of our data solutions


job description
work directly with data scientists clinicians and other stakeholders to understand requirements and incorporate feedback through collaborative iterations of analysis development and testing
develop database solutions for all phases of data transformation including but not limited to data ingestion data cleansing data validation crud operations data enrichments etl etc on the microsoft sql server stack
translate business requirements into functional and technical specifications develop implement and test appropriate solutions
adhere to best practices and standards
provide documentation where needed
actively participate in agile sprint ceremonies standup retrospectives sprint planning etc


experience qualifications and education

strong analytical skills
35 years of working experience coding sql
motivated learner willing to learn new technologies including open source and cloud
selfstarter ability to identify actionable steps towards completing objectives
solid communication and interpersonal skills
bachelors degree in computer science or equivalent experience
process oriented ownership for projects and deadlines


experience in following areas is a strong plus
experience working with healthcare administrative claims or emrehr data
experience with the microsoft sql stack such as sql server and ssis
experience with source control tools and branchingmerging strategies
experience with automated code deployment tools jenkins bamboo
experience working with 1tb plus datasets

lumeris is an eeoaa employer mfvd


location
st louis mo


time type
full time


status
2  co",,MO,False,data_engineer
"Data Engineer II, Scientific Computing","strength through diversity
ground breaking science advancing medicine healing made personal

roles  responsibilities
the data engineer ii will focus on data collection movement storage transformation processing and storage of big data the incumbent will work with both current etldata warehousing and future big datastreamingpipeline architectures the focus will be on choosing optimal solutions to use for these purposes then implementing maintaining and monitoring them always keeping in mind the overarching goal of accelerating translational research and improving clinical care

duties and responsibilities
facilitate data collection from a variety of different sources getting it in the right formats assuring that it adheres to data quality standards and assuring that downstream users can get that data quickly and with a common standard interface
ensure that data streamspipelines are scalable repeatable and secure and can serve multiple users within the institute
develop as a core member of an agile team using agile tools and methodology work closely with other team members including application developers database developers and data scientists
responsible for creating the infrastructure that provides insight from raw data and handles diverse sources of data seamlessly
enable big data and batchrealtime analytical solutions that leverage emerging technologies
additional responsibilities include developing prototypes and proof of concepts for the selected solutions and implementing complex big data projects with a focus on collecting parsing and managing large sets of data using multiple platforms to allow for research and data science initiatives
translate business requirements into modern data pipeline solutions create centralized documents and diagrams of all solutions
creates a data catalog store of all metadata
designs and implements monitoring backup and disaster recovery of data systems
approaches all relationships with a worldclass customer service approach maintains a customerfocused approach with users to provide solutions that are scienceresearchdriven
responsible for the integrity and security of data in all forms of storage throughout the data architecture
work with other it professionals through mount sinai effectively comply with the institutional review board and hipaa to follow all applicable policies and procedures
assists in the development of standards and procedures affecting data management design and maintenance documents all standards and procedures
provides presentations and training to other team members in the above
extremely flexible attitude willing to work with multiple types of technologies and languages with an open mind and without technology bias continuous interest in updating skill sets and knowledge of trends in the big data technology space


requirements
bachelor degree in computer science or a related discipline advanced degree preferred
4 years relevant professional development experience preferably in a linux environment
proficiency with python development flexible to learn another language as needed  scala java andor c knowledge is a strong plus
experience with sql and nosql databases such as oracle ms sql server postgresqlmysql and mongo db or similar such as cosmosdb or dynamodb
experience in restful service development preferably with node js django and php
familiarity with the big data technology space and the ability to leverage a wide variety of open source technologies and tools knowledge of hadoop spark kafka and other big data technology stacks and streaming tools or related cloud service technologies on azure or aws
experience with configuration management software – ansible preferred puppet or chef or an equivalent awsazure infrastructure as code experience also experience with version control git
experience with installation and configuration of big data software and technology or equivalent cloud service technologies on azure or aws
experience working in an agile methodology

experience as a plus
working knowledge of cloud architecture and implementation on azure or aws is a big plus
experience with serverless computing eg aws lambda or azure functions creating vms cloud security and other cloud services is also a big plus
experience with microservices and soa is a plus
knowledge of healthcare data hl7 and mirth are also a big plus
strong skills in data structures datafile formats algorithms and object oriented design
experience working with jira is a plus


strength through diversity

the mount sinai health system believes that diversity is a driver for excellence we share a common devotion to delivering exceptional patient care yet we’re as diverse as the city we call home culturally ethically in outlook and lifestyle when you join us you become a part of mount sinai’s unrivaled record of achievement education and advancement as we revolutionize medicine together

we work hard to acquire and retain the best people and to create a welcoming nurturing work environment where you can develop professionally we share the belief that all employees regardless of job title or expertise can make an impact on quality patient care

explore more about this opportunity and how you can help us write a new chapter in our story

who we are

over 38000 employees strong the mission of the mount sinai health system is to provide compassionate patient care with seamless coordination and to advance medicine through unrivaled education research and outreach in the many diverse communities we serve

formed in september 2013 the mount sinai health system combines the excellence of the icahn school of medicine at mount sinai with seven premier hospital campuses including mount sinai beth israel mount sinai beth israel brooklyn the mount sinai hospital mount sinai queens mount sinai west formerly mount sinai roosevelt mount sinai st luke’s and new york eye and ear infirmary of mount sinai

the mount sinai health system is an equal opportunity employer we promote recognition and respect for individual and cultural differences and we work to make our employees feel valued and appreciated whatever their race gender background or sexual orientation

eoe minoritieswomendisabledveterans",,NY,False,data_engineer
Data engineer,"contractnew york ny

full time

mandatory technical skills

directing a team of engineers to design develop and implement data pipelines for business operational support analytical workflows and machine intelligence opportunities
identifying the right data sources establishing data modeling best practices and installingadministering or designing a data modeling tools
analyzing existing datasets creating requirements for incorporation into data flow pipelines as well logical and physical data models
establishing a continuous process for optimization by developing and enforcing data modeling best practices
facilitating the communication of the architecture design and project status to project stakeholders
providing business insight through integration of data with available machine learning and business intelligence tools
optimizing workflows so that they might be migrated into and out of public cloud infrastructure where sensible

desirable technical skills

need to bring in thought leadership and be innovative
need to keep pace with latest trends and technologies in analytics and visualization area

diverse lynx llc is an equal employment opportunity employer all qualified applicants will receive due consideration for employment without any discrimination all applicants will be evaluated solely on the basis of their ability competence and their proven capability to perform the functions outlined in the corresponding role we promote and support a diverse workforce across all levels in the company",,NY,False,data_engineer
Intern- Internet of Things Data Engineer,"internshipreq id 123929
micron technology’s vision is to transform how the world uses information to enrich life and our commitment to people innovation tenacity collaboration and customer focus allows us to fulfill our mission to be a global leader in memory and storage solutions this means conducting business with integrity accountability and professionalism while supporting our global community

as an iot data engineer intern within the data science department at micron technology inc in manassas va you will be part of a team responsible for expanding the facilities “internet of things” the primary role will be the setting up and analyzing new sensors and sensor data streams the data science team is responsible for transforming and analyzing enormous amounts of data generated by fab facilities and fab processing equipment

you will apply a mix of computer science mechatronics concepts to
device hardware and software setup
device hardware and software monitoring
documenting issues for tracking and improvements
conducting and managing small scale experiments with new sensors

qualified candidates will have
strong understanding of iot edge devices including sensors sensor modules and related boards raspberry pi odroids arduinos etc
an understanding of mechatronics basics with a good awareness of electrical engineering mechanical engineering and sensordatacollection
ability to prepare and format large sets of data
ability to visualize large sets of unstructured data
ability to troubleshoot edgenode devices at a basic level
good analytic and problem solving skills
excellent multitasking skills
strong written and verbal communications
previous experience in a semiconductor environment a plus
able to work inside a clean room when needed

education
in one of the following disciplines engineering computer science data science mechatronics

about us
as the leader in innovative memory solutions micron is helping the world make sense of data by delivering technology that is transforming how the world uses information through our global brands  micron crucial and ballistix  we offer the industrys broadest portfolio we are the only company manufacturing todays major memory and storage technologies dram nand nor and 3d xpoint™ memory our solutions are purpose built to leverage the value of data to unlock financial insights accelerate scientific break throughs and enhance communication around the world
we recruit hire train promote discipline and provide other conditions of employment without regard to a persons race color religion sex age national origin disability sexual orientation gender identity and expression pregnancy veteran’s status or other classifications protected under law this includes providing reasonable accommodation for team members disabilities or religious beliefs and practices
each manager supervisor and team member is responsible for carrying out this policy the eeo administrator in human resources is responsible for administration of this policy the administrator will monitor compliance and is available to answer any questions on eeo matters
to request assistance with the application process please contact micron’s human resources department at 18003368918 or 2083684748
keywords manassas  virginia usva  united states us  frontend manufacturing  entry  internship  engineering  not applicable ",,VA,False,data_engineer
Streaming Data Engineer,"tpc energy fund is a proprietary energy trading firm located in washington dc our business is primarily focused on the wholesale power markets we combine quantitative analysis fundamental knowledge of the grid cutting edge technology and regulatory knowhow to shape our success our team is young dynamic collaborative and results oriented we are looking for a candidate who can rapidly build and evolve our analysis and trading platform and who possesses the following skills

relevant research experience such as a phd masters or architect role in math computer science physics machine learning or a relevant quantitative field

35 years managing and optimizing large sets of data

ability to work with trading team and make creative suggestions for evaluating the data

knowledge of time series data classification and anomaly detection

excellent programming skills proficient in python go or java

aws experience andor experience architecting cloud based system

eager to conquer large sets of data and improve both our capabilities and speed of analysis

driven by solving complex problems

strong communication skills and a selfstarter

ability to learn from mistakes and make improvements

experience in the energy markets is preferred but not a must

apply now",,DC,False,data_engineer
Data Engineer,"a snapshot of what you would do

the data engineer possesses the knowledge necessary to collect store process and analyze huge sets of data the primary focus will be on choosing optimal solutions to use for these purposes then maintaining implementing and monitoring them data engineer will work closely with data scientists and is mainly in charge of architecting the solutions for data science and business intelligence projects

build data pipelines to pull together information from different source systems
integrate consolidate and cleanse data
structure the data for use in individual analytics applications
work with operations to understand all different pieces of information and learn how data is being captured in the business process
provide data in ready to use form for data scientists who are looking to run queries and algorithms against the information for predictive analytics machine learning and data mining purposes
work with business units and department to deliver data aggregations to executives and other end users for more basic types of analysis to aid in ongoing operations
generate meaningful data visualizations
research opportunities for data acquisition and new uses for existing data
recommend ways to improve data reliability efficiency and quality
troubleshoot data issues within analytics databases and presents solutions
 required skills

comprehensive knowledge of the following areas
sql programming in ms sql server or similar sql based database server to do data modelling data validation table building and data joins efficient indexing complex query building query optimization and analysis
ssis sql server integration services or other etldata integration tool
database management systems
programming in any of python java c c etc
fundamental knowledge of the following areas
bi tool such as powerbi tableau etc
knowledge data security practices
knowledge in microsoft excel
knowledge in data science tool is a plus r python stata etc
knowledge in natural language processing and text analysis is a plus
knowledge in rest apis is a plus
required experience

bachelors degree master’s degree is preferred in computer science softwarecomputer engineering applied mathematics physics statistics or related technology or quantitative field
two years sql script writing
one year in etl
one year programming
about us

apex analytix is a cloud based software and services company that works with over 200 of the global fortune 1000 to recover lost profits protect against procurement fraud and manage the process of supplier onboarding compliance and payment profit optimization we receive from our clients annually roughly 9 million supplier records and 46 trillion in invoices and payments we work with clients like the world’s largest retailer electronics company entertainment company financial institutions pharmaceutical manufacturers automotive manufacturers services companies and many others with shared services locations in the us uk and hong kong

delivering our solutions to the world’s largest companies has enabled us to develop what the world’s largest and most respected it industry analyst describes as possibly the only trusted source for accurate and high value supplier information we are making this apex data available to the world solution software developers enterprises and other entities through the launch of an ondemand api business model initially targeting global fortune 1000 companies our api service to this validated and enhanced “smartvm” data source is supplemented with over 400 realtime data sources through direct integration subscription and robotics in turn  our clients will have the trusted data they need to ensure compliance manage risk improve b2b transaction processing enable strategic initiatives predict outcomes and prescribe action if you want to be a key contributor creating and building the world’s only trusted api based supplier data brokerage solution …never seen before in the industry… this opportunity is for you

apex culture

our culture drives everything we live our culture of performance respect candor and fun—in that order performance is measured by delivering value to our clients generating goodwill trust and partnership sincere respect for each other our diverse backgrounds and our wellbeing are our cornerstones we value open and honest relationships with each other our clients and our communities and life is too short to not have fun we look for team players who possess the qualities of being humble hungry and smart we recruit candidates who will strive for accountability in performance and career growth serving fortune 1000 clients in longterm respectful relationships and working in a diverse and caring environment

perks

we owe our growing success to our team of bright passionate and innovative individuals we truly value our associates and strive to provide the highest quality benefits program offering competitive compensation packages with tailored bonus plans and generous benefits our benefits include health plans medical dental optical life insurance disability insurance fsa hsa employee assistance program supplemental insurance options and prepaid legal generous paid time off plan 401k plan flexible work schedules wellness programs company fitness and weight loss challenges financial wellness software tool and gym membership stipend associate and customer referral bonus programs and paid community hours and here at apex you won’t get lost in the shuffle our focus on internal training growth and development results in over a quarter of our open positions filled with internal promotions annually with resources such as a strong mentor program internal training portal education tuition and certification assistance we provide the tools for our associates to grow and develop if you are looking for a place to shine come join the team",,NC,False,data_engineer
Senior Data Engineer,"jetblack is the first portfolio company within store nº8  httpswwwstoreno8com  the incubation arm of walmart which is focused on transforming the future of retail jetblack is a membersonly personal shopping and concierge service that combines the convenience of ecommerce with the customized attention of a personal assistant our ultimate goal is to create a new standard of consumer shopping with the fastest most delightful endtoend consumer experience

our unique positioning as the first standalone company incubated by walmart gives us access to resources needed to have impact at massive scale and reinvent consumer shopping behaviors our journey has just begun and we are building a hardworking passionate founding team to join us changing the retail landscape and driving technical innovation

jenny fleiss the ceo and cofounder of jetblack previously cofounded rent the runway a business that has transformed the retail industry by making designer clothing rentals a convenient and accessible luxury experience for millions of women

about the job
data is core ingredient to our success in conversational commerce the data lake developed by the data engineering team will materialize our customer interactions in a flexible and powerful way that drives our experimental learnings product insights and personalization research our ultimate goal is to create a new standard of consumer shopping with the fastest most delightful endtoend consumer experience our unique positioning as the first standalone company incubated by walmart gives us access to resources needed to support datadriven learnings and the ability to have impact at massive scale and reinvent consumer shopping behaviors our journey has just begun and we are building a hardworking passionate founding team to join us changing the retail landscape and driving technical innovation

were blushing some of our favorite press links
httpswwwentrepreneurcomarticle314307  httpswwwentrepreneurcomarticle314307 

httpswwwinccomzoehenryrenttherunwaycofounderlaunchesjetblacktakesonamazonhtml  httpswwwinccomzoehenryrenttherunwaycofounderlaunchesjetblacktakesonamazonhtml 

you will love this job if you

are passionate about technology and motivated by building cool things that bring tangible value
thrive in loosely structured environments and help create increased structure as we mature
consistently deliver and have an appreciation for practices that keep you from slowing down
play well with others and want to work with and inspire other great engineers

what youll do

own the design and implementation of jetblacks production data lake as both a store of our schematized event logs and a central source of truth for business users and analysis
optimize dataflows to power our machine learning practice for research and live systems
own documentation and best practices around data materialization and usage
implement audit and anomaly detection logic to guarantee the reliability of data views
thoughtfully partner with product business intelligence and backend engineering to materialize new data products serve as an expert on data schemas and uses to the rest of the business

what you should have

46 years of industry experience
bs  ms in computer science or related field
experience with spark  flink  hive andor hadoop is a big plus
familiarity with a jvmbased language java  scala  clojure
prior work with textual data documentsemantic indexing and natural language analysis
experience with sql query optimization and rdms data modeling familiarity with nosql solutions a plus
experience with workflow schedulers airflow  oozie
previous work with microservices and containerization docker  kubernetes a plus
effective communication interpersonal and teamwork skills

pay perks  such

at jetblack we function like a startup and have the benefits of the largest retailer in the world walmart our benefit package includes a monthly gym stipend a generous parental leave program leading healthcare options 401k matching and more we offer unlimited vacation and a great culture filled with quarterly outings happy hours work out classes celebrations and clubs we host biweekly lunch n learns and weekly allhands meetings most importantly we empower employees to dig in and focus on solving big consumer problems join us",,NY,False,data_engineer
Data Scientist Spine (N902),"job description

the spine global product engineering team seeks an accomplished data engineer and aspiring data scientist for an exciting opportunity on the data team you will be involved with designing a new workflow for data science and analytics that are a big part of the roadmap for 2018 and implement workflow processes for data science projects that scale for data in the billions you will design large distributed technical solutions manage research projects resulting in real world project and data pipelines that support data products to start you will assist with but eventually lead data science poc projects
your day to day will include
the design and management of data pipelines using luigi or other etl system
uncanny ability to look at code identify bottlenecks and adjust through code refactor andor tuning spark parameters
writing java and scala applications for data processing and engineering
implementing standard and custom machine learning techniques across big data
facing challenging and complex business problems daily
the investigation procurement and ramp up to new technologies
collaboration and team work you enjoy fostering relationships and partnering with others daily and will work closely with the product management team

qualifications

we are looking for a talented team member who is also a delight to work with which usually includes
bachelors degree in mathematics computer science engineering statistics
data engineering experience in java python andor scala
accomplished in the design of efficient and robust etl workflows
a background in software engineering
clear understanding of web services
knowledge of big data architectures hivehadoop redis andor dynamo db
experience with sql andor nosql
excellent oral and written communication skills
a collaborative spirit and a drive to solve problems creatively
extra credit for implementing machine learning on parallelize infrastructure
got the goods we would love to hear from you
additional information

all your information will be kept confidential according to eeo guidelines",,NY,False,data_engineer
Data Scientist,"reed exhibitions rx is one of the largest trade show organizers in the world and is one of the four group companies within relx formerly reed elsevier which is a ftse 100 company as part of a set of csuite supported strategic programs that aim to use data to deliver the best of facetoface and digital services around trade shows a number of projects have been identified under the ‘data  analytics’ program the first of these projects is to globally rollout a single leadbadge scanning capability across 100s of rx 500 shows over the next two years
the opportunity here is to provide a consistent data platform for this data so exhibitors and visitors can easily access who they have met but additionally underlying business networks can be identified and understood to improve business outcomes for rx’s 7 million annual customers through the development of worldclass products and services in the b2b and b2c trade show space
the role
rx is putting together a project team for this and subsequent projects under the data  analytics program an important member of the team will be a data scientist who with a data engineer and product manager will make up the central team who will work with local show teams and business units around the world additional project resources will come from central it and 3 rd party agencies as required
the ideal candidate will be a ‘true’ multiskilled data scientist with a business leaning a genuine hybrid of computing statistical communication skills and business acumen combined with the imagination to see what and how data is currently or can be collected and then developed into new customer valued services
due to the semidecentralized nature of rx the following list of skills and personal attributes would be prized if these skills can be evidenced by past projects that would be ideal
statistical modelling eg general linear model survival models cox regression
hypothesis testing ideally for product development ab testing eg anova ttests chisquared mcnemar nonparametric methods
r or python script writing
understands data pipelines and can support strategic decisions on technology choices
restful apis usage ability to write them is desirable but not required
sql both ddl indexing when and why dml
experience in design and enhancing data models that have been used in production code
visualisation experience to include dashboards management or customer reports eg excel ggplot matplotlib shiny d3
 lilp1
reed exhibitions is an equal opportunity employer qualified applicants are considered for and treated during employment without regard to race color religion sex national origin disability status protected veteran status or any other characteristic protected by law if a qualified individual with a disability or disabled veteran needs a reasonable accommodation to use or access our online system that individual should please contact 18777341938",,CT,False,data_engineer
Data Engineer,"function engineering
career level senior professionals  5 years
legal entity evonik corporation
business line process technology  engineering


what we offer
you will work on exciting and challenging topics together with a team in an ultramodern innovative and creative environment intensive onthejob training with expert colleagues guarantees you will quickly become familiar with your duties and perform them independently performance related pay and the opportunity for personal and professional development are of course part of the package since 2009 evonik industries ag has been certified as a familyfriendly company by the german hertie foundation
we are seeking an individual in our mobile al location as an engineer in the area of manufacturing intelligence primary responsibility develop and implement tools to enable productivity gains through manufacturing intelligence


responsibilities
specific activities include but are not limited to
data aggregation from diverse sources including chemical process data
contextualization providing structures and models to support customers utilizing data supported by standards eg isa95
data analysis across data sources and plants
visualization of kpis through dashboards
propagation of data throughout diverse enterprise systems
provide technical assistance to the chemical processing facilities of evonik
facilitate exchange of knowledge between evonik plants in order to promote improvements company wide
participate in technology and methodology exchange between international regions
collaborate on a global basis with other departments within process technology  engineering
support development of new process engineering service offerings that provide value to evonik business lines


requirements
master’s degree or phd in computer science programming data processing or related field
minimum 35 years of it experience in fullstack systemsoftware design and programming
minimum 12 years of experience in data visualization and data analysis
aspiration to develop new solutions in the area of manufacturing execution systems andor manufacturing intelligence and to drive implementation across americas region
ability to utilize process documentation eg pfds pids equipment specifications
ability to utilize diverse data sources and associated applications eg plant information management systems laboratory information management systems enterprise resource planning systems
ability to planorganize tasks and consistently produce highquality results
ability to work efficiently and effectively in a multidisciplined crossfunctional environment including in teams
ability to work in international teams
flexibility to respond quickly to changing job demands and prioritize multiple responsibilities
experience managing projects involving complex scope
excellent communication skills both oral and written across hierarchy levels ranging from plant operators to management level",,AL,False,data_engineer
Data Engineer (Hbase & Spark),"overview
we are expanding our efforts into complementary data technologies for decision support in areas of ingesting and processing large data sets including data commonly referred to as semistructured or unstructured data our interests are in enabling data science and search based applications on large and low latent data sets in both a batch and streaming context for processing to that end this role will engage with team counterparts in exploring and deploying technologies for creating data sets using a combination of batch and streaming transformation processes these data sets support both offline and inline machine learning training and model execution other data sets support search engine based analytics exploration and deployment of technologies activities include identifying opportunities that impact business strategy collaborating on the selection of data solutions software and contributing to the identification of hardware requirements based on business requirements responsibility also includes coding testing and documentation of new or modified scalable analytic data systems including automation for deployment and monitoring this role participates along with team counterparts to develop solutions in an endtoend framework on a group of core data technologies
responsibilities
job duties
contribute to the evaluation research experimentation efforts with batch and streaming data engineering technologies in a lab to keep pace with industry innovation
work with data engineering related groups to inform on and showcase capabilities of emerging technologies and to enable the adoption of these new technologies and associated techniques
contribute to the definition and refinement of processes and procedures for the data engineering practice
work closely with data scientists data architects etl developers other it counterparts and business partners to identify capture collect and format data from the external sources internal systems and the data warehouse to extract features of interest
code test deploy monitor document and troubleshoot data engineering processing and associated automation
reporting relationship

data integration manager us
qualifications
knowledge
2 years of handson experience with sql data modeling and relational databases such as oracle db2 and postgres
1 years of experience with software engineering to include java scala and python
experience with processing large data sets with kafka rabbitmq flume hadoop hbase cassandra andor spark or similar distributed system
experience with nosql data stores such as mongodb cassandra hbase redis riak or other technologies that embed nosql with search such as marklogic or lily enterprise
bachelors or higher degree in computer science or other quantitative discipline or equivalent work experience
experience or familiarity with etl and business intelligence technologies such as informatica datastage ab initio cognos businessobjects or oracle business intelligence
skills
ability to quickly prototype and perform critical analysis and use creative approaches for solving complex problems
excellent written and verbal communication skills
work condition
work primarily in a controlled climate environment mostly stationary with occasional need to travel between nearby dfw office locations to visit business partner customers and attend meetings occasional travel to attend conferences or training for development pursuits",,TX,False,data_engineer
Data Engineer,"as a data engineer with tredence you will demonstrate ability to transform business requirements to code specific analytical reports and tools you will also provide business insights while leveraging internal tools and systems databases and industry data


the ideal candidate will

very strong engineering skills should have an analytical approach and have good programming skills
provide business insights while leveraging internal tools and systems databases and industry data
minimum of 5 years’ experience experience in retail business will be a plus
excellent written and verbal communication skills for varied audiences on engineering subject matter
ability to document requirements data lineage subject matter in both business and technical terminology
guide and learn from other team members
demonstrated ability to transform business requirements to code specific analytical reports and tools
this role will involve coding analytical modeling root cause analysis investigation debugging testing and collaboration with the business partners product managers other engineering team
must have

strong analytical background
selfstarter
must be able to reach out to others and thrive in a fastpaced environment
strong background in transforming big data into business insights


eligibility criteria

technical requirements

knowledgeexperience on teradata physical design and implementation teradata sql performance optimization
experience with teradata tools and utilities fastload multiload bteq fastexport
advanced sql preferably teradata
experience working with large data sets experience working with distributed computing mapreduce hadoop hive pig apache spark etc
strong hadoop scripting skills to process petabytes of data
experience in unixlinux shell scripting or similar programmingscripting knowledge
experience in etl processes
real time data ingestion kafka
nice to have

development experience with java scala flume python
cassandra
automic scheduler
rr studio sas experience a plus
presto
hbase
tableau or similar reportingdash boarding tool
modeling and data science background
retail industry background
education

bs degree in specific technical fields like computer science math statistics preferred",,CA,False,data_engineer
Data Engineer,"job summary

the data engineer is responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for crossfunctional teams the data engineer will create processes and data models to enable performance management reporting as well as data science advanced analytics and personalization efforts

 the data engineer will work closely with technology finance and commercial analytics to drive value through best in class data architecture and data model design

key responsibilities

act as data strategist responsible for the short and long term vision of data management warehouse performance and data architecture supporting both business intelligence and prescriptive analytics
partner with both internal stakeholders and external vendors involved in project definition design and planning and mapping the data journey from source through consumer data visualization application or predictive model
gather document and analyze business requirements establish and prioritize efforts to deliver data models that support business needs
design develop test and deploy data models data collection and transformation components determine best point for transformations calculations and joins eg data lake data warehouse or tableau data source
troubleshoot and support existing data workflow processes deliver fixes and optimizations where appropriate
work closely with cio chief architect and chief analytics officer on data governance and planning  ensure scalability and sustainability of business intelligence data architecture
required qualifications
2 years experience building data solutions including aws s3 emr and redshift tableau and tableau server
expert sql scripting skills r python or sas preferred but not required
ability to effectively build relationships across the business at all levels
selfstarter entrepreneurial highenergy who can take initiative in a fastmoving environment
strong technical understanding of current and emerging business intelligence and analytics technologies
 education

bachelors degree in technology computer science or data science preferred",,WI,False,data_engineer
Big Data Engineer (S&P Global Ratings),"the role

sp global ratings is looking for an experienced big data engineer to join data engineering team within chief data office a team of data and technology professionals who define and execute the strategic data roadmap for sp global ratings the successful candidate will participate in the design and build of sp ratings cloud based analytics platform to help develop and deploy advanced analyticsmachine learning solutions

the team
you will be an expert contributor and part of the rating organization’s data services team this team who has a broad and expert knowledge on ratings organization’s critical data domains technology stacks and architectural patterns fosters knowledge sharing and collaboration that results in a unified strategy all data services team members provide leadership innovation timely delivery and the ability to articulate business value be a part of a unique opportunity to build and evolve sp ratings next gen analytics platform

our hiring manager says

if you are an individual that brings demonstrated experience of delivering big data projects as a data engineer this is an excellent opportunity i am looking for someone with sound technical knowledge can be handson worked on transformational initiatives and can drive results

responsibilities
design and develop efficient and scalable data pipelines between enterprise systems and analytics platform
work closely with data science team and participate in development of feature engineering pipelines
provide technical expertise in the areas of design and implementation of ratings integrated data facility with modern aws cloud technologies such as s3 redshift emr hive presto and spark
build and maintain a data environment for speed accuracy consistency and ‘up’ time
support analytics by building a worldclass data lake environment that empowers analysts to determine insights into revenue and power products across the organization
work with the machine learning engineering team to build a data eco system that supports ai products at scale
ensure data governance principles adopted data quality checks and data lineage implemented in each hop of the data
partner with the chief data office enterprise architecture organization to ensure best use of standards for the key data domains and use cases
be in tune with emerging trends big data and cloud technologies and participate in evaluation of new technologies
ensure compliance through the adoption of enterprise standards and promotion of best practice  guiding principles aligned with organization standards
experience  qualifications
bs or ms degree in computer science or information technology
5 years of experience as data engineer at an innovative organization
3 years of handson experience in implementing data lake systems using aws cloud technologies such as s3 redshift emr hive presto and spark
expert managing aws services ec2 s3 route 53 elb vpc cloudwatch lambda in a multi account production environment
experience with machine learning libraries and frameworks tensorflow  mllib is an added advantage
exposure to r  sparklyr  and other r packages is a plus
experience with development frameworks as well as data and integration technologies such as informatica python scala
expert knowledge of agile approaches to software development and able to put key agile principles into practice to deliver solutions incrementally
monitors industry trends and directions develops and presents substantive technical recommendations to senior management
excellent analytical thinking interpersonal oral and written communication skills with strong ability to influence both it and business partners
ability to prioritize and manage work to critical project timelines in a fastpaced environment
financial services industry experience",,NY,False,data_engineer
Data Engineer,"american specialty health inc is seeking a data engineer i to join our information technology team this position will be responsible for delivering bestinclass analytical data solutions primary role will be participating in data curation projects and reporting system support and maintenance with opportunities to develop innovative solutions and explore new technologies
you are invited to learn more about american specialty health’s events on our events page
responsibilities
data curation projects and reporting system support and maintenance
participate in the entire lifecycle for business intelligence solution delivery
design build document and manage data warehouse objects
design and develop etl processing solutions
assist with bi solutions dbms ssis ssas ssrs tableau development and performance tuning
develop test and deliver error free data
stay abreast of bi industry best practices and relevant new technologies
design and develop reportsvisualizations using sql serve reporting services and tableau
perform requirements gathering and analysis
ability to work independently as well as within a team environment and unsupervised
ability to work a flexible day schedule required including occasional evenings
design and develop high performance reporting assets
work with smes both technical and nontechnical for knowledge transfer and documentation
work with endusers to support adoption of team deliverables
qualifications
bachelor’s degree or higher in computer science computer engineering mis or related field or equivalent work experience is preferred if equivalent experience high school diploma required
1 year or more of experience developing business intelligence solutions
3 or more years of experience developing solutions using the ms sql server bi stack
microsoft datarelated certification
basic knowledge of microsoft excel
recent working knowledge of a major bi tool tableau preferred
strong technical skills able to work with multiple platforms integrate data with various sources
strong problem solving and analytical skills able to think outside of the box on a consistent basis
willingness to learn new technology
basic knowledge of tsql
basic knowledge of data modeling
basic knowledge of data visualization practices and methods
core competencies
demonstrated ability to interact in a positive respectful manner and establish and maintain cooperative working relationships
ability to display excellent customer service to meet the needs and expectations of both internal and external customers
excellent listening and interpersonal communication skills to identify critical core competencies based on success factors and organizational environment
ability to effectively organize prioritize multitask and manage time
demonstrated accuracy and productivity in a changing environment with constant interruptions
demonstrated ability to analyze information problems issues situations and procedures to develop effective solutions
ability to exercise strict confidentiality in all matters
mobility
primarily sedentary able to sit for long periods of time with ability to travel within and outside the facility
physical requirements
ability to speak and hear other personnel andor objects ability to communicate both in verbal and written form ability to travel within the facility capable of using a telephone and computer keyboard ability to lift up to 10 lbs
environmental conditions
within facility normal office conditions including lighting and ventilation minor noise from conversations and general office equipment telephone printer etc when required to travel outside the facility usual weather traffic and related conditions are applicable
american specialty health is an equal opportunityaffirmative action employer
all qualified applicants will receive consideration for employment without regard to race color religion sex including sexual orientation and gender identity national origin disability protected veteran status or any other characteristic protected by applicable federal state or local law
please view equal employment opportunity posters provided by ofccp here
if you are a qualified individual with a disability or a disabled veteran you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability to request an accommodation contact our human resources department at 800 8483555 x6702
ash will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant however employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by the employer or c consistent with the company’s legal duty to furnish information",,CA,False,data_engineer
Market Data Engineer,"7730 an hourcontractimmediate need for a talented market data engineer that brings experience in market data platfroms this is a 1218 month  contract opportunity with longterm potential and is located in downtown nyc if interested please respond with the most current version of your resume referencing 1810513 in the subject line for information on similar positions please refer to the website below or simply request this info when sending replying with your resume

hourly rate 7730hr w2

key responsibilities
the new hire will be a member of the market data engineering team and will play a key role in facilitating the integration of market data technologies within the firm he she will also be involved in design and deployment of market data systems and services that will be used by the different business units in the firm

the candidate must have 710 years of experience in the design and implementation of large scale market data systems the position will involve working closely with senior technologists from the engineering operations and development communities so excellent communication and technical skills are a must

expert knowledge of industry standard market data platforms nyse technologies bloomberg reuters treprt

demonstrates key experience with low latency and enterprise market data systems

expert knowledge of consolidated and direct exchange feeds

solid understanding of network and os fundamentals

strong knowledge of system tuning performance and monitoring tools across os platforms

good working knowledge of linux and windows operating environments

mastery in configuration management frameworks like ansible

experience with cicd tooling like jenkins

understanding of the software deployment processes with a focus of standardization of global configuration and performance testing

develop performance and diagnostic tools to assist in debugging issues with market data systems

monitor infrastructure utilization and develop a capacity planning program

work closely with businessaligned teams to optimize market data usage and improve system design to satisfy the requirements of ultra low latency and high frequency trading applications

ability to plan prioritize communicate and perform tasks in a team environment

bachelors degree

experience with messaging middle ware tibco rendezvous 29 west

understanding of market data apis mama rfa bbg api v3

participate and contribute in design review sessions

work with market data vendors on new requirements and ongoing issues

regards

mary martini

diversant llc

recruiting manager

61 broadway suite 1702

new york ny 10006

mmartinidiversantcom

view all of our open job requirements on our home page httpwwwdiversantcom under job search if you know any it professionals who are looking for new job opportunities please pass along my contact information

diversant diversantcom is one of the largest africanamerican owned it staffing firms in the us we offer rewarding career opportunities with many of the nation’s leading corporations our experienced recruiters understand what hiring managers look for in a candidate and provide our applicants with the proper support and guidance along the entire application and interviewing process we offer opportunities on a contingent contracttohire and direct hire basis at diversant we are committed to providing the highest level of service and satisfaction to our customers consultants and employees

diversant provides equal employment opportunities eeo to all employees and applicants for employment without regard to race color religion sex national origin age disability or genetics in addition to federal law requirements diversant complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities",,NY,False,data_engineer
Sr Data Engineer,"purpose  overall relevance for the organization
this role will be responsible for designing engineering and scaling a “big data” data set analytical data asset in a designated area such as “customer” “quality” “plant” etc the role will be tightly interlinked to zf’s divisions  functions and it closely partnering with respective technical teams and data subject matter experts in the business to deliver a comprehensive data set synthesized from multiple data sources the principal data engineer will constantly seek to improve the predictive power of analytical data assets as well as support the digital monetization team in monetization of data and analytics

principal subject matter expert for data engineering
serve as the expert internal consultant for data engineering and its integration with enterprise it systems iot i40 data and analytics across all zf divisions and function
strong background knowledge and understanding of data engineering both in data center and cloud environments with traditional or modern stacks masters or similar level of accomplishment evidenced by patents or papers
proven track record of working across the enterprise and with it
data engineering management
serve as the single point of contact spoc for data engineering and analytical data assets in a designated functional domain
work with senior technology stakeholders to articulate opportunities for analytical data assets across the zf portfolio
identify and facilitate xdivisionfunction synergies and collaborative data engineering opportunities – deliver “whole is greater than the sum of the parts” in the designated area
manage the technical content education best practices and technical competency in data engineering and analytical data assets in designated domain
manage and oversee lighthouse data engineering initiatives
overall responsibility for achieving the quality outcomes of the lighthouse data engineering projects to create large scale analytical data assets in designated domain
develop modules and implementation patterns on the zf platforms to accelerate delivery of lighthouse analytical data assets and other capabilities
manage the transformational change
foster companywide commitment for analytical data assets as part of the digital strategy and prioritize initiatives per the company needs and align it with the overall strategy of the company
act as the ambassador within the company for digital transformation
act as a spokesperson in the external community helping zf positioning as a digital leader attracting highly talented workforce

key responsibilities


relationship management with divisionsfunctions to ensure buy in to internal analytical data assets
coordination work and relevant communication with other cross functional teams within the broader zf organization it rd … to assure seamless and “team beats silos” delivery
act as the change agent in building credibility for the digital organization by consistently delivering to business expectations
work with the internal teams digital labs digital factory … to maximize synergy
support the buildup of an efficient organization that allows for realization of zf’s digital goals
lead and manage necessary project teams to successfully deliver the stated objectives for lighthouse analytical data assets projects
use appropriate and effective communication methods to engage and manage stakeholder expectations
hands on development of the skeleton and key functions of the data pipelines and data wrangling required to deliver the analytical data assets in designated domain

authorities


technical leadership in data engineering
business relationship management
life cycle ownership for analytical data assets
responsibility for realizing stated objectives for data engineering


key relationships

divisional  functional technical leaders and data subject matter experts
project teams within the zf digital organization
project vendors for development
cross functional coordination with it rd

equal employment opportunityaffirmative action employer mfdisabilityveteran
job requirements
education requirements
a technical degree from an accredited college or university is required an advanced degree or equivalent technical standing

experience and skill requirements
demonstrated experience working both at either an oem or the supply base or equivalentpassion for technology with the requisite operations expertise and an entrepreneurial spirta builder not just a refiner who is versatile and agile in an evolving environmentminimum of 37 years of experience in data engineering with at least 3 years of technical leadership experience with functionwide responsibility preferably in a complex organizationstrong managing organizing and evaluating skills with a track record of developing and implementing a sophisticated endtoend data pipeline producing a “flat table” for advanced analytics and machine learningdemonstrated capability to communicate findings orally and visually to senior leadership members and outside partners and customers in the technology ecosystemdeep technical understanding of data engineering as well as a demonstrated track record of envisioning the application of these methods to achieve documented results in particular a demonstrated mastery of concepts such as “features” and their construction and “predictive power” and its quantificationability to impact outcomes via influence versus authorityeffective negotiation and influencing skills including strong written and verbal communication and strong presentation abilitiesdevelops loyalty and commitment in others by articulating an appealing vision for the future communicating high expectations and leading by examplea playercoach who is focused on mentorship and developmentcan “work the matrix” and gain credibility quickly with internal and external constituentsa technical degree from an accredited college or university is required an advanced degree or equivalent technical standing a pluscreative and organized problem solver who is passionate about driving strategy through technologystrategic mindset to maintain enterpriselevel vision while driving daily operational goals and controlsinspires heartfelt engagement a collaborator with the ability to influence and build consensusconsistently achieves results even under tough circumstancesclear and efficient communicatorleader and collegial team player with strong interpersonal skills balancing low ego with management capabilities",,MI,False,data_engineer
Data Engineer,"hi there we’re zipcar the world’s leading carsharing network driven to make cities better places to live

since 2000 we’ve worked hard to turn a brilliant and disruptive idea into a movement that serves more than a million members worldwide we’re keeping the pedal to the metal and growing every day that’s why we need talented passionate people with great ideas to join the zipcar family

want to work for a company that is shaping the future of urban mobility ready to join a dynamic playful diverse and respectful company that’s seriously changing the world then apply to learn more visit zipcarcom or zipcarcomcareers

summary

zipcar is seeking a data engineer that will be a leader in our efforts to leverage data about our members and vehicles so that we may continually improve the zipcar experience and support internal operations

responsibilities

responsibilities include but are not limited to the following

design and build scalable data infrastructure to support realtime analytics
manage data capture transformation and pipelines across our production applications and hadoop cluster
collaborate closely with data scientists and software engineers to deploy and scale machinelearning models into production
support the development of backend and frontend tools serving a variety of internal business processes and consumerfacing products
contribute to data architecture and technology decisions with expert understanding of data engineering best practices
use modern software tooling for rapid development integrated testing and high performance


qualifications

the successful candidate must have the following experience skills and education

bs in computer science mathematics statistics engineering or equivalent experience
experience and skill in data technologies including
hadoop distributions eg cloudera aws
data pipelines eg kafka  flume kinesis  lambda
data storage eg hdfs s3
data processing frameworks eg spark mapreduce
data querying eg impala redshift sparksql
programming languages eg java python scala
experience supporting datadriven products applications and features
excellent verbal and written communication skills


the ideal candidate has

experience with data storage and processing at scale
experience with geospatial data
desire to learn new tools frameworks languages
exposure to various software lifecycle tools such as git jira etc
a commitment to zipcar’s ideals of sustainable resource sharing and urban mobility


as a member of the zipcar team you get a great benefits package including health and dental insurance 401k vacation time paid holidays personal and sick leave along with a full complement of other insurance and support programs

because our work has a global impact we enthusiastically support each employee’s commitment to creating a better world by offering

free zipcar membership  discounted driving rates for you and your significant other
paid volunteer time off
bicycle commuter reimbursement
paid parental leave for mothers  fathers
training and development programs to accelerate career growth
global footprint of job locations and opportunities
flexible and open work arrangements
fun respectful passionate and collaborative environment
educational assistance program
company sponsored parties outings and events
discounts on a variety of products and services through zipcar partners
zipcar is an eeo employer
 to all recruitment agencies zipcar does not accept agency resumes please do not forward resumes to our jobs alias zipcar employees or any other company location zipcar is not responsible for any fees related to unsolicited resumes",,CA,False,data_engineer
Data Science Engineer,"sp global ratings is looking for an experienced data science engineer to join data engineering team within chief data office a team of data and technology professionals who define and execute the strategic data roadmap for sp global ratings the successful candidate will participate in the design and build of sp ratings cloud based analytics platform to help develop and deploy advanced analyticsmachine learning solutions

the team
you will be an expert contributor and part of the rating organization’s data services team this team who has a broad and expert knowledge on ratings organization’s critical data domains technology stacks and architectural patterns fosters knowledge sharing and collaboration that results in a unified strategy all data services team members provide leadership innovation timely delivery and the ability to articulate business value be a part of a unique opportunity to build and evolve sp ratings next gen analytics platform

our hiring manager says
if you are an individual that brings demonstrated experience of delivering big data projects as a data science engineer this is an excellent opportunity i am looking for someone with sound technical knowledge can be handson worked on transformational initiatives and can drive results

responsibilities
design and develop efficient and scalable data pipelines between enterprise systems and analytics platformwork closely with data science team and participate in development and deployment of machine learning models and feature engineering pipelinesprovide technical expertise in the areas of design and implementation of ratings integrated data facility with modern aws cloud technologies such as s3 redshift emr hive presto and sparkbuild and maintain a data environment for speed accuracy consistency and ‘up’ timesupport analytics by building a worldclass data lake environment that empowers analysts to determine insights into revenue and power products across the organizationwork with the machine learning engineering team to build a data eco system that supports ai products at scaleensure data governance principles adopted data quality checks and data lineage implemented in each hop of the datapartner with the chief data office enterprise architecture organization to ensure best use of standards for the key data domains and use casesbe in tune with emerging trends big data and cloud technologies and participate in evaluation of new technologiesensure compliance through the adoption of enterprise standards and promotion of best practice  guiding principles aligned with organization standards
experience  qualifications
bs or ms degree in computer science or information technology8 years of experience as data engineer at an innovative organization4 years of handson experience in implementing data lake systems using aws cloud technologies such as s3 redshift emr hive presto and sparkexpert managing aws services ec2 s3 route 53 elb vpc cloudwatch lambda in a multi account production environmentexperience with machine learning frameworks such as tensorflow  pytorch h2o scikitlearn theano caffe or spark mlib is an added advantageexposure to r sparkr sparklyr or other r packages is a plusexperience in constructing fast data staging layers to feed machine learning algorithmsexperience in building data apis to consume analytic model outputfamiliarity with machine learning model training and deployment process is a plusexperience with development frameworks as well as data and integration technologies such as python scala or informaticaexpert knowledge of agile approaches to software development and able to put key agile principles into practice to deliver solutions incrementallymonitors industry trends and directions develops and presents substantive technical recommendations to senior managementexcellent analytical thinking interpersonal oral and written communication skills with strong ability to influence both it and business partnersability to prioritize and manage work to critical project timelines in a fastpaced environmentfinancial services industry experience",,NY,False,data_engineer
Data Engineer,"job summary
reports to the manager business intelligence the data engineer will work under the supervision of the data architect to design implement and maintain data warehousing and data management solutions to support business reporting and analytical requirements this includes building source system data etl processes verifying data accuracy and designing complex interactions between data fields within the data management solution the data engineer will develop data set processes for data modeling mining and production and create custom software components and analytics applications additionally the data engineer designs develops and automates reports that communicate performance on valuebased reimbursement contracts strategic planningmarket analysis financial analysis and a variety of other business needs the data engineer is expected to anticipate business needs by designing and building custom queries and frontend reports that provide actionable insight to endusers

mission  vision

mission
to enhance the physical mental and emotional wellbeing of the communities we serve as the community’s provider of outstanding quality superior value and comprehensive health care services

vision
our vision is to achieve
innovative health care and wellbeing services of the highest quality at the greatest value
easy access and convenience
outstanding patient experiences
ongoing education involving physicians patients and the community

job specifications

education and experience
the knowledge skills and abilities as indicated below are normally acquired through the successful completion of a bachelors degree in information systems data analytics informatics database management business economics or a related field experience in data analytics programming or database management preferably in a healthcare setting is preferred

knowledge  skills
requires strong analytical skills with the ability to collect organize analyze and disseminate significant amounts of information with attention to detail and accuracy
requires a strong background in financial analysis and using data to support decisionmaking
requires indepth technical expertise regarding data models data analysis and design master data management metadata management data warehousing business intelligence and data quality improvement
requires proficiency in the use of structured query languages for building maintaining and extracting data from relational databases
understands relational database structure and is able to design and maintain robust custom database schemas
requires ability to research and implement bestpractice database management techniques
requires basic knowledge of the healthcare business needs including a basic knowledge and understanding of the healthcare revenue cycle and healthcare delivery systems
requires strong skills in organization and time management
demonstrates welldeveloped communication skills necessary to effectively communicate both verbally and in writing and work within the business intelligence team and with outside technical contacts
working conditions
works in an office environment
physical demands
requires the physical ability and stamina to perform the essential functions of the position

essential job duties

the below statements are intended to describe the essential job functions and level of work performed by individuals assigned to this classification they are not to be construed as an exhaustive list of all job duties performed by the personnel occupying this position

assists the data architect in designing maintaining and enhancing a systemwide enterprise data warehouse edw system by
designing building and maintaining etl feeds for new and existing data sources
ensuring ongoing accuracy of data etl feeds monitoring for changes in the source systems which may alter inbound data
building appropriate linkages and relationships between data fields within edw
creating and maintaining sourceoftruth relationship tables for key fields to be referenced throughout the edw
implementing a standard nomenclature for use within the edw in accordance with established business intelligence policies
documenting all metadata regarding data source field type definition etc for each field and table created
serving as a subject matter expert on data sources structure or definitions
working with members of business intelligence finance and information systems teams to optimize data and information usage
working with information systems teams to optimize the data warehouse through hardware or software upgrades or enhancements
structuring data in a way that is easy to understand query and display



provides information necessary to the financial and clinical success of beacon organizations by
collecting organizing analyzing and disseminating significant amounts of information with attention to detail and accuracy
creating analyses of strategic planning and market research data to provide insight to business development and growth opportunities for beacon health system
creating analyses of population health and valuebased reimbursement contract performance to determine future contracting opportunities and opportunities for improvement in cost or quality performance
developing designing and automating regular reports accurately and on a timely basis
designing and building adhoc reports that provide actionable and meaningful information
responding to analytics inquiries from various departments of beacon health system by identifying data that will provide appropriate and actionable answers
identifying analyzing and interpreting trends or patterns in complex data sets and connecting those trends to actionable insights and business needs
interpreting reports or contractual language to analyze the impact on beacon’s overall operations and financials
communication of strategic priorities to beacon departments based on insights gleaned from data analytics

assists the business intelligence team in planning for the evolution of beacon’s data management initiative by
providing input into strategic direction and decisions for the business intelligence department
researching new data management techniques or best practices
actively promoting and supporting a culture of datadriven decision making within various departments of beacon health system this may include innovative data visualization and data science methodologies
completing all other duties as assigned

standards of behavior
patientcustomer centered
anticipates and takes proactive steps to ensure customer’s needs are met
places courtesy and service above routine and goes beyond customer expectations
keeps patientwork environment neat and clean
understands and applies jobrelated aspects of patient safety and identifies reports and corrects safety concerns as quickly as possible
respect
keeps others well informed
practices active listening
develops and maintains positive working relationships
uses problem solving techniques to resolve issues and makes decisions within personal sphere of influence
seeks to understand patients experience
integrity
demonstrates integrity and strong business ethics
utilizes time and resources in a prudent manner
strives to continually improve department processes and services
projects professional image through enthusiasm towards work behavior and appearance
compassion
demonstrates beacon values verbally and through actions
displays and exhibits caring behaviors with each interaction
demonstrates selfawareness and sensitivity to the perceptions of others
listens carefully to input and concerns and takes appropriate action
interacts with dissatisfied customers in a calm respectful manner and seeks resolutions
trust
maintains confidentiality at all times
fosters a sense of trust and collaboration among associates
verbal and written communications are clear and effective
responds to change in a positive manner

organizational responsibilities

associate complies with the following organizational requirements
attends and participates in department meetings and is accountable for all information shared
completes mandatory education annual competencies and department specific education within established timeframes
completes annual employee health requirements within established timeframes
maintains licensecertification registration in good standing throughout fiscal year
direct patient care providers are required to maintain current bcls cpr and other certifications as required by positiondepartment
consistently utilizes appropriate universal precautions protective equipment and ergonomic techniques to protect patient and self
adheres to regulatory agency requirements survey process and compliance
complies with established organization and department policies
available to work overtime in addition to working additional or other shifts and schedules when required

commitment to beacons sixpoint operating system referred to as the beacon way
leverage innovation everywhere
cultivate human talent
embrace performance improvement
build greatness through accountability
use information to improve and advance
communicate clearly and continuously",,IN,False,data_engineer
Data Engineer / Data Systems Architect,"about bark
bark is a company building products experiences and entertainment for dogs and the people who love them the lasting brand that disney has built for kids and families bark is building for the fastgrowing market of dog people

our ambitionlevel is high the opportunity is huge and our love for dogs is through the roof we launched in 2011 with barkbox a monthly themed subscription of allnatural treats and clever toys since then weve shipped more than 50 million toys and treats to the dogs across the world and use all of that direct customer feedback to inform new initiatives and ways to make dogs happier

but what kind of company is bark its a company that has gone to the dogs we are committed to a culture that is open inclusive generous and enthusiastic — just like our pups united by this dogobsession we embrace diversity of all stripes and spots if your camera roll is 90 pictures of your dog you belong here

at bark we know that dogs arent pets theyre family our people – crazy dog people – believe that their dogs deserve the best the best treats the best toys the best seat on the couch together were driven to be the people our dogs think we are

who were sniffin for
can you give a pup belly scratches until you get carpal tunnel listen to squeaky toys until your ears bleed bark is a fastgrowing business for people who love ruv dogs

as data engineer  data systems architect at bark you will design and build our systems for ingesting and processing data to address data integrity data security and data scaling  both in size and complexity your end users will be data scientists and analysts who will rely on these systems to deliver accurate data for reporting and analysis as we ingest data from multiple external sources and internal sources with frequent upstream schema changes a strong engineering background with an eye for generalizability and abstraction will be key for this role

doodies

productionizing existing etls dashboards pipelines and models to produce reliable outputs that maintain consistency in data definitions
implementing and maintaining a data warehousing solution with finegrained access control and security levels to adequately protect sensitive data
implementing software and platform services that empower analysts and data scientists to more efficiently automate and share analytical work product
providing technology guidance to data scientists and analysts as needed for larger

experience

we are looking for a passionate and experienced technologist with the following competencies


expert in at least one programming language comfortable with learning new ones
adept at picking up new technologies and evaluating them against business requirements
strong experience with traditional relational databases including writing sql schema modeling performance tuning and query optimization
understanding of data technologies algorithms and design patterns
experience working with data frames with a passion to grow in this area
comfortable with data structures distributed systems and fault tolerant systems design
excellent grasp of aws and cloud computing
selfstarter positive attitude with an emphasis on supporting the team and achieving long term goals

bonus points

the data engineer  data systems architect need not possess these skills on day 1 but would be encouraged to grow into many of these areas over time and recognized as an especially strong applicant if any of these points were met


heroku postgres redshift airflow nifi sqs lambda spark docker
experience implementing microservices
strong competency in data and systems security
experience integrating with saas tools such as netsuite zendesk

this position is a fulltime salaried position it is located onsite at our office in new york ny we offer health insurance for both you and your pup 401k wonderful team lunches unlimited pto and a dog to pet anytime you wish",,NY,False,data_engineer
Data Engineer,"key role
design implement and manage databases and data delivery systems and transform it into beautiful insights analysis and reporting comprehension of database design and implementation tools including entityrelationship data modelling and sql distributed computing architectures operating systems storage technologies memory management and networking enables you to create structure and value out of complex and ambiguous technical challenges with little guidance

basic qualifications

experience with structured and unstructured data streaming and batch data processing etl data wrangling data ingest and data access
experience in a professional work environment
knowledge of sql python and data engineering fundamentals
ability to work with databases to extract and transform data
ability to obtain a security clearance
ba or bs degree

additional qualifications

experience with hadoop is a plus
knowledge of cloud services including aws and azure
ability to work in a fastpaced environment

clearance
applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information

we’re an eoe that empowers our people—no matter their race color religion sex gender identity sexual orientation national origin disability or veteran status—to fearlessly drive change",,VA,False,data_engineer
Data Engineer,"about the valuebased care solutions group
valuebased care solutions group is a leading software provider that leverages technology and analytics to help healthcare providers across the continuum of care effectively manage their financial clinical and human capital workflows offering a comprehensive suite of innovative technologyenabled solutions the company aims to improve quality increase efficiency and reduce waste in the healthcare industry veritas capital a leading private equity investment firm with significant experience in the healthcare technology space acquired valuebased care solutions group from ge healthcare in july 2018

position overview
the data engineer will work on data structure implementation both relational and nonrelational this is a handson position which is responsible for working with software engineering teams support as well as clients below are the responsibilities for this role
fine tune and optimize database performance by tuning the queries and troubleshoot databaseprogramming objects
advocate for database best practices and engineering excellence
provide internal and external database support
create and maintain automated tests and other utilities for testing database systems
coordinates conversion and migration of existing or legacy databases to next generation dbmss
educate others on database techniques and technology by providing guidance and learning sessions
analyze problems develop solutions and provide support to application analysis development and client support teams
provide basic database modeling services for engineering team
support and maintain data and database systems to meet business delivery specifications and needs
lend support to various business and technology teams as necessary during design development and delivery to ensure solid scalable robust solutions
data warehouse database development and administration including schema design etl process monitoring performance querydatabase tuning and backup strategy
help identify best practices for standardization of data names definitions usage and structures and maintenance
configure monitor and tune database software and systems
configuration management and environment setups including file organization indexing methods and security procedures for system databases
create and maintain backup and recovery plans
install and upgrade database software
maintain database servers by installing patches and checking for hardware issues

qualifications and education requirements
5 years of experience in a data engineer or database administrator role
bachelor degree in computer science statistics informatics information systems or related field
effective presentation and training skills
experience with microsoft and windows applications including work excel and powerpoint
ability to prioritize and multitask between multiple projects and tasks
experience with windows and linux operating systems
ability to effectively manage daytoday tasks  activities in coordination with the engineering team to effectively meet the deliverables and schedule of a data solution component within a larger application project
ability to work independently when needed
must be able to communicate well with teams team oriented
experience with agile practices serviceoriented environments and better development practices
knowledge of innovation methodologies and tools
continually strives to selfeducate and learn new skills and tools
can perform the role of a database administrator
intermediate knowledge of tsql ability to author queries and procedures for databases
intermediate knowledge of etl packages ability to author etl packages and write data transformation scripts
intermediate knowledge of analysis services cubes ability to create and maintain analysis services cubes
intermediate knowledge of microsoft sql server data services integration services and analysis services
intermediate knowledge on sql clustering sql replication and sql encryption
intermediate knowledge of other database systems including mysql and oracle
understands other database systems and can speak intelligently about them and leverage other techniques to provide value to a teamenterprise
at vvc holding corp we believe that diversity fuels innovation vvc holding corp is committed to equal employment opportunities regardless of race color genetic information creed religion sex sexual orientation gender identity lawful alien status national origin age marital status nonjob related physical or mental disability or protected veteran status we support an inclusive workplace where associates excel based on personal merit qualifications experience ability and job performance",,WI,False,data_engineer
LE Big Data Engineer,"who we are

fueled by a fundamental belief that having access to financial services creates opportunity paypal nasdaq pypl is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy our open digital payments platform gives paypal’s 244 million active account holders the confidence to connect and transact in new and powerful ways whether they are online on a mobile device in an app or in person through a combination of technological innovation and strategic partnerships paypal creates better ways to manage and move money and offers choice and flexibility when sending payments paying or getting paid available in more than 200 markets around the world the paypal platform including braintree venmo and xoom enables consumers and merchants to receive money in more than 100 currencies withdraw funds in 56 currencies and hold balances in their paypal accounts in 25 currencies
when applying for a job you are required to create an account if you have already created account  click sign in
creating an account will allow you to follow the progress of your applications

note
provide full legal first namefamily name
do capitalize first letter of first and last name example john smith
dont capitalize entire first andor last name example john smith
note use correct grammar for names with multiple cases example mcdonald or oconnell

provide full address details
resume is required
multiple attachments can be uploaded including resume and cover letter for each application


job description summary
does it excite you to work on systems that process billions of dollars in payments per year in 195 countries how about making an impact on 200 million paypal users around the world


paypal core payment is looking for a talented creative and passionate engineer to help automate and operationalize payments data for business processes and insight as a selfmotivated and enthusiastic member of our team you will work with extremely talented peers in a fun environment building performance efficient highly scalable configurable and available systems you will work in an agile environment with a focus on problem solving and engineering excellence

job description
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
create and maintain optimal data pipeline architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and big data technologies
execute and automate extract transform  load operations on large datasets
work with stakeholders including the management product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
keep data separated isolated and secured
participate in establishing best practices while team is transitioning to new technologies tools and infrastructure
recommend and implement process improvements
maintain specifications and metadata follow and develop best practices
coach and technically train new hires if needed
prepare and review operational reports or project progress reports
assist in the daily operations of the architecture team a functional unit within the business intelligence group analyzing workflow establishing priorities developing standards and setting deadlines
continued growth as a technical expert in data integration technologies and solutions
work with cross functional operations teams such as systems storage and network to design technology stacks
exhibits strong business knowledge and builds strong customer relationships



skills required

510 years of experience of the eco system such as schedulers databases
 linuxunix systems etl plsql python other etl tools
experience in exception remediation flows in informatica workflows and scripts
data warehousing experience data models database design etc
practical experience with git
comfortable working with open source tools in a unixlinux environment
comfortable handling large amounts of data
works independently without the need for supervision
experience with hadoop environment hivepresto is a plus

subsidiary
paypal

travel percent
0

primary location
san jose california united states of america



additional locations






were a purposedriven company whose beliefs are the foundation for how we conduct business every day we hold ourselves to our one team behaviors which demand that we hold the highest ethical standards to empower an open and diverse workplace and strive to treat everyone who is touched by our business with dignity and respect our employees challenge the status quo ask questions and find solutions we want to break down barriers to financial empowerment join us as we change the way the world defines financial freedom


paypal provides equal employment opportunity eeo to all persons regardless of age color national origin citizenship status physical or mental disability race religion creed gender sex pregnancy sexual orientation gender identity andor expression genetic information marital status status with regard to public assistance veteran status or any other characteristic protected by federal state or local law in addition paypal will provide reasonable accommodations for qualified individuals with disabilities",,CA,False,data_engineer
Master Data Engineer (Partial Remote),125000  155000 a yearsan francisco based series c data analytics company is now expanding to their 4th location and have chosen pittsburgh and one of the first few hires they are looking to make for that office is 2 master data engineers ideally folks who are adept with postgres andor rdbms python programming strong with sql programming and quires coming from an opensource environment working with linux based systems and ideally a background with aws and elastic search as mentioned this person will be one of the first employees hired in the pittsburgh office and will have an aggressive growth path and eventually be building out teams around them thus leadership qualities are important as wellkey qualifications3 years of experience and strong understanding of rdbms concepts query optimization etc2 years of experience in programming with pythonexpert level sql programmingexperience utilizing open source technologies in a linux environment preferable with centos in terms of flavorbachelors or above in the fieldleadership experience and qualitiesfamiliarity with linuxunix work environmentbackground using modern etl toolspreferred qualificationsbackground working in a fully hosted aws environment andor experience with awsexperience working for a startup or midsized companyexpert level elastic search experiencethe offer up to 155k year salarydoehealth dental visionlife insurance401k with 4 matchpaid holiday and vacationequityjob type fulltimesalary 12000000 to 15500000 yearjob type fulltimesalary 12500000 to 15500000 yeareducationbachelors preferred,140000.0,PA,False,data_engineer
"Data Engineer, Software Solutions","as the data developer software solutions you will use your talent for data focused development to support the architectures and procedures of horizon media’s institutional data warehouse this may include etl procedures for data sources development of the core data lakes data marts or the data warehouse itself knowledge of data preaggregated data structures olap and unstructured data nosql is required previous experience with adtech or martech data sources is desirable

responsibilities
strategybusiness

knowledge of complex event processing cep models for streaming andor near real time nrt data updates
experience with topic creation using stream processing tools such as kafka andor map r streams
development expertise with lambda architecture models including hadoop apache flink apache spark or similar
ability to provide batch processing direction when coupled with lambda nrt processing
deep knowledge of coding sql rdbms structures including functions tabular  scalar stored procedures inmemory processing objects etc
knowledge of mdx olap query language and familiarity with processing with tuples
expert in query path and execution analysis with focus on performance optimization
ability to logically troubleshoot existing routines quickly and resolve identified issues
adhere to defined structure policies including naming conventions population of
routine headers code comments etc

collaborate with software solution team members and other staff to validate
desired outcomes for code prior to during and post development

provide unit testing on anyall deliverables
propose innovations to existing procedures to provide better user experiences
with data routine
communications
communicate with integrations analysts business consultants and the ad media technology  data software solutions to update status on current projects convey issues encountered and educate them on determined issue resolutions
communicate material enhancements to data structures or processes and convey the value of these changes to the business users

qualifications
5 years experience working with large volume “big data” storage and processing
challenges

well versed in lambda architecture design and implementation
proficient in the object oriented programing concept and design patterns
familiar with soap and rest full protocol
experience with multi threadprocess programming
works well in a continuous build and unit testing model
bsba degree in computer science statistics mathematics or related field or
equivalent experience masters degree preferred

desired not required knowledge of the media transactional process order of
operations financial procedures and dependencies across all media channels

desired technology
office
ms excel
ms powerpoint
ms project
ms visio
database
ms sql server
mysql
kafka
aws redshift
hadoopflink
olap
ssasssis
bids
mdx

visualization
one or more
tableau desktop
qlikview
jaspersoft

media
sizmek
doubleclick
strata
coremedia
omniture

certificates licenses and registrations
none

physical activitywork environment
none

additional information
infrequent travel may be required 10

the statements herein are intended to describe the general nature and level of work being performed by employees and are not to be construed as an exhaustive list of responsibilities duties and skills required of personnel so classified furthermore they do not establish a contract for employment and are subject to change at the discretion of the employer",,NY,False,data_engineer
Associate Business Data Analyst,"the hartford’s data asset management organization is seeking entrylevel talent to build careers in data in hartford ct in this role associates will grow in the business data analysis track providing analysis reporting and research support for the hartford critical data assets associates will participate in the entire software development lifecycle process in support of information data projects and grow with emerging technologies and processes

overall knowledge

you must be a team player with a positive ‘can do’ attitude and possess the following qualities
interest in data analytics technology and problem solving
excellent communication analytical interpersonal and organization skills required
organizational and time management skills with the ability to adjust to changing priorities in a fastpaced environment
entrepreneurial mindset
responsibilities
leads planning sessions with clients and team members to solicit business requirements
responsible for writing business requirements obtain signoff from business partners and develop test cases
will serve as point of contact with business partners and communicates project plans resource estimates and performs status reporting
coordinates testing of reporting solutions reinforcing use of testing principles and processes
analytical thinking and problem solving abilities and ability to manage multiple projects and customer expectations
ability to work independently on multiple projects with varying levels of priority
work and collaborate closely with our it counterparts
involved in the creation of use cases with the business verification of data business training and educate business partners on impacts of development decisions and data issues
ability to adapt to change and willing to learn and develop new skill sets as applicable
ability to work and communicate effectively with both business and technical communities
ability to network and influence across the organization at all levels
effective selfstarter with a cando attitude who takes ownership and accountability for project deliverables with a demonstrated ability to multitask
qualifications
qualifications
bachelors degree – seeking december 2017 and may 2018 grads
a desired cumulative gpa of 30 or higher out of 40 scale or equivalent at the time of graduation
desired majors include but are not limited to computer science engineering it management information systems data analytics applied mathematics and business
desire candidates with prior data analysis andor data engineer competencies
understanding of current and emerging it products services processes and methodologies
prefer working knowledge of etl process and experience with sql


equal opportunity employerfemalesminoritiesveteransdisabilitysexual orientationgender identity or expression

higclg
job function
 business data analysis
primary location
 united statesconnecticuthartford
schedule
 fulltime
job level
 entry level
education level
 bachelors degree ±16 years
job type
 standard
shift
 day job
employee status
 regular
overtime status
 exempt
travel
 no
job posting
 oct 4 2018 82710 pm
remote worker option  no",,CT,False,data_engineer
Data Engineer,"the data engineer will create tools and data pipelines that use the latest advances in data engineering to address research and business questions across research and development enabling scientists to build predictive modelsalgorithms
additionally the selected candidate will
· automate existing manual data and new data flow processes into extracttranslateload etl or extractloadtranslate elt operations using fitforpurpose tools
· write clean maintainable data pipelines that feed data scientistssoftware developers through integrationpresentation layer
· correct transform and enrich multiple sources of data and provide quality reports
· quickly and efficiently load bulk and streaming data
· work closely with the data science team and internal business partners to identify the path to successful products
perform other duties as required
qualifications
the successful candidate will possess the following minimum requirements

· education and work experience
o bachelor’s degree in information systems engineeringmanagement computer science computer information systems applied mathematics or closely related field of study and six 5 years of documented work experience in in postgresql mongodb mysql oracle database queries and programming including three 3 years of documented work experience using extracttranslateload etl toolsets
o or master’s degree in information systems engineeringmanagement computer science computer information systems applied mathematics or closely related field of study and five 4 years documented work experience in in postgresql mongodb mysql oracle database queries and programming including three 3 years of documented work experience using extracttranslateload etl toolsets
· experience programming in pentaho or informatica
· familiarity with data quality cleaning and masking techniques and handling unstructured data
· experience working across multiple computer environments to create workflows and pipelines eg hpc cloud linux systems
· ability to interact with a variety of largescale data structures eg sql nosql hdfs preferable
· demonstrated ability to organize and incorporate complex systems requirements into product features and prioritize features effectively
· demonstrated experience with algorithms and performance optimization
· demonstrated experience with data vault methodology and implementation experience
· strong adherence to data privacy standards and ethics
· strong interpersonal and communication skills and a demonstrated ability to work and collaborate in a team environment
· excellent written and oral communications
· prior work experience in healthcare life sciences andor pharmaceutical industries preferred
· prior work experience with aws cloud technologies and stack preferred knowledge of distributed data processing and management systems big data analytics platforms andor worktools preferred
· ability to work onsite monday through friday during normal business hours 800 am – 500 pm at client facilities located in research triangle park nc
ability to pass a background investigation and a drug test
unusual or special physical requirements of position
examples
specify
10 of time

· lifting
· climbing
· crawling
· special clothingequipment wearing
· unusual physical requirements
· high noise level
· other
requires sitting for extended periods of time at a desk 90 requires sitting at a computer terminal for long periods of time 90 there is a possibility that due to parking availability and location of work area walking moderate to long distances can sometimes be required


description of work environment
examples
specify
100 of time

· inside outside where
· combination of above
· extreme hotcold temperatures involved
· hazardous conditions  what are they
· traveltransportation requirements
· other
inside officecubicle environment requires ability to interact professionally with coworkers and all levels of management 100


equipment and machines involved in work tasks
examples
specify
100 of time

· office equipmentmachines electricallybattery operated  which
· vehicles forklifts etc operated which
· tools used in trade  which ones
· other
requires ability to operate a personal computer a telephone copier and other general office equipment 100 ability to conduct evaluation of third and fourth generation or current state of the art computer hardware and software and its ability to support specific requirements interfacing with other equipment and systems


criticality of attendance
examples
specify
100 of time

· overtime regular days off days
· shift 2nd 3rd
· necessity for regular attendance
· urgency for punctuality
attendance is critical work hours are normally 8 hours per day and 5 days per week monday through friday being prompt is important to provide continuous and ongoing service to customers attendance is important to maintain continuity of service work outside of normal duty hours may be required with as little as one hour advance notice overtime is infrequent but important when required 1

other essential functions
list other essential functions here

must be able to communicate effectively both verbally and in writing must be able to interface with individuals at all levels of the organization must be able to obtain unescorted access to work areas grooming and dress must be appropriate for the position and must not impose a safety riskhazard to the employee or others


jacobs is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability veteran status or other characteristics protected by law jacobs is a background screening drugfree workplace",,NC,False,data_engineer
Data Engineer & Architect,lumen is seeking a highly motivated innovative data engineer  architect to build and maintainsystem architectures for data processing they will construct administer and improve componenttechnologies including analytical databases and data pipelines to feed analytics solutions and reportsdata solutions established and maintained by the data engineer will collect data from a variety of sources eglaboratory instruments sensors probes lims they will parse transform integrate store and make data available in formats useful for querying and analysis these solutions will ultimately enable the generation of reports and dashboards that provide critical insights to scientists and managersas an early information technology hire for the company the data engineer will have the opportunity to work collaboratively on a variety of implementation projects and initiatives the data environment created by the data engineer will help to kickstart lumen’s analytics capabilities supporting lumen’s development of food vaccine and therapeutic solutions produced in the bluegreen algae spirulinaessential job functionsthe major tasks for this position are as followsdevelop build test and maintain database and data processing system architecturesarchitect appropriate data solutions to meet research and business needs while ensuring fit within the broader platform ecosystemcollaborate with consultants and contractors to provide sound data architecture built for performance reliability and securitycreate and maintain best practices policies procedures and standards for data architecture and testingimprovement processesdocument data designs and data flow diagramsdevelop analytical databases by designing proposed systems and creating their structure and functional capabilitiessetup and populate databases participating in the creation of table schemasadminister databases managing access permissions and backups to ensure data security and integritytest and debug database architectureemploy a variety of languages and tools to combine data sources and create reliable pipelinesdesign and implement etl scripts to integrate and transform data into useful formats for analysis and interpretation by researchersperform legacy data migrationsfacilitate and help lead it implementation projects and initiativesassist in the development and implementation of standard data tables reports dashboards and visualizations supporting research and business goalsgather requirements from end users eg scientific researchers and facilitate the translation of these requirements into analytics solutionscommunicate with end users to ensure meeting of requirementsprovide enduser support documentation and training where appropriateresearch opportunities for additional data acquisition and automation work closely with scientists and managers to determine which data are neededprovide recommendations on how to expand data collection and improve data reliability efficiency and qualityeducation and experience requirementsbs degree in computer science or related field or equivalent work experienceindepth knowledge and experience with cloud eg aws google cloud azure architecture best practices security design implementation and operational supportexperience designing data systemssolutions to manage complex data in complex distributed systemsindepth knowledge of databases and best engineering practices with 5 years of experience in database programming design and analysisdemonstrated experience building analytical relational databases and developing advanced sql queriesproficiency in shell scripting and one or more scripting languages including pythondemonstrated experience with etl integration developmentexperience processing large multidimensional datasets from multiple sourcesexperience in development of professional database reporting with business intelligence tools eg tableaudesired qualificationsfamiliarity with devops conceptsbroad range of technical skills covering systems and applicationsexposure to life science and research environmentsfamiliarity with 21 cfr part 11 requirementswork experience in regulated data environmentexperience estimating technical solution buildsthe successful candidate will have the following attributesexcellent collaboration and communication skillsselfstarter with ability to work as part of a diverse team andor individuallyhigh integrity and ethicscommitment to quality and timely delivery of resultsflexible outlook for finding the best solution based on constraintsphysical requirementsstand or sit for extended periods working with computer screens 2 or more hours at a timehow to applyplease submit a resume and cover letter via email address provided below with the job title in the subject linethis position is available immediately applications will be reviewed upon receipt only successful applicants will be contactedabout lumenbased in seattle washington lumen bioscience has developed proprietary technologies for synthesizing highvalue products in a novel platform organism lumen completed its series a financing in mid2017 and is using these technologies to produce novel products that solve longstanding problems in human and animal health and nutrition the lumen team works out of a beautiful lab and office facility in fremont a picturesque neighborhood on the north shore of lake union in the heart of seattle at lumen youll be challenged youll be inspired and youll be proud to be part of an innovative organization making a real impact on improving the quality of life globallylumen is proud to be an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin or protected veteran status and will not be discriminated against on the basis of disabilitynote to employment agencies lumen values its relationships with recruitment partners and will only accept resumes from those partners that have been contracted by a member of the human resources team lumen is not responsible for any fees related to resumes that are unsolicited or are received by any employee of lumen who is not a member of the human resources teamjob type fulltimeeducationbachelors preferred,,WA,False,data_engineer
Data Science Engineer,"job description

information technology at abercrombie  fitch is fundamental to designing sourcing developing and delivering fashionforward merchandise to our customers we are committed to implementing new strategic and systematic approaches to generate dynamic technology solutions for our growing business as an expert on the data science team a data engineer is responsible for setting up datasets for data mining building predictive models and building insight apps our data science focus surrounds core retail areas including planning merchandising inventory management and real estate this position will work closely with other data science team members and our business partners
what will you be doing
use data engineering skills to build mineable datasets
mine prepared datasets for initial descriptive or anomalous insights
build accurate and reproducible supervised  unsupervised models
work with business owners to understand context within datasets  processes
deliver insight to leadership helping drive strategic business decisions
hypothesize experiment  drive insight by any means necessary
drive innovation by evaluating business processes and identifying data science solutions
what will you need to bring
a selfstarter with a cando attitude and resilient work ethic
3 years’ experience with coding in python pandas numpy scipy etc
1 years’ experience with data warehousingbi technologies including one or more of the following or similar hadoop ie hbase hive mapreduce sqoop spark etc netezza andor datastage etl
some experience developing complex sql and database views in a large data warehouse environment
knowledge of web app development with highlevel framework like flask or shiny
experience mungingwrangling data to create workable datasets from messy or noisy data sets
experience with data processing techniques such as dimensionality reduction normalization imputation and feature extraction
experience developing reproducible predictionforecasting models such as deep learning neural nets decision trees glm arima regression etc
wellpracticed in version control with git
experience with virtual environments or dockers for containerization
4year degree in math statistics engineering or information technology
2 years’ fulltime work experience
nice to haves
experience with coding in r dplyr shiny ggplot sparklr etc
experience with unguided problem formulation or hypothesis development
experience with optimization techniques such as genetic algorithms simulated annealing etc
experience with data visualization with tools like matplotlib tableau ggplot plotly etc
knowledge of retail problems such as product classification demand forecasting supply chain optimization etc
knowledge of nlp and text analytics
knowledge of webscraping

qualifications

null

additional information

abercrombie  fitch co is an equal opportunity  affirmative action employer © abercrombie  fitch co 2012",,OH,False,data_engineer
Data Engineer Intern (Summer 2019),"temporary internshipdescription

we are looking for a tech savvy engineer to join our innovation team and shape the future of the automotive industry

this position will give you an opportunity to work alongside enterprise data engineering teams to migrate from our onprem hadoop environment to a nextgeneration big data analytics platform in aws this platform will serve as a foundation for new products and services and enable other engineers and data scientists in solving real world data problems

key responsibilities
participate in agile ceremonies to estimate refine implement and showcase features
collaborate with other developers to migrate key data ingestion workflows to aws
collaborate with data engineers to design implement test and automate data transformations to derive new strategic datasets
troubleshoot and resolve workflow issues onprem and in aws
all other duties as assigned

qualifications

understandingexperience with cloud technologies
experience developing in languages such as java or python
demonstrated proficiency with structured query language sql
working knowledge of linux operating system
overall ability to use best practice tools and writemodify scripts
working towards degree in computer science or related degree graduate or undergraduate



about cox automotive
cox automotive inc makes buying selling and owning cars easier for everyone while also enabling mobility services the global company’s 34000plus team members and family of brands including autotrader® clutch technologies dealercom® dealertrack® kelley blue book® manheim® nextgear capital® vinsolutions® vauto® and xtime® are passionate about helping millions of car shoppers tens of thousands of auto dealer clients across five continents and many others throughout the automotive industry thrive for generations to come cox automotive is a subsidiary of cox enterprises inc a privatelyowned atlantabased company with revenues exceeding 20 billion wwwcoxautoinccom
cox is an equal employment opportunity employer  all qualified applicantsemployees will receive consideration for employment without regard to that individual’s age race color religion or creed national origin or ancestry sex including pregnancy sexual orientation gender gender identity physical or mental disability veteran status genetic information ethnicity citizenship or any other characteristic protected by law
statement to all thirdparty agencies and similar organizations cox accepts resumes only from agencies with which we formally engage their services please do not forward resumes to our applicant tracking system cox employees cox hiring manager or send to any cox facility cox is not responsible for any fees or charges associated with unsolicited resumes

organization cox automotive

primary location usgaatlanta6205 peachtree dunwoody rd ne

employee status temporary

job level interncoop

shift day job

travel no

schedule fulltime

unposting date ongoing",,GA,False,data_engineer
Data Engineer,"description
seeking a data engineer that will play a key role in helping realize the organization’s dedication to creating datadriven solutions to improving the quality and lowering the costs of healthcare delivery in camden nj this person will be responsible for helping to develop and optimize a nascent data warehouse of clinical social service delivery and other individuallevel data captured from a multitude of internal and external sources the data engineer will help build data integrations develop data best practices and governance perform clinical and administrative reporting and help optimize data flow and collection for cross functional teams this person should be a problem solver equipped with a variety of approaches and tools for handling complex problems that arise in large messy data sets and someone who enjoys optimizing data systems and building solutions from the ground up the data engineer will support our information architect data analysts and data scientists as well as nontechnical colleagues who generate and use the data on a daily basis

essential functions


data modeling – evaluate structured and unstructured data determine the most appropriate schemas for new fact tables data marts etc
data integration – incorporate new and legacy data into the coalition’s nascent data warehouse while maintaining enterprise best practices and adhering to data governance standards
etl – help implement etl procedures to apply business rules to our data as we migrate from source to target and validate data to ensure quality
reporting – collaborate with data and nontechnical colleagues to scope requests extract data from various data sources create relevant data visualizations share with requesters and validate results
rapid feedback analytics – develop maintain and automate as appropriate operational dashboards that foster a culture of enduser data literacy and critical inquiry
governance  best practices – help develop document and adhere to data governance standards also educates and supports colleagues in best practices to ensure that data is used appropriately
assemble large complex data sets that meet business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data using sql and various programming technologies
develop analytics tools that utilize data resources to provide actionable insights operational efficiency and other key business performance metrics
build processes supporting data transformation data structures metadata dependency and workload management

knowledge skills and abilities


strong proficiency in sql postgresql preferred
competence in a highlevel general purpose programming language python preferred
exposure working with apis
exposure to statistical data analysis tools r spss matlab etc r preferred
exposure to visual analytics tools tableau preferred
familiarity with electronic health record and medical financial systems
experience performing root cause analysis on code and data processes to answer specific business questions and identify opportunities for improvement
a successful history of manipulating processing and extracting value from large messy and disconnected datasets
strong communication project management and organizational skills
familiarity with cloudbased hosting environments azure preferred
strong analytical and problem solving skills

requirements
3 years of business intelligence  data warehousing experience preferably in a data engineering role within a healthcare environment

bachelor’s or advanced degree in computer science informatics information systems or other quantitative field preferred",,NJ,False,data_engineer
Information /Data Analyst,"the information analytics specialist provides data analysis support to the customer by assisting with development of reports andor dashboards to monitor program and operational performance promote selfservice analytics for customer adoption understanding and use of data supports design of programmatic analyses and reporting capabilities in addition to business requirement definition for new analysis and performs adhoc data analysis as directed as a subject matter expert this position supports data quality and data stewardship functions to maintain data accuracy and identify new metrics

the ideal candidate will have solid experience with sql use of business intelligence tools and detailed data analysis

education level
bachelors level degree  experience in lieu of education yes

experience
required data analysis  1 year financial analysis  1 year information technology  1 year statistics  1 year

preferred none unless noted in the other section below

license
none unless noted in the other section below

skills
required communication complex problem solving critical thinking service orientation writing

preferred none unless noted in the other section below

other
4 years related experience required in lieu of education

data visualization  analytics consultantdata engineer – skill set strong analytical statistical and problem solving skills utilizing current visualization tools ie tableau qlik power bi etc advanced knowledge and experienced sql coder with working knowledge of other analytical and statistical packages such as python and r knowledgeable of current informatics infrastructure data structure information systems and workflows excellent writtenverbal communications skills excellent interpersonal skills and customer management",,VA,False,data_engineer
"Software Engineer, Data","circle is a global internet finance company built on blockchain technology powered by crypto assets and dedicated to helping people everywhere create and share value

weve already made sending money around the world free and easy using blockchain technology with circle pay with circle invest were expanding our offerings with a cryptocurrency investment product enabling anyone to buy and sell crypto assets through circle trade were market makers for the top crypto coins and offer otc trading services in march 2018 circle acquired poloniex one of the worlds leading token marketplaces

as a data engineer at circle youll work closely with the data science team productizing machine learning solutions and developing the scalable data pipelines that support these solutions

working in either boston or new york youll have the opportunity to significantly impact internal data consumption and decisionmaking risk and compliance growth and marketing as well as our customer experience

projects we are working on

productize machine learning models and build a worldclass automated evaluation system to manage risk exposure while delivering the best possible experience to our customers
design build and implement scalable streaming data pipelines and etl frameworks to increase data access and decrease analysis and decision times across the organization
build an open transaction protocol where users can send money and exchange value that utilizes both new and traditional technologies to deliver value the fastest and cheapest way possible
leverage blockchain technology in a new transaction framework so that financial institutions an exchange value and associated metadata in a compliant manner

you will also work on

own software throughout the entire development lifecycle
share ideas to improve our product and processes make decisions that have significant impact and provide feedback so we can continue to get better
develop your skills collaborate across teams and continue to learn

what youll bring to circle

experience writing high quality code in python plus another oop language java scala c go etc
experience working with rdbm systems particularly familiarity with sql
3 years experience building distributed solutions in spark mapreduce or other mpp system with associated data models and datastores eg redshift cassandra hbase parquet
production development of eventbased applications using frameworks such as kinesis kafka spark streaming or similar
familiarity with machine learning techniques continuous deployment pipelines and tools and aws technology stack a plus
desire to work across internal teams to identify requirements and iterate on solutions
debug complex production issues across various levels of the tech stack
interest in impacting the way money moves between people
experiencefamiliarity with slack mac osx and gsuite

circle was founded in 2013 by internet entrepreneurs jeremy allaire and sean neville were backed by 250 million from investors including jim breyer facebook goldman sachs idg capital baidu tencent general catalyst airbnb snapchat accel partners and bitmain with offices in boston new york san francisco dublin london and hong kong

check us out at circlecom  httpcirclecom  and download circle pay  circle invest for ios and android today

we are an equal opportunity employer and value diversity at circle we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status

about your personal information

we respect your privacy and are committed to protecting your personal information please refer to our candidate privacy notice here  httpswwwcirclecomengbcandidateprivacynotice  for more information on how we will be using your personal information by submitting your application you agree that you have read and understood the candidate privacy notice  httpswwwcirclecomengbcandidateprivacynotice ",,NY,False,data_engineer
Data Engineer,"why we work at dun  bradstreet

life here at dun  bradstreet is changing – for the better with almost two centuries of experience and a new modern vibe work at db has never been more exhilarating our purpose is to grow the most valuable relationships in business by uncovering truth and meaning in data we’re wildly passionate about our purpose and it has us evolving everything we do – from how we engage with our customers to how we energize one another so if you thrive in a fluid agile culture but want the solidity of a storied and commanding brand come join us

content is a global team delivering thought leadership and inspiration by building strategic relationships through modern experiences so our customers can grow our key focus areas are to 1 uncover truth and meaning from data 2 drive contentvalue through data 3 leverage modern technology analytics and platforms and 4 build relationships with influencers there’s never been a more exciting time to join the team

a data engineer’s role involves developing applications designed to accumulate derive meaning from and apply stewardship to large datasets a data engineer will have to both be able to work with the global people data team’s internal datasets and tools as well as be able to coordinate with outside groups to continuously meet their needs a data engineer is expected to be a key developer of global people data tools and products both in maintaining and upgrading existing tools and in developing new products using state of the art techniques and programming concepts


responsibilities
develop new applications in a variety of programming languages
take ownership of existing applications for further developmentimprovements
work closely with related groups to ensure business continuity
perform analysis on large datasets to make and implement recommendations for maximizing customer experience
work as a member of one or more agile teams using lean principles and scrum methodology

requirements
bachelor’s degree preferable in computer science or a related field
2  5 yrs experience with sql
2 – 5 yrs experience with python
ability to work closely with others to problem solve
experience with hosted environments aws and azure recommended
understanding of software testing methodologies
understanding of unit testing and automated test tools


dun  bradstreet is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race color religion creed sex age national origin citizenship status disability status sexual orientation gender identity or expression pregnancy genetic information protected military and veteran status ancestry marital status medical condition cancer and genetic characteristics or any other characteristic protected by law

we are committed to equal employment opportunity and providing reasonable accommodations to applicants with physical andor mental disabilities if you are interested in applying for employment with dun  bradstreet and need special assistance or an accommodation to use our website or to apply for a position please send an email with your request to talentacquisitionteamdnbcom determination on requests for reasonable accommodation are made on a casebycase basis

please note that all dun  bradstreet job postings can be found at httpsdnbwd1myworkdayjobscomcareers and all communication from dun  bradstreet will come from an email address ending in dnbcom",,MA,False,data_engineer
Data Engineer,are you looking for a fulltime opportunity as a senior data engineer in scottsdale as the senior data engineer you will research evaluate and recommend appropriate technology and strategy for building products and delivery services you will consult with customers on custom project requests gather specifications document statements of workquotes for clients develop and validate reports coordinate with development team to implement specific requests test deliver and close projectsbenefits  features comprehensive benefits with 401k matchcover 100 of employee insurance premiumsopportunity to have a direct impact on the organization as a technology expertchance to represent the organization to clients and develop solutionsqualifications bachelors degree in information systems business administration or related field7 to 10 years of sql and c experience including infrastructure development sdlc and databaseexpert sql skillsable to do sql queries and leverage that knowledgeable to do data optimization strategies know how to manipulate unstructured datamore the thought process and predicting what could occur and what needs to be done to get the right resultssolid understanding of development specifically cstrong understanding of business intelligence and reporting toolsexperience product implementation and customization to meet client needsorganized project management experience or implementation coordinationability to learn new technologies quickly and ability to overcome obstaclesjob type fulltime,,AZ,False,data_engineer
Test Data-Engineer,"job description

we are seeking a test data engineer with a minimum of 5 years of experience based in our pleasanton location
job responsibilities
collaborates with application smes project teams and data management to establish test data requirements
ability to understand business process information and associated data flows
leads the analysis of test data requests defines test data characteristics and the design development and implementation of test data automation
basic qualifications

design develop and implement automated extraction transformation and load processes for test data
collaborates with application smes project teams and data management to establish test data requirements
ability to understand business process information and associated data flows – protocols hl7 edi etc for each health care applications such as epic tapestry membership system and other health care related systems etc
ability to work with various databases eg oracle sql server informix db2 etc and file formats eg xml mismo cldf edf etc
must have any of the following scripting experience python shell java jscript
should have experience in jenkins or any ci tools
experience of industry etl tools eg informatica tdm grid tools or oracle test data management etc
leads the analysis of test data requests defines test data characteristics and the design development and implementation of test data automation
creates and validates test data all phases of testing
ability to liaise with business qa and dev stakeholders to understand processes data and system specs and test data requirements
knowledge of data models and entity relationship diagrams
knowledge and experience in data masking methodologies
prior experience with healthcare domain preferred
ba of computer science or related discipline
preferred qualifications
good to have understanding on various databases eg oracle sql server informix db2 etc and file formats eg xml mismo cldf edf etc",,CA,False,data_engineer
Big Data Engineer,"requisition id 29059

our reliability is one of the best in the nation and we’re working to make it even better we live here too that’s why we’re committed to making florida a better place join our team today learn more

position specific description

smile you’ve found us at nextera energy our people are our greatest asset and our enterprise data services team is looking for a principal big data engineer to join the organization in this role you will be responsible for establishing and maintaining an enterprise data platform which will utilize the latest in big data technologies in order to enable a wide variety of analytical solutions across the enterprise

candidates with the following experience will be highly considered
designing architecting and developing solutions leveraging big data technologies open source andor aws to ingest process and analyze large disparate data sets
expertise in data modeling structured unstructured or semistructured data processing for cloud and on premise implementations
experience in big data stores such as hadoopcassandramongodb aws s3 redshift and traditional data stores such as oracle sql server greenplum and sap bwhana
handson experience with aws big data technologies including but not limited to aws emr hortonworks cassandra mongo redshift and kafka
designing and deploying dynamically scalable highly available faulttolerant and reliable applications on aws
experience in building microservices web services map reduce spark based analytics processing


job overview

employees in this role are responsible for all activities associated with the administration of either mainframe or distributed computerized databases this role leads database administration teams andor projects



job duties  responsibilities

designs implements maintains and monitors databases
develops documents and implements guidelines standards and procedures maintenance of database dictionaries and integration of systems through database design
performs other jobrelated duties as assigned



required qualifications

high school grad  ged
bachelor’s or equivalent experience
experience 7 years



preferred qualifications

none



employee group exempt
employee type full time
job category information technology
organization florida power  light company
location juno beach florida
other work locations florida
relocation provided yes if applicable

nextera energy is an equal opportunity employer qualified applicants are considered for employment without regard to race color age national origin religion marital status sex sexual orientation gender identity gender expression genetics disability protected veteran status or any other basis prohibited by law we are committed to a diverse and inclusive workplace

if you require special support or accommodation while seeking employment with nextera energy please send an email to askhrneecom providing your name telephone number and the best time for us to reach you alternatively you may call 18446944748 option 1 press 6 between 8 am and 5 pm est mondayfriday please do not use this line to inquire about your application status

nextera energy will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant however employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by the employer or c consistent with the contractor’s legal duty to furnish information

nextera energy does not accept any unsolicited resumes or referrals from any thirdparty recruiting firms or agencies please see our policy for more information
liam1",,FL,False,data_engineer
Spark developer (Data Engineer),80  90 an hourcontractjob requirements qualifications and skills510 years of experience in data web or mobile servicesdata architecture skillsexperience in sql or similar languages and development experience in at least one scripting language python perl etcexperience with redshift and other aws technologies8 years of experience working with large data sets and distributed computing tools mapreduce hadoop hive spark etc8 years utilizing object oriented design and programming with scalapython skills to design develop and maintain largescale web applicationsexperience with data sets hive and data visualization tools is a plusbabs in computer science math physics or another technical fieldadditional bonusdeep knowledge of machine learning information retrieval data mining statistics nlp or related field3 years of experience building machine learning networks to scale problems at scale with knowledge using scikit learn spark mllibetcjob type contractsalary 8000 to 9000 hourexperiencespark 5 years preferredjavascalapython 5 years preferredbig data 5 years preferred,,CA,False,data_engineer
Senior Data Engineer.,"50 a daytechnical requirements
 strong experience working with large data sets experience
working with distributed computing mapreduce hadoop hive pig apache spark etc
 knowledgeexperience on teradata physical design and
implementation teradata sql performance optimization
 experience with teradata tools and utilities fastload
multiload bteq fastexport
 advanced sql preferably teradata 
 strong hadoop scripting skills to process petabytes of data 
experience in unixlinux shell scripting or similar programmingscripting knowledge
 experience in etl processes
 automic scheduler

engineering skills
 very strong engineering skills should have an analytical
approach and have good programming skills
 provide business insights while leveraging internal tools and
systems databases and industry data
 excellent written and verbal communication skills for varied
audiences on engineering subject matter
 ability to document requirements data lineage subject matter
in both business and technical terminology
 guide and learn from other team members
 demonstrated ability to transform business requirements to code
specific analytical reports and tools
 this role will involve coding analytical modeling root cause
analysis investigation debugging testing and collaboration with the business partners product managers other engineering team
 strong analytical background
 selfstarter
 must be able to reach out to others and thrive in a fastpaced
environment
 strong background in transforming big data into business insights
 experience in retail business will be a plus

nice to have
 development experience with java scala flume python
 cassandra
 hbase
 tableau or similar reportingdash boarding tool
 modeling and data science background
 retail industry background

education bs degree in specific technical fields like computer science math statistics preferred",,AR,False,data_engineer
Senior Data Engineer,120000  145000 a yeardriven by curiosityat vistaprint we believe that everything we do has a lasting impact on our customers and on each other it begins and ends with a passion for helping our customers succeed to give them our best we empower our team with the autonomy they need to make smarter decisions and pursue higher value we thrive on exploration collaboration and helping every customer grow their business beyond imagination fueled by technology and innovation we are so much more than business cardsabout our teamthe data engineering teams mission is to enable our internal business partners with the information to make better decisions for our customers all of our team members collaboratively work together to design build and sustain our data ecosystem which includes technologies like our data warehouse data lake and proprietary predictive analytics tools we build the right thing the right way through positive relationships with marketing analytics and financewhen you join our team you will have a fantastic opportunity to advance your career by working in cuttingedge technology and growing your business expertiseputting your expertise to workas a senior data engineer you will help us scale our data infrastructure to expand our proprietary predictive analytics and big data capabilities you will work with our vast data ecoysystem including our data warehouse and data lake to build out our platform and provide tooling to empower our internal customers your technical experience and business insight will directly drive real business results your ability to seek complex challenges and collaborate in a team environment will mean you have an immediate impactessential functionsdesign develop and support our data infrastructure utilizing various technologies to process terabytes of data including sql python microsoft azure and awscreate solutions to enable diagnostic and predictive analytics capabilitiespartner with the analytics marketing and finance organizations to get feedback and iterate upon the data ecosystem developmentdevelop components and distributed etl systems for our suite of large data platformsbe curious about trends and emerging technologies in the data space participate in user communities and share what you learn with your teammatesexperience were looking forfamiliarity with developing data processing solutions and data applications utilizing technologies like python c java sql spark or no sql dbexperience working with all kinds of data clean dirty unstructured semistructured and relationalproblem solving and multitasking ability in a fastpaced globally distributed environmentstrong communication skills including the ability to work with business partners to understand and refine requirementsexperience with developing endtoend data pipelines in large cloudcompute infrastructure solutions such azure aws and google is a plusminimum of 12 years working directly on big data technologies preferredlifeinvistaprintjob type fulltimesalary 12000000 to 14500000 yearexperiencecloud computing 1 year preferrednet 1 year preferredwork authorizationunited states required,132500.0,MA,False,data_engineer
Cloud Data Engineer,"about us

at maven wave we are relentless in hiring the industry’s top talent each employee is handpicked not only for their skills but for their personality and broad expertise we are looking for this rare combination of talent that sets us apart in the industry
founded in 2008 maven wave has experienced rapid growth we combine the experience and knowledge of a management consulting firm with the innovation and technology expertise of a cloud services firm providing a truly unique work environment employees have the opportunity to gain invaluable experience and make a significant impact on the business outcomes of our clients and our company

over the past years maven wave has received the following awards and accolades
google cloud north america services partner of the year 2018
21 best workplaces in chicago fortune 2018
great place to work certification great place to work 2017  2018
fast fifty crains chicago business 2014 2015 2016 2017 2018
101 best and brightest companies to work for national association for business resources nabr 2014 2015 2016 2017 2018
top google cloud partner clutch 2017
fastest growing consulting firms in north america 11 37 consulting magazine 2016 2017
top it services companies clutch 2015
google global rising star partner of the year 2015

maven wave google and you help us build and deliver data driven cloud solutions
we are looking for a skilled big data  cloud data engineer to join our team the ideal candidate has extensive experience building and implementing complex data solutions in the cloud aws microsoft andor google the primary job role will be designing building and testing data ingestion and etl programs with a strong focus on performance and data quality management
responsibilities
designing building and testing data ingestion and etl programs from a variety of source systems both unstructured and structured
uncovering and recommending remediations for data quality anomalies
investigating recommending and implementing data ingestion and etl performance improvements
document data ingestion and etl program designs present findings conduct peer code reviews
develop and execute test plans to validate code
work in a collaborative agile environment
requirements
bachelors degree in a technical or quantitative field with preferred focus on computer science or information systems
4 years experience building complex etl programs with one of the following informatica datastage spark dataflow etc
expert in data extraction experience
3 years experience developing complex sql
experience using cloud storage and computing technologies such as bigquery redshift snowflake
experience configuring and developing big data solutions in a cloud environment aws microsoft or google
3 years experience programming in python andor java
3 years with unix shell scripting
2 years experience with git
2 years experience in data quality testing adept at writing test cases and scripts presenting and resolving data issues
2 years experience developing complex technical and etl programs within a hadoop ecosystem hadoop yarn hive pig sqoop spark
2 years implementing and programming data ingestion and etl programs with large datasets 10 terabyte analytical environment
experience with integration of data from multiple data sources
experience developing and implementing streaming data ingestion solutions
3 years working with relational database technologies
3 years investigating recommending and implementing solutions that resolve data quality issues
demonstrated independent problem solving skills and ability to develop solutions to complex analyticaldatadriven problems
demonstrated experience developing data analytics solutions within aws andor google cloud platform
must be able to communicate complex issues in a crisp and concise fashion to multiple levels of management
excellent interpersonal skills necessary to work effectively with colleagues at various levels of the organization
check out our data team",,NY,False,data_engineer
Data Engineer,"the data engineer is responsible for designing developing and supporting data management solutions the position will develop data models perform data analysis construct technical designs develop data integration solutions collaborate with team members and business stakeholders and support existing data solutions this position will also lead and coordinate the work activities of offshore development and support resources

people or process management responsibility works on multiple complex projects as technical lead and coordinates the work of other technical bi resources

position responsibilities may include but not limited to

responsible for the solution architecture design development and support of data management applications

drive data sourcing and integration solution design and development on hybrid cloud  onprem data solutions

perform data analysis and architect data models for analytics

providing guidance and direction to offshore etl supportdevelopment resources

collaborate with cross functional teams such as infrastructure support dba and business team

assist with task identification and effort estimates for etl development

assist with risk and issue identification and resolution

provide offhourweekend etl support on a rotating basis

other duties as assigned

position requirements
position requirements

position requirements minimum requirements

4 year degree in computer science information systems

5 years of relevant business intelligencedata warehousingdata integration work experience

4 years of handson experience developing data management solutions using msbi ssis

2 years data modelling logicalphysical relational and documentobject and 2 years of data integration solution design experience

13 years of developing solutions using windows server os

strong understanding of dimensional modeling techniques

experience leading other developers

strong written and verbal communication skills

strong problem solving and analytical skills

strong understanding of sdlc best practices with an emphasis on dwbi practices

this position must pass a postoffer background and drug test



preferred

experience with one of the etl tools – ms ssis informatics on sql server db

1 year of public cloud experience azure aws

proficiency in scripting languages such as power shell

1 year of experience leveraging cloud services iaas paas

1 year handson development experience using open source data integration tool such as talend azure data factory

experience leading offshore resources

itil certification

experience in agile scrum and waterfall methodologies

distribution and logistics industry experience

physical demands and work environment

the physical demands and work environment characteristics described here are representative of those that must be met by an employee to successfully perform the essential functions of this job reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions

due to the nature of our business in regard to such things as delivery schedules order inputs selection and department of transportation hours of service overtime attendance and punctuality are essential job functions should an individual in this classification not be able to adhere to this requirement due to a disability they should contact their human resource department to see what if any reasonable accommodation may be made",,IL,False,data_engineer
Staff Data Engineer,"overview of the role
the staff data engineer works on a team of data engineers and administrators supporting a data platform centered around what is today a sql server enterprise data warehouse this platform holds clinical financial and population health data for our 6m patients and serves business critical needs for our product and analytics teams our warehouse is central privia’s results oriented culture having leveraged our platform to achieve industrybest revenue cycle awards and earned ongoing benefits from 1 and 2sided risk performance
we are looking for a candidate with hardwon expertise to take our data platform and team to the next level this role is for the candidate who excels at understanding business problems and providing handson technical leadership to build scalable highquality solutions
primary job duties
deliver value in the form of timely high quality performant software components and services
collaborate with product owners and stakeholders to plan and define requirements
know the business value of your work and ensure team success in meeting sprint commitments be flexible show initiative and develop additional skill sets to improve team capabilities and throughput
apply a thorough understanding of the data structure and business logic to effectively solve problems
investigate data discrepancies and errors and determine the best resolution
provide guidance to the data engineering team in best practices for coding conventions architecture quality scale productivity and best practices
lead and mentor other team members both onshore and offshore in dw best practices and development processes including automation validation quality assurance and monitoringalerting
provide expertise in building for scale including potentially migrating data warehouse operations to a cloud service such as google compute engine snowflake andor other platforms
advise and train members of the team to maximize overall productivity and effectiveness of the team
identify skills gaps and silos on the team and advocate for resolution
participate in and contribute to scrum meetings ie daily standup sprint planning and retrospectives
minimum qualifications
5 years of experience with designing architecting and implementing commercial data warehouses and data marts including integration with commercial bi tools eg microstrategy sas
3 years’ experience with relevant scripting languages or programming frameworks desired python ruby bash
deep knowledge of healthcare data especially claims data
strong data warehouse modeling expertise ie integrated model and starsnowflake schema data model
experience migrating a sql server dw to a cloud provider such as aws google cloud services and snowflake
demonstrated knowledge of unixlinux objectoriented programing relational database technologies database performance and tuning distributed computing tech hadoop spark restful api
proven experience mentoring engineers in dw best practices and development
handson proficiency with sql ssis and etl jobs including stored procedures
handson proficiency in working with cloud services such as amazon web services google compute engine and snowflake
experience with quality assurance and testing in a relational database environment
experience designing data management processes and standards for metadata management data architecture data quality and data security
experience with agile sdlc
ability to work collaboratively on a multilocation crossfunctional team with a wide range of experience levels
ability to communicate and work with both technical and nontechnical audiences
interpersonal skills  attributes
excellent communication skills verbal and written necessary to effectively interact with data engineering staff product owners and stakeholders
ability to establish strong harmonious working relationships with supervisors peers and stakeholders to accomplish objectives
able to manage competing priorities
experience working with a distributed team
excellent analytical and problem solving skills
physical demands
the physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job while performing the duties of this job the employee is occasionally required to stand walk sit use hands to finger handle or feel objects tools or controls reach with hands and arms climb stairs balance stoop kneel crouch or crawl talk or hear and taste or smell the employee must occasionally lift or move up to 25 pounds specific vision abilities required by the job include close vision distance vision color vision peripheral vision depth perception and the ability to adjust focus
privia health is committed to providing equal employment opportunity to all persons regardless of age color national origin citizenship status physical or mental disability race religion creed gender sex sexual orientation gender identity andor expression genetic information marital status status with regard to public assistance veteran status or any other characteristic protected by federal state or local law in addition privia will provide reasonable accommodations for qualified individuals with disabilities privias goal is for our people to reflect the communities that we serve and to increase representation of women people of color veterans and individuals with disabilities in our organization",,,False,data_engineer
Sr. Big data engineer,contractjob summaryrole  senior big data engineerlocation  bentonvillearresponsibilities and dutiestechnical requirementsstrong experience working with large data sets experience working with distributed computing mapreduce hadoop hive pig apache spark etcknowledgeexperience on teradataphysical design and implementation teradata sql performance optimizationexperience with teradata tools and utilities fastload multiload bteq fastexportadvanced sql preferably teradata strong hadoop scripting skills to process petabytes of data  experience in unixlinux shell scripting or similar programmingscripting knowledgeexperience in etl processesautomic schedulerbenefitsregardssushmacont  847 258 9595 extn 468job type contractexperiencebig data 1 year preferred,,AR,False,data_engineer
Data Engineer,"if youre motivated by the challenge of building sophisticated solutions that solve complex business challenges we want to meet you

join our team a data engineer and help us develop innovative enterpriseready web software and mobile applications

heres what were looking for
responsibilities
assist with data collection and optimization of storage approaches
provide support for scalable batch or realtime data processing for discovery and model creation
implement scalable apis for utilizing analytics results eg utilizing models produced
collaborate with data scientists and help them evaluate the computationdata requirements for discovery and the deployed solution
design build operationalize and scale some of the largest data pipelines in the world
advise on and manage big data infrastructure
architect and develop data ingestion pipelines
develop proofs of concept with emerging technologies
assist with data preparation
required education and skills
bachelors degree in computer science or a related technical field
3 years of experience as a software engineer or closely related position
3 years of of experience with the following
designing integrating and optimizing distributed dataprocessing pipelines
utilizing database technologies including sql and nosql eg hadoop splunk spark samza mysql postgres mongodb sqlite neo4j apache giraph within a cloud environment
writing data processing code in go java python scala or other highperformance languages
using distributed and faulttolerant computing and mapreduce processing techniques
utilizing linuxunix systems
systemslevel debugging
building rest apis for analytics services
working with or in support of multiple open source communities
optimizing critical components in applications for efficiency using c or c
utilizing cloud deployment and virtualization and containerization technologies eg docker ansible terraform and vagrant
1 year of experience with the following
machine learning libraries such as google cloudml dataflow datalab tensorflow scikit learn mahout and mlib
optimizing advanced sql queries
working in an agile environment with scrum and pods
this position is located in our brandnew stateoftheart development center in st louis missouri
relocation assistance may be available",,MO,False,data_engineer
Lead Data Engineer,"figs is looking for an extremely smart and curious data engineer who will own the data delivery internally that will help stakeholders make educated decisions as a part of the technology team you will be deft at working with a wide variety of languages such as python and sql a variety of raw data formats such as json and csv in a fastpaced and friendly environment the ideal candidate is obsessed with how to provide actionable analysis into our business information the role will report directly to figs vp of technology

what youll do

build dashboards and reports using mode analytics to give stakeholders visibility into important data
manage data warehouse plans for finance operations and marketing teams
work closely with department managers to understand the data needs across the company
act as internal expert in each of the data sources so that you can own overall data quality
design build and deploy new data models and etl pipelines into production
experience contributing to full life cycle deployments with a focus on testing and quality
make smart engineering and product decisions based on data analysis and collaboration
act as inhouse data expert and make recommendations regarding standards for code quality and timeliness

qualifications

degree in computer science or a related field or a minimum of 3 years working as a data engineer
2 years professional experience in the data warehouse space
expert proficiency with python and aws services eg redshift s3
indepth knowledge of how to write and optimize sql statements
deep familiarity with distributed processing map reduce mpp etc
innately curious and organized with the drive to analyze data to identify deliverables anomalies and gaps and propose solutions to address these findings
ability to manage and communicate data warehouse plans
thrives in fastpaced startup environment

other must haves

positive attitude
proven work ethic and integrity
entrepreneurial mindset
desire to excel and grow with figs
100 awesome like our scrubs

please apply with your cover letter and resume to be considered

a little bit about us…

the 50 billion medical apparel industry is antiquated highly fragmented and until figs was driven solely by lowcost providers offering a limited selection of poor quality products sold through third party distributors figs is revolutionizing the medical apparel industry by creating the highest quality medical apparel in the world and by selling directly to medical professionals through our branded ecommerce site

figs foundation is built on product quality and we have a relentless focus on three key areas fabric fit and function we developed our proprietary performanceoriented fabric technology to meet the demands of the medical profession figs core collection fabric is antimicrobial wrinkle resistant stain and liquid repellant moisturewicking odor proof lightweight breathable and offers fourway stretch our designs are tailored sophisticated and innovative incorporating features such as yoga waistbands smart storage pockets zippers hidden pockets and inspirational sayings inside each garment that appeal to modern healthcare professionals

by offering a branded and customercentric online shopping experience we are changing how medical professionals buy their workwear through our website social media and participation in medical conferences and events we have built a strong following within the medical community and a meaningful connection with our customers which allows us to understand their needs and to ensure that figs is continuously improving and innovating

figs threads for threads initiative is central to our mission figs has donated hundreds of thousands of scrubs to healthcare providers in need in over 35 countries",,CA,False,data_engineer
Big Data Engineer,"we are searching for a big data engineer to join our engineering team to play a key role in building our next generation cloud platforms you will be an integral part of an engineering team that continues to work on a comprehensive internet ecosystem if you are an engineer who understands closures and prototypes writes clean and modular code and is constantly refactoring then we have a spot for you

what you’ll dobuild core data capabilities and services for cloud platformdesign develop and implement data solutionsdesigning a flexible recommended systembe an active handson team member collaborating with other developers and architects in developing client solutions
basic qualifications
bachelors or master of science in computer science or other itrelated major
understanding of big data mechanics analytical processing modeling and implementation
solid understanding of sql and nosql databases
experience with big data tools hadoop spark flink kafka etc
experience with data pipeline and work flow management tools
experience with streamprocessing systems sparkstreaming flink etc
experience with objectorientedobject function scripting languages python java scala etc
perks  benefits
stock options for every employee
healthcare  dental  vision benefits free for youdiscounted for family
401k options
engineering orientation  onboarding
daily catered lunches onsite nominal cost
healthy snacks  beverages 247
relocation assistance  reimbursement
free parking  carpool reimbursement
casual dress code  relaxed work environment
culturally diverse progressive atmosphere
“soul of faraday” community outreach team",,CA,False,data_engineer
BI Engineer - Alexa Engagement,"job description
come help us shape the future of the best voice controlled computer in the cloud alexa and echo are shaping the future of voice recognition and cloudbased contentservices alexa is the name of the amazon cloudbased voice service and the brain that powers echo the awardwinning and groundbreaking amazon device designed around your voice echo connects to alexa to provide information answer questions play music read the news check sports scores or the weather and more—instantly its handsfree and always ready all you have to do is ask

to achieve this we blend of a variety of disciplines such as nlp data mining machine learning big data semantic web graph stores cloud computing in an effort to understand our customers and the things theyre excited about to complement our complex algorithms and extensive data analyses we create elevated and inspirational mobile and web features across the entire communication experience we use artificial intelligence data mining and usability studies to develop new features and we test them through hundreds of r  d experiments a year we are also incredibly intent on solving some of the most complex computing problems to be found in industry and academia and we get to test our solutions in the real world every day and most importantly we relentlessly ask what havent we thought of yet

the business intelligence engineer will work closely with data scientists software engineers and product managers to build out reporting to inform key stakeholders and decisionmakers in this role you’ll design execute and iterate on high visibility business intelligence reporting for the teams of people that are actively building out alexas capabilities if you love working with huge data sets and delivering the insights you discover through business intelligence reporting and automated systems then this is the job for you

key responsibilities
collect analyze and share data to help product teams drive improvement in key business metrics and customer experiencepropose and prioritize changes to reporting and create additional metrics and processes based on program changes and customer requirementswork closely with alexa program teams to create adhoc reports to support timely business decisions and project workidentify and implement new capabilities and best practices to develop and improve automated data analysis processeslearn and understand a growing range of amazon data resources and discover how and when to use which datasets
basic qualifications
bachelor’s degree in math statistics computer science or finance or equivalent experience
5 years of experience as a data engineer bi engineer businessfinancial analyst or systems analyst
sql writing experience and experience with etl
redshift experience
preferred qualifications
expert understanding of best practices to handle extremely large volume of data
ability to create extensible and scalable data schema that lay the foundation for downstream analysis
a clear passion for learning new bi skills and techniques independently and continuously
ability to prioritize multiple concurrent projects while still delivering timely and accurate results
experience working in a lean successful startup or on a new product team where continuous innovation is desired and ambiguity is the norm
experience mentoring others in sql modeling forecasting and the use of large datasets
proficiency with scripting languages and unix systems python perl bash etc
experience with the following is a plus looker tableau microstrategy
experience in an internetbased company with large complex data sources
amazon is an equal opportunityaffirmative action employer – minority  female  disability  veteran  gender identity  sexual orientation",,WA,False,data_engineer
MySQL Data Engineer,"mysql data engineer
at xpanxion we focus on our people because we know they represent our most valuable asset with training courses featuring the latest and greatest technologies that are tailored to your interests you can build your future while building awesome software work towards a career you can be proud of while having fun along the way
we are currently looking for an experienced senior data engineer
responsibilities
perform common duties of a mysql dba
work on linux systems
migrate data to a cloud environment
work within a distributed team
develop measurement and analytics products
perform adhoc analytics
create etl
skills we look for
mysql dba
installation upgrade backuprecovery tuning and monitor

mysql 56  57 oracle enterprise

replication

innodb and myisam moving to innodb

mysql enterprise backup

mysql enterprise monito

linux centosred hat
scripting bash shell
firewalls
aws aurora
moving mysql to the cloud

system admin
sql server dba
 installation upgrade backuprecovery tuning and monitor
ss bi tsql ssis ssrs and visual studio 2012
sql server 20122017
business intelligence
dimensional modeling
understanding of oltp systems
etlelt
data warehouse
architecture
engineering
us citizenship is required
participate in all of our employee benefit programs
health insurance
dental insurance
vision insurance
life insurance
401k
bonus programs
18 pto days and 11 holidays",,CO,False,data_engineer
Big Data Engineer,contractjob summaryclairvoyant is looking for big data engineer with participate in technical planning  requirements gathering phases including design coding testing troubleshooting and documenting big dataoriented software applications responsible for the ingestion maintenance improvement cleaning and manipulation of data in the business’s operational and analytics databases and troubleshoots any existent issues implements troubleshoots and optimizes distributed solutions based on modern big data technologies like hive hadoop spark elastic search storm kafka etc in both an on premise and cloud deployment model to solve large scale processing problemswork inside the team of industry experts on the cutting edge big data technologies to develop solutions for deployment at massive scaleresponsibilities and dutiesresponsibilitiesparticipate in technical planning  requirements gathering phases including design coding testing troubleshooting and documenting big dataoriented software applications responsible for the ingestion maintenance improvement cleaning and manipulation of data in the business’s operational and analytics databases and troubleshoots any existent issuesimplements troubleshoots and optimizes distributed solutions based on modern big data technologies like hive hadoop spark elastic search storm kafka etc in both an on premise and cloud deployment model to solve large scale processing problemsdefine and build largescale near realtime streaming data processing pipelines that will enable faster better datainformed decision making within the businesswork inside the team of industry experts on the cutting edge big data technologies to develop solutions for deployment at massive scalekeep up with industry trends and best practices on new and improved data engineering strategies that will drive departmental performance leading to improvement in overall improvement in data governance across the business promoting informed decisionmaking and ultimately improving overall business performancequalifications and skillsrequired qualifications bachelor’s degree with a minimum of 6 year’s relevant experience or equivalent6 years of experience with big data  analytics solutions hadoop mapreduce pig hive spark storm awsemr redshift s3 etcazure hdinsight data lake design and other technologies3 years of experience in large scale fault tolerance systems with components of scalability and high data throughput with tools like kafka spark and nosql platforms such as hbase mongo db4 years of experience in building and managing hosted big data architecture toolkit familiarity in hadoop with oozy sqoop pig hive hbase avro parquet spark nifi2 years of experience in deploying big data solutions hadoop ecosystem on cloud technologies such as amazon aws azure etcexperience in working with team foundation serverjiragithub and other code management toolsetsstrong handson knowledge ofusing solutioning languages like java scala pythonoperations support with a solid understanding of release incident and change managementneed someone who is a selfstarter and team player capable of working with a team of strategists architects codevelopers and businessdata analystsjob types fulltime contractexperiencelarge scale 3 years preferredbig data  analytics solutions hadoop mapreduce pig hive 5 years requiredstrong handson knowledge ofusing solutioning languages l 9 years requiredbuilding 4 years preferrededucationbachelors preferredlocationpleasanton ca requiredwork authorizationunited states required,,CA,False,data_engineer
Data Engineer,"the enterprise analytics team is responsible for using data  analytics to drive value across our organization in support of these activities the data engineer is responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for the business intelligence and data warehousing team and other teams that are represented in the analytics center of excellence
the data engineer will support our developers data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects this position will help to optimize and expand our existing data architecture to support our next generation of data initiatives
advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
experience building and optimizing big data pipelines architectures and data sets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
strong analytic skills related to working with unstructured datasets
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queuing stream processing and highly scalable big data data stores
strong project management and organizational skills
experience supporting and working with crossfunctional teams in a dynamic environment
we are looking for a candidate with 5 years of experience in a data engineer role who has attained a bachelors degree in computer science statistics informatics information systems or another quantitative field they should also have experience using the following softwaretools
experience with big data tools hadoop spark kafka etc
experience with relational sql and nosql databases
experience with data pipeline and workflow management tools
experience with aws cloud services
experience with streamprocessing systems storm sparkstreaming etc
experience with objectorientedobject function scripting languages
organizational information


at children’s hospital of wisconsin we believe kids deserve the best
children’s hospital is a nationally recognized health system dedicated solely to the health and wellbeing of children we provide primary care specialty care urgent care emergency care community health services foster and adoption services child and family counseling child advocacy services and family resource centers our reputation draws patients and families from around the country
we offer a wide variety of rewarding career opportunities and are seeking individuals dedicated to helping us achieve our vision of the healthiest kids in the country if you want to work for an organization that makes a difference for children and families and encourages you to be at your best every day please apply today
please follow this link for a closer look at what it’s like to work at children’s hospital of wisconsin httpswwwinstagramcomlifeatchw",,WI,False,data_engineer
Big Data Engineer,contractsenior big data engineer required skills include spark kafka mongo hbase and springboot realtime streaming sql and experience working with large data sets expert knowledge of big data concepts and common components familiarity in dev opspuppet chef pythonlocation south metro denver costatus contractjob type contractexperiencebig data 6 years required,,CO,False,data_engineer
Senior Data Engineer,"the company

were a tech company thats changing how people bank and think about their finances we value empathy curiosity craft and efficacy our mission is to help people feel confident with their money we do that by bringing humanity elegance and ease to the consumer banking experience and we make banking beautiful

the team

the data engineering team builds and operates the pipeline that feeds simples data needs currently using postgres kafka and redshift the team is composed of data management specialists working together to reduce operational defects and increase the capabilities of simples internal data customers in product and platform engineering risk management analytics and customer support

about you
you love both the human and technical challenges of building data solutions that create awesome business impact you think deeply about technology  data and what it can unlock for customers you thrive in a collaborative environment that values discussion and empirical reasoning and believe these components lead to a successful outcome for the team and the business

what youll do all day

as a senior data engineer you will design implement and coordinate projects within the data team you will mentor junior engineers and participate in development and operational work that meets the standards of practice for both youll interact across the platform and engineering teams in order to have an impact on the business at large


ensure our data pipelines are healthy and operational
respond to alerts and customer requests for data and analytics support
lead design and implementation of pipelines features and enhancements
mentor junior engineers
plan and coordinate small projects

wed like to see

a minimum of 5 years of relevant experience
experience designing and implementing data management systems for business impact
proficiency with sql and python or a jvm language
experience with data modeling warehousing and analysis
experience with aws or other cloud services

details

we recognize the dire lack of diversity in our industry and were not okay with it we actively seek to address it with our hiring and retention processes as well as our office culture if youre on the fence about whether youre a fit we say go for it and apply

why simples a great place to work


based in portland oregon a beautiful place to live and work or just see in the background if you work remotely
competitive salary and benefits package
a supportive and nurturing place to work we actively consider how we can improve employees quality of lifeboth inside and outside the office
committed to hiring quality human beings simple is a place where others will watch out for you and help you learn we actually like and respect each other
we give a damn about what we do both as individual contributors and as a company on a mission to change banking were passionate and nerdy about our work in fact were kind of that way about things outside of work too

in compliance with federal law all persons hired will be required to verify identity and eligibility to work in the united states and to complete the required employment eligibility verification document form upon hire email our team at careerssimplecom  careerssimplecom  if you need an accommodation in the application process

a background check will be required for this opportunity

simple provides equal employment opportunities eeo to all employees and applicants for employment without regard to race color religion sex national origin age disability​ or genetics in addition to federal law requirements ​simple ​complies with all ​applicable state and local laws governing nondiscrimination in employment in every location in which the company has ​employees this policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation and training

by submitting this application you certify that the facts contained in your application are true and complete to the best of your knowledge if you are employed false statements on your application will be grounds for termination",,OR,False,data_engineer
Data Scientist - Hedge Fund - Manhattan & Stanford CT,contractjob titlemarket intelligence technology data scientistsummaryour technology team is looking to hire a senior data scientist for a central data initiative to build out a data science platform that will provide analytic and machine learning workspaces these are 12 month rolling contracts paying market leading rates depending on experience what you’ll doas a data scientist you will be working on building out new technology platform that will be used by firm’s data scientists and analysts you are expected to work on fast paced and highly visible project that has significant business impactwriting efficient modular and dependable code packages libraries and scriptswork closely with team’s data engineersystems developer and platform customers to design research eg backtesting software and production eg model serving api processesdocumenting all work extensively and train teammates on use of work products eg custom python libraries or r packagescollaborating regularly with firm’s big data group and other firm resourcesfacilitate building research hypotheses and assumptions of portfolio manager and investment analysts by designing methodology and writing necessary code to perform backtesting crossvalidation event studies data analysis etcfunction as an extension of data engineering team to build out data science use cases of the platformwhat’s requiredseasoned data scientist with experience on buy side or sell side firms doing equity researchan expert in python or r with 5 years of programming experiencestrong programming skills in relational sqlnosql databasesstrong written and verbal communication skillshold and advanced degree in computer science or relevant engineering disciplineconversant with advanced statistical analysisjob type contractsalary 5000 to 20000 hourexperiencepython 2 years requiredr 2 years requiredlocationnew york ny required,,NY,False,data_engineer
Data Engineer,"company information

paccar is a fortune 500 company established in 1905 paccar inc is recognized as a global leader in the commercial vehicle financial and customer service fields with internationally recognized brands such as kenworth peterbilt and daf trucks paccar is a global technology leader in the design manufacture and customer support of highquality light medium and heavyduty trucks under the kenworth peterbilt and daf nameplates paccar designs and manufactures advanced diesel engines and also provides customized financial services information technology and truck parts related to its principal business

whether you want to design the transportation technology of tomorrow support the staff functions of a dynamic international leader or build our excellent products and services — you can develop the career you desire with paccar get started

division information
paccar financial
paccar financial facilitates the sale of premiumquality paccar vehicles in 20 countries on three continents worldwide by offering a full spectrum of creative flexible financial products and valueadded services specifically tailored to the transportation industry

requisition summary
does empowering teams to make data driven decisions excite you do you wake up in the morning wondering what possibilities could be unlocked with more data paccar financial is looking for a seasoned data engineer to join the team data engineering focuses on making possible fast accurate and reliable access to data we build data pipelines manage a data warehouse and support the production use of our data we advocate for good data practices and make sure that our business users are able to make good data driven decisions



job functions  responsibilities

provide data engineering on modern cloudbased and legacy data processing technology stacks
build data pipelines data validation frameworks job schedules with emphasis on automation and scale
contribute to overall architecture framework and design patterns to store and process high data volumes
ensure product and technical features are delivered to spec and ontime
design and implement features in collaboration with product owners reporting analysts  data analysts and business partners within an agile  scrum methodology
proactively support product health by building solutions that are automated scalable and sustainable – be relentlessly focused on minimizing defects and technical debt



qualifications and skills

5 years of experience in largescale software development with emphasis on data analytics and highvolume data processing
3 years of experience in data engineering development
2 years of experience implementing scalable data architectures
2 years of experience with aws and related services eg ec2 s3 dynamodb elasticsearch sqs sns lambda airflow snowflake
experience in datacentric programming languages eg python go ruby javascript scala
proficiency with etl tools and techniques
knowledge of and experience with rdbms platforms such as ms sql server oracle db2 ims mysql postgres sap hana and teradata
experience with participating in projects in a highly collaborative multidiscipline team environment
work settings
requires frequent sitting and walking
availability to work “oncall” 24 hoursday for emergencies
position could be required to minimal traveling up to 20



education

masters or bachelors degree in computer science or a related field



additional job board information

paccar is an equal opportunity employerprotected veterandisability",,WA,False,data_engineer
Big Data Engineer,"140000  170000 a yearcontractare you excited about being in a startup and being in the cyber security industry this company in san jose is changing internet security as we know it with their security as a service platform that protects against cyber attacks and data breaches they are looking to grow their team with a big data engineer that can enhance their current big data ecosystem so if this is the fit for you apply today
required skills  experience
bs in computer science or related field
4 years experience
java or python
restrestful
experience with the big data ecosystem
desired skills  experience
aws
rabbitmq or activemq
what you will be doing
tech breakdown
100 backend
daily responsibilities
100 hands on
the offer
competitive salary up to 170kyear doe
you will receive the following benefits
medical vision health insurance
401k
flexible pto
paid sick leave
catered lunches
unlimited snack bar


applicants must be currently authorized to work in the united states on a fulltime basis now and in the future
jobspring partners part of the motion recruitment network provides it staffing solutions contract contracttohire and direct hire in major north american markets our unique expertise in today’s highest demand tech skill sets paired with our deep networks and knowledge of our local technology markets results in an exemplary track record with candidates and clients",155000.0,CA,False,data_engineer
Data Engineer,"description
overview

the data engineer will be responsible for assisting the cx lab survey research team to create functionality for transforming and importing qualtrics data to workbook sheets these data will be sourced from multiple unique cx survey files the survey data capture the experience and opinions of customers working with advertising programs and products a second phase of development for the data engineer to accomplish will be to develop original programming to execute appropriate statistical testing and also compute metrics such as error bars for export into clientfocused topline data decks


main responsibilities
develop code to transform and import data from qualtrics to sheets using javascript to create functionality across app script andor sql platforms
script programming to operationalize appropriate statistical testing routines for insightful comparisons


requirements
experience programming with javascript for app development
proficiency with sql programming and query script
3 years of data engineering experience especially working with data files and data pipelines
masters degree in statistics data science data management or other quantitative field
experience in the application of analytical and data analysis procedures
experience working with at least one statistical package eg r sas spss
good interpersonalcommunication skills written and oral
excellent organizational skillsability to work under tight deadlines with little supervision
working knowledge of google docs sheets slides


nice to have
experience developing data visualization programming and formatting using google sheets and slides",,CA,False,data_engineer
Data Engineer (Startup),"120000  140000 a yearwe are the fastestgrowing fitness startup here in new york city right now and we are looking for a data engineer to come work handinhand with our director of data engineering to work with our large amount of data

whats the job

the data engineer on our team will

work on building the data pipelines for all of our data across all of our divisions
oversee setting up our data integrations including with salesforce
be tasked with scaling up our analytics capabilities across the company
work in a fun highenergy startup environment
have the ability to have a very flexible schedule with workfromhome hours
use the latest and newest technologies in the market

what skills do we need


advanced python skills
experience with core data engineering including data pipeline development and integrations
its a plus if youve worked with pyspark andor spark

who are we

we have already generated over 60 million in profit this year and receive about 650000 visits per second on our app at peak time headquartered here in new york we are in the health and wellness space and believe that a healthy lifestyle including eating right and exercise will benefit you in the long run

compensation


120000  140000
great equity in a fastgrowing company
very employeefriendly environment healthy lifestyle open pto days worklife balance

how should you apply

if you are interested please apply online or email me your resume to mattstabileaverityteamcom",130000.0,NY,False,data_engineer
Data Engineer,"donnelley financial solutions nyse dfin provides software and services that enable clients to communicate with confidence in a complex regulatory environment with 3500 employees in 61 locations across 18 countries we provide thousands of clients globally with innovative tools for content creation management and distribution as well as data analytics and multilingual translations services leveraging advanced technology deepdomain expertise and 247 support we deliver costeffective solutions to meet the evolving needs of our clients

position summary

donnelley financial solutions is seeking a data engineer to join our data and analytics team the ideal candidate is a selfstarter who is effective working with large development teams in a highly collaborative environment



job description

develop maintain test and troubleshoot data solutions including database development etl  data migration development and big data development
collaborate with technical and nontechnical resources to solve issues and develop new functionality
participate in requirements gathering and analysis meetings with team members internal customers and stakeholders



required skills

database development skills sql tsql
sql server 2012 or later
sql server 2016 experience is a plus
etl  data integration
troubleshooting of complex data solutions
big data technologies including azure data factory spark nosql hadoop hdinsight big data architecture a plus
data analysis
requirements analysis
bachelor’s degree in computer science information technology or relevant experience
2  years development experience with sql and tsql using sql server 2012 or later
2  years development experience using etl  data integration tools ssis preferred
1  years of experience performing data analysis  data profiling
1  years of requirements analysis experience
1  years of experience working in environments with formal sdlc software development life cycle experience experience working on teams utilizing agile methodologies a plus
1  years authoring technical and functional documentation


it is the policy of donnelley financial solutions to select place and manage all its employees without discrimination based on race color national origin gender age religion actual or perceived disability veterans status actual or perceived sexual orientation genetic information or any other protected status
if you are a qualified individual with a disability or a disabled veteran you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access jobsdfscocom as a result of your disability you can request a reasonable accommodation by sending an email to accommodationrequestsdfscocom",,IL,False,data_engineer
Google Cloud Data Engineer - Remote,130000  165000 a year indeed est contract otherwe have an immediate project requirement for a data engineer with a google cloud professional data engineer certification preferred this role will lead the team on client projectsthe data engineer should have excellent time and task management skills have proficientteam communications and be able to either telecommute from home or work in one ofour regional officesthis role can be on contract contract to hire or as a fulltimepermanentemployee for the right candidateresponsibilities leadoversee the design of industryleading cloudbased datasoftware solutionsto run on google cloud platform gcp lead the design delivery of and maintenance of data structures anddatabases data processing systems analyze data and enable machinelearning model business processes for analysis and optimization visualizedata and advocate policy design for security and compliance assemble solution teams for data engineering projects make internal recommendations to help improve and streamline the technicaland architectural processes work with the teams to develop web and mobile applications apis sdks andother tools as required document software designs functional and design specifications presentationsand other documents as needed lead our team on presales scoping as a technical expertexperience  10 years handson experience in engineering with solutiondata designleadership experience previous experience leadingdesigning multiple cloud data projects gcp andother cloud platforms aws azure experience leading large scale data migrations previous knowledge and experience with machine learningai expert capabilities with structured unstructured and realtime data google cloud professional data engineer certification preferred experience leadingdesigning with multiple cloud platforms such as googlecloud aws or azure big data pipelines and management experience with data security for data at rest and in transit ie firewallshashing encryption and ssl experience automating and managing key business data pipelines to deliver theoutput of models to targeted applications excellent sql coding and experience with a broad array of development toolsand platforms including a strong linux background and big data environmenttoolslanguages such as sql r sas python etc experience with google data tools such as mysql postgres bigtable dataflowspanner and bigquery experience with machine learning an asset handson experience with two or more of go python php java net or nodejs expert knowledge of and experience with gcp budgeting and billing strategies ms in computer science or equivalent program from an accrediteduniversitycollege able to collaborate and thrive in a fastpaced diverse highperformanceenvironment demonstrated excellence in written and verbal communicationjob type contractexperiencegoogle cloud 2 years required,147500.0,CT,False,data_engineer
Data Engineer/Analyst,"oath ad platforms is our unified ad tech solution for both advertisers and publishers our innovative ad tech gives one stop access to oaths trusted data high quality inventory and demand creative ad experiences and industryleading machine learning at global scale


a lot about you
you get people you have a unique blend of skills in developing deep consumer insights and competitive intelligence through data that drives product innovation to create the right experiences for people’s daily lives that achieve our goals to acquire engage and retain them
you get data you have a thirst for knowledge and insight you thrive and strive to present data in ways that product design engineering marketing and executive teams understand and act upon your data is 100 accurate and credible your reports are always clear and actionable
you get growth you are a consumerfocused datadriven and growthenabling analyst who has supported growth strategies roadmaps scrums and final product rollouts across the analyticsinsights acquisitionreferrals activationonboarding and adoptionretention loop
you get mobiledigital you have significant industry experience – and a strong understanding of the mobiledigital ecosystem – from apps to advertising and analytics you have successfully applied the latest mobiledigital tools to help drive reach retention and revenue growth
you get it done you have successfully worked with product design engineering marketing and executive teams to understand requirements translate business needs into data requests develop methodologiesplans analyze data and present findings that are embracedenacted
your day
understand the marketplace trends and help answer revenue trends
analyze supply as well as demand patterns and find revenue opportunities explain model behaviors suggest improvements etc
gain insights on what drives performance in terms of reach and revenue growth
create dashboards and reports that provide analysis and commentary explaining product sales and business trends for executive reporting
work closely with product and inform and update stakeholders on product performance plans and progress towards metrics
define data testing plans and create methodologies that help teams to iterate fast and release new features for testing and if successful rollout to all users globally
generate and go deep on consumer insights and competitive intelligence to help teams drive product innovation and iteration
build strong partnerships with product sales engineering and marketing teams and enable them to launch new growth initiatives for testingiteration
provide feedback to product sales and engineering teams on impact of product launches target launch metrics ab testing postlaunch metrics
investigate data and monitor data quality – partner closely with and provide requirements to the data engineering teams that can be clearly acted upon
frame business problems into questions that can be answered through data analysis and translate business needs into requirements

you must have
bsms in highlyquantitative field analytics computer science mathematics is preferred
data analysis generating insights for consumerfocused products
b2b or advertising experience is a must
experience with big data technologies such as hive hadoop mapreduce spark pig etc
experience with scripting programming languages such as perlpython is good to have
familiarity with unixlinux environment highly recommended
significant experience proficiency in and passion for mobile andor web products
track record of proactively establishing and following through on commitments
demonstrated use of analytics metrics and benchmarking to drive decisions
excellent interpersonal organizational creative and communications skills
team player in driving growth results combined with a positive attitude
strong work ethic and strong core values honesty integrity creativity
problem solver who never stops thinking about ways to improve



oath is proud to be an equal opportunity workplace all qualified applicants will receive consideration for employment without regard to and will not be discriminated against based on age race gender color religion national origin sexual orientation gender identity veteran status disability or any other protected category oath is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment please let us know if you need a reasonable accommodation to apply for a job or participate in the application process


currently work for oath please apply on our internal career site",,CA,False,data_engineer
Data engineer,"the requirements

bachelor or master degree in computer science or a related study
knowledge of and experience with
data modelling
data warehouse architecture
data integration and data clearing
python andor java c 
cloud computing aws and or azure
hadoop hive hbase redshift
rdbms sqlserver or oracle or mysql
spark scala is a plus
english  intermediate 
flexible proactive team player",,TX,False,data_engineer
IT Data Engineer Internship - Summer 2019,"temporary internshipas a data engineer the intern would have a variety of potential jobs available based on a candidate’s background experience and expertise duties would entail working in a team setting in order to design implement and test webbased solutions utilizing rli’s technology fabric and microsoft net technologies candidate would gain exposure to best practice enterprise patterns for application architecture and systems integration

the project that the intern will be assigned to will be based on 2019 planning and what the current priority of project work is during the intern period some examples include

data create enhance and support data services etl processes and reports for enterprise data
document services models processes and policies modernize data warehouse architecture and visualization capability
retire legacy artifacts and process


it would place more than one student in this position if multiple qualified candidates are found
required skills
solid understanding of foundational knowledge appropriate for a developer objectoriented programming database management systems etc additional knowledge specific to rli’s technology is a plus for example specific net experience and webbased development
demonstrated success in a classroom setting natural curiosity and desire to learn
excellent communication skills ability to work in a team


required experience
junior or senior student majoring in computer science management information systems computer information systems or related discipline
3040 cumulative gpa required",,IL,False,data_engineer
Data Engineer,"position overview
at the heart of our data solutions team are our super talented highlytechnical data engineers data engineers are data experts who dive right into new client projects and make it their job to understand how a client’s data fits together and what that data means

utilizing this knowledge and the industry’s newest technologies aunsight hadoop docker etc they create data lakes fed by realtime data streams that become the very foundation of the work we do critical at all stages of the data science process data engineers work crossfunctionally with both external and internal teams – from business analysts to data scientists mobile app developers to platform engineers it teams to highlevel executives data engineers also provide valuable feedback to our software team that helps to shape the development of aunsight our proprietary endtoend cloud analytics platform and the development of our proprietary mobile app sightglass

the best data engineers are patient persistent focused creative and incredibly curious they love to learn and seek out opportunities to identify unexpected solutions or develop alternate ways to solve challenging problems

essential duties  responsibilities
build and own “one source of truth” data sets to facilitate consistency and efficiency in extracting and analyzing data from disparate data sources
ensure data integrity by developing and executing necessary processes and controls around the flow of data
innovate and improve efficiency of managing data to allow for greater speed and accuracy of producing analyses metrics and insights
collaborate with internal and external teams to understand business needsissues troubleshoot problems conduct root cause analysis and develop cost effective resolutions for data anomalies
provides input into data governance initiatives to enhance current systems ensure development of efficient application systems influence the development of data policy and support overall corporate and business goals
utilizes technology to analyze data from applicable systems to review data processes identify issues and determine actions to resolve or escalate problems that require data system or process improvement
verifies accuracy of table changes and data transformation processes test changes prior to deployment as appropriate
recommend and implement enhancements that standardize and streamline processes assure data quality and reliability and reduce processing time to meet client expectations
communicate progress and completion to project team escalate roadblocks that may impact delivery schedule
stay uptodate on data engineering and data science trends and developments
follow company policy and procedures which protect sensitive data and maintain compliance with established security standards and best practices
additional duties as assigned to ensure client and company success
required skills
bachelor’s degree in computer science computer engineering mathematics or related field or 3 plus years of relevant work experience
experience working with relational database structures sql andor flat files and performing table joins web crawling and web development
proficiency in one or more of the following programming languages php java or python and a familiarity with nodejs
natural curiosity about what’s hidden in the data through exploration attention to detail and ability to see the big picture – similar to putting together a 10000piece puzzle
resourceful in getting things done selfstarter and productive working independently or collaboratively—ours is a fastpaced entrepreneurial environment with performance expectations and deadlines
ability to learn quickly and contribute ideas that make the team processes and solutions better
ability to communicate your ideas verbal and written so that team members and clients can understand them
ability to defend your professional decisions and organize proof that your ideas and processes are correct
share our values growth relationships integrity and passion
preferred skills
experience working in one of the following industries healthcare financial services media or manufacturing
experience working with commercial relational database systems such as electronic medical records or other clinical systems customer relationship management software or accounting systems
familiar with various data management methodologies data exploration techniques data quality assurance practices and data discoveryvisualization tools
prior experience supporting business intelligence operations managing technical business and process metadata related to data warehousing
experience working with nosql hive mapreduce and other big data technologies is preferred but not required
willing to train the right candidate
experience working with distributed andor parallel systems experience or knowledge of concepts",,IN,False,data_engineer
Data Engineer,"data engineer
agentis is a chicagobased data analytics and saas platform provider that empowers energy providers and their business customers to optimize energy consumption our saas customer engagement platform has been deployed to over 15 million businesses nationwide and growing we combine our strengths of data visualization data science and software development to create compelling and powerful customer experience at the intersection of clean tech and information technology agentis has an exciting and compelling mission with a very passionate and talented team leading the charge
interested in making a positive impact and creating great technology
were looking for a data engineer to be part of our growing core team
as data engineer you will play an important role in helping to develop a highly scalable saas application you must have solid communication skills be detail oriented and show leadership and an exemplary work ethic
as a data engineer you will
create and maintain optimal data pipeline architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and big data technologies using aws servers and technologies
build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics
work with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
keep our data separated and secure across national boundaries through multiple data centers and aws regions
create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
work with data and analytics experts to strive for greater functionality in our data systems
required skills
we are looking for a candidate with 3 years of experience in a data engineer role who has attained a bachelors andor graduate degree in computer science statistics informatics information systems or another quantitative field they should also have experience using some of the following softwaretools big data tools such as hadoop spark kafka etc relational sql and nosql databases such as mysql postgres cassandra hdfs data pipeline and workflow management tools such as azkaban luigi airflow etc aws cloud services objectoriented scripting andor programming languages such as php python java c scala etc
advanced working sql knowledge and experience working with and optimizing relational databases as well as working familiarity with a variety of databases
experience building and optimizing data pipelines architectures and data sets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
strong analytic skills related to working with unstructured datasets
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queues stream processing and big data databases
strong project management and organizational skills
experience supporting and working with crossfunctional teams in a dynamic environment
compensation
we offer a competitive salary benefits and bonus structure based on experience and performance
we will setup you up with a workstation of your choice and whatever software you need for development
we value teamwork innovation and productivity and foster an exciting and committed work environment that will help you become successful and grow in your position to apply email resumes to jobsagentisenergycom
agentis energy is an equal opportunity employer
eeo employer no recruiters or phone calls please",,IL,False,data_engineer
Data Engineer - People Analytics (Contract),"qualifications
strong experience with at least two of the following technologies python scala java
strong experience in traditional data warehousing  etl tools ssis informatica talend pentaho datastage
the ability to work across structured semistructured and unstructured data extracting information and identifying linkages across disparate data sets
good experience in multiple database technologies such as distributed processing spark hadoop emr splunktraditional rdbms ms sql server oracle mysql postgresql mpp aws redshift teradata nosql mongodb dynamodb cassandra neo4j titan elasticsearch lucene
a proven ability in clearly communicating complex solutions
have a strong understanding of information security principles to ensure compliant handling and management of client data
experience and interest in cloud platforms such as aws azure goole platform or databricks
who youll work with
you will be joining the orgsolutions team in boston we are also open to other north american locations

orgsolutions combines innovative design technology and advanced analytics with deep expertise to accelerate effective organizational decisions orgsolutions can help human resources and business leaders to make smarter organizational decisions by leveraging advanced data analytics usercentered design technology and proven methodologies these approaches help clients to answer critical questions related to cost reduction efficiency and effectiveness streamlining merger plans divestments and carve outs and talent deployment

mckinsey new ventures fosters innovation driven by analytics design thinking mobile and social by developing new productsservices and integrating them into our client work it is helping to shift our model toward assetbased consulting and is a foundation for –and expands our investment in –our entrepreneurial culture through innovative software as a service solutions strategic acquisitions and a vibrant ecosystem of alliances we are redefining what it means to work with mckinsey

as one of the fastestgrowing parts of our firm new ventures has more than 1500 dedicated professionals including more than 800 analysts and data scientists and we’re hiring more mathematicians data scientists designers software engineers product managers client development managers and general managers
what youll do
you will be responsible for architecting developing and deploying a wide range of real time applications both on premise and in the cloud for the people analytics team

as a data engineer you will write etl pipelines to process large amounts of semistructured data you will be responsible for indexing and retrieving semistructured documents from databases and search engines you will build large scale fuzzy matching capabilities and architect  build data application in the cloud aws

working with people analytics you will model hr data obtain data extracts and go on to define secure data exchange approaches you will acquire ingest and process data from multiple sources and systems into large scale data platforms in doing this you will design maintain  tune large data warehouse sets",,MA,False,data_engineer
Data Engineer,"as an it consulting firm founded in 1986 zirous has a solid history of providing the technology solutions our clients want and need to make their organizations successful we have partnerships with oracle hortonworks sailpoint microsoft and splunk in addition to the many other technologies we use to fit our clients’ needs
we are seeking a data engineer to join our team
only candidates local to the des moines ia area will be considered
what youd be doing
work on a variety of projects as a fulltime consultant  length of projects and types of client industries will vary
work closely with project managers to ensure successful project implementation
provide expert and specialized handson technical support consultation and coaching to clients
collect aggregate and analyze data solve complex problems through data and analytics and provide insights that are logical data drivenand aligned to client business goals
examine methods for data validation building statistical models and data visualization using a cutting edge technologies
integrate model inputs and outputs with existing systems for real time online usage
other duties as assigned
have the ability to create your career
requirements
bachelor’s degree in computer science computer engineering software engineering data science statistics mathematics information systems or in a related field or equivalent work experience
sound fundamentals of data structures algorithms and objectoriented programming
previous experience with either machine learning advanced analytics or big data mining is highly desirable
previous experience with codebased visualization toolslibraries
ability to quickly learn and communicate the latest findings in data reporting  analytics tools processes methodologies and best practices
clear and concise written and verbal communication skills you can articulate complex technological concepts to fellow engineers and translate for nonengineers you are adept at navigating technical conversations with both team members and clients alike
1  5 years of experience with the following technologies
sas
hive
sql
spark
storm
nifi
kafka
atlas
ranger
java
benefits
contributing to the success of a high caliber team
competitive salary and benefits package including 401k
an environment that fosters personal and professional growth
opportunities to work on exciting and varied projects
flexible time off fto
we value our employees personal time career desires and life goals
zirous is an equal opportunity employer",,IA,False,data_engineer
Big Data Engineer,contractjob summary4 years of experience expertize and handson experience on java must have exp with hadoop hive mapreduce spark must have good knowledge of shell script must have good knowledge of one of the workflow engine like oozie autosys good to have good knowledge of agile development good to have passionate about exploring new technologies good communication skillsresponsibilities and duties4 years of experience expertize and handson experience on java must have exp with hadoop hive mapreduce spark must have good knowledge of shell script must have good knowledge of one of the workflow engine like oozie autosys good to have good knowledge of agile development good to have passionate about exploring new technologies good communication skillsrequired experience skills and qualifications4 years of experience expertize and handson experience on java must have exp with hadoop hive mapreduce spark must have good knowledge of shell script must have good knowledge of one of the workflow engine like oozie autosys good to have good knowledge of agile development good to have passionate about exploring new technologies good communication skillsjob type contractexperienceexpertize 4 years required,,AZ,False,data_engineer
Data Engineer,"summary

boxy charm is seeking a highly motivated individual responsible for building the analytics data platform for the company

the data engineer will work closely with data scientists and analysts across different business units to build data products that will enable fast decisionmaking and action across the company the position will be part of the data  algorithms team and as such the ideal candidate will not only possess great communication skills but will also be very technical equally at home writing code solving complex problems and working in a cuttingedge cloudbased platform and technology stack

essential duties and responsibilities


build cloudbased data products using sql python snowflake spark and other technologies
build data lifecycle and health tools to enable monitoring of key business kpis
work with a wide variety of data ranging between social media and email to customer transactions and logistics
partner with various business stakeholders and implement solutions that improve their business process
break down complex projects and problems into actionable tasks that be delivered quickly and iteratively and provide value to the business stakeholders
be a data advocate throughout the company

education andor experience


bachelors degree or higher in computer science information technology data analytics or a related field
3 years of experience programming in multiple languages such as python java scala etc
3 years of experience working with sql and relational databases and strong sql skills are a must
knowledge of big data and nosql systems such as snowflake hadoop spark mongodb etc
experience working in an agile scrum xp etc development environment
experience with aws or other cloud environments is strongly desirable
experience with streaming data systems is desirable

",,FL,False,data_engineer
Scala/Spark Big Data Developer,120000  170000 a yearcontractwe are a leading provider of open scalable nextgeneration ecommerce and cloud technology solutions for a number of larger firms and we work with some of the countrys leading and bestrecognized companies we serve as ecommerce consultants and subject matter experts for them helping to provide todays demanding and technologically savvy consumers with an exceptional shopping experience across multiple channels we are also a pioneer in private and enterprise cloud technology and work on the cutting edge of continuous delivery and release automation currently were looking for an experienced big data engineer to work with one of our best clients in cupertinoresponsibilities and dutiesdesign support and continuously enhance the project code base continuous integration pipelinehelps in design and development of big data analytical applicationscarry out largescale near realtime streaming data processing pipelinescreate complex etl processes and frameworks for analytics and data managementqualifications and skillsexcellent knowledge of hadoop and spark experience with data mining and kafka spark akkaworking scala knowledgeexperience with version control like gitexperience with jvm build systems a pluslinuxunix experience a strong plusbenefitsvery strong compensation  benefitsbenefits include medical dental vision and lifegenerous 401k packagea client list of whos who in the retail spacea fantastic and highenergy working environment with some very sharp colleaguesjob types fulltime contractsalary 12000000 to 17000000 yearlocationcupertino ca required,145000.0,CA,False,data_engineer
Data Engineer - Big Data and AWS,contractthis is a contract to hire position for our direct clientthe job requirements  responsibilities include· knowledge of data management fundamentals and data storage principles· knowledge of distributed systems as it pertains to data storage and computing· proficiency in at least one modern programming language such as java scala or python· experience working with aws big data technologies emr redshift s3· experience working with open source big data tools parquet spark hadoop presto· proven track record of delivering a big data solution· experience developing tools for data engineers and machine learning· experience working with both batch and real time data processing systemsjob type contract,,CA,False,data_engineer
Sr. Data Engineer,contractjob summaryjob requirements responsibilities demonstrate deep knowledge of data and the ability to lead others in the data engineering team to build and support noninteractive batch distributed  realtime highly available data data pipeline and technology capabilitiesdemonstrate focus in working towards defined business objectives and understanding the business value of work performeddemonstrate deep understanding of the etl process and variants thereof including orchestration and development of data productstranslate strategic requirements into business requirements to ensure solutions meet business needswork with infrastructure provisioning  configuration tools to develop scripts to automate deployment of physical and virtual environments to develop tools to monitor usage of virtual resourcesassist in the definition of architecture that ensure that solutions are built within a consistent frameworklead resolution activities for complex data issuesdefine  implement data retention policies and proceduresdefine  implement data governance policies and proceduresidentify improvements in team coding standards and help in implementation of the improvementsleverage subject matter expertise to coordinate issue resolution efforts across peer support groups technical support teams and vendorsdevelop and maintain documentation relating to all assigned systems and projectsperform systems and applications performance characterization and tradeoff studies through analysis and simulationperform root cause analysis to identify permanent resolutions to software or business process issueslead by example by demonstrating the mission and valuesadditional requirements ability to apply knowledge of multidisciplinary business principles and practices to achieve successful outcomes in crossfunctional projects and activitiesstrong working knowledge of python java scala or cstrong working knowledge of sql and nosql platformsproficiency in debugging troubleshooting performance tuning and relevant toolingstrong working knowledge of hadoop yarn mapreduce pig or hive sparkdemonstrated ability to “productionalize” at least 2 big data implementationsexperience using one of the public cloud aws or azure preferred for data applicationsproficiency in shell scriptingsolid understanding of data design patterns and best practicesproficiency in cicd toolsproficiency in logging and monitoring tools patterns  implementationsunderstanding of enterprise security rest  soap services best practices around enterprise deploymentsproven ability and desire to mentor others in a team environmentthanks  regardskanthibusiness development managermxpractice  alpharetta ga 30004contact number  17704060486job type contract,,WA,False,data_engineer
Data Engineer,"years of experience 5 years
responsibilities
the data warehouse developer is responsible for the successful delivery of business intelligence information to the entire organization and is experienced in data warehouse and bi development implementations heshe will be part of the team to review analyze modify and create etls testing debugging integration and implementation processes this person will also help create a roadmap for our clients technology platform for the next 5 years as they are moving to azuretasks will also include documenting technical needs for etl processes and databases and ensuring optimal technical infrastructure is utilized this position involves the delivery of big data integration projects and requires leveraging best practices expertise and experience at implementation as well as effective technology knowhow to support the ongoing activity of those working within business intelligence and analytics teams

essential functions
develop and maintain logical  physical data model designs data management standards and conventions data naming standards and metadata normalized denormalized and starbased structuresperform reverse engineering of physical data models from databases and sql scriptsevaluate data models and physical databases for variances and discrepanciesvalidate business data objects for accuracy and completenessparticipate in higher level planning efforts play a role in definition of processguidelinesstandardsdirect support of business intelligence and analytics teams












required skills

associates or bachelor’s degree – computer science or related field
4 years of data experience with microsoft stack ssis etldw with modern enterprise data architectures and data toolsets ex data warehouse data marts data lake 3nf and dimensional models modeling tools profiling tools proficient with sql ability to work on wide variety of development needs from simple ad hoc queries to complex stored procedures and multidimensional analysis
data integration etl and elt development paradigms and platforms
performance tuning strong performance tuning of etlsql code
cloud platforms azure data lake data bricks hdss sql dw aws redshift sql azure dw
data modeling erwin embarcadero powerdesigner ability to model data using appropriate notation",,IN,False,data_engineer
Data Engineer,"job description

we are looking for a candidate with 3 years of experience in a data analyst role who has attained an undergraduate degree in computer science statistics informatics economics or another quantitative field successful candidate should be able to apply statistical and machine learning methods to analyze large complex data sets and communicate the results and methods clearly

minimum requirements


programming experience of objectorientedobject function scripting languages python java and spark its a plus if candidate knows scala
be part of a multiyear program to build and deliver a centralized customer model implemented as a platform as a service from the groundup
ability to synthesize quantitative results to determine implications and make actionable recommendations
assemble large complex data sets that meet functional  nonfunctional business requirements
discover the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and aws technologies
work closely with product owners and other team members to meet delivery goals
work with data science and analytics experts to strive for greater functionality in our data systems
working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
experience designing and implementing machine learning models
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
strong analytic skills related to working with unstructured datasets
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queuing stream processing and highly scalable big data data stores
project management and organizational skills

company summary

pizza hut a subsidiary of yum brands inc nyse yum serves and delivers more pizzas than any other pizza company in the world with easy order options including the pizza hut app mobile site facebook and twitter messenger and amazon devices pizza hut is committed to providing an easy pizza experience – from order to delivery

founded in 1958 pizza hut has become the mostrecognized pizza restaurant in the world operating more than 16400 restaurants in more than 100 countries

pizza hut is also the proprietor of the literacy project an initiative designed to enable access empower teachers and inspire a lifelong love of reading the program is rooted in the foundation set by the pizza hut book it program which is the longestrunning corporate supported literacy program impacting more than 14 million students each year for more information visit wwwpizzahutcom  follow pizza hut on facebook wwwfacebookcompizzahut  twitter wwwtwittercompizzahut  and instagram wwwinstagramcompizzahut ",,TX,False,data_engineer
Senior Data Platform Engineer,"about knotch


knotch is the independent standard for content marketing roi we help cmos and their teams measure and impact the outcome of their content efforts via realtime actionable intelligence across all of their content investment our endtoend content intelligence platforms helps marketers plan measure optimize and benchmark their content efforts across all owned and paid strategies we work exclusively with brands and we do not monetize from any distribution channels to make sure that our business model isnt invested in the success of what we are measuring

were based in soho nyc and work with brands including ge unilever jp morgan chase  co sprint td ameritrade ford colgate and citi in 2018 alone knotch has been named to inc best place to work  httpswwwinccombestworkplaceslist list and built in nyc top 50 startups to work at  httpswwwbuiltinnyccom2018011650nycstartupswatch2018 

engineering at knotch


engineering is the cornerstone of our organization and we work hard everyday to build the most impactful products as possible we love to experiment find a deep joy in product iteration achieve stability with thoughtful architecture and testing all while monitoring our performance and progress at every step

knotchs founding mission has always been to improve the advertising and marketing industries in a lasting and meaningful way transparency through data is our ethos and something every member of our company takes seriously we are looking for highly motivated engineers who passionate about data and who are eager to transform an industry to join us on our journey

data platform engineering


at knotch our data platform is vital to providing key intelligence and insights to our clients as a result our data platform is the most important element when it comes to successfully scaling our products and technologies as our platform evolves agility with stability are critical to avoid bottlenecks in our products and to ultimately increase our value were looking for an experienced data engineer who deeply values clever platform architecture and who emphasizes speed and stability to join our growing team

what youll do at knotch



design and implement resilient backend architectures that process gigabytes and beyond
write software for backend services using ruby python and other languages
work directly with our data science team facilitate new understandings and insights from our data
work directly with our fullstack engineering team to expose value from our data

what we want from you



5 years of data platform engineering experience
working experience with aws services including dynamodb redshift athena and other data warehouse and data lake services
experience with various aws offerings such as ec2 ecs rds elasticache lambda and others
experience with ruby rails sidekiq python postgres redis
experience working with data science teams and productizing data science models and applications

we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,NY,False,data_engineer
Data Engineer,"at modernizing medicine we look for passionate innovative creative rock stars


peoples choice ux award for modmed® kiosk  2017
customer success team of the year by siias company codie  2017
south florida business journal fastest growing technology company  2016 2017
inc 5000 fastestgrowing private companies in america  2015 2016 2017
deloittes technology fast 500™  2015 2016 2017

modernizing medicine  httpswwwmodmedcom  is delivering truly disruptive and transformative products and services that will impact the healthcare industry the work we do makes a difference

our web and mobile applications are transforming healthcare information technology to increase practice efficiency and improve patient outcomes we offer endtoend specialtyspecific solutions from practice management through emr to revenue cycle management rcm that maximize office interactions patient visits collections and reimbursements

modernizing medicine is looking for an exceptional data engineer with a passion for technology to help us revolutionize the world of healthcare it data engineers are at the core of a datadriven business they build and maintain infrastructure that empowers analysts and data scientists to drive insights weve built a team of passionate creative and innovative engineers and data scientists that are changing the world and having fun doing it

you may be a great fit for modernizing medicines data engineering opportunity if…


you are a gifted data engineer passionate about technology in healthcare it
you are a collaborator you thrive in environments that freely exchange ideas and view points
you are an innovator that believes in making a difference and having fun doing it

the role

create maintain and support etl pipelines
maintain data warehouse infrastructure
work with application development teams to understand data representation
maintain documentation for the data warehouse and other data products
support data usage and infrastructure needs of downstream analytics teams

skills  requirements

bs in computer science or equivalent work experience
experience with talend etl or similar
sql and relational databases
objectoriented programming
strong problem solving skills adaptable proactive and willing to take ownership
strong commitment to quality architecture and documentation
experience using aws or other cloud services a plus
experience with big data tools hadoop spark kafka airflow a plus
experience with python scala and r a plus

modernizing medicine benefit highlights

your compensation is a combination of base salary and bonus potential
health insurance 401k vacation employee assistance program flexible spending accounts
weekly catered breakfast and lunch treadmill workstations quarterly onsite massages onsite dry cleaning onsite car wash and many more

",,FL,False,data_engineer
Senior Data Engineer,"data engineers at pandora are responsible for the services and infrastructure capable of processing and making available the extensive volume of data produced on its platform each day data engineers build the infrastructure needed to enable analysts and scientists to query and author data products that operate against our largest collections billions of events per day at pandora the data team supports a variety of business functions including our science marketing product finance and sales teams you should have a solid understanding of java software development and take personal responsibility for testing the code you write you should have strong academic credentials and a degree in computer science or a related field you should be enthusiastic about learning new technologies and skills you must be capable of managing your time well and working collaboratively excellent communication skills both written and verbal are required
responsibilities
5 years development experience of which 23 years are focused on data or analytics engineering working with big data technologies hadoop ie mapreduce hdfs tez hive spark
experience with one of the following distributed databases mysql postgres redis nosql or newsql
experience developing in one of the following java scala cc or python
experience developing for linuxbased deployment platforms developing scalable multithreaded server side software for deployment
experience developing sql applications of significant complexity
experience developing service oriented architecturesorchestration including the support of data science
experience with api designdevelopment ie rpc rest json
significant experience unit testing with frameworks ie junit
requirements
experience collaborating with data scientists exposure to machine learning algorithms andor statistical modeling methods
experience with anomaly detection recommender or search systems
experience with apache spark and kafka
experience working across the full technology stack
babs or above in computer science or a related field
“were considering candidates for multiple positions and levels successful candidates will be placed at appropriate level depending on their qualifications or experience”",,CA,False,data_engineer
Principal Data Engineer,"the opportunity

scholastic is seeking a principal data engineer to lead ongoing development of the scholastic data cloud sdc the candidate will demonstrate a successful track record of thought leadership and management skills coupled with deep experience engineering and managing cloudbased data platforms the ideal candidate will be distinguished not only by their experience working in a cloudbased multitenant environment but also by high levels of creativity passion and thought leadership

your responsibilities

lead the scholastic data cloud sdc development effort focusing on scalability quality and performancemanage a team of data engineers located both on and off shoreserve as the organization’s expert on sdc platform technologies and architectureperform employee performance reviews and regular oneonone sessionsperform code reviewsensure adherence to scholastic’s enterprise best practicesdesign efficient scalable processes to acquire manipulate and project dataparticipate actively in all facets of the agile processcontribute to the sdc codebase directly by taking on development tasks
how you can fit

bachelor’s degree in computer science math statistics or other quantitative discipline8 years experience implementing enterprise data solutions3 years experience in a management roleextensive experience with aws data services redshift rds dynamodb data pipeline emrextensive experience writing and tuning sql queries5 years using etl  data movement tools talend pentaho glue ssis sqoop matillion informatica3 years programming in one or more languages python java scala cc2 years experience with nosql data platformsexperience implementing a data lake architectureexperience with agile process methodology cicd automation test driven developmentexperience with aws kinesis kafka storm spark sonarqube highly desired
who we are

scholastic corporation nasdaq schl is the worlds largest publisher and distributor of childrens books a leading provider of core literacy curriculum and professional services and a producer of educational and entertaining childrens media the company creates quality books and ebooks print and technologybased learning programs for prek to grade 12 classroom magazines and other products and services that support childrens learning both in school and at home with operations in 14 international offices and exports to 165 countries scholastic makes quality affordable books available to all children around the world through schoolbased book clubs and book fairs classroom collections school and public libraries retail and online true to its mission of 97 years to encourage the personal and intellectual growth of all children beginning with literacy the company has earned a reputation as a trusted partner to educators and families learn more at wwwscholasticcom

some benefits that we offer

100 vested of 401k retirement plan after 5 years employmentup to 1m worth of supplemental life insurancetuition reimbursementpurchase scholastic stock at a 15 discount
thank you for your consideration in choosing scholastic",,NY,False,data_engineer
Sr. Data Engineer,"were lendinghome were on a mission to revolutionize the world of mortgages and put the power and the keys where they belong—in your hands

the team

lendinghome is reimagining the mortgage process from the ground up and data is at the core of everything we do as a data engineer you will be immersed in some of the most fascinating data sets in the world your work is highleverage as it impacts business strategies loan operations credit decisions product offerings and risk management

responsibilities


build data pipelines that collect connect centralize and curate data from various internal and external data sources
manage and extend a reliable effective and scalable data infrastructure
work closely with analysts data scientists and product engineers to understand business needs and designmaintain scalable data models
implement systems for monitoring data quality and consistency
productionize machine learning models that power our data products and integrate with our loan origination platform

qualifications


3 years of applied big data experience
advanced skills in javascalapython
expertise in distributed databasecolumnar data store redshiftbigquery
expertise in a modern data processing and workflow management framework airflowluigiazkaban
understanding of dimensional modeling and familiarity with bi tools lookertableau
excellent teamwork and communication ability
cs engineering math or related quantitative discipline
mortgage background not required but eager to learn the business

lendinghome is an equal opportunity employer
san francisco fair chance ordinance police code article 49  httpsfgovorgolsesitesdefaultfilesfilecenterdocuments11600art20204920official20notice20final20091114pdf 

 httpswwwthemusecomcompanieslendinghome 

 httpswwwlinkedincomcompanybeta3637074 

 httpstwittercomlendinghomelangen 
 httpswwwfacebookcomlendinghome 
 httpstechlendinghomecom ",,CA,False,data_engineer
Senior Data Engineer,"hinge health’s mission is to improve the lives of people suffering from chronic conditions by digitizing the delivery of care  starting with musculoskeletal health we’re already achieving remarkable outcomes  helping people overcome chronic pain avoid surgeries return to work and get back to doing the things they love we’re now rapidly signing large enterprise customers

you’ll work at the intersection of product and engineering and be responsible for implementing data infrastructure that will enable the company to scale its data science and analytics operations you’ll also be working on challenging data science problems such as creating models to predict clinical outcomes and patient engagement

we’re firm believers in growth and career development you’ll own your role be part of the decisionmaking process and manage your own time
responsibilities
guide the development of hinge health’s data infrastructure
work closely with our product and business development teams to derive insights and think critically about user behavior and clinical data
considerations
experience implementing and maintaining data infrastructure
opinionated on how to organise and maintain functions  modules  scripts across a data science team
opinionated on how data should be accessed by nontechnical analysts and product people
sql python andor r expertise expected
ability to work autonomously when needed and work in a fastpaced environment
previous dba experience is a huge plus
bonus points
competitive salary
meaningful stock options we want everyone to feel like a real owner
medical dental vision 401k
flexible vacation policy
lunch  snacks
company outings hikes running climbing events and more
opportunity to join a fantastically talented diverse and passionate team that’s working on a meaningful problem
we’re firm believers in “learnitall” versus “knowitall” to that end we are looking for a candidate with an open mind and willingness to hustle to drive success at hinge health if youre interested  wed love to hear from you no recruiters please",,CA,False,data_engineer
Senior Data Engineer,"as a data engineer on the analytics systems team you’ll work with a talented team of engineers to improve credit karma’s data pipeline that powers our recommendation systems enterprise tools and data warehousing you’ll help to build a general secure scalable fast and high throughput data pipeline to process many terabytes of data a day
we are very passionate about performance correctness and data quality the team spends their time day to day developing new pipelines or features that make it seamless for data to be moved throughout our infrastructurethis includes working with cutting edge tools such as scala kafka spark akka and google cloud we are looking for data engineers at all levels if you enjoy working in a collaborative environment where everyone can have their say while still being able to set and hit deadlines then this is the role for you
responsibilities
work with analysts and data scientists to define processes and standards to inform system design transform their needs into streaming or batch processing
design infrastructure and systems to scale easily as data ingest grows
implement new data pipeline features with verified high quality from unit test coverage and production monitoring
focus on data quality detect dataanalytics quality issues and implement bug fixes and data validation for prevention
help understand our day to day operations for continuous improvement of production systems
our ideal candidate
2 years experience with big data technologies we’re hiring all experience levels
experience with scalajava spark kafka or demonstrated ability to pick up new technology quickly
fundamental knowledge about databases and strong sql skills
familiar with google cloud ecosystem such as bigquery gcs dataproc etc
enjoys working collaboratively ck’s values include empathy and helpfulness
able to estimate and meet deadlines
excellent verbal and written communication skills
nice to have
experience working with cloud technologies
experience scaling data throughput or building low latency streaming pipelines
experience solving for data quality
learn more about credit karma at creditkarmacomcareers
liag1",,CA,False,data_engineer
Cyber Analytics Data Engineer,"company profile
morgan stanley is a leading global financial services firm providing a wide range of investment banking securities investment management and wealth management services the firms 55000 employees located in 1200 offices across 43 countries serve clients including corporations governments and individuals as a market leader the talent and passion of our people is critical to our success together we share a common set of values rooted in integrity excellence a strong team ethic and giving back to our communities morgan stanley provides a superior foundation for building a professional career  a place for people to learn achieve and grow a philosophy that balances personal lifestyles perspectives and needs is an important part of our culture

division  department profile
the mission of the global enterprise technology  risk etr division is to provide a highly reliable and commercial technology platform which supports the firms strategy delivered by an innovative worldclass team of professionals technology  information risk tir is part of the etr organization and manages operational and technology related risks on behalf of the firm tirs mandate is to enable the firm to manage its technology and data related risks through implementing proactive comprehensive and consistent risk management practices across the firm to protect the franchise while capturing business opportunities the tir team partners with the business by ensuring that technology and data understands how to manage escalate and monitor risk the mission of the cybersecurity organization within tir is to identify and protect firm assets through proactively assessing threats and vulnerabilities and detecting events and ensuring resiliency through agile response and recovery
with cybersecurity morgan stanley’s stateoftheart fusion center fusion is charged with understanding detecting and responding to cyber events vulnerabilities and incidents that threaten the firm’s clients assets and reputation partnering with key stakeholders across enterprise technology  risk and the business units fusion manages cyber events from detection through response to resolution and serves as the firms focal point for cyber communications and reporting fusing together information received externally from our partners and internally from our detection and analytics teams to enable rapid decisionmaking fusion is the cornerstone of the firms agile and adaptive cyber defence strategy enabling rapid realignment of our defensive capabilities to adapt to changing adversary threats

team profile
the cyber analytics team plays a critical role in the fusion centers ability of to detect and respond to threats against the firm the team is responsible for developing and delivering a suite of advanced monitoring capabilities to enable realtime threat detection delivered directly to incident response teams as well as the incident response workflows and tools used by incident responders the team is also responsible for the content and technology of the fusion ops wall an array of large highresolution displays that provides situational awareness and realtime visualization of the firms technology assets applications and security controls designed to allow cyber teams to quickly detect any evidence of anomalous activity

role description primary responsibilities
the cyber analytics team is seeking a data engineer to collaborate with other developers and business users in an agile environment to develop stateofthe art detection and response capabilities to counter cybersecurity threats including

engage with business users to define requirements
discover and correlate data from disparate sources to report on and analyze computer and network activity
collaborate with other developers on technical design of data discovery components
automate data collection and delivery
prepare data for use in analytics
implement streaming and batch data transformations
work in on premise and cloud environments

skills required

3 years of data engineering experience with a demonstrable portfolio of achievement
expertise with big data platforms such as kafka splunk hadoop and elastic
knowledge of linux and computer networking
experience with relational databases is nice to have
ability to provide technical leadership to junior team members and direct contingent resources
excellent written and verbal communication skills
proven collaborative abilities to work with other developers and business users to craft endtoend solutions

skills desired

positive attitude and enthusiastic desire to learn new technologies and expand professional skills
strong interest in cybersecurity concepts and incident response process
experience working on a team distributed across continents and time zones",,MD,False,data_engineer
Big Data Engineer - AWS (Sagemaker enablement),contractin immediate need for an experienced big data engineer for a longterm engagement in malvern pa candidate will be required to work onsiteaws sagemaker enablemento for enabling aws sagemaker build train and deploy and infer work within customer’s chief technology office cto cloud analytics services team to assist customer to meet requirements related to authentication with active directory or radiantlogic authorization auditing ensure aws cloudwatch logs have appropriate audit trail and integration with customer anaconda repo work with customer’s cto team to meet requirements related to working within customer virtual private cloud “vpc” using amazon simple storage services amazon s3 bucketsassist customer to support enablement of aws sagemaker via aws service catalog using standard customer tools such as bitbucket bamboo ansible aws cloudformation templates notifying tracking and enabling any gaps in aws sagemakerartificial intelligence integration provide engineering and ai related services to integrate amazon transcribe amazon comprehend amazon rekognition and amazon lex to the customer cto cloud analytics services team· automation of domino data labs – ongoing improvement of automated install· enabling of alternative data access patterns for center for analytics and insights cai it to leverage data lakes· enabling higher performance usercase based data stores such as amazon redshift in line with customer requirements· investigation of financial services data patterns and how to leverage those within it· improving amazon emr reliability in areas of network and domain name system dns issues and provide recommendations to increasing reliability for amazon emr cluster operations· assist in implementing recommendations and reference architecture that can will serve as the foundation for cai’s continuous integration  continuous delivery pipeline for model deployment· implementing amazon emr and domino data labs integration with customer business system· implementing best practices for data science model stores in line with customers data pattern use casesjob types fulltime contractexperienceamazon emr cluster operations 2 years requiredaws sagemaker 5 years requiredartificial intelligence ai 2 years requiredlocationmalvern pa required,,PA,False,data_engineer
Sr. Data Engineer/Architect,"sr data engineerarchitect

about capgemini
with almost 200000 people in over 40 countries capgemini is one of the worlds foremost providers of consulting technology and outsourcing services the group reported 2017 global revenues of usd 1578 billion together with its clients capgemini creates and delivers business and technology solutions that fit their needs and drive the results they want a deeply multicultural organization capgemini has developed its own way of working the collaborative business experiencetm and draws on rightshore® its worldwide delivery model learn more about us at httpwwwcapgeminicom rightshore ® is a trademark belonging to capgemini rightshore® is a trademark belonging to capgemini
 capgemini america inc is an equal opportunity employer encouraging diversity in the workplace all qualified applicants will receive consideration for employment without regard to race national origin gender identityexpression age religion disability sexual orientation genetics veteran status marital status or any other characteristic protected by law
this is a general description of the duties responsibilities and qualifications required for this position physical mental sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed whenever necessary to provide individuals with disabilities an equal employment opportunity capgemini will consider reasonable accommodations that might involve varying job requirements andor changing the way this job is performed provided that such accommodations do not pose an undue hardship
job description
job title sr data engineerarchitect
job type full time
job location multiple locations in ny nj nc il
role and responsibilities
the insights  data team is looking for a senior data prep engineer with strong background in big data and business intelligence this is a handson data engineer role where the individual will be responsible in the overall design including integrated data warehouse idw ods and or hadoop data lake a person entering this role requires experience in data modeling data architecture for nearreal time data ingestion api design etc
responsibilities
perform detailed design reviews with product owners developers and business stakeholders
stay abreast of information management trends and standards master data management data services selfservice business intelligence metadata management data quality and data governance
build  maintain reference model architecture and standards for communicating direction of information architecture
work with the platform team in optimizing data architecture and optimize use of data assets for data science
develop proofofconcept and prototypes to help illustrate approaches to technology and business problems
qualifications
excellent english communication skills both written and verbal
experience with linux grep shell scripts and command line tools
development experience using some of the following technologies python php sql or java angular js sql or sas etl
ability to prioritize and manage time efficiently
capacity for independent and autonomous work within a team environment",,,False,data_engineer
Junior Data Engineer,"our client an excellent company in new haven ct is seeking a junior data engineer to join their growing team
please apply to this job posting with your resume and contact information and our team will reach out to you right away
responsibilities of the position will include the following
create and maintain reporting processesworkflows for assigned campaigns
campaign setup in systems prior to launch date
reporting file uploads into analytics database
report build out for analytical purposes
api queries  vba macro implementation
provide support in key developmentprocess improvement projects
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
work with stakeholders including the analyst  media teams to assist with datarelated technical issues and support their data infrastructure needs
excellent applicants for this position should have the following qualifications
bachelor’s degree is preferred
interest in coding
eagerness to start asap


apply now

not ready to apply",,CT,False,data_engineer
"Staff Engineer, Data","at harrys we are building a cutting edge technology stack to support our multibrand vision we are already a successful mens grooming brand we launched in 2013 focused on quality craftsmanship simple design and modern convenience and now we have over 3 million customers worldwide

with our most recent round of financing 112 million we are developing brands beyond mens grooming the technology required to enable our goals is more sophisticated than first meets the eye if you are a driven talented engineer come join us and help build the platform that will enable our new vision

about the role

as a staff data engineer you will be responsible for building scalable data pipelines to support a variety of business needs you will drive the tooling and construction of harrys data lake and warehouse solutions you are an expert in constructing and maintaining performant and scalable pipelines leveraging kappa  lambda architecture best practices you will report to the senior manager of data engineering

what you will accomplish

take ownership of the design and implementation of scalable etl processes and data pipelines
drive the construction of the harrys data lake and data discovery platform
drive the rearchitecture and fine tuning of the harrys data warehouse for use by bi tools marketing platforms and machine learning models
partner with data scientists data analysts and business users in enabling data driven decisioning including data wrangling adhoc queries and supporting ml modeling
work with vendors and other developers to ingest new sources of data
contribute to improving key data engineering performance availability and customer satisfaction metrics in support of additional brands systems and geographies

this should describe you

you have experience with the aws stack including s3 athena redshift emr ecs lambda
you have 35 years of hands on experience with python or scala
you have 35 years of experience in the field of business intelligence application development database development and etl andor data analysis domains with strong hadoop hive andor spark knowledge
you have hands on experience with event based streaming pipelines
you have a strong command of sql
you have experience with nosql databases
you know how to make large software projects maintainable and extensible in the long run
you are curious about software and how things work you work to understand technical problems deeply and you stay current
you are able to productively collaborate with business users data analysts and data scientists you invest in the success of your teammates crossfunctional partners and projects

harrys is committed to bringing together individuals from different backgrounds and perspectives we strive to create an inclusive environment where everyone can thrive feel a sense of belonging and do great work together as an equal opportunity employer we prohibit any unlawful discrimination against a job applicant on the basis of their race color religion veteran status sex parental status gender identity or expression transgender status sexual orientation national origin age disability or genetic information we respect the laws enforced by the eeoc and are dedicated to going above and beyond in fostering diversity across our company",,NY,False,data_engineer
Data Engineer,are you seeking an opportunity to be a key partner in the enterprise level data management operations and development for a large organization are ready for an opportunity that not only allows you the opportunity to grow but the opportunity to grow others do you enjoy working in collaborative environments are you a team player are you able to work with clinicalbusinessfunctional partners 3rd party vendors regarding the the impact on data architecturethis position requires an advanced data engineer to work closely with other data engineers dba’s data analysts and analytics experts in addition assist in mentoring level i data engineers and data analysts the data engineer will be responsible for integration migration and optimization of data flow and collections across a variety of environments working with other departments across the entire enterprise the data engineer will support other technology specialists not limited to software engineers data architects data scientist software engineers web developers and quality analyst assist in the future strategy and direction of data innovations and implementing the next generation data advancements able to adapt to constant change growth and new solutions this engineer must be comfortable working independently yet able to collaborate when necessary supporting multiple systems and groups within it and the organizationresponsibilities include but not limited toidentifyin innovative uses of data and information to drive improved patient care productivity and operational efficiency increased departmental agility and higher performanceassist in establishing standards and guidelines for the design  development tuning deployment and maintenance of information advanced data analytics and text mining models and physical data persistence technologiescreatemaintain the development business intelligence data architecture to increase the robustness performance and scalability of systemsprovide oversight and direction for the design and development of the data infrastructuremaintain quality of data in the development data martensuring integrity of data in the data mart correcting any data problems data consistency establish and design procedures to purgearchive old dataprovide guidance to hits regarding data consistency between developments oltp application ancillary systems and enterprise data warehousecreatemaintain the etl architecture and design using health catalyst participation in the data advisory committee or other governance groupsmentor bi data application and infrastructure strategy team members on etl tool and architecturecreate streamlined scalable integration solutions to support bi and analytic environmentrequiredhigh school diplomabachelor’s degree in computer scienceinformation systems5 to 7 years experience with etl technologies ssis data stage informatica5 to 7 years’ experience with oop c c java etc3 to 5 years’ tsql experience in a relational database modeling preferably in a large complex healthcare environment or an equivalent combination of education and experience35 years’ experience with consuming data from api’s rpc restwsdl etc57 years’ experience with one or more bi tools such as sap business objectstableau powerpivot qlikview sasjob type fulltimeexperiencebi tools 5 years requireddata warehouse 5 years requiredtsql 3 years requiredetl technologies 5 years requiredopen object programming 5 years requiredapi 3 years requirededucationbachelors required,,KS,False,data_engineer
Data Engineer,"drillinginfo who we are
at drillinginfo our mission is to provide better faster decisionmaking support to the oil and gas industry through our data intelligence and analytics products we are building an agile development culture that delivers great products to a wide variety of customers we truly believe that diversity of experience perspectives and background will lead to a better workplace for our employees and better products for our clients we need an experienced engineer with a passion for software development someone to be handson in designing implementing and delivering features for our flagship product

job overview
as a data engineer a person will have the opportunity to shape the future of drilling info inc by building and maintaining businesscritical customerfacing applications and helping deliver the next generation of oil and gas information retrieval and analytics
a data engineer will be responsible for creating and maintaining the pipelines to assemble different datasets all this following an architecture defined by the company
a data engineer should write maintainable code and work in a professional software engineering and teamwork environment source control shortened release cycles continuous integrationdeployment documentation agile development
a data engineer should have excellent analytical and critical thinking skills should show initiative and a positive attitude
competitive candidate profile
bachelor’s degree in computer science or similar
5 years of experience building maintaining and delivering databased products
advanced level with programing languages python
strong familiarity with database languages sql server ssis
strong familiarity with version control systems git svn
strong familiarity with agile development
experience with developing objectoriented enterprisesized systems
desirable experience with programing languages c net
desirable experience with airflow aws kafka docker
desirable experience with every layer of an enterprise system from database to ux",,TX,False,data_engineer
Data Engineer,"job description

the auto club group acg provides membership travel insurance and financial services offerings to approximately 9 million members and customers across 11 states and 2 us territories through the aaa meemic and fremont brands acg belongs to the national aaa federation and is the second largest aaa club in north america

primary duties and responsibilities details of the basic job functions
the data engineer is responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for crossfunctional teams responsibilities include
create and maintain optimal data pipeline architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and google cloud platform ‘big data’ technologies
build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics
work with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
keep our data separated and secure across national boundaries through multiple data centers and cloud vendor regions
create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
work with data and analytics experts to strive for greater functionality in our data systems

supervisory responsibilities briefly describe if applicable or indicate none
none

preferred qualifications
knowledge of meta and master data management
familiar with google cloud platform service cloud services like cloud sql bigquery dataflow dataprep appengine
knowledge of streamprocessing systems ie storm kafka etc

work environment
works in a temperature controlled office environment

qualifications

required qualifications these are the minimum requirements to qualify
education include minimum education and any licensingcertifications
bachelor’s degree in computer science statistics informatics information systems or another quantitative field

experience
3 years of experience in a data engineer role
advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
proficiency building and optimizing ‘big data’ data pipelines architectures and data sets
background performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores
experience supporting and working with crossfunctional teams in a dynamic environment

knowledge and skills
strong analytic skills related to working with structured and unstructured datasets
project management and organizational skills
experience with relational sql and nosql databases
knowledge of data pipeline and workflow management tools ie knime dataflow dataprep airflow etc
familiar with objectorientedobject function scripting languages ie python java c scala etc
familiar with big data tools examples include hadoop bigquery kafka etc

the auto club group offers a competitive compensation and benefits package including a base salary with performance based incentives medicaldentalvision insurance 401k generous time off a complimentary aaa membership and much more

important note the above statements describe the principal and essential functions but not all functions that may be inherent in the job this job requires the ability to perform duties contained in the job description for this position including but not limited to the above requirements reasonable accommodations will be made for otherwise qualified applicants as needed to enable them to fulfill these requirements

the auto club group and all of its affiliated companies is an equal opportunityaffirmative action employer all qualified applicants will receive consideration for employment without regard to race color religion sex gender identity sexual orientation national origin disability or protected veteran status",,MI,False,data_engineer
Data Engineer II,"about the opportunity
got a taste for something new

we’re grubhub the nation’s leading online and mobile food ordering company since 2004 we’ve been connecting hungry diners to the local restaurants they love we’re moving eating forward with no signs of slowing down

with more than 85000 restaurants and over 156 million diners across 1600 us cities and london we’re delivering like never before incredible tech is our bread and butter but amazing people are our secret ingredient rigorously analytical and customerobsessed our employees develop the fresh ideas and brilliant programs that keep our brands going and growing

long story short keeping our people happy challenged and wellfed is priority one interested let’s talk we’re eager to show you what we bring to the table
some challenges you’ll tackle
working with high volumes of data to efficiently process and expose for analysis
collaborating with other engineering teams on strategies for data
work with cutting edge data processing technologies
understand our stakeholder finance marketing product requirements and write complex and efficient code to transform raw data into an easy to approach data marts
doing deep dives on business verticals where you become one of the foremost experts on that vertical in the company
analyze data to measure impacts of data schemas and use it to iterate on improvements
translate from technical to business and vice versa you need to be able to speak with the least technicallyminded client internal or external and make technology make sense to them then turn around and do it the other way
you should have
excellent knowledge on sql data modelling and patterns
35 years experience with python or another general purpose programming language
background in writing etl jobs within a business intelligence context
a bachelors degree preferably in a computerrelated discipline
enthusiasm for the job are you excited about data do you love your users good the same goes for us
got these even better
experience big data processing with spark and other big data tools a plus
excellent communication skills including the ability to crystallize and broadly socialize insights
problem analysis and problemsolving skills
rigorous attention to detail and accuracy
exposure to amazon aws or another cloud provider
adaptability and collaborative skills
and of course perks
unlimited paid vacation days choose how your time is spent
never go hungry we provide weekly grubhubseamless credit
regular inoffice social events including happy hours wine tastings karaoke bingo with prizes and more
companywide initiatives encouraging innovation continuous learning and crossdepartment connections

we deliver favorites every day join us as we move eating forward
grubhub is an equal opportunity employer we evaluate qualified applicants without regard to race color religion sex sexual orientation gender identity national origin disability veteran status and other legally protected characteristics the eeo is the law poster is available heredol poster grubhub is committed to working with and providing reasonable accommodations to individuals with disabilities if you need a reasonable accommodation because of a disability for any part of the employment process please send an email to talentacquisitiongrubhubcom and let us know the nature of your request and your contact information",,IL,False,data_engineer
Sr. Data Engineer,contractjob summarydoes empowering teams to make data driven decisions excite you do you wake up in the morning wondering what possibilities could be unlocked with more data data engineering focuses on making possible fast accurate and reliable access to data we build data pipelines manage a data warehouse and support the production use of our data we advocate for good data practices and make sure that our business users are able to make good data driven decisionsprovide engineering on modern cloudbased data processing technology stackbuild data pipelines data validation frameworks job schedules with emphasis on automation and scalecontribute to overall architecture framework and design patterns to store and process high data volumesensure product and technical features are delivered to spec and ontimedesign and implement features in collaboration with product owners reporting analysts  data analysts and business partners with an agile  scrum methodologyproactively support product health by building solutions that are automated scalable and sustainable  be relentlessly focused on minimizing defers and technical debtqualificationsmasters’ or bachelors’ degree in computer science or a related field5 years of experience in largescale software development with emphasis on data analytics and highvolume data processing3 years of experience in data engineering development2 years of experience implementing scalable data architectures2 years of experience with aws and related services eg ec2 s3 dynamodb elasticsearch sqs sns lambda airflow snowflakeexperience in datacentric programming languages eg python go ruby javascript scaleproficiency with etl tools and techniquesknowledge of and experience with rdbms platforms such as ms sql server oracle db2 ims idms mysql postgres sap hana and teradataexperience with participating in projects in a highly collaborative multidiscipline team environmentjob type contractexperiencedata engineer 5 years preferred,,WA,False,data_engineer
Big Data Engineer,"160  180 a dayone of the world’s leading videosharing platforms is hiring for a big data engineer this company attracts over 300 million unique visitors and 3 billion videos views worldwide per month by offering the best content from users independent content creators and premium partnersthis company is building its programmatic and monetization product by building its own video ad stack to deliver new monetization solution for its own ecosystem around online mobile and tv and provide innovative marketing solutions for advertisers
in this role you will design and build highlyscalable data pipelines and data stores using cutting edge big data technologiesdesign build and maintain petabytescale datastores and highperformance horizontallyscalable processing pipelines and create processes for largescale ingest and export of data as well as enabling fast data query capabilities
required skills  experience
handson experience using the hadoop mapreduce andor spark distributed computing frameworks
experience programming andor architecting a back end language java j2ee core
experience with nonrelational  relational databases – sql mysql nosql cassandra redis aerospike redshift vertica
strong skills with the sql and hql hive data query languagesstrong coding skills in java python or scala a plus
exposure to streaming technologies eg spark streaming apache storm flink andor containerization technologies eg mesos docker kubernetes is a plus
ad tech experience is a plus
the offer
strong compensation competitive annual bonus 401k health dental vision limitless pto policy",,NY,False,data_engineer
Data Engineer,"responsibilities
business requirement analysis and assist in the implementation of new and existing systems
actuarial domain knowledge of business analysis development testing and implementation of software for insurance services for hedging product
continually increase business acumen and awareness of technology best practices to help the team deliver business solutions
supports process framework governance standards audit controls architecture and financial management
work with various quantitative and actuarial staff members to determine and implement possible solutions for valuation and projection of annuities
communicates effectively with project sponsors and stakeholders of project status progress risks issues and expected outcomes
devise document and implement conceptual and quantitative models to solve business problems
gather pertinent information and data sources across disciplines to formulate solutions
analysis design and implement software using an agile approach
coordinate with the it team the adoption of systems in the production environment under sdlc guidelines
is responsible for producing and presenting departmental level analysis to midlevel management
develop and maintain subject matter expertise required to advise businesses management
this role may include work in alm modeling research tradinghedging strategies
required qualifications
requires a graduate degree in mathematics actuarial science finance business or related field with 4 years relevant work experience or bachelor’s degree and fsacfaequivalent designation plus 5 years relevant work experience or bachelor’s degree plus 8 years relevant work experience may be substituted for graduate degree
must possess excellent understanding of investment and finance concepts and be able to creatively apply them in solving analytical problems in the business setting
must possess excellent communication skills
preferred qualifications
degree in mathematics or engineering
works well under pressure and within time constraints to effectively accomplish individual and team objectives
able to work within a fastpaced environment with quickly changing priorities
advanced computer skills including sql and unix
knowledge of etl tool preferably informatica
at least 1 year of experience in insurance product
experience in big data technologies like hive impala
communication skills to convey complex information to business both verbally and in writing at an appropriate level of detail for each audience
developed and delivered datadriven solutions to support business needs and analytics
expertise in relational database and sql preferably sql server and oracle
strong understanding of data warehousing analytics reporting and best practices
experience in financial services industry
knowledge of equity fixed income credit and derivative instruments
behavioral and leadership competencies
make tactical data driven decisions leveraging experience and with consideration to competing priorities consult with endusers and respond with solutions
able to exercise judgment as it relates to business decisions and their effects on stakeholders
highly organized and detail oriented with the ability to maintain a high level of accuracy
demonstrated business acumen and the ability to apply technology solutions to solve business problems
our culture
at transamerica we promote a future fit mindset what is a future fit mindset
acting as one fosters an environment of positive collaboration
accountability allows us to own the problem as well as the solution
agility inspires new ideas innovation and challenges the status quo
customer centricity encourages an above and beyond approach to our customer",,IA,False,data_engineer
Data Engineer,"about us

teza is a quantitative asset management firm that strives to develop innovative highsharpe investment products for its clients originally founded in 2009 as a science and technologydriven global quantitative trading business teza derives its unique edge in asset management from its highfrequency trading past and sciencebased investment approaches under the leadership of ceo misha malyshev tezas innovative approaches to quantitative research and platform engineering distinguish us from other quant trading firms we have successfully attracted and assembled a group of top talent including widely recognized experts in quantitative trading teza has over 50 professionals worldwide with offices in austin berkeley chicago london new york and shanghai

about the role

teza technologies is looking for a lead data engineer to join our core services technology team data drives systematic trading and is critical to all aspects of the firms business this is a handson senior position on a team of 3 data engineers with significant growth potential as this team will grow rapidly over the next couple of years firm is looking for outstanding technical skills and significant experience architecting and building data platforms

responsibilities


design and build a data platform that will leverage stateoftheart data technologies to minimize

development time and maximize performance and flexibility

the platform will facilitate data pipelines from vendors and other sources
clean and store the data
automated anomaly detection
mange accessentitlements
build mechanisms that allow our researchers and analysts to interact with the data
manipulate the data and store it back for reuse
provide a platform for backtesting
be an sme for companywide questions about the nature completeness and correctness of the data
onboard new data sources and maintain external relationships

requirements


it is critical that the candidate will bring a cs view to the process of data management
significant experience in systems design is desired
experience with sql and no sql databases
postgres mongodb is preferred
experience with big data technologies hadoop spark
preference for python java is a plus

",,TX,False,data_engineer
Hadoop Data Engineer,75  85 an hourcontractour client is seeking experienced data architects that take advantage of data analytics architectures  various tools to deliver solutions this is an excellent opportunity for an individual to grow their capabilities in a thriving organizationresponsibilitiesdesign  develop solutions for present data from a variety of sources and formats for analysis and use across use casesextensive handson experience using hadoop in large enterprise environmentsperform data profiling and discoverywork with source system and business sme’s to develop an understanding of the data requirements for the organizationperform hands on data development to accomplish the data extraction movement and integration leveraging state of the art tools and practices including both streaming and batched data ingestion techniquesassist in creation of data requirements and data model design as necessary and appropriatequalificationsexperience working with the apache hadoop ecosystem of tools and technologieskey sets of toolssparkkafkahivesqooppythonexperience working with enterprise wide etl and streaming dataexperience working with data governance frameworkssome experience performing conceptual and logical data model designstrong nosql sparksql and ansi sql query language skillsstrong verbal and written presentation skillsremote workwith some travelcontact johnny allen 6787306966job types fulltime contractsalary 7500 to 8500 hourwork authorizationunited states required,,PA,False,data_engineer
Data Engineer,"vets first choice vfc is the market leader in providing veterinarians and their clients with cost effective home delivery service of medications and food our advanced web tools client marketing programs and competitive ecommerce offering far surpass the competition vfc is licensed in all 50 states with the highest quality accreditation possible ensuring the safest products for our pet customers and their loving owners in 2013 vets first choice was named 24 on the inc 500 fastest growing companies list and we are still growing
at vets first choice you’ll work on solving interesting problems with current technologies and best practices in a collaborative team that builds an exciting welldesigned product used by veterinarians nationwide
summary
as a data engineer use your professional expertise to enhance and support the current data services machine learningartificial intelligence model training and services execution environments working in an agile environment this position collaboratively partners across administrative and functional areas of the company this position works sidebyside with other data developers data scientists data architects and analysts utilizing expert handson data and development skills
responsibilities
thrives in a fast moving environment working on a variety of projects and technologies in an iterative team based culture
strong desire to learn new skills and adapt to new technologies while maintaining attention to detail
converting product requirements into a well thought through cleanly designed data integration solutions
education
bachelors degree in computer science computer programming computer engineering or related field preferred or comparable jobrelated experience and training
35 years of relevant work experience
competencies
programming languages python java
web services development
system integrations eg web services rest json
relational databases mysql postgresredshift and ms sql server preferred
advanced sql
experience in data centric processing environments
experience developing data migration processes
pluses
aws database machine learning analytics security identity  compliance services
apache big data processing technologies eg hadoop hive sqoop spark kafka
nosql eg dynamodb mongo and graphing databases eg orientdb neo4j
physical demands work environment the physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions normal office environment with extensive use of computer",,ME,False,data_engineer
Data Engineer,"who you’ll work with
are you excited to be part of a new team does the thought of building a new highly secure cloud infrastructure excite you are you ready to tackle the challenge of ensuring system security from development to deployment do you want to become an expert in the system and undertake new challenges
this is an opportunity for you to join the security team within cisco amp for endpoints one of the world’s leading security products the amp team ships security software for windows mac linux ios and android operating systems
as a member of the security team you will have two essential responsibilities you along with the team will be responsible for building a brandnew government cloud environment and maintaining the associated fedramp certification you will engage across development teams to ensure secure development of the system you will contribute positively by building efficient tooling and processes which enable the organization to deliver secure code at an unprecedented pace you will work alongside product owners and engineers to ensure new features meet strict security requirements you will be tasked with maintaining a deep technical knowledge of the information system and need to be able to write code and features
in this role you will work closely with the data team the team is responsible for running malware identification on incoming event data streams storing and indexing that data data is indexed both for future detailed investigations of malware incidents and to retrospectively detect previously unidentified malware in stored data
we inspire employees to hone their talents and skills every single day with innovative and challenging projects we recognize and reward quality results and dedication to our companys purposes and principles
what you’ll do
we are looking for a software engineer computer scientist or data engineer to join a team whose goals are to focus on the fedramp system and secure development your primary responsibilities will be
build and maintain a new cloud environment for fedramp
ensuring new code meets security requirements and writing supporting documentation
provide guidance to teams on building secure software
craft tooling to improve processes and coordination among groups
supporting continuous monitoring and audit requirements
implementing new features to drive customer success
bug fixes and refactoring
assisting with production issues
who you are
you are selfmotivated resultsdriven and engaged you are passionate about backend development and enjoy collaborating in a teambased environment you do not back down when faced with complex problems
required skills
bachelor’s degree in computer science math or physics
enjoy writing serverside code and unit tests
knowledge of algorithmic complexity
ability to debug diagnose and resolve occasional production problems
have four or more years of experience developing in objectoriented ruby java jruby and scala
experience with linux commandline and system administration basics ssh permissions packages log files c
desired skills
experience with distributed systems architecture
production experience with streaming platforms like storm and flink
production experience with distributed databases like mongo and cassandra
opensource contributions
peerreviewed publications
experience with agile software development methods
experience in secure development methodologies
experience performing secure code reviews
experience in security
experience working with security standards fedramp iso pci etc
why cisco
the internet of everything is a phenomenon driving new opportunities for cisco and its transforming our customers businesses worldwide we are pioneers and have been since the early days of connectivity today we are building teams that are expanding our technology solutions in the mobile cloud security it and big data spaces including software and consulting services as cisco delivers the network that powers the internet we are connecting the unconnected imagine creating unprecedented disruption your revolutionary ideas will influence everything from retail healthcare and entertainment to public and private sectors and far beyond collaborate with likeminded innovators in a fun and flexible culture that has earned cisco global recognition as a great place to work with roughly 10 billion connected things in the world now and over 50 billion estimated in the future your career has exponential possibilities at cisco",,NC,False,data_engineer
Data Engineer,"position

data engineer  bangor

department
business intelligence



function design  deploy data warehouses marts and lakes where appropriate as data stores for business intelligence solutions identify gaps and improvements to the data management systems with an emphasis on automation quality and data delivery solutions implement full endtoend data warehousing solutions including data architecture data provisioning data integration data publishing and execute effectively as part of a team

a seniorlevel data engineer is additionally expected to have a practical working knowledge of data modelling concepts and will be able to successfully lead teams or projects related to data design and deployment an individual in the senior role will require a demonstrated ability to work harmoniously with teams and business lines throughout the bank in a productive and thoughtful manner this position is expected to act as a role model for other bi team members in all aspects of daily work including the education of less experienced team members and by leading by example

a principallevel data engineer is additionally expected to provide leadership and mentoring to other bi team members – both analysts and technical staff this role additionally takes a proactive approach to continue their education and maintain an expert level working knowledge persons in this position are considered the most senior of bi staff and as such will be expected to take primary responsibility for developing solutions and fulfilling job duties this position may also act as a backup for management in several capacities including but not limited to training coaching and mentoring fellow employees they will lead within business intelligence and work on strategic initiatives that are key to the success of business lines


accountabilities
understand the data architecture needs and data structures in the source systems and business processes
design data marts for business units and collaborate with development teams during the implementation
collaborate with internal  external data consumers to understand their data needs and drive towards unifying collections of data requirements for key data elements across the organization
document and maintain documentation related data mapping and other data design artifacts that encompass data specifications business  transformation rules
have a high proficiency in a ms sql environment
collaborate with vendors and internal developers in requirements gathering sessions with stakeholders to determine user needs and capture data requirements
translate business requirements and data needs into solutions easily used for reporting scorecards and dashboards
apply bank standards and industry best practices to the ongoing management of the database infrastructure and related technologies
demonstrate ownership of database and related technologies and all issues that arise with them
ensure the highest levels of availability and performance within bi systems and infrastructure
perform bi administrative functions as requested
be responsible for ensuring that all necessary documentation is completed and maintained


compliance and control
assists in ensuring that the bank is in compliance with local state and federal regulations


general
interact harmoniously and effectively with others focusing upon the attainment of bank goals and objectives through a commitment to teamwork
conform to acceptable punctualityattendance standards as expressed in the employee handbook
perform additional duties as requested


competencies
analytical – observe processes and trends at the senior role make recommendations for process changes that help achieve departmental and individual goals at the principal role proactively make strategic recommendations and work with business line leaders to implement them
adaptabilityflexibility – adapt to change be open to new ideas be willing to take on new challenges handle pressure adjust plans to meet changing needs and be able to work in a fastpaced and dynamic environment at the senior role drive change and promote new ideas at the principal role work with the team to adopt change help prioritize tasks and take on complex challenges
initiative – take independent action operate as a proactive selfstarter act on opportunities and practice selfdevelopment be willing and able to convey highly technical concepts to nontechnical audiences at the senior role proactively works to cross train others on the team at the principal role actively mentors fellow associates and assists with their development
integrityethics – deal with others in a straightforward honest manner be accountable for actions maintain confidentiality support company values and convey news good or bad
interpersonal skills – exhibit good listening skills be able to participate successfully in team endeavors and positively influence decisionmaking processes at the senior role have presentation skills and be able to convey ideas to a large and varied audience at the principal level will be able to help leadership convey new ideas and processes to bank leadership
visionvalues – support company missionvalues through daily actions and decisions communicate the bank’s vision mission and values to others incorporate vision when planning


knowledgeskillsexperience requirements
a bs or ms degree in computer science or a related technical field or relevant work experience in the field
experience and implementation of data architecture data lake data marts operational data store analytical systems  metadata management initiatives
experience with schema design and dimensional data modeling
experience in one or more programming languages like python javascript c java etc
experience working with apis like rest apis sdks and cli tools as part of etl provisioning
experience working with multiformat files likes json xml csv flat etc
relevant technical certifications strongly preferred
exceptional troubleshooting abilities
strong verbal and written communication skills
strong documentation skills to include proficiency with msword msexcel and msvisio
expertlevel knowledge of modern databases and their related toolsets reporting packages and underlying technologies
strong knowledge of sql development performance tuning index management
handson experience with data modeling techniques including with star schemas and contemporary etl strategies
strong knowledge of relational and multidimensional databases
analytical approach to problem solving and process improvement
willingness and ability to maintain knowledge regarding relevant current and emerging technologies and industry trends and best practices


physical demandsconditions requirements
general office environment
moderate lifting to 35 lbs required moderate reaching walking sitting and standing required


equipment used
general office equipment


external and internal applications as well as position incumbents who become disabled must be able to perform the essential functions as listed either unaided or with the assistance of a reasonable accommodation to be determined by management on an individual basis",,ME,False,data_engineer
Staff Data Engineer,"did your things make you go wow today were dedicated to improving lives by making the everyday objects around us more useful and with our open platform the opportunities are endless we believe that the internet of things should be accessible to everyone and we strive to create easytouse secure and above all intelligent devices that take your home to the next level our fun creative supportive team needs your help to make things that are a little more connected  and a lot smarter

looking for a motivated sr data engineer to staff data engineer to contribute towards the success of our data and analytics technology initiatives this person will be responsible for defining building and managing architecture strategies data standards digital data management data integration tools and technology the right candidate will play a deep dive handson critical development role in the using data to power data driven decision for smartthings iot platform and in shaping how we acquire ingest transform and deliver data
responsibilities
responsibilities accountable for the big data platform from strategic design all the way to framework development and daily operations
provide technical direction within the organization
handson experience developing “big data” framework at scale using hadoop and related technologies to manage high volume high velocity structured and unstructured data
establish monitoring and management practices to proactively provide necessary capacity and performance
define and champion engineering best practice
work with other infrastructure teams to ensure platform stability
technical liaison with technology vendors
develop procedural and technical documentation define best practice
customer focused and process driven“can do “ attitude and ability to think out of the box and rapidly prototype and deliver innovative solutions
ability to collaborate with data scientists and business analysts to define solution requirements and develop processes for provisioning data for wide ranging analytics
translate complex functional and technical requirements into architectureplatform design
design for now and future successbig datahadoop overall architecture including high availability disaster recovery multitenancy management replication etc
design and implement big data development framework with standardized module to increase etl development efficiency and quality
design and implement best practice for security and data privacy that adhere to samsung business requirement and policy
fine tune overall system performance and continuously identify performance bottleneckimprovement opportunity
provide guidance and support to big data etl engineer on performance and facilitate etl performance tuning
following a data driven approach in defining and measuring platformoperation success
production support and operation planninghardening
requirements
8 years’ experience in designing and implementing high available and high scalable big data systems with hadoop technology
4 years of hands on experience with hadoop hive pig impala and spark nosql hbasecassandra and other big data technology experience with demonstrated technical proficiency
full lifecycle project development involving hadoop and related technologies
4 years experience overseeing hadoop environments and operating big data system to enable business successindustry expertise of database structures theories principles and practices
extensive experience working with aws google components
analytical and problem solving skills applied to big data domain demonstrated handson success with “can do” attitude
bs or ms in computer science or engineering",,CA,False,data_engineer
Software Data Engineer I,"software data engineer ijob number r106769
description

why our company is a great place to work …

join a fortune 300® company in the growing healthcare industry and work for their largest technology division henry schein practice solutions a subsidiary of new yorkbased henry schein inc develops practice management software and electronic services that help dental practices run their businesses our solutions lead the market in technology advances and market share and include product leaders such as dentrix dentrix enterprise and dentrix ascend cloudbased our customers include many of the dental industries’ highest profile constituents including the us department of defense

based in american fork utah henry schein practice solutions is committed to providing our team members with the tools training and technology they need to excel in their roles our dedication to giving back to our community is illustrated in the stateoftheart volunteerstaffed dental center located on the first floor of our building which provides free dental care to those in need

our parent company henry schein inc is the worlds largest provider of health care products and services to officebased dental medical and animal health practitioners a fortune 300® company and a member of the sp 500® and nasdaq 100® indices henry schein employs over 22000 team schein members throughout the world and serves more than one million customers the companys sales reached a record 125 billion in 2017 henry schein has also been recognized by ethisphere for six consecutive years as the “world’s most ethical company” in the healthcare products category underscoring the companys longstanding commitment to leading ethical business standards and practices

job overview

this position is responsible for performing basic programming tasks for the maintenance and enhancement of a new or existing product leverage a basic understanding of the business domain and existing frameworks for the success of development projects

key responsibilities
design and code moderately complex solutions that meet business requirements on schedule and within budget
establish a high level of code quality by writing unit tests participating in code reviews reducing cyclomatic complexity removing code duplication and debugging software modules
assist user documentation and technical support by assembling and providing concise and accurate information in regards to software functionality
implement code that follows established standards and demonstrates a basic understanding of user interface design patterns object oriented design database management systems database design database access memory management design patterns test automation continuous integrationdeployment and versioning
modify existing user interfaces by leveraging a basic understanding of user experience design
attend all meetings necessary for the seamless delivery of the product as part of the software development life cycle


qualifications

work experience

typically 2 to 4 years of related professional experience

preferred education

typically a bachelors degree or global equivalent in related discipline

general skills  competencies
basic understanding of industry practices
general proficiency with tools systems and procedures
basic planningorganizational skills and techniques
good decision making analysis and problem solving skills
good verbal and written communication skills
basic presentation and public speaking skills
basic interpersonal skills
developing professional credibility
specific knowledge  skills
basic knowledge of application design patterns
basic ability to remain current on new technology within the software industry
good ability to implement code derived from technical specifications
basic ability to problem solvediagnose in a technical space
good knowledge of an applicable programming language
basic knowledge of data storage formats tools and languages
ability to keep skills current with changing industry demands as identified
fulltime benefits available
earn generous pto
earn 7 paid holidays
get evenings and weekends off
competitive medical dental and vision benefits
401k with competitive company match
flexible spending account fsa
life insurance short and long term disability add
lunch delivered daily from local restaurants for purchase
onsite gym with personal trainer options

henry schein inc is an equal employment opportunity employer and does not discriminate against applicants or employees on the basis of race color religion creed national origin ancestry disability that can be reasonably accommodated without undue hardship sex sexual orientation gender identity age citizenship marital or veteran status or any other legally protected status

for more information about career opportunities at henry schein please visit our website at wwwhenryscheincomcareers
primary location usautamerican fork",,UT,False,data_engineer
Senior NodeJS and Data Engineer,"we are hiring a fullstack engineer to continue to build out our data processing platform and reactbased incrm extension you will help build and maintain parsing and data ingestion from 100s of sources including ingestion classification and scoring systems
what you will be helping us architect and build…
realtime search infrastructure for 100 million recordscrawling tbs of content per day and processing live content into ingestible formatsmonitor and control the gcp  dockerbased devops cd workflow and production infrastructuremachine learning and nlp based systems to associate articles job postings and news releases with companies and eventsdevelopment training and deployment of machine learning and nlp based systems for personalization and classification of unstructured data
what we are looking for…
selforganizing we dont have project managerscare about code quality and testing and strive for consistent standards as we grow our products and teamyou should have a deep understanding of web data mining and data aggregationanalytics or be willing and passionate about learning it quicklyyou know how to test package and deploy a nodejs app and can demonstrate it easilyyou love changing things around on daily basis and thrive in dynamic startup environments require minimal supervision can pick up ideas from the whiteboard and manage the shipping of deliverable codeexperience in hiring eg hiring manager interviewers etc and teambuilding is a major bonus but not required

we are a funded startup headquartered in the heart of tempe az we have 5 fulltime team members technology and sales and work with several contractors we work with small startup customers up to fortune 500s the problems we solve require creative solutions you must enjoy brainstorming and prototype ideas that at first make you think that would never work and thinking outside the box",,AZ,False,data_engineer
Data Engineer,"hagerty the leading provider of classic car insurance valuation tools and roadside service for people who love cars has an opening for a data engineer  this individual will be responsible for building and maintaining our data pipeline and scalable analytics platform in addition this person will partner with data scientists to develop real time predictive models this role can be based in our traverse city or ann arbor locations


responsibilities

build robust and scalable data integration etl pipelines using python sql spark and other awssalesforce cloud solutions
interface with other vendors and internal teams to extract transform and load data from a wide variety of data sources with frequency varying from batch to streaming
develop solutions to catalog and manage vast amounts of data in varying formats
implement data structures using best practices in data modeling etlelt processes
develop automated test cases to validate etl processes and data integrity
partner with data scientist to design code train test deploy and iterate on large scale machine learning algorithms and systems
implement algorithms with production quality code
lead the implementation and testing of these solutions as an active handson part of a small multidisciplinary team

requirements
experience using open source data processing technologies like kafka hadoop hive presto spark graphx
experience following development rigor to ensure high code quality automated testing and other engineering best practices
experience in custom or structured ie informaticatalendpentaho etl design implementation and maintenance
experience cataloging and processing nonrelational data
expert ability in one or more of the following languages python scala r java sql
strong working knowledge of relational databases and query authoring sql
experience or willingness to learn data science frameworks such as numpy ml spark pandas scikitlearn tensorflow moa mlpack etc
knowledge of or willing to learn one or more of the following natural language processing deep learning bayesian reasoning recommendation systems learning for search speech processing learning from semi structured data reinforcement or active learning ml software systems machine learning on mobile devices
experience or willingness to learn machine learning techniques including supervised and unsupervised algorithms clustering graph analytics and time series analysis kmeans clustering gaussian distribution decision tree etc
experience or willingness to learn feature engineering feature selection and other practical machine learning issues such as overfitting

hagerty offers a progressive work environment along with a competitive wage and an impressive benefits package
to apply for this position please visit our career site at wwwhagertycomhagertycorporatecareers eeoaa
if you like wild growth and working with happy enthusiastic overachievers youll enjoy your career with us",,MI,False,data_engineer
AWS Data Engineer,"about billcom
billcom is the leading business payments network with 3 million members paying and getting paid over 52 billion per year billcom saves companies more than 50 of the time typically spent on financial backoffice operations and helps businesses get paid 3  4 times faster by automating endtoend payment processes the company is the choice of 4 of the top 10 us banks leading accounting software providers quickbooks online and xero and over 50 percent of the top 100 us accounting firms it is the only business payments solution endorsed by the american institute of cpas aicpa the recipient of more than 70 awards billcom proudly received multiple pc magazines editors choice awards and ceo rené lacerte was recently recognized as an ey entrepreneur of the year

mission
billcom moves over 50b per year and we have 10 years worth of customer data we are leveraging this data to make data driven decisions and apply data science and machine learning to solve a variety of tough problems we are in the middle of a largescale transformation to the public cloud and are developing data pipelines data warehouse and machine learning infrastructure in aws
aws data engineers at billcom will be responsible for building data pipelines and theinfrastructure to enable data science data analytics and machine learning at scale in aws some of the problems we’re currently working on include detecting payment fraud extracting semantic data from customer documents and increasing customer acquisition through advanced analytics data engineers will own and build the data platform that makes all of this possible we have multiple positions available at different levels of seniority
professional experiencebackground to be successful in this role
5 years of experience owning and building data pipelines
extensive knowledge of data engineering tools technologies and approaches
ability to absorb business problems and understand how to service required data needs
design and operation of robust distributed systems
proven experience building data platforms from scratch for data consumption across a wide variety of use cases eg data science ml scalability etc
demonstrated ability to build complex scalable systems with high quality
experience with multiple data technologies and concepts such as airflow kafka hadoop hive spark mapreduce sql nosql and columnar databases experience with specific aws technologies such as s3 redshift emr and kinesis a plus
experience in one or more of java scala python and bash
expected outcomes
design and implement data infrastructure and processing workflows required to support data science machine learning bi and reporting in aws
build robust efficient and reliable data pipelines consisting of diverse data sources
design and develop real time streaming and batch processing pipeline solutions
own the data expertise and data quality for the pipelines
drive the collection of new data and refinement of existing data sources
identify shared data needs across billcom understand their specific requirements and build efficient and scalable pipelines to meet various needs
build data stores for feature variables required for machine learning
billcom culture

humble – no ego
fun – celebrate the moments
authentic – we are who we are
passionate – love what you do
dedicated – to each other and the customer",,CA,False,data_engineer
Data Engineer,innate intelligence delivers predictive analytics solutions that help businesses improve business performance and make strategic databased decisions at innate we are dreamers we challenge the status quo and have a passion to make a difference in the world we are a team of game changers that thrive on challenge with a vision to deliver solutions that our clients lovein this role you will work with data science and data analytics teams in the delivery of predictive analytics solutions to our clients as a member of our team you will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and data collection for analytics teams the ideal candidate is an experienced data pipeline builder who enjoys optimizing data systems and building them from the ground up in addition you will support our software developers database architects data analysts and data scientists on data initiatives and ensure optimal a data delivery architecture that is consistent throughout ongoing projects the candidate must have a cando attitude ability to deliver results and a willingness to work as part of an entrepreneurial environmentposition requirements bachelors degree in computer science information technology information systems or related field23 years of experience building and maintaining data pipeline architectures and infrastructureexperience building the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql ms azure andor aws cloud technologiesworking sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databasesexperience building and optimizing ‘big data’ data pipelines architectures and data setsstrong analytic skills related to working with unstructured datasetsexperience with data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsexperience supporting and working with crossfunctional teams in a dynamic environmentexperience with big data tools hadoop spark kafka hive etcexperience with relational sql and nosql databases including cassandra and mongo dbexperience with streamprocessing systems storm sparkstreaming etcexperience with objectorientedobject function scripting languages python java c rwilling to travelexperience in the oil  gas industry a plusjob type fulltimeexperiencebuilding 2 years preferrededucationbachelors preferredwork authorizationunited states preferredrequired travel75 preferred,,TX,False,data_engineer
"Senior Data Engineer, FinTech and Membership Platform","los gatos california
data engineering and infrastructure
netflix is the worlds leading internet streaming service with over 125 million members in 190 countries netflix has released over 600 originals and plans to spend over 7b on content in 2018 at the heart of all our initiatives lies data the foundation of almost all our analysis is built on member data netflix derives a significant competitive advantage from the highly analytical approach we take to managing the company

we are looking for an exceptional highly driven senior data engineer that will propel the member data platform to a new level in this role you will own the data engineering pipeline for one of the most heavily leveraged data sets across netflix member life cycle data you will have freedom to innovate as you work closely with our partners to see the big picture and figure out new ways to track and store data to make decisions the best person will have a strong engineering background with the ability to tie engineering initiatives and business impact
what you will do
immerse yourself in all aspects of member data pipeline understand the problems and tie them back to data engineering solutions
transform raw data from different sources both batch and nearrealtime and using different tools spark hadoop redshift kafka internal systems into intuitive data models
come up with architectural patterns to validate and consume source data and think end to end
build robust data pipelines and improve them to support the growing needs of our business
constantly evolve our data model to balance scalability and performance
build and experiment with different tools and tech and share learnings with the larger team
partner with analysts engineers data scientists and business to push netflix forward
who are you
experience building production data pipelines using hadoop hive pig spark etc on webscale datasets you should have an unmistakable passion for elegant and intuitive dataset design hands on and deep experience with schema design and data modeling
programming proficiency in at least one major language eg java python scala you strive to write beautiful code and youre comfortable working in a variety of tech stacks
software engineering mindset and ability to write elegant maintainable code
analytical mindset to bring together engineering solutions and business impact
knowledge and familiarity with other distributed data stores elasticsearch  druid
strong sql skills
excellent communication to effectively collaborate with partners  stakeholders
a few more things to know
our culture is unique and we live by our values so its worth learning more about netflix at jobsnetflixcomculture you will need to be comfortable working in the most agile of environments requirements will be vague iterations will be rapid you will need to be nimble and take smart risks",,CA,False,data_engineer
Senior Data Engineer,"shutterfly is seeking an experienced senior data engineer with software engineering skills to join the data warehouse development team you will own manage and drive endtoend solutions and data infrastructure you will work with analytics and business partners to deliver data solutions in support of insights and analysis of a multimillion customer ecommerce business with both internal and external data if you like applying your expertise with datawarehousing technical concepts cs fundamentals and data and system architecture to multiterabyte multisource data come join the shutterfly data warehouse development team

responsibilities
build data expertise and own data quality for the pipelines you build
architect build and launch new data models and data marts that provide intuitive analytics to your customers
design build and launch extremely efficient  reliable data pipelines to move data both large and small amounts into and out of the shutterfly data warehouse
design and develop new systems and tools to enable folks to consume and understand data faster
use your coding skills across a number of languages including python and java
have a clear understanding of the reportsanalysesinsights to be driven by data and build data solutions to optimally support the analytics needs
integrate third party data to enrich our data environment and enable new analytic perspectives
become fully immersed in the context of business development and partner business initiatives
work across multiple teams in high visibility roles and own solutions endtoend
work with program managers business partners and other engineers to develop and prioritize project plans

qualifications
5 years of experience with implementing big data business solutions at productions scale
expert knowledge of sql
history of building maintaining and automating reliable and efficient etl elt jobs
strong cs fundamentals and experience developing with objectoriented programming java python
expertise with dimensional warehouse data models star snowflake schemas
experience with cloud data warehouses like google bigquery and amazon redshift is preferred
experience with multiterabyte mpp relational databases such as teradata and concepts
understanding of hadoop or spark including manipulating data with with pig hive and potentially with java or python
understanding of streaming technologies and concepts used with data warehouses is preferred
understanding of automation and orchestration platforms such as automic formerly uc4 and airflow",,NY,False,data_engineer
Google Cloud Data Engineer - Remote,contract otherwe have an immediate project requirement for a data engineer with a google cloud professional data engineer certification preferred this role will lead the team on client projectsthe data engineer should have excellent time and task management skills have proficientteam communications and be able to either telecommute from home or work in one ofour regional officesthis role can be on contract contract to hire or as a fulltimepermanentemployee for the right candidateresponsibilities leadoversee the design of industryleading cloudbased datasoftware solutionsto run on google cloud platform gcp lead the design delivery of and maintenance of data structures anddatabases data processing systems analyze data and enable machinelearning model business processes for analysis and optimization visualizedata and advocate policy design for security and compliance assemble solution teams for data engineering projects make internal recommendations to help improve and streamline the technicaland architectural processes work with the teams to develop web and mobile applications apis sdks andother tools as required document software designs functional and design specifications presentationsand other documents as needed lead our team on presales scoping as a technical expertexperience  10 years handson experience in engineering with solutiondata designleadership experience previous experience leadingdesigning multiple cloud data projects gcp andother cloud platforms aws azure experience leading large scale data migrations previous knowledge and experience with machine learningai expert capabilities with structured unstructured and realtime data google cloud professional data engineer certification preferred experience leadingdesigning with multiple cloud platforms such as googlecloud aws or azure big data pipelines and management experience with data security for data at rest and in transit ie firewallshashing encryption and ssl experience automating and managing key business data pipelines to deliver theoutput of models to targeted applications excellent sql coding and experience with a broad array of development toolsand platforms including a strong linux background and big data environmenttoolslanguages such as sql r sas python etc experience with google data tools such as mysql postgres bigtable dataflowspanner and bigquery experience with machine learning an asset handson experience with two or more of go python php java net or nodejs expert knowledge of and experience with gcp budgeting and billing strategies ms in computer science or equivalent program from an accrediteduniversitycollege able to collaborate and thrive in a fastpaced diverse highperformanceenvironment demonstrated excellence in written and verbal communicationjob type contractexperiencegoogle cloud 2 years required,,CT,False,data_engineer
DevOps- Big Data Engineer,"title devops big data engineer
location new york city
reporting relationship director devops  data

about the company
company x is the recognized market innovator with the technology and tools that accurately authenticate the quality of digital media and drive ad performance for the worlds largest brands company x provides media transparency and accountability to deliver the highest level of impression quality for maximum advertising performance since 2008 company x has helped hundreds of fortune 500 companies gain the most from their media spend by delivering best in class solutions across the digital ecosystem that help build a better industry learn more at doubleverifycom

position overview
as a big data engineer you will be designing and implementing systems that crunch and process billions of records a day and make them available in company x analytics platform helping our clients to make smarter decisions that continuously improve their adimpression quality

what you will do

install configure and maintain big data platform as apache kafka spark and hadoop
install configure and maintain kubernetes clusters both on gcp and on premises
building scalable infrastructure for stream processing as well as batch jobs
contribute to the design and implementation of new products and features making sure they are all developed so they fit nicely in our continuous delivery framework and processes
contribute to general system health monitoring and automation
using diverse technology knowledge and a sense of curiosity to explore new and better ways to solve problems
administer project management tools to continuously improve the efficiency of our organization

what you have donewho you are

experience with container technology – docker and kubernetes a must
3 years of experience building production infrastructure and supporting sdlc especially with java c and python software
experience with microservice architecture
devops tools experience gitgithub atlassian suite teamcity maven and nuget
experience with software development methodologies such as continuous integration continuous delivery and automated tests
expert in scripting bash python c java etc and good coding skills
experience working with gcp or other public cloud
experience working with git and git administration tools
strong system skills in windows and linux environments
you have a genuine desire to automate processes and workflows
bsc in computer scienceengineering
msc is an advantage

",,NY,False,data_engineer
Data Engineer,"this position will be located within devit and work closely with computer scientists it and data scientists to deploy and optimize machine learning models in the paycom production system environment
responsibilities
work closely with itcomputer scientists on technical aspects of deploying machine learning models in production
work closely with data scientists to understand implement refine design and test deployment of machine learning models in production
optimize the environment for production machine learning models to access and handle data more efficiently and ensure scalability
designs new processes and builds large complex data sets needed for machine learning processes
serve as sme on machine learning technology and recommend acquisition of appropriate technology for production purposes
advise and assist itinfrastructure on install and configuration of machine learning systems
explore design and implement a robust productiongrade data processing pipeline that can ingest aggregate and transform large datasets
independently conduct literature search to keep informed of best practices and new methods
serve as oncall for production issues related to machine learning processes
qualifications
education
bs degree in computer science or related field with 5 years machine learning engineering experience or msphd degree in computer science or related field with 3 years of machine learning engineering experience
experience
3 years handson experience deploying productionlevel machine learning algorithms and productionizing them at scale in a distributed computational environment
1 year experience with r working knowledge of r required
experience working with large messy realworld data
experience with sql ruby python c pig and other query and programming languages
experience with machine learning database tools and platforms such as hbase mongo hive cassandra mysql sql server postgresql hadoop spark
experience with machine learning optimization tools and related technologies such as h2o theano mlpack tensorflow experience with h2o required
experience with machine learning platforms for production models such as apache pattern shogun
skills and abilities
strong expertise in computer science fundamentals data structures performance complexities algorithms and implications of computer architecture on software performance such as io and memory tuning
working knowledge software engineering fundamentals version control systems such as git and github workflows ability to write productionready code
strong knowledge of data architecture and systempipeline and data processing engines such as spark and hadoop
working knowledge of r and rstudio
working knowledge of sql pig python and other query languages
knowledge of c php java and other languages
knowledgeable with machine learning tools and frameworks like python spark h2o theano mlpack tensorflow
knowledge of machine learning platforms such as amazon ibm watson azure google predict bigml
strong troubleshooting skills
knowledge of technical infrastructure
knowledge of installation and configuration of machine learning systemstechnology
strong technical aptitude
basic knowledge of statistics calculus and probability experimental design and machine learning techniques to enable conceptual understanding of data scientist’s models
has strong critical thinking skills and the ability to relate them to the products of paycom
possesses a combination of creative abilities and business knowledge
demonstrates excellent verbal and written communication skills as well as the ability to bridge the gap between data science and business management
displays exceptional organizational skills and is detailed oriented
paycom provides equal employment opportunities eeo to all employees and applicants for employment without regard to race color religion sex national origin pregnancy military and veteran status age physical and mental disability genetic characteristics or any other considerations made unlawful by applicable state or local laws this policy applies to all terms and conditions of employment including recruiting hiring placement promotion termination layoff recall transfer leaves of absence compensation and training paycom expressly prohibits any form of workplace harassment based on race color religion sex national origin pregnancy military and veteran status age physical and mental disability or genetic characteristics",,OK,False,data_engineer
Data Analyst - Data Engineer / Analyst,"analyze and interpret the data from different sources including file systemsstrong knowledge in sql conceptsability to identify and define new process to analyze the dataanalytical skill with ability organize analyze and report information with attention to detail and accuracy reporting is mostly via excelgood in verbal and written communication skillsknowledge in excel ecommerce is added advantage


candidates should be flexible  willing to work across this delivery landscape which includes and not limited to agile applications development support and deployment

applicants for employment in the us must have valid work authorization that does not now andor will not in the future require sponsorship of a visa for employment authorization in the us by capgemini

qualifications



includes data modeler data miner responsible for importing cleaning transforming validating and modeling data with the purpose of understanding and drawing conclusions from data may be presented in charts graphs andor tables also design and develop relational databases for collecting and storing data and build and design data input and data collection mechanisms

required skills and experience

you are responsible for data related activities such as data extraction profiling cleansing deduplication standardization conversion transformation and loading data mining warehousing archiving and reporting responsible for all activities required to ensure optimum performance and data integrity of databases in production environments in line with the requirements responsible for providing support of server based databases in development and test environments including database software installation database creation performance and capacity design backup and recovery design security design providing analytical feedback as appropriate
qualifications 14 years experience bachelor’s degree
should have progressing skills in software engineering techniques software engineering architecture software engineering lifecycle and data management
should have baseline skills in business analysis business knowledge software engineering leadership architecture knowledge and technical solution design
capgemini is an equal opportunity employer encouraging diversity in the workplace all qualified applicants will receive consideration for employment without regard to race national origin gender identityexpression age religion disability sexual orientation genetics veteran status marital status or any other characteristic protected by law

this is a general description of the duties responsibilities and qualifications required for this position physical mental sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed whenever necessary to provide individuals with disabilities an equal employment opportunity capgemini will consider reasonable accommodations that might involve varying job requirements andor changing the way this job is performed provided that such accommodations do not pose an undue hardship

click the following link for more information on your rights as an applicant  httpwwwcapgeminicomresourcesequalemploymentopportunityisthelaw
about capgemini

a global leader in consulting technology services and digital transformation capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud digital and platforms building on its strong 50year heritage and deep industryspecific expertise capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations capgemini is driven by the conviction that the business value of technology comes from and through people it is a multicultural company of 200000 team members in over 40 countries the group reported 2017 global revenues of eur 128 billion about 144 billion usd at 2017 average rate


visit us at wwwcapgeminicom people matter results count",,WI,False,data_engineer
Data Engineer,"we are currently seeking a creative and highly motivated data engineer for current and future needs within the organization this role will be located in st louis mo reporting to the vegetable rd analytics lead

this role will establish stateoftheart data infrastructure to support advanced analytics spanning discovery trait genetics and new phenotypic data breeding graphbased ancestry and mlguided predictive breeding evaluation of varieties based on mobile analysis building frameworks to combine deep expertise image recognition uavs and sensors manufacturing and supply chain global operations research

key responsibilities
design build and maintain vegetable data infrastructure
leverage crop sciences data and infrastructure to the advantage of vegetables
accelerate vegetable it tools development and therefore the vegetable business by creating and advocating simplified and sustainable methods for research data storage discovery and use
enable quantitative genetics and predictive breeding at scale
facilitate the rapid growth and use of data from lab greenhouse and field including images uav output iot telemetry
stabilize streamline and integrate business critical data currently in ad hoc databases
drive excellent it and data citizenship by advocating good practices which support the larger strategy for the digital transformation of ag
establish data practices to enable data science and prudent security
cultivate digital mastery for the vegetable division tempering fashionistas and accelerating conservatives
bring and spread expertise

required skillsexperience

minimum of a bachelor’s degree
demonstrated passion and success in modeling and deploying data architectures which enable transformative analysis
experience with at least 2 of the following data ecosystem elements such as hbase mongodb cassandra andor couchdb graph databases such as neo4j hadoop mapreduce andor spark aws google cloud andor azure
minimum of 3 years of fluency in a jvm language such as java or scala or demonstrated mastery of another language
excellent data management and software development practice
the ability and desire to coach and learn from other excellent practitioners
exceptional verbal and written communication interpersonal and problemsolving skills such as required to negotiate scope and resources manage projects and synchronize activities with team members stakeholders and management
desired skillsexperience

experience with platformasaservice software such as cloud foundry or kubernetes demonstrated experience building cloud native applications
knowledge of data science practices to better steer our efforts to support them through the infrastructure we create
public contributions to conference presentations community forums eg stack overflow github etc andor open source projects and code samples

about us

bayer successfully completed the acquisition of monsanto in june 2018 bringing together monsanto’s leadership in seeds and plant traits with bayer’s leadership in chemical and biological crop protection by joining forces we will create even more extensive career opportunities for talent around the world we’re a global team working to shape agriculture through breakthrough innovation that will benefit farmers consumers and our planet

while we are now bayer we will continue to hire using separate career sites until we can integrate our career platforms we invite you to explore the career opportunities available at the combined company by visiting advancingtogethercomcareers

lipost",,MO,False,data_engineer
"Senior Data Engineer, Analytics","senior data engineer


quizlets mission is to help students and their teachers practice and master whatever they are learning every month over 30 million active learners from 130 countries practice and master more than 200 million study sets on every conceivable topic and subject we are developing new learning experiences by modeling how students learn and by drawing upon knowledge acquisition retention and tracing pedagogy in cognitive science we are always seeking to help students master any subject by optimizing study efficiency and engagement

were looking for a data engineer to help us improve our product and make strategic decisions using one of the largest education datasets in the world as one of the top 20 most visited websites in the us we have incredibly rich and highvelocity data that allow us to continuously experiment and improve our user experience affecting millions of students worldwide in this role you will help us improve our analyticsfacing data and etl infrastructure and work with analysts and data scientists in order to unlock the potential of our data this role is critical to everything that we do at quizlet experimentation and datadriven decision making is at the core of our philosophy and you will play a central role in shaping our strategic capabilities

quizlet is a leading company in education technology with proven traction and huge growth ahead our business model is strong and got us to profitability before raising venture capital money come help us scale one of the fastest growing and highest quality consumer learning brands as we develop innovative simpletouse study tools that help students everywhere quizlet is a fun and unique company in a truly exciting phase of its growth

the role



take ownership of our analyticsfacing data pipelines lead architectural decisions
interface with analysts and stakeholders to understand their data needs
understand our logging systems and work with application engineers to ensure our logging is reliable
lead data quality efforts to support analytics as a strategic assets
build out abstractions and tooling to ensure that our pipelines are robust and maintainable

required qualifications



strong programming fundamentals proficiency in a scripting language
strong proficiency in sql
an affinity for data modeling and rigorous welltested data transformation pipelines
excellent communication skills and the ability to empathize with others
a genuine interest in improving education

preferred qualifications



experience with php jvm
experience designing elegant apis for data processing
experience with google cloud platform

quizlets team culture


we are here to make education better and more accessible we strive to improve the lives of students and teachers at every stage and in every setting we have a bias for action take initiative and hustle to deliver results we make informed decisions whenever possible but are unafraid to take calculated risks on great ideas to promote learning we embrace challenges and see effort as the path to mastery were constantly seeking opportunities to learn and we embrace curiosity quality matters at quizlet and we hold the bar high on everything we do we sweat the details and take personal accountability and pride in anything that carries the quizlet name we speak up jump in and work with each other to fix problems and never say thats not my job we treat each other with honesty and respect encourage vigorous debate and seek critical feedback we value diversity humility transparency and collaboration as the best paths to our success — as individuals as a team and as a company

quizlets success as an online learning community depends on a strong commitment to diversity equity and inclusion we are actively working to build a team that is representative of the diverse communities we serve and an open inclusive work environment where all employees can thrive as an equal opportunity employer and a tech company committed to societal change we welcome applicants from all backgrounds women people of color members of the lgbtq community individuals with disabilities and veterans are strongly encouraged to apply come join us",,CA,False,data_engineer
Data Engineer – PSJH,"description
providence is calling a data engineer – psjh to providence health  services in either of the following locations renton wa seattle wa portland or beaverton or or anaheim ca
we are seeking a data engineer – psjh who designs and builds modern datacentric software applications to support clinical and operational processes across all parts of the health system these applications leverage cloud computing big data mobile data science and modern software development methodologies and frameworks builds the data pipelines enrichment processes provisioning layers apis and user interfaces to meet the requirements of key initiatives enjoys a fast pace and has a focus on regular delivery seeks simple solutions to complex problems through the use of modern and emerging methods and tools emphasizes sharing and enables collaboration with meticulous source control and documentation works closely with the product platform and architecture teams to deliver on joint efforts
in this position you will have the following responsibilities
design build and deliver quantitative applications that improve operations and generate value
participate in devops agile and continuous integration frameworks
stay abreast of emerging technologies open source projects and best practices in the field
data warehousing big data enterprise search business intelligence analytics modern and mobile applications
build processes that are faulttolerant selfhealing reliable resilient and secure
work effectively and in realtime with other developers product managers and customers to deliver on collective goals
actively participate in code reviews support the overall code base and support the establishment of standard processes and frameworks
take an open and transparent approach to the work by sharing code and expertise by consulting peers for problemsolving and by being a mentor to your peers
qualifications
required qualifications for this position include
bachelor’s degree in in computer science engineering mathematics mis or similar field
3 years in technology roles
demonstrated analytical skills
demonstrated problem solving skills
possesses strong technical aptitude
cloud computing linux hadoop mapreduce spark hbase kudu and nosql platforms in general apache solr and lucene
java scala c python shell scripting andor similar languages
relational database platforms database design and sql
apis json rest and other relevant w3c open standards
modern application development frameworks
familiarity with commercial or open source etl tools
preferred qualifications for this position include
master’s degree
about the department you will serve
providence strategic and management services provides a variety of functional and system support services for all eight regions of providence health  services from alaska to california we are focused on supporting our mission by delivering a robust foundation of services and sharing of specialized expertise
we offer a full comprehensive range of benefits  see our website for details
httpwwwprovidenceiscallingjobsrewardsbenefits
our mission
as expressions of god’s healing love witnessed through the ministry of jesus we are steadfast in serving all especially those who are poor and vulnerable
about us
providence health  services is a notforprofit catholic network of hospitals care centers health plans physicians clinics home health care and services guided by a mission of caring the sisters of providence began over 160 years ago providence is proud to be an equal opportunity employer providence does not discriminate on the basis of race color gender disability veteran military status religion age creed national origin sexual identity or expression sexual orientation marital status genetic information or any other basis prohibited by local state or federal law
schedule fulltime
shift day
job category information technology
location washingtonrenton
other locations washingtonseattle oregonportland oregonbeaverton californiaanaheim
req id 198066",,CA,False,data_engineer
Senior Data Engineer,"instacart is building the best way for people anywhere in the world to shop for groceries since instacart started in 2012 weve launched sameday delivery in 200 us markets we are laser focused on delivering groceries from your favorite stores right to your door we now cover over 60 of us households and aim to have 80 coverage by the end 2018—thats 90 million households from a technology point of view the platform is complex rapidly scaling and processing millions of transactions in realtime all of the time our technology coupled with operational expertise enables instacart to deliver fresh groceries in as little as an hour this is a difficult problem to master and we are making it happen every day we solve incredibly hard problems to create an experience for our customers that is absolutely magical

the data engineering team at instacart is rapidly growing and you will have the opportunity to shape its direction and create large impact the team is looking for a motivated selfstarter with a drive to tackle a variety of data challenges at instacart

responsibilities


design and build high performance batch and near realtime data pipelines
lead partnerships with product managers on building new tools and analytics
contribute to the continual improvement of the instacart data platform
work in an agile collaborative environment

requirements


at least 5 years of handson experience working in a datadriven company
expertlevel proficiency in one or more of the following domains
building data warehouses dimensional modeling sql
building and managing etl pipelines eg airflow alooma informatica
python programming pandas scikit numpy
big data technologies eg hadoop spark
excellent written and verbal communication skills able to effectively collaborate with diverse teams
bsms in computer science engineering math other quantitative field or equivalent experience

benefits


talented and collaborative coworkers who will both push and support you
market competitive salary and equity
medical dental vision benefits
take what you need vacation and we really mean it
16 weeks maternity leave  8 weeks paternity leave so you can truly bond with your child
complimentary instacart express membership

resources


tech blog  httptechinstacartcom 
life at instacart  httpstwittercomlifeatinstacart 
team stories  httpsmediumcomlifeatinstacart 

",,CA,False,data_engineer
CCBD Technology - Data Engineer,"more about this job
what we do
at goldman sachs our engineers don’t just make things – we make things possible change the world by connecting people and capital with ideas solve the most challenging and pressing engineering problems for our clients join our engineering teams that build massively scalable software and systems architect low latency infrastructure solutions proactively guard against cyber threats and leverage machine learning alongside financial engineering to continuously turn data into action create new businesses transform finance and explore a world of opportunity at the speed of markets

engineering which is comprised of our technology division and global strategists groups is at the critical center of our business and our dynamic environment requires innovative strategic thinking and immediate real solutions want to push the limit of digital possibilities start here

who we look for
goldman sachs engineers are innovators and problemsolvers building solutions in risk management big data mobile and more we look for creative collaborators who evolve adapt to change and thrive in a fastpaced global environment
consumer and commercial banking ccbd
consumer and commercial banking brings innovative solutions to traditional banking activities we are a global team of lenders investors risk managers skilled marketers web experts and banking specialists we provide a suite of solutions to help our customers meet their personal financial goals we make direct investments in and risk manage a portfolio of corporate loans and securities and we help transform distressed communities through investments and loans of private capital

digital finance
digital finance a business unit within ccbd is comprised of the firm’s digitallyled consumer businesses which include the marcus deposits and lending businesses as well as the personal financial management app clarity money digital finance combines the strength and heritage of a 148yearold financial institution with the agility and entrepreneurial spirit of a tech startup through the use of machine learning and intuitive design we provide customers with powerful tools that are grounded in value transparency and simplicity to help them make smarter decisions about their money
responsibilities and qualifications
how you will fulfill your potential
design and develop data ingest and transform processesdevelop data visualizations using bi tools and webbased technologieswork as part of a global team using agile software methodologiespartner with marcus risk product acquisition and servicing teamsuse marcus data to drive change throughout the marcus business

skills and experience we are looking for
minimum 3 years of relevant professional experiencebachelor’s degree or equivalent requiredexperience with sql and relational databasesproficient at python spark and the hadoop ecosystemselfstarter motivated and good communication skills strong sense of ownership and driven to manage tasks to completion

preferred qualifications
about goldman sachs
the goldman sachs group inc is a leading global investment banking securities and investment management firm that provides a wide range of financial services to a substantial and diversified client base that includes corporations financial institutions governments and individuals founded in 1869 the firm is headquartered in new york and maintains offices in all major financial centers around the world

â© the goldman sachs group inc 2018 all rights reserved goldman sachs is an equal employmentaffirmative action employer femaleminoritydisabilityvet",,CA,False,data_engineer
Backend Data Engineer,"106000  160000 a year indeed est at peloton technology we are transforming the trucking industry bringing groundbreaking safety efficiency and data to the trucks that drive the economy we are a handson team of action with diverse backgrounds united by a common goal
peloton seeks a back end data engineer to own data ingestion and usage of our diverse data collected from our platooning fleets the back end data engineer will contribute to a rich set of batch and streaming analytic products
responsibilities include design production setup and management of database schemas and implementation of backend applications operating on large data sets integration with data storage such as cassandra redis and aws s3 and the creation of analytic data access apis for internal and external customers this role will interface with the network operations team the web front end team and the devops team
required skills
csce degree with strong analytic focus preferred 57 years industry experience
currency in batch and streaming analytics systems
analytic algorithm implementation in a production context experience designing and coding multitenant systems in the cloud or colobased environments where designing for scale and resilience are critical
preferred languages go java python experience with c for integrating with invehicle embedded systems is a plus
experience building applications in aws or similar is highly desired especially those serving iot ecosystems
experience with nosqlbased storage preferably cassandra and redis strong data modeling experience required in a mixed nosql and sql environments
passionate about leading edge systems tools and processes uncompromising on test driven development continuous integration agile methodologies and tight collaboration",133000.0,CA,False,data_engineer
Data Engineer,"its fun to work in a company where people truly believe in what theyre doing
were committed to bringing passion and customer focus to the business



summary  key responsibilities

this role on the enterprise data team will support our data engineering initiatives including the development of our “data lake” architecture this role is primarily project based but also may provide support and maintenance to applications in production
general summary
this role on the enterprise data team will support our data engineering initiatives including the development of our “data lake” architecture this role is primarily project based but also may provide support and maintenance to applications in production

key responsibilities
build distributed scalable and reliable data pipelines that ingest and process data at scale and in realtime
create metrics and apply business logic using spark scala r python andor java
model design develop code test debug document and deploy application to production through standard processes
harmonize transform and move data from a raw format to consumable curated views
analyze design develop and test applications
contribute to the maturation of data engineering practices which may include providing training and mentoring to others


qualifications
minimum experienceeducation
bachelor’s degree in computer science computer engineering programming management information systems or related field insurance industry experience is a plus
minimum of two years of prior data engineer experience
strong handson experience in spark scala r python andor java
programming experience with the hadoop ecosystem of applications and functional understanding of distributed data processing systems architecture data lake  big data hadoop spark  hive etc
amazon big data ecosystem emr kinesis aurora experience is a plus

communication and collaboration skills
written must be able to convey key messages in technical terms and business terms must be able to create technical documentation such as specifications design documents and testing documents


oral ability to collaborate and communication with a wide range of partners including it and business across all levels of the organization must actively manage expectations with stakeholders

problem solving

must understand the business need and develop technical solutions to meet those needs innovation creativity and critical problem solving skills are required to be successful in this role solutions need to be comprehensive flexible for future changes and delivered with a high degree of quality


communication and collaboration skills
written must be able to convey key messages in technical terms and business terms must be able to create technical documentation such as specifications design documents and testing documents


oral ability to collaborate and communicate with a wide range of partners including it and business across all levels of the organization must actively manage expectations with stakeholders

problem solving
must understand the business need and develop technical solutions to meet those needs innovation creativity and critical problem solving skills are required to be successful in this role solutions need to be comprehensive flexible for future changes and delivered with a high degree of quality


state auto offers a competitive salary an annual bonus program an excellent benefits program including medical dental vision and prescription insurance coverage life insurance matching 401k plan flexible spending accounts tuition assistance and a stock purchase plan

state auto is committed to the principle of equal employment opportunity for all associates and applicants and to providing associates with a work environment that is free from discrimination and harassment all employment decisions hiring placement promotion termination layoff recall transfer leaves of absence compensation training and work assignments are based on business needs job requirements and individual qualifications without regard to race color religion gender sex sexual orientation gender identity national origin age disability genetic information marital status citizenship status military status or status as a covered veteran in accordance with applicable federal state and local laws state auto will not tolerate discrimination or harassment based on any of these characteristics

state auto is a smokefree work environment we utilize drug screening and background checks as conditions of employment for all exempt positions we also obtain motor vehicle reports mvr s

state auto will not accept candidates from thirdparty recruiters without a signed agreement with state auto



full time  part time

full time


worker subtype

regular


if you like wild growth and working with happy enthusiastic overachievers youll enjoy your career with us",,OH,False,data_engineer
GCP Data Engineer,contractjob summaryour client is looking for gcp data engineerfind below the job description kindly reply with your updated resume contact details and best time to reach youi apologize if the job is not of your interest however i will highly appreciate if you can refer some body suitable for this positionjob title gcp data engineerlocation chicago downers grove ilduration contractjob description as a data engineer you will assist in the development of data warehouse data flowdata warehouse functions on google cloud an ideal candidate will be a proficient warehouse developer versed in data integration services development report development data analysis and gcp big data stackresponsibilities build data flow jobs in gcp supports technology tools systems capabilities processes and financials to enable delivery and drive business results across the enterprisebuildsupports analytics  data lake ensure communications both formal and informal are clear and aligned with supported functions and related stakeholderstechnologybusiness plan development supports execution of technology improvements that drive capacity within the enterprisebuild capability to drive growth and eliminate waste deploys tools processes and resources to support the enterpriseexperience must havegcp bigquery andor google dataflow experienceexperience with operationalization including security of google bigquery experience with postgres sql experience with setting up secure accessacls iam roles to google cloud storage experience with writing cloud functions experience with cloud pubsub setup and configuration 35 years of experience in data ingestion and storage systems for big data environment using at least one of the cots integration tools like  snaplogic webmethods tibco talend informatica andor custom scripting in pythonjavajob type contractexperiencegoogle cloud platform 2 years preferred,,IL,False,data_engineer
Data Engineer,"aavalar consulting is a trusted technology staffing partner that helps technology leaders connect with and deploy indemand skilled it and engineering professionals at client sites across the midatlantic region since 1999 aavalar consulting has built an awardwinning reputation with over one hundred of the most innovative fortune 500 and midmarket companies to deliver substantial value through a broad set of technology consulting and it staffing services that include staff augmentation interim technology executives and search and recruitment for it and engineering

position title data engineer

work location plymouth meeting pa area

work environment private office cube high rise office building office building

who does this position report to cio head of software development

why is this position open company is growing

responsibilities help development of company products by collecting and analyzing data using new cutting edge technology

required skills

solid work history building data processing systems with hadoop mapreduce using python and java
working experience with query tools pig and hive
working experience building stream data processing systems using apache spark and pyspark
knowledge of troubleshooting optimizing and administering nosql databases mongodb or dynamodb
history of utilizing agile and creating agile culture

nice to have


aws experience
scripting language experience with java linux c php ruby and python

educationtraining

bs computer scienceengineering preferred

selling point of the job company is growing extremely fast great opportunity to grow from within

work hours and schedule normal business hours

is there travel involved if so how much no travel

dress code business casual

base salary open

bonuses tbd

who is involved in the interview process sr engineers cio director of software development",,PA,False,data_engineer
Senior Java / Big Data Engineer - Enterprise Content & Deliv...,"senior java  big data engineer  enterprise content  delivery
new york ny
posted oct 17 2018  requisition no 71337

this enterprise content  delivery development team is responsible for building highlyperformant distributed systems that manage large volumes of client data we work with multiple groups within bloomberg to gather millions of data points per day and develop tools to transform and store the data in an efficient manner for trend analysis billing and business intelligence
we are looking to enhance our software suite to develop a new automated data ingestion and analytics pipeline we want every application that we onboard to define new schemas and leverage them for data ingestion secondly we want to leverage or develop a framework that can provide for analysis against this data store and do this all in a manner that provides for operational independence the right candidate will be expected to have extensive handson experience in big data technologies such as hadoop and hbase as well as frameworks like apache spark andor apache kafka
well trust you to
understand the capabilities of our current system and enhance it to support the capabilities of this new pipeline
 work with other groups within the organization to set up and configure big data clusters and assist with data volumetrics as well as hardware and software needs
 research design and assist in building tools that can be utilized to analyze the data by internal users and support staff
 maintain systems to ensure they are highly available
youll need to have
3 years of current java development experience
 proven experience with a range of big data architectures including hadoop hbase or other big data frameworks
 experience building large scale distributed data processing systems
 solid understanding of data structures algorithms  objectoriented design concepts
 a passion for big data technologies and a flexible creative approach to problem solving
 excellent communication skills
wed love to see
experience with languages such as pythonperl
 experience developing software using agile methodologies
 working knowledge of development tools such as debuggers memory profilers and performance analysis
if this sounds like you apply",,NY,False,data_engineer
Data Engineer,"req id 13421
shift days
employment status af  active  regular  full time

job summary

we are looking for a data engineer to join our growing team of analytics experts the hire will be responsible for expanding and optimizing our data warehouse and building data integrations developing data best practices and governance performing clinical and administrative reporting and data visualization as well as optimizing data flow and collection for cross functional teams
the ideal candidate has knowledge of and is excited to learn about all aspects of data from multiple complex sources who enjoys optimizing data systems and building them from the ground up the data engineer i will support our developers database architects data analysts and data scientists and will ensure optimal data delivery architecture is consistent throughout ongoing projects they will also support nontechnical colleagues in the collection and appropriate use of clinical and nonclinical data they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our company’s data architecture to support our next generation of products and data initiatives




job responsibilities

1 data modeling – evaluate structured and unstructured data determine the most appropriate schema for new fact tables data marts etc
2 data integration – incorporate new business and system data into the chop data warehouse while maintaining enterprise best practices and adhering to data governance standards
3 etl – apply business rules to our data as we migrate from source to target using informatica or scripting language validate data to ensure quality
4 reporting – collaborate with colleagues across the enterprise to scope requests extract data from various data sources validate results create relevant data visualizations and share with requester develop dashboards and automate refreshes as appropriate
5 governance  best practices – adhere and contribute to enterprise data governance standards also educates and supports colleagues in best practices to ensure that data is used appropriately
6 assemble large complex data sets that meet functional  nonfunctional business requirements
7 identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
8 build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources including ground hybrid cloud and cloud using sql and various programming technologies
9 develop analytics tools that utilize data resources to provide actionable insights operational efficiency and other key business performance metrics
10 work with stakeholders including the executive clinical and analyst teams to assist with datarelated technical issues and support their data infrastructure needs
11 develop optimized tools for analytics and data scientist team members that assist them in building and optimizing projects into an innovative industry leader
12 proficient at integrating predictive and prescriptive models into applications and processes
13 experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
14 strong analytic skills related to working with structured and unstructured datasets
15 build processes supporting data transformation data structures metadata dependency and workload management
16 a successful history of manipulating processing and extracting value from large disconnected datasets
17 working knowledge of message queuing stream processing and highly scalable data stores
18 strong communication project management and organizational skills
19 experience supporting and working with crossfunctional teams in a dynamic environment
20 participate in a shared production oncall support model
21 be a critical part of a scrum team in an agile environment ensuring the team successfully meets its deliverables each sprint




required education and experience

two 2 certifications or proficiency in appropriate business intelligencedata warehousing technology or subject domain
bachelor’s degree in computer related field required
35 years of business intelligencedata warehousing experience preferably in a healthcare environment



additional technical requirements

proficient in sqlexposure to big data tools hadoop spark kafka bigsql hive etcexperience with relational sql and nosql databases including ibm pda netezza ms sql server and hbaseexposure to data integration tools informatica ms integration services sqoop etcexposure to streamprocessing systems ibm streams flume storm sparkstreaming etcexposure consuming and building apisexposure to objectorientedobject function programming languages python java c scala etcexposure to statistical data analysis tools r sas spss etcexposure to visual analytics tools qlikview tableau power bi etcfamiliarity to agile methodology for developmentfamiliarity with electronic health record and financial systems ie epic systems cerner workday infor strata etc


all chop employees who work in a patient building or who provide patient care are required to receive an annual influenza vaccine unless they are granted a medical or religious exemption
childrens hospital of philadelphia is committed to providing a safe and healthy environment for its patients family members visitors and employees in an effort to achieve this goal employment at childrens hospital of philadelphia other than for positions with regularly scheduled hours in new jersey is contingent upon an attestation that the job applicant does not use tobacco products or nicotine in any form and a negative nicotine screen the latter occurs after a job offer
childrens hospital of philadelphia is an equal opportunity employer we do not discriminate on the basis of race color gender gender identity sexual orientation age religion national or ethnic origin disability or protected veteran status
vevraa federal contractorseeking priority referrals for protected veterans please contact our hiring official with any referrals or questions
chop careers contact
talent acquisition
2716 south street 6th floor
philadelphia pa 19146
phone 8668209288
emailtalentacquisitionemailchopedu

nearest major market philadelphia

job segment database medical developer patient care java technology healthcare",,PA,False,data_engineer
Big Data Engineer,contractposition big data engineerduration 1 yearlocation bentonville arjob duties and responsibilitiesminimum 6 years of proven experiencecontribute to the job and data flow design for data management on hadoop platformsexcellent knowledge of hadoop hive teradata automic sqlstrong verbal and written communications skills are a musteducation  bachelor degreemaster degree preferredbest regardsnaveen pratapphone 6786660120wwwlinkedincominnaveenraghavjob type contractexperiencehive 3 years requiredteradata 3 years requiredhadoop 4 years requiredsql 3 years requirededucationbachelors required,,AR,False,data_engineer
Senior Data Engineer,"why varidesk

we’re award winners

best place to work top 10 – dallas business journal
national entrepreneurs of the year – ey
fastest growing company in dfw – smu
we take health seriously

onsite gym with peloton cycle and daily group classes
comprehensive health plans
healthy foods and snacks
wellness program and insurance premium discounts
nicotine free workplace
we value our employees

all employees use varidesk products
enhanced paternity  maternity programs
three weeks of personal time off a year
up to five days of time off for volunteering
offsite events and happy hours
shortterm and longterm disability premiums covered at 100 by varidesk
401k plan with employer match
summary

as a senior data engineer you will be responsible for integrating modeling and reporting on data to create actionable insights for the organization you will analyze design build and support the data warehouse microsoft sql serverazure analytical models in ssas and reporting in power bi you will also interact with a variety of business professionals including clevels and work on critical projects within all aspects of the organization

duties and responsibilites

 create and maintain optimal data pipeline architecture using microsoft sql server sql data warehouse and azure data lakeblob storage
 develop etl processes using sql ssis azure data factory with consideration to faulttolerance error logging auditing and data quality
 buildautomate reportsdashboards in power bi and microsoft analysis services to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics
 implement data cleanup procedures transformations scripts stored procedures and execution of test plans for landing data successfully into the appropriate destinations
 create tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
skills and attributes

 must be an experienced thought leader and expert in business insights warehouses data enrichment and analytics
 understanding of scrum and agile development methodologies
 ability to be a quick problem solver
 outstanding client management skills and the ability to work with customers to execute on an implementation plans
 excellent communication on both technical and nontechnical contexts
 ability to work under deadlines in a fastpaced environment while prioritizing competing demands
 experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
 strong data modeling skills to include data quality source systems analysis business rules validation source to target mapping design performance tuning and high volume data loads
qualifications

 5 years of progressive experience in relevant business data  insights administration  support positions
 advanced working knowledge of ssis tsql sql server and sql data warehouse
 ssas tabularmultidimensional including dax
 power bi or reporting services ssrs
 experience building and optimizing big data pipelines architectures and data sets
 excellent communication skills
 experience working in an agile team environment",,TX,False,data_engineer
Data Engineer - Azure | Fortune 500 Retailer,130000  140000 a yearcontractbicp a dedicated bi analytics  big data consulting firm is currently looking to hire 2x data engineers to support a major transformation effort at our longstanding and direct fortune 500 retail in portland or we’re looking for candidates with 2 years of experience with cloud based data engineering with an emphasis on delivering platforms to enable near real time data analytics and reporting ideal candidates must possess strong relational database engineering oracle sql server or teradata and have expertlevel sql abilities must have experience with large scale data processing data structure optimization and scalability experience with azure is preferred however experience with aws or databricks is fine as well scripting experience with python or powershell is preferred we’re looking to hire candidates that can thrive in an agile environment and who possesses great interpersonal and communication skills to work effectively with parallel technical teams and an closely collaborate with the business start date is asap and this will be a 5 day onsite work week remote is not an optionif you’re looking to join an organization where there is tremendous growth opportunity that operates with transparency and with a highly collaborative approach then bicp could be a great career choice for you we offer excellent compensation and we will reimburse the cost of relocation to portland telecommuting is not an optionjob types fulltime contractsalary 13000000 to 14000000 yearexperienceazure 1 year requirededucationbachelors requiredwork authorizationunited states required,135000.0,OR,False,data_engineer
Senior Data Engineer,"honey is helping millions save money every day and were growing our data pipelines process hundreds of millions of events per day we are looking for engineers who love distributed systems and are motivated by the challenge of scale data engineering at honey is a small team so youll have opportunities to work on a variety of product features and technology platforms

what youll do

implement machine learning models to production
design build and operate honeys data pipelines with a focus on performance and reliability
participate in new feature development for recommendations product catalogs and mobile applications
propose and evaluate storage technologies and methodologies with an eye toward scalability and performance
design and implement data pipelines that handle a thousand messages per second streaming

about you

5 years programming in at least one modern programming environment python scala or nodejs are helpful but not required
5 years architecting with both sql and nosql data stores we use big tablehbase spark dataflow spanner bigquery and elasticsearch but if you have experience using hive hadoop or pig that works too
experience designing schemas and maintaining representations for low latency request cycle queries
experience with streaming platforms pubsub kafka kinesis and nearrealtime data pipelines
working knowledge of statistics and experimental design
comfortable building and maintaining data infrastructure in the cloud

honey is an equal opportunity employer we are committed to building a diverse and inclusive company we do not discriminate on the basis of race religion color national origin gender gender identity sexual orientation age marital status veteran status disability status or genetic information in compliance with applicable federal state and local law",,CA,False,data_engineer
Data Engineer,"65000  70000 a yeardata engineer


job summary

looking for a data engineer to help build the foundation of a new strategy  insights department seeking someone skilled at data extraction preparation analysis and visualization geared towards making the sales  service department more efficient and effective


this individual will also be involved in the execution of predictive modeling projects such as lead scoring retention modeling and pricing to be successful in the role candidates must have a strong understanding of data engineering principles as well as statistical coding and data visualization skills


principal duties and responsibilities

work with the sales  service department to improve reporting and analysis around their kpis
assist with data mining cleansing manipulation insights and reporting
manage the data flow between our core technology suite and ticketing
knowledge of all major aspects of a crm system eg automated processes lead assignment reporting etc
coding proficiency in at least one modern programming language eg python r
expert microsoft excel skills


education  experience

babs in computer science engineering math economics or another related field with a year to three years of backend or data engineering experience

entry level with a ms or phd",67500.0,CA,False,data_engineer
Software Dev Engineer / Data Engineer,"oath a subsidiary of verizon is a valuesled company committed to building brands people love we reach over one billion people around the world with a dynamic house of 50 media and technology brands a global leader in digital and mobile oath is shaping the future of media


a little about yahoo
yahoo is an oath brand oath a subsidiary of verizon is a valuesled company committed to building brands people love we reach over one billion people around the world with a dynamic house of 50 media communication and technology brands a global leader in digital and mobile oath brands are shaping the future of communication and media

what we do and what youll learn
build data pipelines to automate flow of ads data
build machine learning models using deep learning or logistic regression to optimize performance
data mining on hadoop to power search autocompletion
find topics in web documents for better ranking or filtering

responsibilities

as a software engineer  data engineer you will perform
ads performance data collection cleaning and analysis to find revenue opportunities and suggest improvements
use hadoop related technologies for data analysis if necessary
gain insights on what drives performance
turn improvement ideas into production features or new models
design implement and test the production features or new models

qualifications 
bs ms or phd in computer science or related field
strong data analysis and problem solving skills
deep understanding of algorithms and data structures
strong programming proficiency with c or java
strong programming proficiency with scripting language such as python
proficiency with objectoriented programming and design relational databases sql and unixlinux environments
excellent interpersonal organizational creative and communications skills
team player in driving growth results combined with a positive attitude
strong work ethic and core values honesty integrity creativity
fluency in japanese

bonus points if you have 
experience on machine learning modeling and technologies related to big data such as hadoop spark hive and pig



oath is proud to be an equal opportunity workplace all qualified applicants will receive consideration for employment without regard to and will not be discriminated against based on age race gender color religion national origin sexual orientation gender identity veteran status disability or any other protected category oath is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment please let us know if you need a reasonable accommodation to apply for a job or participate in the application process


currently work for oath please apply on our internal career site",,CA,False,data_engineer
QA_Big data,contracttitle qabig data engineerlocation phoenix azduration full time with m3birequired 5 years of direct functional testing experience working with big data testing must have hadoophive hbase experience strong experience with data transformation and working on hive must have 3 years of test automation experience using selenium or any other automation tools and proficient in writing test automation code in java prefer experience with test automation including the cucumber automated acceptance test software deep expertise in test methodology process planning and executionresponsibilitieswrite and execute system and user acceptance strategies plans and scripts for the migration of a relational data warehouse that is being retired create appropriate test scenarios and data sets work with lines of business technology and operations to determine priorities and schedule of releases document test procedures and issues support testing and automation of testing for a range of projects from defect fixes and enhancements to strategic initiatives log bugs and enhancements into the defect tracking and planning tool escalate key testing issues and provide feedback to the stakeholders ensure that all requirements are covered in the testing that it is completed within established time and that objectives conform to the user requirements and line of business provide input and shape sit  uat processes in line with industry best practicesjob types fulltime contractexperiencehadoop 1 year preferredselenium 1 year preferredtest automation 1 year preferredhive 1 year preferredjava 1 year preferred,,AZ,False,data_engineer
Data Engineer,"115000  135000 a yeardata engineer

san francisco bay area

115k135k  benefits

a late stage luxury ecommerce startup focused on ethical business practices in san francisco is seeking data engineer to join their team come join a company whose mission is creating absolute transparency towards their customers and a strong focus on ethical sourcing of their products

the role

as a senior big data engineer you will have the opportunity to take ownership over endtoend solutions this is an opportunity to be product facing and help to personalize products systems and infrastructure in an ecommerce setting you will also be supporting the data science team by building data tools

the role

building data pipelines out from scratch
working with stakeholders in ecommerce marketing and supply chain to create data tools and address problems
build self service tools access to data across the business
required skills  experience

strong python scala or r programming
expert sql skills
experience working with relational databases
previously worked with distributed frameworks spark hadoop
strong communication skills with business stakeholders
please register you interest by sending your cv to angela rego  via the apply link on this page",125000.0,CA,False,data_engineer
"Data Engineer, IdentityAI","at sailpoint we do things differently we understand that a funloving work environment can be highly motivating and productive when smart people work on intriguing problems and they enjoy coming to work each day they accomplish great things together with that philosophy we’ve assembled the best identity team in the world that is passionate about the power of identity

as the fastestgrowing independent identity and access management iam provider sailpoint helps hundreds of global organizations securely and effectively deliver and manage user access from any device to data and applications residing in the data center on mobile devices and in the cloud the company’s innovative product portfolio offers customers an integrated set of core services including identity governance provisioning and access management delivered onpremises or from the cloud iamasaservice

sailpoint has been voted a best place to work in austin 8 years in a row

sailpoint is looking for a data engineer to build maintain monitor and improve a real time scalable fault tolerant data processing pipeline and productize machine learning algorithms for a new cloudbased multitenant saas analytics product

you will be integral in building this product and will be part of an agile team that is in startup mode this is a unique opportunity to build something from scratch but have the backing of an organization that has the muscle to take it to market quickly with a very satisfied customer base

responsibilities
implementing etl processes
monitoring performance and advising any necessary infrastructure changes
defining data retention policies
productizing and operationalizing machine learning algorithms
be part of a team that is creating a brandnew product line
collaborate with team members to help shape requirements
actively engage in technology discovery that can be applied to the product

requirements
1 year of data engineering or related experience
strong java andor scala experience
proficient understanding of distributed computing principles
ability to solve any ongoing issues with operating the cluster
experience with integration of data from multiple data sources
strong knowledge of data cleaning and various etl techniques and frameworks
great communication skills
bs in computer science or a related field

preferred
proficiency with spark
experience with machine learning using mahoutdeeplearning4jspark ml
experience with stream processing using spark streamingstormbeamflink
experience with elasticsearch
experience with messaging systems such as kafka or kinesis
experience with nosql databases such as redshift cassandra dynamodb

compensation and benefits
experience a smallcompany atmosphere with bigcompany benefits
competitive pay 401k and comprehensive medical dental and vision plans
recharge your batteries with a flexible vacation policy and paid holidays
grow with us with both technical and career growth opportunities
enjoy a healthy worklife balance with flexible hours familyfriendly company events and charitable work

all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability or veteran status



all qualified applicants will receive consideration for employment without regard to race color religion sex sexual orientation gender identity national origin disability or veteran status",,TX,False,data_engineer
Sr Big Data engineer,50  60 an hourcontractjob summaryexcellent knowledge of spark spark mlib scala hbase hivegood knowledge of aws environment  ec2 s3 ebs knowledge of cloudformation template is a plusgood knowledge of cloudera cdhexperience of unix shell scripting is a plusexperience of tfsgit eclipsemaven is a plusshould be able to lead the team at onsite and share insite to offshorecoordinate closely with customer to derive the project plan and execute them with close monitoring and on timeattend customer discussions as and when required and schedule weekly  monthly meetings to go over the project governance explore and participate in proof of concepts to build confidence to customer and present the best possible solutionsresponsibilities and dutiesexcellent knowledge of spark spark mlib scala hbase hivegood knowledge of aws environment  ec2 s3 ebs knowledge of cloudformation template is a plusgood knowledge of cloudera cdhexperience of unix shell scripting is a plusexperience of tfsgit eclipsemaven is a plusshould be able to lead the team at onsite and share insite to offshorecoordinate closely with customer to derive the project plan and execute them with close monitoring and on timeattend customer discussions as and when required and schedule weekly  monthly meetings to go over the project governance explore and participate in proof of concepts to build confidence to customer and present the best possible solutionsjob type contractsalary 5000 to 6000 hourexperiencebig data 9 years preferred,,KY,False,data_engineer
Data Engineer - Professional Services,"forcepoint is transforming cybersecurity by focusing on what matters most understanding people’s intent as they interact with critical data and intellectual property wherever it resides our uncompromising systems enable companies to empower employees with unobstructed access to confidential data while protecting intellectual property and simplifying compliance based in austin texas forcepoint supports more than 20000 organizations worldwide for more about forcepoint visit wwwforcepointcom and follow us on twitter at forcepointsec


forcepoint is seeking a qualified fulltime professional services data engineer working on client site to facilitate configuration data integration and training of our commercialofftheshelf regulatory surveillance and cybersecurity user and entity behavioral analytics ueba products this individual must be highly motivated have great interpersonal skills and be technically proficient

in this role you will be joining a small but rapidly growing team in new york your role will include working directly with customers to understand their goals help shape requirements own the design and implementation of analytic strategies and develop robust etl pipelines to support these analytic strategies additionally you will interface with the broader forcepoint professional services team to drive analytic capabilities of the platform and overall facilitate an efficient effective and robust deployment of the forcepoint ueba platform to characterize and detect insider threats and compliance violations
the successful candidate will receive specialized training to support our technologies and is expected to become proficient in all aspects of complex software solution deployment initially the focus will be working with one of our major multinational clients to build out a new deployment of ueba this position requires 510 travel domestic and international as needed to meet customer and project requirements

work location new york city
must have uscitizenship or permanent resident green card holder status

responsibilities include
provide exceptional implementation services to new customers including supporting data ingestion analytic configuration customer training and troubleshooting
work directly with customers to design and implement robust analytic strategies in the forcepoint ueba platform to address use cases in cyber security and regulatory surveillance
partner with the ueba delivery team to integrate with and automate ingest for a wide variety of data sources databases remote servers flat files apis etc to ensure data is quickly and reliably available in all contexts
prepare technical documentation to include asbuilt design requirements and standard operating procedures
interface with the broader forcepoint data science team about analytic opportunities and accomplishments in the field to drive the evolution of the forcepoint ueba platform
provide technical briefings to customer leadership and forcepoint corporate leadership as required
coordinate tasks and activities with various groups within forcepoint the government or partners

required skills  experience
experience writing modular and reusable code in python
facility in scripting and troubleshooting application errors in linuxunix environments
experience with the etl cleaning transforming and ingesting large datasets
experience with full software development life cycle sldc from requirements through to testing and deployment
possess strong analytical verbal and technical written communication skills
must be able to coordinate collaboratively across traditional engineering disciplines and effectively engage with customers
must be eligible to work in the us

desired skills
prior technical experience in finance andor information security organisations
experience with apache nifi and high volume etl tasks
integration experience with data stores such as elasticsearch postgresql splunk arcsight cloudera etc

required education
degree in a technical field such as computer science or equivalent work experience",,NY,False,data_engineer
Data Engineer,"join a team recognized for leadership innovation and diversity
at honeywell we are blending physical products with software solutions to link people and businesses to the information they need to be more efficient more productive and more connected we have a real passion for the place where physical meets digital
in this emerging internet of things era the world is moving from simple digital transactions to complex digitaltophysical interfaces half of our engineers globally are developing software to augment our extensive technology portfolio which include
technologies for connected buildings
the worlds most advanced cockpits jet engines auxiliary power units and turbochargers
mobile computing
refining and petrochemicals process technologies and controls
voiceautomated systems
as a data engineer at honeywell building technologies you’ll be a member of our global team and help bring our connected buildings platform and solutions to life our solutions power connected buildings which allow occupants to be safer and more productive and the building to be more energy efficient and sustainable

you will expand and optimize our data pipeline architecture and you’ll optimize the data flow and collection across teams you are experienced – you’ve been there done that before you enjoy building data pipes and wrangling data – so much so that you like to clean things up when they don’t meet your needs and build new pipes when they’re needed you’re not scared of redesigning the pipeline – you just want it to be efficient and maintainable
you will identify and implement process improvements – and you don’t like to the same thing twice so you’ll automate it if you can you are always keeping an eye on scalability optimization and process oh – and gdpr is not a dirty word to you you’ve worked with big data before iot data sql azure aws and a bunch of other acronyms
you will work on a team of 1012 people including scrum masters product owners designers software engineers data scientists and devops you and your team collaborate to build products from the idea phase through launch and beyond the software you write makes it to production in 12 short weeks we work on important new features and functionality  those things that will impact our bottom line immediately your team will be working on creating a new platform using your experience of apis microservices and platform development
our teams live by its ‘teach and learn’ mantra we value our more seasoned engineers because they bring additional value to our company by using their years of experience to guide the next generation well assign you a mentor on day one so you can take advantage of this amazing learning opportunity we want you to get to your next level whatever that might be we also continue to support your professional development by paying for conferences advanced degrees and involvement in local and national organizations
honeywell has a strategic goal to make our company stronger and work better by growing gender diversity by changing several of our practices and working hard to recruit women into the company we’ve made significant progress we welcome all qualified candidates to apply but we especially encourage women and other groups underrepresented in technology
as a data engineer with honeywell this is your opportunity to
create and maintain data pipeline architecture
assemble complex data sets to meet a bunch of needs
build the infrastructure for etl of several data sources
help us make the data actionable
actively represent our culture by leading and participating in efforts around continuous learning personal and professional development community service and team building
benefits highlights

we know benefits are important to you they are to us too we offer health vision and dental and we take our benefits to the next level at honeywell in atlanta youll free lunches every day and you will eat in our cafeteria where you can collaborate with your peers you can also play games with your coworkers
board games video games chess pingpong and foosball be prepared with the games  we occasionally do game olympics where you can show your style
we have 401k contributions and a generous leave package as well whats not to love we are located in the heart of midtown at 3rd and peachtree st  and you can choose between free parking onsite or free marta transport we also offer a discount on the bouldering gym in the building
25 sdlc

50 data engineering

25 process improvement




you must have
bachelor’s degree in engineering computer science data analytics statistics information systems or some other stem degree
5 years of experience
5 full lifecycle development experience – your products have made it to production and have scaled globally
2 years experience with sql and nosql databases data pipelines and workflow management tools
we value
understanding software development lifecycle
analytical skills  software development skills
iot domain expertise
scaled agile experience
an ownership mindset with a servant leadership attitude
be familiar with several programming languages we use python java c javascript html5 css and bash shell scripting
some frameworks we use are spark hadoop hive pandas tensorflow and keras some of the tools we use include docker kubernetes bamboo october and more
knowledge and experience in multistructured data modeling and nosql technologies such as hbase and cassandra
data wrangling and data mining skills – integrate data sources coming from different products restructure columns clean bad data standardize data fields and types ultimately increase data quality and usability
exempt how honeywell is connecting the world
includes
1st shift
continued professional development

additional information
job id hrd41752
category engineering
location 715 peachtree street ne atlanta ga 30308 usa
honeywell is an equal opportunity employer qualified applicants will be considered without regard to age race creed color national origin ancestry marital status affectional or sexual orientation gender identity or expression disability nationality sex or veteran status",,GA,False,data_engineer
Data Engineer,"we are currently looking for a data engineer to join the thales avionics a subsidiary of thales usa team in irvine ca

the data engineer will work closely with big data reporting and analytics they should be familiar with data extraction preparation loading of data from a variety of relational and nonrelational sources into a cloud based big data environment this individual will be familiar with contract and business required reporting compiled from large data extracts this position is necessary to continue to be able to complete the necessary customer reports outlined in existing business contracts

key responsibilities
this individual will work with existing team members to produce all reports to existing release schedules
this person shall have the skills to be able to work alone as well in a team environment
review existing tools utilized by the department and offer suggestions for tool improvement in the handling of all data sources
shall suggest and build data and analytic tools that will offer insight into the pipeline to better existing key performance indicators

required education competencies and experience
bachelor’s degree in computer science information systems or equivalent quantitative field or equivalent blend of education and experience
3 years of experience in a similar data engineer role
experience working with large data sets and extracting from structured or unstructured datasets
demonstrated ability to build processes that support data transformation data structures metadata dependency and workload management
advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
experience building and optimizing ‘big data’ data pipelines architectures and data sets
experience with displaying data geospatially
strong interpersonal skills and ability to project manage and work with crossfunctional teams
experience with the following tools and technologies a plus
cloudera hadoop spark kafka nifi elasticsearch hive solr
relational sql and nosql databases
data visualization tools such as d3js leaflet
aws cloud services such as ec2 emr rds and redshift
streamprocessing systems such as storm and sparkstreaming
programming languages and related web technologies such as python java javascript c json r etc
thales champions inclusion and we believe diversity strengthens the fabric of our culture we are an equal opportunity employeraaminoritiesfemalesveteransdisabled",,CA,False,data_engineer
Senior Data Engineer,contractjob summarysenior data engineersunnyvalesanta clara cathis positions is a critical project position with one of our marquee clients in the bay area sunnyvalesanta clara area which is redefining the world of ecommercelocal candidates bay area california are highly preferredtype fte with clairvoyant c2c contractw2 1099position summaryvery strong engineering skills should have an analytical approachand have good programming skillsprovide business insights while leveraging internal tools and systems databases and industry dataminimum of 5 years’ experience experience in retail business will be a plusexcellent written and verbal communication skills for varied audiences on engineering subject matterability to document requirements data lineage subject matter in both business and technical terminologyguide and learn from other team membersdemonstrated ability to transform business requirements to code specific analytical reports and toolsthis role will involve coding analytical modeling root cause analysis investigation debugging testing and collaborationwith the business partners product managers other engineering teammust havestrong analytical backgroundselfstartermust be able to reach out to others and thrive in a fastpaced environmentstrong background in transforming big data into business insightsresponsibilities and dutiestechnical requirementsstrong handson expertise in sqlexperienced in hivehiveqladvanced sql preferably teradataexperience working with large data sets experience working with distributed computing mapreduce hadoop hive pig apache spark etcstrong hadoop scripting skills to process petabytes of dataknowledgeexperience on teradata physical design and implementation teradata sql performance optimizationexperience with teradata tools and utilities fastload multiload bteq fastexportexperience in unixlinux shell scripting or similar programmingscripting knowledgeexperience in etl processesreal time data ingestion kafkanice to havedevelopment experience with java scala flume pythoncassandraautomic schedulerrr studio sas experience a plusprestospark druidhbasetableau or similar reportingdash boarding toolmodeling and data science backgroundretail industry backgroundeducationbs degree in specific technical fields like computer science math statistics preferredsiteus  sunnyvalejob posting service typecontractorjob types fulltime contractexperiencelarge data experience with distributed computing 8 years preferrededucationbachelors preferredlocationsunnyvale ca preferredwork authorizationunited states preferred,,CA,False,data_engineer
Big Data Engineer,50000  140000 a yearcontractjob summarybachelors degree in engineering or equivalent work experience2 years of hands on health care domain experience2 years of quality engineering testing experience in a web application environment testing user interfaces backend database web services api’s batchetl application components2 years of experience writing functionalintegration test plans and test cases for complex software application2 years of handson testing experience in a continuous integrationdeliverydevops environment supporting weekly or daily production deployments2 years of handson testing experience working with xmljson mq interface edi x12 sql transactions1 years of handson experience working with unix operating system and writing db sql scriptsexposure to incremental agile software development methodologiesprior experience in working closely with developers and architects in solving software defectsexperience in creating and implementing testing methodologies processes to solve testing problem in handresponsibilities and dutiesflexible to take both manual and automation testing needsunderstand complex healthcare domain workflows and work on creating test scenarios execution plan and automation of those areasresponsible for developing test strategy test scenarios qa project plan coordinating test data setup environment readiness test execution and issue resolutionsystemintegration testing rest api’s user interface database reporting etlbatch application componentsexplore new software tools and capabilities to automate system integration testing to supports continuous deliverydevops agendarequired experience skills and qualificationsbachelors degree in engineering or equivalent work experience2 years of hands on health care domain experience2 years of quality engineering testing experience in a web application environment testing user interfaces backend database web services api’s batchetl application components2 years of experience writing functionalintegration test plans and test cases for complex software application2 years of handson testing experience in a continuous integrationdeliverydevops environment supporting weekly or daily production deployments2 years of handson testing experience working with xmljson mq interface edi x12 sql transactions1 years of handson experience working with unix operating system and writing db sql scriptsexposure to incremental agile software development methodologiesprior experience in working closely with developers and architects in solving software defectsexperience in creating and implementing testing methodologies processes to solve testing problem in handpreferred qualifications job type contractsalary 5000000 to 14000000 yeareducationbachelors preferred,95000.0,VA,False,data_engineer
Data Engineer,"at morningstar helping investors is what brings us together and drives our work we are looking for a data engineer with relational sql nosql etlelt sysops and general programming experience having a proven track record of modeling data solving analytical problems aggregating data bring novel engineering solutions and helping the business move forward is a big bonus you will have the opportunity to help build move transform and model customer behavior existing models warehouses and influence our transformation into the cloud overall this role is designed to help us move forward every day you’ll work with team members across disciplines developing products for investors you’ll interact daily with our product managers to understand our domain and create technical solutions that push us forward we want to work with other engineers who bring knowledge and excitement about our opportunities this position is based in our chicago office

responsibilities
understanding the business and working with product managers architects and dev to source transform and build datasets into aws data technology solutions
break down data silos and provide our business with a competitive advantage
bring focus and attention to the future of our platform in the cloud and open new data technology possibilities there
ensure that our data is secure and compliant to necessary compliance and governance standards
align with morningstar overall data strategy and assist our overall firm success
work closely with the software engineering teams
help the business define its data recovery point objectives drpos
solve investors’ problems with technology and data
be passionate about quality process engineering and investing in general seeing opportunities for improvement seizing them and then sharing your findings with others
familiarity or desire to become proficient with data technology and operating in an aws cloud environment

additional items to stand out from the crowd
excellent relational data skills
experience working with streaming data and solving near real time problems for customers
design indexes for existing applications choosing when to add or remove indexes
advise others on efficient database designs tables datatypes stored procedures functions etc…

requirements
a driven curiosity about our data and a proactive nature to get things done
understanding of etl best practices and data engineering
strong need to communicate clearly consistently and proactively in person and in writing
focus on balancing internal and external customer desires with delivering results the right way in the right timeframe
3 years data engineering experience
expertise with rdbms concepts including stored procedures tables views etc
beginner to midlevel experience with cloud aws based software systems
some experience with performance tuning and query optimization
experience with agile methodology and tools like jira

morningstar is an equal opportunity employer


001mstarinc morningstar inc legal entity",,IL,False,data_engineer
Data Engineer,about evolytics evolytics is evolving analytics by inspiring people to use data in ways that make a difference in the world with a focus on optimizing consumer experiences and strengthening business growth evolytics works with worldclass brands to support data initiatives that span the data lifecycle capabilities include measurement strategy  planning data audits analytics implementation services data engineering reporting  analysis data visualization testing  optimization predictive analytics and customized trainingposition overview the data engineer will work directly with client and internal team members tocreate reportdashboard inputscultivate and finetune data automationconduct data analysis with outcomes that include delivery of actionable insights and business intelligence designed to optimize digital marketing performance of paidownedearned campaigns social media marketing web sites and mobile appssiteswhat you’ll be doing as a data engineer at evolytics you will be expected todevelop processes and procedures for ingesting data from disparate sourcesdevelop andor maintain database architecture including fine tuning and optimizing query plans indicesprojections etccreate and maintain customized sql queries develop reporting structures using sql develop and build data modelsassess client implementation efforts and conduct data qa to determine and document any gaps between the data being collected and what is needed for reporting outputsproject manage multiple client requests and detailed project activities at any one time to ensure accurate timely and efficient reporting and analysis deliverablessql skills are critical for this data engineer role consideration will be given to qualified candidates with varying levels of experience with compensation commensurate with experiencewhat experience would we like to seeexperience with at least one of the following scripting languages python bash java scala r perl and or nodejsexperience with linux command lineexperience with sqlexperience with a leading analytics or relational database system such as redshift vertica bigquery postgresql or mysqlexperience developing data solutions on aws azure or google cloudexperience with big data solutions such as hadoop hive or sparkexperience with change release processes and tools such as gitexperience developingimplementing data transformation via etl processes and data pipelinesminimum of a bachelor’s degree in computer science information systems business marketing or a related disciplineother experience that is helpful but not required experience with any of the following database systems will be a plus nosql mongo db and or couch dbexperience working with clickstream web analytics tools such adobe analytics omniture sitecatalyst adobe discover google analytics or working knowledge of the field of web analyticsknowledge of commonlyused digital metrics analytics concepts and online marketing channel best practicesexperience with tableauknowledge of bi methodologies and toolsproficiency in excel and powerpointthis role includes the unique opportunity to work alongside some of the best talent you will find in the digital analytics industry worldwideculture relaxed work environment casual dress code pool table break room treadmill desksopen office floor plan enhances collaborationlearning opportunities and companyprovided trainingoffsite teambuilding events and company happy hoursfree weekly lunch on taco tuesdayfree snacks fruits and beveragesbenefits competitive benefits package including health dental  vision  life insurancegreat compensation package with paid time off performance bonuses and ira matching contributionsjoin evolyticsawesome people make powerful teams let’s do great things togetherplease include a cover letter describing your experience with analytics as well as your resumejob type fulltimeexperiencesql 1 year requiredlocationkansas city mo preferredwork authorizationunited states required,,MO,False,data_engineer
Senior Application Data Engineer,"can you own the data layer guiding the underlying data architecture to support a fast growing application stack do you enjoy working closely with software engineers to develop and refine software systems can discriminate use cases between transactionally consistent acidcompliant systems of record vs eventually consistent options vs nontraditional data stores
this role will be part of our data engineering group that works closely with our feature product teams facilitating the underlying data model and architecture as our product evolves knowledge and experience within systems and software architecture is required
porch’s tech stack has evolved around microservices architecture and underlying microdatabases we integrate the application of ddl and dml into our software ci systems via flyway so that our services have true ownership of our data we have our domain  canonical model represented behind their own apis as part of a master data management solution postgresql is our relational database of choice
responsibilities
the architecture stuff
data architecture  you will need to ensure we have the correct level of normalization to support that application features maintain the integrity of the underlying data ensure we have a transactionally consistent view of the data when necessary and support eventually consistent data representations when appropriate
domain modeling  is a a part of b or a part of c or is a actually d sometimes microservices get scope creep it is generally most apparent and least reversible at the data layer be comfortable asking questions and giving frank answers
oltp vs olap  is the request a functional requirement of the application or a reporting need keep analytical requirements out of transactional systems and evangelize the usage of the data warehouse be the bridge between the engineering product and development epd teams and the analysts data scientists and data warehouse
the engineering stuff you will work with several software engineering teams to ensure the application is supported by a high quality data layer this means you need to own
data migrations  underlying data model changes new features migration plans may be needed to support the evolution of the systems while maximizing availability
technologies  not everything has to be in a relational database be open to leveraging keyvalue stores document databases and other technologies to provide the right tool for the job
process improvement  is there a better way periodically question what how and why you are doing a task don’t be a drone
collaboration  vertically fulfill the needs of the application layer and front end horizontally communicate and coordinate with data engineering team to establish conventions utilize best practices and share lessons learned
scaling  identify appropriate applications of partitioning and sharding
experience
at least five years as a software systems or data engineer during which you
have been the go to for query optimization and performance troubleshooting
have had 3 years owning ddl and data model implementations in production environments
are comfortable being part of the oncall rotation everyone is on the oncall rotation
have done all of these things in a cloud environment—aws gcp or other public cloud
about porch
porch sprang to life to tackle an age old recurring problem moving in maintaining and managing one’s home is hard porch is becoming the partner for the home helping homeowners to get any home project done both by providing porch services to get all small jobs done ourselves and a large professional network to provide homeowners with multiple quotes for larger projects home services is a 400 billion market and porch is positioned to build a large and rapidly growing company with an opportunity to change home ownership porch’s mission is to ensure every home project gets done with every customer satisfied we aim to build a lasting brand that delivers quality datadriven delightful results
porch was founded by successful entrepreneurs and is led by an experienced team of techies who build beautiful products are operationallyminded datadriven have relentless customer focus and put team before self based in seattle porch is backed by valor equity partners lowe’s home improvement and many others",,WA,False,data_engineer
Senior Big Data Engineer,55  95 an hourcontracttitle  senior software engineer  java python big data  612 month contractoverview  are you a senior software engineer senior java engineer java developer software engineer software contractor or software consultant with solid java and big data map reduce r python hive sqoop or hbase experience are you looking for a lengthy 612 month contract assignment immediate hire in this role you will be customer facing strong communication both written and verbal is required experience beyond java and python would be a huge plus this means any scala or spark experience is highly desired you will have a solid grasp of data structures algorithms interpreting uml diagrams and the ability to develop software solutions to complex business challenges this position will be working in and around northern nj or new york ny manhattan area for best results apply todaywhat’s in it for you immediate hire opportunity612 month contractsolid compensationinteresting projectshere is a little more about what you will be doing working in a team environment with individual accountabilityhandson java python and spark projectssoftware designinterpreting uml diagramsworking with internal and external stakeholdershere is the background and experience we are looking for bs in computer science math science technology engineering physics or related field or equivalent experiencesolid communication and interpersonal skillsability to work in northern new jersey jersey city andor new york ny manhattanso if you have the background and experience listed above please call me or send me your resume today must have the ability to work in the us for any employer and preferably be located in the jersey city nj or new york ny manhattan area but if you are looking to relocate here please applyjob type contractsalary 5500 to 9500 hourexperiencespark 3 years preferredscala 3 years preferredhive 3 years preferreduml diagrams 5 years preferredpython 5 years requiredmapreduce 3 years requiredjava 5 years requiredbig data 5 years requirededucationmasters preferredlocationnew york ny requiredwork authorizationunited states required,,NY,False,data_engineer
Senior Data Engineer,"about us
our company
datafiniti provides instant access to web data for businesses were like a b2b google for data we can provide data sets on every product business or property listed online and we continue to add more data our data is used by startups fortune 500 companies and every sort of company in between

our culture
the datafiniti team is smart driven and passionate about the hard work required to build an amazing company create an ambitious product and serve a wide variety of customers we celebrate our wins and grind through our challenges were a small closeknit team dedicated to each other and our vision

the role
what youll do at datafiniti
at datafiniti we face a variety of fascinating data challenges that all relate to producing highquality data from the wild expanse that is the internet as a senior data engineer youll take on different software projects related to those challenges including

analyzing the html source of an online business product or property listing to automatically extract structured data around name address brand pricing and more
deriving additional information around business product or property records based on what information has already been collected
validating existing data through development of heuristics data models and other tools
any software models or other technologies developed to handle these tasks must operate atscale across tens of millions of records

what we must see from you

highly proficient software developer  includes excellent understanding of software design and coding best practices
deep understanding of machine learning and other data science technologies along with previous experience at least 2 years using these technologies in a production environment
critical thinker extremely detailoriented and processdriven
what wed love to see but its ok if we dont

experience with nlp when used in data extraction
experience with supervised and unsupervised classifiers
experience with technologies we use in our stack java elasticsearch aws docker
benefits

how youll feel the love

competitive pay
complete insurance package medical dental vision life
equity in a growing startup
flexible vacation policy  take it when you need it
foodie fridays  lunch is catered every friday
monthly happy hours
company adventures  mini golf board game nights and other shenanigans
working with awesome people that get stuff done",,TX,False,data_engineer
Data Quality Analyst/Data Engineer,"amyx is seeking to hire a data quality analystdata engineer to be located in washington dcthis position will be supporting the security exchange commission  center for risk and quantitative analytics crqa contract this is a specialized quantitative group that resides under the office of market intelligence omi the data quality analystdata engineer will support two service lines within crqa the fraud analysts and the data cleaning group the fas provide investigationspecific analysis solutions to large datasets in order to identify anomalies that could be indicative of wrongdoing the dcg is a group that provides data manipulation and data management services across enforcement their solutions include converting unstructured data into structured output pdf to excel and merging disparate datasets into a centralized usable product bringing together trade blotters from multiple brokerages
while industry knowledge of fraud detection and securities markets would be beneficial we are putting more of an emphasis on technical proficiency the contractor should have basic knowledge of a robust database platform such as oracle sql or sas deliverables are often created in excel and intermediate knowledge of excel chart creation pivot tables and standard formulas such as vlookupsumcountsubtotal would be a plus knowledge of vba as a backend support to excel is useful we plan to expand into visual dashboard solutions such as tableau and r packages so knowledge of those types of platforms or an ability to learn new systems is beneficial
responsibilities and daily tasks
data profiling
contractor shall conduct a data audit against all identified data sources identifying the data that needs to be corrected
contractor shall provide a data analysis report from the data audit eg description of problem data source number of occurrences missing data impact on production data
contractor shall identify who the contractor the vendor of the data or the business owner will be responsible for correcting the data elements that are in error along with an explanation as to how they came to this conclusion
will assist crqa data quality manager in working with the business owners to identify the data cleansing needs and identify criteria for the data sampling for the data audit eg trade dimensions like volume amounts date dimensions identifiers such as tax ids account numbers
contractor shall ensure the data rules are in compliance with the agency rules policies and statutes pii confidential sensitive
contractor shall provide data analysis to support both the fas and the dcg the primary function will be to provide highlevel analysis of data that has been processed by the dcg group these would be relatively simple aggregates of large datasets to provide summary information of the data that is returned to the case team the contractor may also serve to support the fas in more complex analyses that involve the identification of patterns within large datasets such as analysis of trading activity
data engineering
perform data engineering tasks – data mapping source to target  etl design and development in order to extract and transform the data as required for delivery to customers
work to develop repeatable modules for data extractiontransformation
develop automated data cleansing techniques
develop unit testing framework and modules
supported technologies
various file formats csv xls xml pdf json
oracle database
pdf conversion tools
ibm data stage etl
basic unixlinux knowledge
python

bachelors degree required
solid experience 310 years in relational database concepts with a solid knowledge of oracle sql and plsql
experience in data integration  cleansing and profiling using oracle data base and access andor other technologies
expert level in excel and access and ability to manipulate disparate data sources
exposure to working with multiple data sets  csv excel flat files pdf json and other file formats
experience with unit testing framework
ability to solve problems and work through conflicts
extreme attention to detail and common sense
excellent written interpersonal and communication skills
highly organized detail oriented strong work ethic and team player
ability to follow rules and direction and work independently
positive attitude
ability to obtain public trust clearance
preferred skills
python for data analytics experience is
familiarity with ibm infosphere datastage development etl tool
experience with the financial sector",,DC,False,data_engineer
Data Engineer,"at volusion we make products that people love our teams are dedicated to providing saas ​e​commerce solutions and services for all business types from startups to wellestablished companies if youre a creative professional who loves working with teams has a passion for driving positive change and wants to better the world with your ​ideas we want to hear from you

the rundown
as a data engineer you will assist in the development of data warehouse information architecture on both google cloud bigquery and microsoft sql server optimize sql performance and provide operational support to our high availability microsoft sql server warehouse infrastructure an ideal candidate will be a proficient warehouse developer versed in data integration services development report development data analysis and database administration

you will

assist in building and maintaining data warehouse data integrations leveraging both ms sql integration services and python technologies
assist in the development of bigquery data model
develop and optimize sql queries leveraged by existing integration services reporting processes and data analysis reports
develop dashboards and visualizations for ongoing measurement and kpis
plan for nontransactional data storage for reporting and analytics
database schema design and data flow architecture planning
maintain current reports in existing reporting platforms
profile source system data as needed to provide feedback for business requirements
analyze and verify data warehouse data
assist in the design build and maintenance of ssas cubes

we are looking for someone with

must be a team player with excellent oral and written communication skills
bachelors degree in computer science or engineering
sql skills for data analysis is a strong must have
2 years microsoft sql server integration services development or similar extract transform load development
2 years of experience microsoft sql server database administration
2 years of experience with python 27 or 3x
strong experience with performance optimization and tuning with database applications is a must
kafka experience required
python scripting and net knowledge preferred
familiarity with cloud services google cloud platform gcp and the gcp data services experience is a major plus
git experience is also a plus
highly organized selfstarter with an eye for detail who can maintain multiple ongoing projects simultaneously

who is also the embodiment of our culture code  httpsculturevolusioncom  we hope you are nodding your head in agreement as you browse through it


humble have humility and be respectful no egos allowed
effective get stuff done
adaptable willing to fill any role anytime going abovebeyond the call of duty
transparent open and honest to self and others
a founder think big go fast and solve for the customer

benefits  perks

competitive compensation packages
medical dental vision and voluntary life insurance
flexible paid time off
401k with company matching
paid parental leave
onsite fitness and yoga classes
casual dress and beer fridays
endless supply of coffee and snacks
two volunteer days off
bring your dog to work days
chair massages
team sports and team outings

",,TX,False,data_engineer
Senior Data Engineer,aline staffing is seeking a qualified candidate for the position of senior data engineer located in hygiene cothis is a direct hire opportunityplease review the desired qualifications listed below and apply or contact greg wagner with questionsthis is a blended role of business intelligence and data engineering the core focus of this role will be designing developing and deploying of assigned data processes including etlelt data pipelines file feeds reports and dashboards while managing and actively participating in the data governance processour ideal candidate has a passion for data and bi is an analytical thinker and can act as data subject matter expertin addition someone who has strong communication skills is a great collaborator and mentor possesses a high level of experience with hadoop and one who will complete tasks ontime with high quality results will be successful in this roleresponsibilities include but are not limited to proactively communicate issuesbuild and tune data modelsdevelop data visualization dashboards reportsdevelop data pipelines and file feeds etl elt processescreate a data driven story with data visualizations and recommendations package it via tools like ppt tableau etc and deliver to internal and external audience at various levelsmanage data governance integrity quality lineage metadatabe a thought leader in the data and analytics space be a consultant and a liaison to internal and external teamsmentor and encourage newer less experienced members of the teamcommunicate clearly concisely and professionally with internal west teams customers and executivesqualifications bachelors degree from an accredited college or university with major course work in computer science mis or a related field is requiredequivalent work experience in a similar position may be substituted for education requirementsexperienceminimum 5 years of experience with data analysis and migration to include experience in the analysis or design of applications or systems to store and extract dataminimum 3 year of experience with telecommunications billing preferredminimum 3 years of experience with one or more of the following areas software development database development oracle preferred business analysis systems integration or system administrationminimum 1 year of experience writing detailed test plans for small to medium sized projects preferredtechnical skillsproficiencyminimum 4 years of experience with sql requiredany of the following scripting languages python pig r sas spss perl c or any other scripting languageability to produce production ready code deploy code into productionany of the following relational databases postgresql mysql informix sql server oracle db greenplum vertica db2 or any other rdbms systemhadoop environments and the tools associated within the environment such as yarn sqoop impala flume hive dril hawk or any other similar toolsintermediate knowledge of word excel and powerpoint requiredknowledge of systems and  or database security mechanisms encryption data loss prevention etc is highly preferredgreg wagner – aline staffingjob type fulltime,,CO,False,data_engineer
Sr Data Engineer,"a sr data engineer builds manages integrates and optimizes our reservoirs for data in support of delivering relevant information for business consumption they promote advances in data preparation for predictive analytics and machine learning this individual develops constructs tests and maintains designs for databases and largescale data processing systems in support of underlying business solution and enterprise architectures they support and maintain pipelines delivering relevant data sets for business consumption and analysis this individual works closely in the selection of appropriate data management systems onpremises and in cloud for the business to achieve optimal analysis and predictive analytics they will wrestle with complex rules associated with data integration from many types of source systems to achieve the ultimate goal of providing clean usable data to the enterprise
responsibilities include  promotion and facilitation of data governance through coordination of business stakeholder participation enforced with the onboarding of mdm  mds tools  delivering large and complex solution data needs creating requirements and technical specifications resulting in data architectures and designs  participate in strategic data innovations  implement and advance data models and configurations in support of integrating data from multiple source systems and environments  research design and implement next generation analytics and machine learning platforms  build tools frameworks apis and dashboards to support telemetry and advanced analytics focusing on ways to improve data security accessibility reliability scalability efficiency and quality
education

bs in computer science mathematics softwarecomputer engineering information systems or science related field
a data professional certification eg iccp certified data professional bi professional big data professional data governance professional or vendor equivalent is encouraged
years of related work experience

710 years of data design  development experience in relevant technologiessystems required including technical experience implementing and delivering from system architecture design integration implementation security and capability roadmap for a data environment
experience with rdms databases sql server and data warehouse olap redshift  awarenessexposure to nosql technologies keyvalue columnar document graph 
experience with mdm mds data dictionarymarketplace a plus  ability to facilitate technical and nontechnical stakeholders in governance discussions with distinct outcomes  creative problemsolving leveraging experience with multiple diverse technical configurations technologies and processing environments  intellectual curiosity for advancements in data visualization
power bi microstrategy tableau big data systems including mapreduce technologies nosql technologies keyvalue columnar document graph and monitoring platforms  awarenessexposure to development and modeling programming languages eg java c r python  exposure to cloud data architectures
symetra is a dynamic and growing financial services company with 60 years of experience and customers nationwide in our daily work delivering retirement employee benefits and life insurance products were guided by the principles of value transparency and sustainability that means we provide products and services people need at a competitive price we communicate clearly and honestly so people understand what theyre getting and we build products that stand the test of time we work hard and do whats right for our customers communities and employees join our team and share in our success as we work toward becoming the next national player in our industry

learn more at wwwsymetracomcareers",,WA,False,data_engineer
Data Engineer,marstone inc is seeking a data engineer that is interested in pushing boundaries and disrupting the financial industry using machine learning artificial intelligence and predictive analytics to help clients plan their financial future and to get a wider view of their investment roadmap the candidate should be passionate about analytics and big data architecture the candidate brings experience designing data lakes and data warehouses related to machine learning ml artificial intelligence ai and advanced analytics the candidate will work on an architecture team developing a greenfield predictive analytics application that integrates with various data sources to provide deep learning insight to historical investment patternswe offer a competitive salary health benefits and 401k plan our development team is based in providence rhode island’s historic jewelry district marstone offers a bright and attractive loft office space within walking distance of many nearby lunch spots cafes and other amenitiesresponsibilities contribute to the design and development of a scalable and costeffective cloudbased data lake designcollaborate with an architecture team to develop an advanced analytic platformdevelop data transformation components in a cloud environment to ingest data and events from cloud and onpremises environments as well as third parties and partnerscreate etl pipelines and data services to validate catalog aggregate and transform ingested datadesign automated data pipelines and services to integrate data from the data lake to internal and external consuming applications and servicesthe candidate will bring some of the following qualifications to marstone handson experience architectingdeveloping data lake solutions using amazons awsaws development skills include s3 iam lambda rds kinesis apigateway redshift emr glue and cloudformationworking experience and detailed knowledge in java scala or pythonexperience with etl and pipeline tools glue emr sparkexperience with large or partitioned relational databases aurora mysql postgresqlexperience with nosql databases dynamodb cassandranumpy pandas pyspark radvanced sql and ormrdbms skills using any of the following oracle sql server mysql postgresql auroraadvanced sql scripting skills including etl design stored procedures triggers indexescaching and objectkey value stores such as redis memcachedsearch and logging tools such as elk stack or cloudwatchcloud architecture  design in aws or azureexperience with agilescrum sdlc process and tools such as pivotal tracker confluence jiraproject coordination and estimationversion control repositories such as bitbucket git tfs svnrelated bachelors degree with 35 years of experience or 58 years professional work experience with demonstrated ability to fulfill the roleadditional familiarity with any of the following tools and concepts is a plus experience developing financial analytic applicationsauthoring application design documentation and unit test casesmore about us marstone is a rapidly expanding fintech company whose mission is to empower investors to take control of their financial lives with knowledge and confidence we are an experienced team of designers technologists and wealthmanagement professionals who have developed a new breed of intuitive and relevant financial investment solutions used in support of global institutional clientswe are motivated technology professionals that thrive in a creative and collaborative software engineering environment we offer a collaborative and supportive team atmosphere that encourages developers and engineers to expand their own skills and contribute to our team through skillful problem solving knowledge sharing and mentorship we are passionate about implementing horizon technologies and solving the technical challenges of providing leading edge investment solutions to our clientsas a secregistered investment advisor our digital advice platform powered by marstone assists clients in creating personalized investment portfolios that suit their needs goals and aspirations we continually monitor and maintain each portfolio to assure those investments stay aligned with their original financial targetsjob type fulltime,,RI,False,data_engineer
Data Engineer,"about syapse

maybe youve supported a friend or family member whos dealing with cancer maybe youve battled it yourself at syapse our mission is to enable healthcare providers to deliver the best care to every cancer patient through precision medicine our personal connections to this mission unite us

we integrate genomics and clinical data on a single platform and allow doctors to share important treatment and outcomes information across a national network our customers manage more than 1 million active cancer cases at hundreds of hospitals across the us and asia now were racing to meet growing demand and bring precision cancer care to every patient regardless of location or income

about the engineering team

the engineering team at syapse builds our revolutionary oncology decision support platform that empowers physicians to deliver consistent highquality precision cancer care were scaling our data platform using distributed systems stream processing and microservices to do this and tackle all our engineering challenges our autonomous customer value focused scrum teams work in short sprints and own product areas end to end our domainbased guilds eg data semantics web technology architecture balance that by encouraging the building of communities and foster collaboration across teams

as syapse continues to grow well use advanced software engineering methods to expand the capabilities of the platform—and help deliver the best cancer care to every patient

about the role

you will join our newlyformed ecosystem team whose focus is to develop dataintensive applications that are the bridge between our healthsystem customers and companies in the healthcare ecosystem pioneering the use of real world evidence in the treatment of cancer as an early member of the ecosystem team you will have a unique opportunity to establish new infrastructure and processes that enable us to deliver insights that drive the practice of precision medicine forward you will design and build out the applications and tooling that make data more accessible and enable analytics pipelines data visualization and other services

our team is based out of syapses east coast office and takes pride in our unique culture and environment our mission as a company is a serious one so you can expect to join a nimble team that strives for ever increasing standards of delivery with quality fortunately when you love what you do and you are surrounded by great people you can grow and accomplish more than you think possible

what you bring to the table


bs ms or phd in computer science or related field
5 years relevant work experience
successful track record of manipulating processing and extracting value from large complex datasets
expertise in writing sql and working with largescale relational databases built on postgresql mysql or similar platforms
experience building solutions that leverage nonrelational database technologies dynamodb cassandra mongodb etc…
strong programming skills in languages like python ruby or java
skilled at working with a mix of structured and unstructured data from a variety of sources
an affinity for simple solutions to complex problems
a strong motivation to meet our mission

bonus points if you


have experience working with aws cloud technologies especially dynamodb redshift athena and kinesis
exposure to other big data tools hadoop spark kafka etc…
understand distributed systems and patterns for data replication
switched from premed or biology to computer science in college

benefits and perks

amazing coworkers

competitive pay and ownership in the company

100 company paid medical dental and vision for employees

401k matching

flexible time off

transit assistance  pretax commuter benefits

weekly catered lunches and office snacks

company sponsored gym membership  lots of other perks

next steps

after submitting an application a team member will reach out to you shortly while each interview is unique to the role our interview process typically consists of an introductory phone conversation with a recruiter a second phone or video interview with a hiring manager or senior team member and wraps up with a visit our to our office usually lasting  4 hours

have a quick question about the role email careerssyapsecom  careerssyapsecom  or simply apply here",,PA,False,data_engineer
Sr Big Data Engineer,contractjob title srbig data engineerlocation atlanta gamultiple locationsduration 12 monthsminimum required skillsbig data scala hadoop data mining kafka git unix akka streams mavenif you are a big data engineer with scala hadoop and spark experience we would like to hear from you we are an engineering services company working with leading technology companies to develop a high performance data analytics platform that can handle petabytes of datasets if you are a truly talented big data engineer with super skills in scala hadoop and spark and you are looking for an opportunity to help design and implement an amazing big data solution that will be deployed on a massive scale this is your chancewhat you need for this position9 yeras of ot experience4 years of big data experiencebachelors degree in computer science or related field masters degree a plusstrength with scalastrong knowledge of hadoop and sparkexperience with data mining and stream processing technologies kafka spark streaming akka streamsexperience with version control systems particularly gitdesire and ability to quickly learn new tools and technologiesunderstanding of the best practices in data quality and quality engineeringknowledge of unixbased operating systems bashsshpsgrep etc  a plusexperience with githubbased development processes  a plusexperience with jvm build systems sbt maven gradle  a plusplease share updated resume in ms word format with below client submission informationfull namecontact numberemail idimmigration statuscurrent locationrelocation yesnoavailabilitybest time to reachrate skype idtotal exp usa exp dob ssn last 4key skills domain worked linkedin id must job type contractexperiencespark 4 years preferredssh 4 years preferreddata mining 4 years preferredshell scripting 4 years preferredakka 4 years preferred,,GA,False,data_engineer
MarkLogic Data Engineer,"tdb communications inc is seeking qualified marklogic data engineers

description of specific duties in a typical workday for this position
provides design recommendations based on longterm it organization strategy
develops enterprise level application and custom integration solutions including major enhancements and interfaces functions and features uses a variety of platforms to provide automated systems applications to customers
provides expertise regarding the integration of applications across the business
determines specifications then plans designs and develops the most complex and business critical software solutions utilizing appropriate software engineering processes – either individually or in concert with a project team will assist in the most difficult support problems
develops programming and development standards and procedures as well as programming architectures for code reuse has indepth knowledge of stateofthe art programming languages and objectoriented approach in designing coding testing and debugging programs
understands and consistently applies the attributes and processes of current application development methodologies
researches and maintains knowledge in emerging technologies and possible application to the business
viewed both internally and externally as a technical expert and critical technical resource across multiple disciplines acts as an internal consultant advocate mentor and change agent


position requirements
at least 8 years of experience in developing cloud based multi user application with expertise in designing building testing and implementing it application
must have a strong background in software engineering principles and techniques
8 years of overall experience in information technology
2 years implementation experience in marklogic
experience in translating the business requirement into a technology solution roadmap
ability to consult and advice customers in the nosql implementations
extremely good in communication skills
experience with java development xml and web technologies
experience in implementing xquery and marklogic api development
experience in rolling out large nosql implementations
excellent design development implementation documentation and problem solving skills
experience with integration methodologies and tools
experience in big data technologies hadoop and nosql experience in devops functions
experience in defining best practice and patterns for ingestion and retrieval of data from marklogic
familiarity with other nosql and big data technologies
a bachelors degree from an accredited college or university with a major in computer science information systems engineering business or other related scientific or technical discipline is required




tdb communications inc is an eeo affirmative action racesexsexual orientationgender identitynational originveterandisability employer
required skills

required experience",,MD,False,data_engineer
Data Engineer,"summary

boxy charm is seeking a highly motivated individual responsible for building the analytics data platform for the company

the data engineer will work closely with data scientists and analysts across different business units to build data products that will enable fast decisionmaking and action across the company the position will be part of the data  algorithms team and as such the ideal candidate will not only possess great communication skills but will also be very technical equally at home writing code solving complex problems and working in a cuttingedge cloudbased platform and technology stack

essential duties and responsibilities

build cloudbased data products using sql python snowflake spark and other technologies
build data lifecycle and health tools to enable monitoring of key business kpis
work with a wide variety of data ranging between social media and email to customer transactions and logistics
partner with various business stakeholders and implement solutions that improve their business process
break down complex projects and problems into actionable tasks that be delivered quickly and iteratively and provide value to the business stakeholders
be a data advocate throughout the company
education andor experience

bachelor’s degree or higher in computer science information technology data analytics or a related field
3 years of experience programming in multiple languages such as python java scala etc
3 years of experience working with sql and relational databases and strong sql skills are a must
knowledge of big data and nosql systems such as snowflake hadoop spark mongodb etc
experience working in an agile scrum xp etc development environment
experience with aws or other cloud environments is strongly desirable
experience with streaming data systems is desirable",,FL,False,data_engineer
DW Big Data Engineer,"109000  138000 a year indeed est job title
dw big data engineer
flsa
exempt

department
engineering
band
individual contributor

location
los angeles
job level
reports to
senior data warehouse architect
position type
full time

travel required
jd creation date
job summary

this position is to support increased dw engineering responsibilities especially around sportsbook focusing on but not limited to big data integration api data pipelines and scripting based automation

essential functions
implements big data integration framework and batchrealtime analytical solutions leveraging transformational technologies
support design development of all data pipelines required in the data warehouses to help business solve complex business challenges
works on multiple projects as a technical team member and support design and development of data applications testing and builds automation tools
codes tests and documents new or modified data systems to create robust and scalable applications for data pipeline
implements security and recovery tools and techniques as required
ensures all automated processes preserve data by managing the alignment of data availability and integration processes
conducts logical and physical database design and designs key and indexing schemes
monitors performance and fine tune any necessary infrastructure changes

required qualifications

bs in information systems computer science engineering or related field preferred
3 years of solid data engineering or software engineer experience with big data componentsframeworks hadoop streaming yarn spark hive hbase mapreduce hdfs pig hive sqoop flume ozie etc in largescale data infrastructure
experience with how algorithms work and have experience building algorithms
experience within large relational data warehouse environment including technical architectures infrastructure components etl elt and reportinganalytic tools
experience developing data engineering using python java or any other programming or scripting languages
experience with restful web services open api development and soa concepts
expertise writing sql queries

preferred qualifications

physical demands ada

the physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions

while performing the duties of this job the employee is regularly required to walk and talk or hear the employee is frequently required to use hands to finger handle or use calculator or numerical keys on computer keyboard the employee is frequently required to sit for long periods of time as well as bend reach and stoop or kneel moderate physical activity is required including the ability to lift 15 pounds

specific vision abilities required by this job include close vision distance vision color vision peripheral vision depth perception and ability to adjust focus

work environment

work is normally performed in a typical interioroffice work environment must be able to multitask in a constantly changing environment requires the ability to meet pressure deadlines and time constraints

the above statements are intended to describe the general nature and level of work being performed by people assigned to this classification they are not to be construed as an exhaustive list of all responsibilities duties and skills required of personnel so classified all personnel may be required to perform duties outside of their normal responsibilities from time to time as needed

tvg networkbetfair us is an equal opportunity employer all qualified applicants will receive consideration for employment without regard to race color religion gender pregnancy national origin ancestry citizenship age legally protected physical or mental disability protected veteran status in the us uniformed services sexual orientation gender identity or expression marital status genetic information or membership in any other legally protected category



employee name

employee signature date

i have received a copy of the job description",123500.0,CA,False,data_engineer
Big Data Engineer(USC & GC),job summarywe are looking for a savvy data engineer to join our team of field engineersthe hire will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for crossfunctional teamsthe ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing big data systems and building themthe data engineer will support our solution architects sales executives and technical account managers on big data implementations and will ensure optimal big data solution delivery throughout ongoing projects client engagementsthe candidate must be selfdirected and comfortable supporting the needs of multiple project teams and clientsthe right candidate will be excited by the prospect of optimizing or redesigning our clients’big data architecturetoolsecho system using our industryleading automated data warehouse engine to support data needs and initiativesresponsibilities and dutiesdesign create and maintain optimal data pipeline architectureassemble large complex data sets that meet functional  nonfunctional business requirementsidentify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etcbuild the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and aws ‘big data’ technologiesbuild analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metricswork with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needskeep our data separated and secure across national boundaries through multiple data centers and aws regionscreate data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leaderwork with data and analytics experts to strive for greater functionality in our data systemsup to 50 travel may be neededrequired experience skills and qualificationsmust have worked for at least 3 years in a big data environmentmust have at least intermediateexpert skills in various dataware house reporting  etl technologiesadvanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases  experience building and optimizing big data pipelines architectures and data sets  strong analytic skills related to working with unstructured datasetsbuild processes supporting data transformation data structures metadata dependency and workload managementa successful history of manipulating processing and extracting value from large disconnected datasetsworking knowledge of message queuing stream processing and highly scalable ‘big data’ data storesstrong project management and organizational skillsexperience supporting and working with crossfunctional teams in a dynamic environmentwe are looking for a candidate with 5 years of experience in a data engineer role who has attained a graduate degree in computer science statistics informatics information systems or another quantitative field they should also have experience using the following softwaretools1experience working with one or more of the hadoop distributions cloudera hortonworks mapr2experience with big data tools hadoop spark hive hbase yarn map reduce kafka sqoop3experience with relational sql and nosql databases including postgres and cassandra4experience with data pipeline and workflow management tools airflow5experience with public cloud services aws gcp azure ibm bluemix6experience with streamprocessing systems storm sparkstreaming7experience with objectorientedobject function scripting languages python java c scalabenefitsyes there will be benefitsjob type fulltimeexperiencebig data 4 years preferredlocationatlanta ga preferredwork authorizationunited states preferred,,WA,False,data_engineer
Senior Data Warehouse Engineer,"what were looking for

engineering at 2u is fast paced innovative and full of people passionate about delivering on the promise of higher education via technology we’re growing rapidly and are seeking collaborative and resultsdriven individuals to join us in return we can offer you a fun learning environment where your skills experience and creativity will make a material impact on the company’s success and its overall mission your tenure at 2u will be a highlight of your career

we strive for our teams to be crossfunctional selforganizing and autonomous you’ll be working directly with product managers and business analysts in a highly collaborative manner

about the role

we are looking for a collaborative and resultsdriven data engineer with experience in system management and monitoring within aws infrastructure automated testing and continuous deployment agile techniques like test driven development tdd is a plus

above all you care about delivering quality software in a sustainable and timely manner and about software craftsmanship you have experience in and passion for highquality maintainable code that confers low operating costs high change velocity and is a point of professional pride for you and the team

responsibilities include but are not limited to

you are a competent data engineer and a technical leader with the following competencies

strong database background
data warehouse architecture and data modeling
monitoring administration and performance tuning of the database servers
design and implementation of etl data flows
data governance and security
writing maintainable highperformance code
refactoring to keep code maintainable
conducting exploratory and automated testing
job scheduling and monitoring
debugging complex problems under time constraints
lead technical design of applications and participate in larger system design efforts
providing technical guidance and mentoring more junior teammembers
stay current with the industry trends and best practices
you have experience in

collaborating with the stakeholders product managers business analysts and data science teams to define and refine requirements
planning and estimating development tasks and shortterm projects
relating your project deliverables to products you are building and strategy behind them
advocating for end user needs in software you are building
over time we expect engineers in this role to grow by learning and practicing the following skills

participating in application and system level technical design
conducting technical interviews
participating in planning staffing needs on your team
metrics driven software development
this role reports to director of engineering for data systems team

about the team

the data systems team maintains and develops a reliable wellsupported and frequently updated data lake comprising raw and processed data from 2us platforms we provide a curated set of standardized and consolidated data from all of 2us programs as well as financial data that can be used by the business to build mission critical reporting services we also strive to provide generic facilities for product engineering teams to move data between systems all our hardware infrastructure is in deployed on the amazon web services cloud and we make extensive use of saas services like salesforce segment streamsets and others

we are motivated to build a team where members bring sound computer science fundamentals and a diverse set of skills and experiences to the table we looking for experience and expertise in the following technologies

tsql using postgres and ms sql
python and shell scripting
aws aurora redshift kinesis cloudwatch
big data applications spark sql apache drill aws athena and data visualization tools eg tableau are a plus
about 2u inc nasdaq twou

2u partners with great colleges and universities to build what we believe is the world’s best digital education our platform provides a comprehensive fusion of technology services and data architecture to transform highquality and rigorous campusbased universities into the best digital versions of themselves 2us no back row® approach allows qualified students and working professionals around the world to experience a firstrate university education and successful outcomes to learn more visit 2ucom

2u diversity and inclusion statement

at 2u we are committed to creating and sustaining a culture that embodies diverse walks of life ideas genders ages races cultures sexual orientations abilities and other unique qualities of our employees we strive to offer a workplace where every employee feels empowered by the ways in which we are different as well as the ways in which we are the same

why it’s great to work at 2u

2u offers a highenergy work environment that’s both challenging and fun we work hard but our offices are casual and social places we wear jeans to work and fuel brainstorming sessions with snacks and seltzer

benefits

2u offers a comprehensive benefits package

medical dental and vision coverage
life insurance disability and 401k
unlimited snacks and drinks
generous paid leave policies
tuition reimbursement program
spontaneous dance parties
no asshole policy
note the above statements are intended to describe the general nature and level of work performed by individuals assigned to this position and are not intended to be construed as an exhaustive list of all responsibilities duties and skills required all employees may be required to perform duties outside of their normal responsibilities from time to time as needed

2u is an equal opportunity employer that does not discriminate against applicants or employees and ensures equal employment opportunity for all persons regardless of their race creed color religion sex sexual orientation pregnancy national origin age marital status disability citizenship military or veterans’ status or any other classifications protected by applicable federal state or local laws 2u’s equal opportunity policy applies to all terms and conditions of employment including but not limited to recruiting hiring training promotion job benefits pay and dismissal",,NY,False,data_engineer
"Principal Engineer, Data Engineering","jw player is looking for a principal data engineer to partner with senior leaders product managers and other stakeholders to enable actionable insights that accelerate the growth of the business through the implementation of a robust data management infrastructure

this role offers the opportunity to influence datadriven culture through the analysis of large amounts of data and the building of metrics and business cases around key performance the principal data engineer understands and owns the health of the services and drives necessary changes as needed

the ideal candidate is a selfstarter with excellent analytical abilities as well as a passion for problemsolving and a penchant for tackling the ambiguous the principal data engineer will architect the data platform from multiple sources and spearhead best practices throughout the evolution of data  from structured data warehouse methods to big data analytics  while keeping ahead of the technology curve

most importantly the principal data engineer will help lead the charge in leveraging data to the fullest extent for both customers and the jw player business as a whole

responsibilities

drive and implement data management strategy design and deliver automated solutions whenever applicable
work closely with business and software engineering leaders to lead catalog data improvements so as to maximize customer improvement impact
lead business intelligence and data engineers to design and develop data infrastructure strategy for the quality and software development organization
partner with data scientists and product analysts enable effective decision making by streamlining data pipelines and make data from from multiple sources available with highest quality
perform deepdives to find the root causes behind variances and identify opportunities for quality control automation
triage many possible courses of action in a highambiguity environment making use of both quantitative analysis and business judgment
collaborate with software engineering teams to integrate experimental capabilities into largescale highly complex jw player production systems
ensure results in a manner which is both statistically rigorous and compellingly relevant
assist in recruiting mentoring developing and training other data engineers and business intelligence and product analysts within the organization

requirements

babs in computer science engineering mathematics or related field or experience equivalent
10 years of relevant work experience in a role requiring application of analytic skills to integrate data into operationalbusiness planning or advanced degree
5 years of operations andor multisource data engineering experience eg s3 data lake
strength in writing and tuning sql data modeling etl development and data warehousing
proficiency with scripting languages pythonr or other modern program languages
advanced ability to draw insights from data and clearly communicate them verbalwritten to the stakeholders and senior management as required
selfdriven with ability to deliver on ambiguous projects with incomplete or dirty data
an ability and interest in working in a fastpaced and rapidlychanging environment
experience in working with very large data petabytes warehouse environment
familiarity with aws and latest big data technical stack eg spark storm kafka flink …

about jw player

jw player pioneered video on the web over a decade ago and continues to innovate as the worlds largest networkindependent platform for video delivery and intelligence current the company serves over 15 billion unique users a month and ingests over 15 terabytes a day media companies including fox vice business insider and univision in addition to hundreds of thousands of creators of all types and sizes rely on jw player to deliver and monetize their content across all devices jw players massive global footprint of over 2 billion unique devices creates a powerful data graph of unique consumer insights and generates billions of incremental video views the company is headquartered in new york with offices in london and eindhoven and was named to deloittes technology fast 500™ in 2017 for more information visit httpwwwjwplayercom  httpwwwjwplayercom 

we are an equal opportunity employer and value diversity at our company we do not discriminate on the basis of race religion color national origin gender sexual orientation age marital status veteran status or disability status",,NY,False,data_engineer
Data Engineer,contractrequired experience skills and qualificationsetlaws redshiftbig data – hadoop hive pig hbase python spark  scalaec2s3oracleplsqljob type contract,,CA,False,data_engineer
Data Engineer,"req id 121909
as a member of the micron data science team the data engineer
develops and codes software programs algorithms and automated processes to consolidate integrate and evaluate large datasets from multiple sources
assists in the design of user interface and business application prototypes
interacts with product and service teams to identify questions and issues for data analysis and experiments
interprets actionable insights from large data and metadata sources and communicates the findings to product service and business managers for product enhancement

requirements

must have 3 to 5 years of relevant work experience
experience working with structured semistructured and unstructured data sources
the ability to problem solve and provide complex solutions with limited direction
strong experience with design development and implementation of complex architecture
extensive experience with web front end development htmlcss javascript jquery or angular preferred
handson experience with various machine learning methods
excellent communication and leadership skills
demonstrated capability in python java and at least one other programming language
ability to learn quickly and become productive on new technologies apis development languages and frameworks
some working knowledge of hadoop environment including hive map reduce nosql hbase and spark

education
bachelor’s degree or master’s degree in computer science science engineering information science or a related field

desired skills

image analytics with opencv or equivalent
proficiency in r language
signal analysis methods
deep neural networks dnn
experience with gui development
complex data visualization techniques
flow simulation and analytics methods
experience using a version control system

we recruit hire train promote discipline and provide other conditions of employment without regard to a persons race color religion sex age national origin disability sexual orientation gender identity and expression pregnancy veteran’s status or other classifications protected under law this includes providing reasonable accommodation for team members disabilities or religious beliefs and practices

each manager supervisor and team member is responsible for carrying out this policy the eeo administrator in human resources is responsible for administration of this policy the administrator will monitor compliance and is available to answer any questions on eeo matters

to request assistance with the application process please contact micron’s human resources department at 18003368918 or 2083684748

keywords manassas  virginia usva  united states us  frontend manufacturing  entry  regular  engineering  liad1 ",,VA,False,data_engineer
"Data Engineer, Data Science","who we are
twitter users generate many terabytes of data every day twitter engineers run hundreds of experiments twitter data engineers build data pipelines and data processes that calculate metrics and scale increasingly sophisticated models of users and content

the data science team at twitter is at the intersection of all this data and strives to make it actionable to all business units around twitter data engineers work alongside data scientists analyze this data via observational analyses trend analyses modeling and new measurement strategies we also implement metrics to track the impact of new product experiments and more generally find ways to make very large scale data approachable to guide our decisions

what you’ll do
twitter has very large and complex datasets as a twitter data engineer you will build datasets and make them accessible to our partner teams by writing great production code to simplify the complexity your work will enable product managers and other decisionmakers across the company to bring together insights and inform our product and strategy in every decision that you influence you will see the product improve and be more valuable to twitter users

we are trying to improve twitter to improve something we need to be able to measure it as a data engineer you will enable better measurements and ensure measurement accuracy so that we know where we are doing well and where we want to improve

as such you will
design develop and launch extremely efficient and reliable data pipelines to move data and to provide intuitive analytics to our partner teams
make twitterscale data more discoverable and easy to use for data scientists and analysts across the company
collaborate with other engineers and data scientists to discover the best solutions
support your colleagues by reviewing code and designs
diagnose and solve issues in our existing data pipelines and envision and build their successors

who you are
you want to be part of a community of the most talented forwardthinking data scientists and engineers in the industry you are a strong scala or java developer you demonstrate clear and concise communication and datadriven decisionmaking

you are passionate about learning or growing your expertise in some or all of the following

data pipelines
data warehousing
statistics
metrics development

requirements
bs andor ms in computer science or a related technical field or equivalent experience
2 years of experience in either data infrastructure or backend systems
strong understanding of sql
broad knowledge of the data infrastructure ecosystem
experience with hadoop or other mapreducebased architectures
experience working with large data volumes
good understanding of one or more of the following scala c or java

experience with any of the following is a plus
scalding
full stack development
presto or hive
spark

applicants will be considered for this role at all levels from swe i to senior swe depending on qualifications

﻿we are committed to an inclusive and diverse twitter twitter is an equal opportunity employer we do not discriminate based on race ethnicity color ancestry national origin religion sex sexual orientation gender identity age disability veteran status genetic information marital status or any other legally protected status

san francisco applicants pursuant to the san francisco fair chance ordinance we will consider for employment qualified applicants with arrest and conviction records",,CA,False,data_engineer
DATA ENGINEER,"we’re here to ensure the advertising industry and the people in it are healthy and engaging positively and effectively with those around them we’re here ultimately to improve the lives of people working in the media industry and we take our responsibility seriously

about the product and engineering team

at centro we’ve always been about making people’s lives better—from our employees to our clients today we’re building a unified platform to execute every digital media advertising transaction thus providing a new level of automation and intelligence in ad tech this is an enormous task that will disrupt an industry and improve the lives of those who work within it

to do this we’re aggressively growing our team of engineers product developers and designers we are imaginative passionate determined and relentless in our efforts of course we are fascinated by the complexity of engineering problems at this scale—it’s what brings bright minds together but what keeps us coming back and why we love coming to work everyday is the chance to improve how work gets done freeing up people’s time so that they can dream bigger and make life better

come build something amazing with us

about the role

we are seeking forwardthinking data engineer to join data team you will be involved in the design and implementation of the data platform were looking for a data engineer who has passion for data processing and the challenges presented by different types of data at high velocity

core responsibilities

implement scalable fault tolerant and accurate etl pipelines
gather and process raw data at scale from diversified sources
build enterprise business analytics and reporting applications
develop platform services to operate the data applications at scale

qualifications

proficiency with relational databases and sql queries postgres mysql oracle or similar
knowledge of hadoop ecosystem components spark hive impala kafka oozie is a plus
understanding of factors affecting performance of etl processes and sql queries ability to work on performance tuning
experience in data modeling for oltp and olap applications
experience implementing data pipelines
experience coding in python or scala
experience with tools such as git jenkins jira intellij
experience with pentaho is a plus
experience with other big data technologies such as cassandra mongodb elastic search is a plus
ability to work independently as well as part of a team
strong aptitude toward problem solving and working with different data sets
having a passion and knowledge of adtech industry is a plus
have a bachelor’s degree in computer science or software engineering

centro is an equal opportunity employer and does not discriminate against any employee or applicant on the basis of race gender age disability or any other basis protected under the law",,IL,False,data_engineer
Senior Data Engineer,"adaptive management is a saas company building a unified ecosystem for leveraging data our cloudbased platform datamonster™ enables companies to interface with thousands of data providers to quickly find answers from data our team includes former financial investors nsa cryptology and applied mathematics experts and silicon valley software veterans adaptive management is headquartered in manhattan new york city

this is an exciting time to get in on the groundfloor of a wellfunded and fastgrowing startup that is solving complex problems and setting the standard for how data is found visualized and ultimately used we have revenue a healthy sales pipeline and a clear pathway to the next funding round if you are looking to join a highly talented and passionate team of software engineers data scientists and business leaders then reach out to us at careersadaptivemgmtcom or apply now

the role

we have relationships with hundreds of vendors in the alternative data space and this number will only continue to grow we are seeking a senior data engineer to leverage industry bestpractices to spearhead the design creation and management of our data warehouse and all related extraction transformation and loading of partner data

the senior data engineer will play a critical role in leading the review interpretation and onboarding of new data sets they will be adept at designing and implementing data management frameworksetl processes and will possess a deep technical knowledge and skillset

we are a wellfunded startup offering full benefits and competitive compensation the position will be fulltime we are a startup but prioritize worklife balance

responsibilities


understand the bigpicture view of the companys data landscape and longerterm goals in order to develop and implement innovative big data architectures on aws
govern etl best practices  standards
learn key vendor data sets and become proficient with extracting data from them
build etl mechanisms to onboard vendor data and publish it via existing channel
develop database and api representation strategies that reflect the needs of our end users
design quality checks to ensure the highest level of data quality and accuracy finding root causes of potential issues and outliers when needed
develop target data models including data policies for sensitive data assets security policies backup and recovery specifications
help implement data strategy data governance processes and maintenance of business definitions policies and glossaries for data assets
support quality processes that ensure that the data is timely and correct as well as serve as the steward of data sets across vendors

requirements


bachelors degree or higher in computer science or a related discipline
10 years of systems engineering experience
5 years of design and implementation of custom data warehouse solutions
experience working in cloud environments aws gcp azure
handson development mentality with a willingness to solve complex problems
strong communication skills ability to simplify complex designs for developers to code
experience working on an agile scrum team a plus
experience in a startup environment a plus

",,NY,False,data_engineer
Data Engineer,"requisition id 28593

nextera energy resources is one of the largest wholesale generators of electric power and renewable energy from the wind and sun in north america

position specific description

we are looking for a savvy data engineer to join our growing team of analytics experts the hire will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for cross functional teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up the data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our company’s data architecture to support our next generation of products and data initiatives
responsibilities for data engineer
1 create and maintain optimal data pipeline architecture
2 assemble large complex data sets that meet functional  nonfunctional business requirements
3 identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
4 build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using mqtt sql and aws ‘big data’ technologies kfkacassandrahivemq
5 build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics datadog dashboards powerbi
6 work with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
7 keep our data separated and secure across national boundaries through multiple data centers and aws regions
8 create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
9 work with data and analytics experts to strive for greater functionality in our data systems

qualifications for data engineer
1 advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
2 experience building and optimizing ‘big data’ data pipelines architectures and data sets hivemq kafka cassandra mqtt s3
3 experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement data quality dimension analysis based on statistical measurements
4 strong analytic skills related to working with unstructured datasets
5 build processes supporting data transformation data structures metadata dependency and workload management preferably in java c or linux tools
6 a successful history of manipulating processing and extracting value from large disconnected datasets
7 working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores
8 strong project management and organizational skills
9 experience supporting and working with crossfunctional teams in a dynamic environment
10 we are looking for a candidate with 5 years of experience in a data engineerdata science role who has attained a graduate degree in computer science computerelectrical engineering statistics informatics information systems or another quantitative field they should also have experience using the following softwaretoolsexperience with big data tools hadoop spark kafka etcexperience with relational sql and nosql databases including postgres and cassandraexperience with aws cloud services ec2 emr rds redshiftexperience with streamprocessing systems storm sparkstreaming etcexperience with objectorientedobject function scripting languages python java c scala etc

job overview

this position develops and integrates new or existing applications into the technical infrastructure and existing business processes employees in this role provide technical or functional guidance to project or work teams as needed within a specific discipline



job duties  responsibilities

analyzes designs develops tests debugs implements maintains andor enhances existing or new systems that are reliable and efficientdevelops customized programming solutions and maintains existing system functionalitydevises or modifies procedures to solve complex problems and prepares detailed specifications from which programs will be writtenapplies appropriate development methodologies system development lifecycles tools and technologycollaborates on an ongoing basis with the business systems analystparticipates in the ticket management and resolution processes including receiving resolution monitoring and customer satisfactionleads projects when neededprovides direction training and guidance for less experienced staffbuilds strong working understanding of the solution being deliveredensures user satisfaction by providing preventative maintenance troubleshooting and timely resolution of more complex problemsfollows and participates in the defined software development lifecycle sdlc sarbanes oxley sox compliance and general computing controlsdefines metrics and monitors service level agreements slas for systems being developedmeets daily weekly and monthly reporting requirementsperforms other jobrelated duties as assigned


required qualifications

high school grad  gedbachelors or equivalent experienceexperience7 years


preferred qualifications

bachelors  sciencesweb technologiesinformation coding standardsprogrammingstrategic planning


employee group exempt
employee type full time
job category information technology
organization nextera energy resources llc
location juno beach florida
other work locations florida
relocation provided no

nextera energy is an equal opportunity employer qualified applicants are considered for employment without regard to race color age national origin religion marital status sex sexual orientation gender identity gender expression genetics disability protected veteran status or any other basis prohibited by law we are committed to a diverse and inclusive workplace

if you require special support or accommodation while seeking employment with nextera energy please send an email to askhrneecom providing your name telephone number and the best time for us to reach you alternatively you may call 18446944748 option 1 press 6 between 8 am and 5 pm est mondayfriday please do not use this line to inquire about your application status

nextera energy will not discharge or in any other manner discriminate against employees or applicants because they have inquired about discussed or disclosed their own pay or the pay of another employee or applicant however employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information unless the disclosure is a in response to a formal complaint or charge b in furtherance of an investigation proceeding hearing or action including an investigation conducted by the employer or c consistent with the contractor’s legal duty to furnish information

nextera energy does not accept any unsolicited resumes or referrals from any thirdparty recruiting firms or agencies please see our policy for more information",,FL,False,data_engineer
Big Data Engineer,"about us
we are a full stack data science company and a wholly owned subsidiary of the kroger company we own 10 petabytes of data and collect 35 terabytes of new data each week sourced from 62 million households as a member of our engineering team you will use various cutting edge technologies to develop applications that turn our data into actionable insights used to personalize the customer experience for shoppers at kroger we use agile development methodology starting with big room planning bringing everyone into the planning process to build scalable enterprise applications

data developer – what youll do
as a data developer we develop strategies and solutions to ingest store and distribute our big data our developers use scala hadoop spark hive json and sql in 10 week long scrum teams to developer the products tools and features

responsibilities
take ownership of features and drive them to completion through all phases of the entire 8451° sdlc this includes external facing and internal applications as well as process improvement activities such as

lead design of hadoop and sql based solutions
perform development of hadoop and sql based solutions
perform unit and integration testing
collaborate with senior resources to ensure consistent development practices
provide mentoring to junior resources
participate in retrospective reviews
participate in the estimation process for new work and releases
bring new perspectives to problems
be driven to improve yourself and the way things are done

education

requirements

bachelors degree typically in computer science management information systems mathematics business analytics or another technically strong program
5 years proven ability of professional data development experience
strong understanding of agile principles scrum
proficient with relational data modeling
5 years proven ability of developing with sql oracle sqlserver
5 years proven ability of developing with hadoophdfs
full understanding of etl concepts
full understanding of data warehousing concepts
exposure to vcs git svn
3 year developing experience with either java scala or python
experience with spark
preferred skills – experience in the following
exposure to nosql mongo cassandra
soa
junit
cicd

",,OH,False,data_engineer
Senior Data Engineer,"the gbg loqate engineering team

the gbg loqate engineering team develops and maintains loqate’s product suite consisting of address verification geocoding and power search solutions team members contribute to development and provide assistance to customers

the role vision

design and development and testing of data manipulation systems and providing solutions to customer issues that relate to data organise daytoday operations and mentor team members

what you’ll do objectives

develop data manipulation systems or etl using a mixture of technologies including sql shell scripting javadebug fix and test modules and provide solutions to customer issuestest and integrate code changes to our data manipulation systemswrite user documentationimprove on existing data processing while designing future systemsmentor team members and assist or embed with other teams on data processing
how you’ll deliver it… strategies
these will be determined by you in collaboration with your manager and you’ll update them regularly to keep your contribution relevant as we evolve you’ll do this via your personal vos

to help you be successful we’re looking for

bachelor’s degree in computer science or an equivalent technical subjectfluent in sql java and shell scriptingworking knowledge of mysqldemonstrable software development andor data engineering experienceexperience with etl software andor data manipulation systems nice to havebig data nice to havewillingness to work hard learn and possess a positive attitudemeticulous attention to detailindependent thinkerproblem solvermotivated to learn and empower others and when meeting obstacles not afraid to test new concepts or ask for guidance



tweet",,CA,False,data_engineer
Big Data Developer,contractclient is seeking to hire a big data engineer to help with our current demands in big data technologies we are looking for strong experienced candidates with 34 years of big data ecosystem experience who have done similar work elsewhere financial services experience is a plusresponsibilities lead definition and socialization of end to end big data enablement solution architecturedesign develop and implement a real time data integration and cognitive fabric using big data technologies such as hadoop spark hbasebe accountable for thesolution design and development of hadoopspark environments integration with analytic platformsenterprise information management eim and data warehouse dw platformsformulate approaches and gather data to solve business problems develop conclusions and present solutions through formal deliverablesa successful history of manipulating processing and extracting value from large disconnected datasetsrequired technical and professional expertisestrong experience in hadoop platform and data architecturestrong experiencein use of open source tools such as hadoop hive hbase spark stormkafkaand file storage formats parquet avro orccandidate must have prior experience working with one or more of the following cloudera hadoop distribution hortonworks data platform mapr microsoft hdinsightsfluency in several programming languages such as javascala or pythonwith the ability to pick up new languages and technologies quicklyexperience working on hadoop cluster setting map reduce job optimizations queue management job schedulingorchestrationusing oozieworking experience on development build  deployment tools such as eclipse maven git jenkin gradleexperience working with tableau and big data lake integration is a plusjob type contract,,AZ,False,data_engineer
Database Administrator/Data Engineer,"overview
since 2011 branch creative network has been bringing the digital world to life with strategic innovative and entrepreneurial solutions clients from a wide variety of industries rely on our expertise in social media strategy web design analytics research and mobile implementation

branch creative network a division of jackson dawson is seeking a talented database administratordata engineer to join our analytics and business intelligence team in our fast paced opportunity rich business environment the role of the database administrator is to perform a range of functions with respect to information collection analysis and presentation including responding to requests for reports and dashboard design and proactively providing relevant data and information in support of program initiatives within bcn
responsibilities
through the etl process prepare data for data scientist and other team members
design buildmaintain data structures
confidently speak to front end output
as an sql practitioner coach and mentor others on the team
work collaboratively with developers
actively participate in data quality assurance
research and recommend data solutions
recommend effective marketing channels online and offline and develop test plans
collaborate with social media team to ensure proper campaign metrics are being captured
maintain project timeline according to projection
performance monitoring and tuning capacity planning
drive business by ensuring key programs goals are met
travel as required to meet clientpartners
perform all other duties as assigned by supervisor
qualifications
bachelor’s degree in related field of business marketing statistics computer science mathematics
must have at least 7 years of experience in a dba role
minimum 5 years’ experience buildingmanaging data warehouses data marts and data lakes
expert sql practitioner with minimum 7 years of experience
proficient in sas sql write sql and use sql server adobe analytics microsoft outlook word powerpoint and access
minimum 5 years of experience managing marketing data such as demographic and psychographic data
must possess data management experience
visualization experience with ms power bi andor tableau considered a plus
highly adept with etl extract transform load
database security experience
knowledge in python or r programming data mart data lake data governance
expert knowledge in excel required
understanding of market research and analysis techniques
automotive marketing experience preferred
clearly demonstrated businessrelated problem solving and produce a viable solution
excellent written and oral communication skills
ability to manage client relationships including sensitive data and confidential materials
ability to manage deadlines and multiple priorities including competing demands
must be a selfstarter work well with minimal supervision and accept responsibility
team participation and effectiveness
must have ability to collaborate across functions to form strong working relationships",,MI,False,data_engineer
Big Data Engineer,specific qualifications for the big data engineer position includedemonstrated growth over 3 years’ experience working as a data engineerhigh level understanding of big frameworksdevelopment experience with big datanosql platforms such as hbase mongodb or apache cassandraexpert knowledge of sql and nosql toolsknowledge of mapreduce and mapreduce generating tools like pig or hiveexperience with message buses or realtime event processing platforms is a plusjava development experiencescripting language experience perl python etcunderstanding of nosql data modelingknowledge of how to assess the performance of data solutions how to diagnose performance problems and tools used to monitor and tune performancecodes and performs unit and integration testing on following hadoop ecosystem tools like hdfs hive  yarn flume oozie kafka storm scala spark and spark streaming including nosql database knowledge to ensure proper and efficient execution and adherence to business and technical requirementsjob type fulltimeexperiencebig data 3 years required,,MO,False,data_engineer
"Data Engineer, AR/VR Camera","facebooks mission is to give people the power to build community and bring the world closer together through our family of apps and services were building a different kind of company that connects billions of people around the world gives them ways to share what matters most to them and helps bring people closer together whether were creating new products or helping a small business expand its reach people at facebook are builders at heart our global teams are constantly iterating solving problems and working together to empower people around the world to build community and connect in meaningful ways together we can help people build stronger communities — were just getting started
at facebook we have many opportunities to work with data each and every day how would you like to work on data and build some of the tools that are critical to moving  transforming this data into valuable  insightful information if so this is the right job for you join a team of data engineers and scientists in the camera team the mission of the camera team is to empower people through augmented reality ar and in doing so build a world class camera the data engineers support everything from helping product teams build new pipelines to track new and existing ar experiences measure the performance of the underlying ar tech eg face and hand trackers plane detectors etc

the camera team is also a platform team meaning that the technology we build supports not just facebook’s main app but also instagram messenger bonfire etc data engineers on this team will be uniquely positioned to analyze data influence teams and create impact across the facebook family of apps
responsibilities

manage data warehouse plans for a product or a group of products

interface with engineers product managers and product analysts to understand data needs

build data expertise and own data quality for allocated areas of ownership

design build and launch new data models in production

design build and launch new data extraction transformation and loading processes in production

support existing processes running in production

define and manage sla for all data sets in allocated areas of ownership

work with data infrastructure to triage infrastructure issues and drive to resolution

analyze data to identify deliverables gaps and inconsistencies
minimum qualifications

2 years experience in the data warehouse space

2 years experience in custom etl design implementation and maintenance

2 years experience working with either a mapreduce or an mpp system

2 years experience with objectoriented programming languages

2 years experience with schema design and dimensional data modeling

2 years experience in writing sql statements
preferred qualifications

bsba in technical field computer science mathematics or equivalent experience

1 years experience in python or java",,CA,False,data_engineer
Data Lake Engineer,"115000  125000 a yearazure data engineer
115000  125000  10 annual bonus
des plaines il
permanent full time this is not a contract opportunity
us citizen or permanent residency status required

over the next 1218 months this team will focus on modernization of their data and bi tools replatformrewrite existing legacy etl solutions from decision stream and custom java to the latest ssis in azure environment and schedule them using orchestrator you will also develop bietldm solutions in azure iaas environment using cona and hana sources you will be part of a team responsible for designing developing and supporting data management solutions for this 10 billion enterprise

requirements
experience in azure data factory andor azure data lake
you should already have 5 or more years of relevant business intelligence andor data warehousing andor data integration work experience which should include 35 years in the microsoft bi stack  ssis ssrs etc
experience in data modelling logicalphysical relational and documentobject and data integration solution design experience understanding of dimensional modeling techniques
experience  ability to quickly  easily parse data from sources other than ms sql server either on a realtime basis or nightly batch

big plus if you have
experience leveraging cloud services iaas paas
experience using open source data integration tool such as talend azure data factory
itil certification

would you be interested in exploring this opportunity ",120000.0,IL,False,data_engineer
Data Engineer,"at abbott were committed to helping people live their best possible life through the power of health for more than 125 years weve brought new products and technologies to the world  in nutrition diagnostics medical devices and branded generic pharmaceuticals  that create more possibilities for more people at all stages of life today 99000 of us are working to help people live not just longer but better in the more than 150 countries we serve
main purpose of role
this will be a foundational member role in a small team of talented and highly motive data engineers and big data architects to create big data based advanced analytical platforms and products

main responsibilities create deploy and optimize large scale data use extensive data engineering expertise to design and build solutions products for analyzing large data sets and identify patterns and relationships manage data sources organize data and create data assets using identified open source or proprietary tools work closely with smes functional experts in commercial rd finance etc for building data pipeline from structure and unstructured data sources work on newest tools and technologies powering these analytics wave  scala scalding spark hadoop deploy advanced machine learning techniques and algorithms and work in a truly big data way
travel occasionally per needs of the assigned project

qualifications

education level
bachelors degree ± 16 years bachelor’s degree in any of the following – math physics computer science statistics economics quantitative sciences

 experience

minimum 16 yearsstrong problemsolving skillsexperience in any from aws python r spark hive hbase hadoop kafka yarn etc will be a plusattention to detail and organization documentation skillsability to prioritize and triage deadlinedriven tasks in a highpressure environmentbasic knowledge of distributed computing parallel processing and large scale data managementexperience manipulating and analyzing complex highvolume data from varying sourcesability to communicate complex quantitative analysis in a clear precise actionable manner",,IL,False,data_engineer
Big Data Engineer,contractjob summaryas developer within the big data team you will contribute to high quality technology solutions that address business needs by developing data applications for the customer business lines you will contribute to the development and ongoing maintenance of a number of strategic data initiatives and data and analytic applications the ability to communicate effectively is required as you will work closely with other groups including development and testing efforts of your assigned application components to ensure the successful delivery of the projectresponsibilities and dutieshands on development role focused on creating big data and analytics solutions  coding of mission critical components  analyze business and functional requirements and contribute to overall solution  participate in design reviews provide input to the design recommendations  participate in project planning sessions with project managers business analysts and team members  handson expertise with graph databasesrequired experience skills and qualificationsexperience with middletierbackend systems development in javalinux –minimum 35 years working experience with hadoop in an enterprise setting –experience with java enterprise development python and scalar –handson expertise with sql  nosql data platforms –handson expertise with big data technologies hbase hive sqoop –experience with pubsub messaging jms kafka etc stream processing storm spark streaming etc –understanding and application of security best practices as they relate to big data technologies –experience with horizontally scalable and highly available system design and implementation with focus on performance and resiliency –experience profiling debugging and performance tuning complex distributed systems –experience with unix shell scripts and commands –experience with data modeling –ability to clearly document solution designs –agilescrum methodology experience –experience with etlelt tools –experience with bi solutions tableau microstrategy d3 etc complexity works on complex issues where analysis of situations and data requires an indepth evaluation of variable factorsexercises judgment in selecting methods techniques and evaluation criteria for obtaining resultssupervision acts independently to determine methods and procedures on new assignments and may provide work direction to othersworks under minimal supervisionminimum educationtrainingcertification bachelors degree in an information technology area of studymasters degree preferred specializing in computer science information management data science or equivalent combination of education and experiencejob type contractlocationsan francisco ca required,,CA,False,data_engineer
Machine Learning Data Scientist,"machine learning data scientist

who we are

murmuration is an organization dedicated to sustainable policy change in the us and we believe that the path to real change in america’s education system is through political activism and participation together with our partners we develop shared infrastructure and coordinated support for organizations on the ground to massively improve outcomes for all children we do this by working directly with local schools and organizations to amplify the voices of parents and families as key stakeholders in setting education policy

as part of our work murmuration has developed a technology product called “minsights” that seeks to aggregate data from a combination of sources including member data from partner organizations publicly available data consumer data voter file data and more the compiled data are then used to build a variety of analytic models and tools that enable murmuration’s partner organizations to activate expand and mobilize their supporter bases effectively for sustained political change

about the position

we are looking for a creative and endlessly inquisitive data scientist with a machine learning emphasis to join our team you will be working handinhand with our senior data engineer and senior data scientist to develop highly optimized predictive models from a large volume of regularly updated data in addition you will be a key contributor to our python analytics code base to build and automate custom analytics to help analyze our partners’ work in the political and advocacy spheres you will be working in a small but dedicated detailoriented team that is committed to our mission the murmuration work environment is friendly driven and noncorporate but professional

the machine learning data scientist will
create predictive analytics using the latest machine learning algorithms on relatively “big” data hundreds of features on  100 million records
provide analytic insights for partners throughout the lifecycle of their campaigns build review and recommend custom models provide realtime visualizations and analysis of campaign work and produce postcampaign analytics to help our partners constantly learn from their efforts
work with senior data engineer to help build and optimize our predictive analytics pipeline to perform well on large datasets stored in amazon web services aws
help develop and maintain python analytics code base to build and automate custom analytic products
analyze the performance of our production machinelearning models
work closely with the data engineering team to analyze and augment our data
candidate profile

murmuration attracts employees with distinctive and diverse backgrounds and accomplishments integrity creativity flexibility and drive are key attributes of competitive candidates the data and analytics teams are highly collaborative friendly and hardworking and we are looking for a machine learning data scientist who embodies those values
the ideal candidate will have

phd in political science sociology mathematics statistics or other related field or 45 years of experience building production level machine learning models on large datasets
excellent general data science skills data cleaning munging data visualization
excellent python skills with additional experience in r desired
experience with amazon web services in particular applying analytics in that setting
experience identifying appropriate statistical techniques and applying them to a variety of realworld datasets
strong problemsolving skills as well as the ability to manage several tasksprojects concurrently and prioritize work effectively
experience with databases and knowledge of sql preferred
interest in politics andor educational policy
location

this position will be based in new york ny and requires occasional travel

compensation

the machine learning data scientist position is a fulltime salaried position with a comprehensive benefits package compensation for this position is commensurate with experience

an equalopportunity employer with a commitment to diversity

murmuration is proud to be an equal opportunity employer and as an organization committed to diversity and the perspective of all voices we consider applicants equally of race gender color sexual orientation religion marital status disability political affiliation and national origin we reasonably accommodate staff members andor applicants with disabilities provided they are otherwise able to perform the essential functions of the job",,NY,False,data_engineer
Data Engineer,"data engineer – wilmington de or gaithersburg md

at astrazeneca we turn ideas into life changing medicines working here means being entrepreneurial thinking big and working together to make the impossible a reality we’re focused on the potential of science to address the unmet needs of patients around the world we commit to those areas where we think we can really change the course of medicine and bring big new ideas to life

we are looking for a savvy data engineer to join our team of analytics experts in either wilmington de or gaithersburg md the hire will be responsible for expanding and optimizing our data and data pipeline architecture as well as optimizing data flow and collection for cross functional teams the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up the data engineer will support our software developers database architects data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects they must be selfdirected and comfortable supporting the data needs of multiple teams systems and products the right candidate will be excited by the prospect of optimizing or even redesigning our company’s data architecture to support our next generation of products and data initiatives

responsibilities
create and maintain optimal data pipeline architecture
assemble large complex data sets that meet functional  nonfunctional business requirements
identify design and implement internal process improvements automating manual processes optimizing data delivery redesigning infrastructure for greater scalability etc
build the infrastructure required for optimal extraction transformation and loading of data from a wide variety of data sources using sql and aws ‘big data’ technologies
build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition operational efficiency and other key business performance metrics
work with stakeholders including the executive product data and design teams to assist with datarelated technical issues and support their data infrastructure needs
keep our data separated and secure across national boundaries through multiple data centers and aws regions
create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
work with data and analytics experts to strive for greater functionality in our data systems
essential requirements
degree or equivalent experience
advanced working sql knowledge and experience working with relational databases query authoring sql as well as working familiarity with a variety of databases
experience building and optimizing ‘big data’ data pipelines architectures and data sets
experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
strong analytic skills related to working with unstructured datasets
build processes supporting data transformation data structures metadata dependency and workload management
a successful history of manipulating processing and extracting value from large disconnected datasets
working knowledge of message queuing stream processing and highly scalable ‘big data’ data stores
strong project management and organizational skills
experience supporting and working with crossfunctional teams in a dynamic environment
we are looking for a candidate with 5 years of experience in a data engineer role who has attained a graduate degree in computer science statistics informatics information systems or another quantitative field they should also have experience using the following softwaretools
experience with big data tools hadoop spark kafka etc
experience with relational sql and nosql databases including postgres and cassandra
experience with data pipeline and workflow management tools azkaban luigi airflow etc
experience with aws cloud services ec2 emr rds redshift
experience with streamprocessing systems storm sparkstreaming etc
experience with objectorientedobject function scripting languages python java c scala etc
8 years of application services administration and system engineering experience
5 years of 247 operational production support experience supporting multiple time zonesgeographical regions
strong communication skills
developing on an aws platform s3 aurora redshift kinesis elastic beanstalk docker
developing with mysql or postgresql
sap data model experience esp fico sd
data modelling particularly in erwin
database design
agile development safe scrum
experience with 35nf and star schemas

desirable requirements
masters degree
demonstrated leadership skills interacting with senior leaders
should have demonstrable skills in handling projects of midlarge size
should have worked in a team environment and possess good written and oral communication skills
good organizational and interpersonal skills
aptitude and motivation learn new technologies and make appropriate recommendations for consideration
ability to prioritize tasks and work in a dynamic environment support with minimal supervision in very large user community that is geographically dispersed
demonstrated skills in communicating directly with user community

next steps – apply today

to be considered for this exciting opportunity please complete the full application on our website at your earliest convenience – it is the only way that our recruiter and hiring manager can know that you feel well qualified for this opportunity if you know someone who would be a great fit please share this posting with them

astrazeneca is an equal opportunity employer astrazeneca will consider all qualified applicants for employment without discrimination on grounds of disability sex or sexual orientation pregnancy or maternity leave status race or national or ethnic origin age religion or belief gender identity or reassignment marital or civil partnership status protected veteran status if applicable or any other characteristic protected by law",,DE,False,data_engineer

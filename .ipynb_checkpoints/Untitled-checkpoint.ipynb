{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scraper Version 3.0 -- Job Descriptions and locations from multiple search pages, duplications removed\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import pandas as pd\n",
    "import random  # for generating random delay times, to confuse Indeed\n",
    "from urllib.error import URLError, HTTPError\n",
    "\n",
    "\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for 1 pages of 'Data Engineer' job postings\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a0ec9a0812e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mjob_desc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "# Number of search result pages to scrape (~18 posts per page)\n",
    "num_pages = 1\n",
    "\n",
    "# Job title to search for\n",
    "job = \"Data Engineer\"\n",
    "\n",
    "# URL's we need\n",
    "base_url = \"https://www.indeed.com/\"\n",
    "base_search_url = base_url + \"jobs?q=\" + job.replace(\" \",\"_\") + \"&start=\"\n",
    "\n",
    "# HTML class id used to grab the html element containing the job description\n",
    "class_id = \"jobsearch-JobComponent-description\"\n",
    "\n",
    "\n",
    "# These lists will store each job description and location as individual list elements\n",
    "job_descriptions = list()\n",
    "job_locations = list()\n",
    "job_titles = list()\n",
    "\n",
    "\n",
    "print(\"Looking for {0} pages of '{1}' job postings\".format(num_pages, job))\n",
    "# Start Scraping here\n",
    "\n",
    "num_done = 0\n",
    "\n",
    "\n",
    "for page_num in range(0, num_pages):\n",
    "    # Get links from each page of the search results, up to a specified number of pages\n",
    "    time.sleep(float(random.randrange(5, 50)/100))\n",
    "    # Retrieve the search results one page at a time (starting at 0, 10, 20, ....)\n",
    "    while True:\n",
    "        try:\n",
    "            soup = BeautifulSoup(urllib.request.urlopen(base_search_url + str(page_num*10)), 'html.parser')\n",
    "            break\n",
    "        except (URLError, HTTPError) as e:\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    \n",
    "    search_results = soup.find_all(\"div\", attrs={\"data-tu\":\"\"})\n",
    "    \n",
    "    # Will hold dictionaries, each being one job posting\n",
    "    jobs = list()\n",
    "    \n",
    "    for result in search_results:\n",
    "        title = result.find(\"a\", attrs={\"data-tn-element\":\"jobTitle\"})\n",
    "        loc = result.find(\"div\", attrs={\"class\":\"sjcl\"})\n",
    "        if title is not None and loc is not None:\n",
    "            # We got a match for a sponsored job - \n",
    "            \n",
    "            # Grab the Title of the job, the job description, and the location\n",
    "            job_location = loc.get_text()\n",
    "            job_title = title.get_text()\n",
    "            \n",
    "            job_link = base_url + str(title.get('href'))\n",
    "            print(job_link)\n",
    "            while True:\n",
    "                # Force Indeed to give us the job description\n",
    "                try:\n",
    "                    soup_job = BeautifulSoup(urllib.request.urlopen(job_link), 'html.parser')\n",
    "                    #job_desc = soup_job.find(\"div\", attrs={\"class\":\"jobsearch-JobComponent-description icl-u-xs-mt--md\"})\n",
    "                    break\n",
    "                except (URLError, HTTPError) as e:\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "                break\n",
    "                \n",
    "            job_desc = soup_job.find(class_=class_id).get_text()\n",
    "            print(job_desc)\n",
    "\n",
    "            if job_location is not None and job_title is not None and job_desc is not None:\n",
    "                # This job has a location, title, and description. Add it to our data\n",
    "                print(\"here 2\")\n",
    "                jobs.append({\"job_location\": job_location,\n",
    "                            \"job_title\": job_title,\n",
    "                             \"job_description\": job_desc.get_text(),  # Extract job desc text here\n",
    "                            \"sponsored\": True})\n",
    "                \n",
    "                # Update progress bar\n",
    "                printProgressBar(num_done, num_pages*11, prefix='Progress:', suffix='Complete', length=50)\n",
    "                num_done += 1\n",
    "        \n",
    "        else:\n",
    "            # Check if this element is an organic job (not sponsored)\n",
    "            title = result.find(\"h2\", attrs={\"class\":\"jobtitle\"})\n",
    "            loc = result.find(\"span\", attrs={\"class\":\"location\"})\n",
    "            \n",
    "            if title is not None and loc is not None:\n",
    "                # We have a match for an organic job, extract info\n",
    "                \n",
    "                # Grab the Title of the job\n",
    "                title_element = title.find(\"a\", attrs={\"data-tn-element\":\"jobTitle\"})\n",
    "                job_title = title_element.get_text()\n",
    "\n",
    "                \n",
    "                # Extract Location Text\n",
    "                job_location = loc.get_text()\n",
    "            \n",
    "                while True:\n",
    "                    # Force Indeed to give us the job description\n",
    "                    try:\n",
    "                        soup_job = BeautifulSoup(urllib.request.urlopen(base_url + str(title_element.get('href'))), 'html.parser')\n",
    "                        break\n",
    "                    except (URLError, HTTPError) as e:\n",
    "                        time.sleep(5)\n",
    "                        continue\n",
    "                    break\n",
    "                \n",
    "                # Extract Job Description\n",
    "                job_desc = soup_job.find(class_=class_id).get_text()\n",
    "            \n",
    "                print(\"here 3\")\n",
    "                if job_location is not None and job_title is not None and job_desc is not None:\n",
    "                    # This job has a location, title, and description. Add it to our data\n",
    "                \n",
    "                    jobs.append({\"job_location\": job_location,\n",
    "                                \"job_title\": job_title,\n",
    "                                 \"job_description\": job_desc,\n",
    "                                \"sponsored\": False})\n",
    "                    print(\"here 4\")\n",
    "                    # Update progress bar\n",
    "                    printProgressBar(num_done, num_pages*11, prefix='Progress:', suffix='Complete', length=50)\n",
    "                    num_done += 1\n",
    "\n",
    "print(pd.DataFrame(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.DataFrame(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>sponsored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InternshipPosition Summary:\\nThe New York Coun...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Data Engineer Internship</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book of the Month is looking for a detail-orie...</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$50,000 a yearJob Description\\n\\nNo Computer S...</td>\n",
       "      <td>Tampa, FL 33612</td>\n",
       "      <td>Entry Level Data Engineer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Junior Data Engineer will leverage a dynamic...</td>\n",
       "      <td>Poulsbo, WA</td>\n",
       "      <td>Junior Data Engineer (2 yrs experience required)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Company DescriptionNovantas Solutions is a div...</td>\n",
       "      <td>New York, NY 10017 (Midtown area)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You will have the opportunity to work as part ...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>DATA ENGINEER</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job Description\\nWe are a startup within one o...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Job Description\\n-Thinking Big-\\nDo you want t...</td>\n",
       "      <td>Santa Monica, CA</td>\n",
       "      <td>Data Engineer - Amazon Studios Research</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ContractNo OPT's.GC/USC preferable.Long term c...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We are Farmers!\\n\\nJob Summary:\\n\\nThe Data Ro...</td>\n",
       "      <td>Woodland Hills, CA</td>\n",
       "      <td>Data Engineer I (seeking the December 2018 gra...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description  \\\n",
       "0  InternshipPosition Summary:\\nThe New York Coun...   \n",
       "1  Book of the Month is looking for a detail-orie...   \n",
       "2  $50,000 a yearJob Description\\n\\nNo Computer S...   \n",
       "3  A Junior Data Engineer will leverage a dynamic...   \n",
       "4  Company DescriptionNovantas Solutions is a div...   \n",
       "5  You will have the opportunity to work as part ...   \n",
       "6  Job Description\\nWe are a startup within one o...   \n",
       "7  Job Description\\n-Thinking Big-\\nDo you want t...   \n",
       "8  ContractNo OPT's.GC/USC preferable.Long term c...   \n",
       "9  We are Farmers!\\n\\nJob Summary:\\n\\nThe Data Ro...   \n",
       "\n",
       "                        job_location  \\\n",
       "0                       New York, NY   \n",
       "1  New York, NY 10001 (Chelsea area)   \n",
       "2                    Tampa, FL 33612   \n",
       "3                        Poulsbo, WA   \n",
       "4  New York, NY 10017 (Midtown area)   \n",
       "5                       New York, NY   \n",
       "6                       New York, NY   \n",
       "7                   Santa Monica, CA   \n",
       "8                       New York, NY   \n",
       "9                 Woodland Hills, CA   \n",
       "\n",
       "                                           job_title  sponsored  \n",
       "0                           Data Engineer Internship      False  \n",
       "1                                      Data Engineer      False  \n",
       "2                          Entry Level Data Engineer      False  \n",
       "3   Junior Data Engineer (2 yrs experience required)      False  \n",
       "4                                      Data Engineer      False  \n",
       "5                                      DATA ENGINEER      False  \n",
       "6                                      Data Engineer      False  \n",
       "7            Data Engineer - Amazon Studios Research      False  \n",
       "8                                      Data Engineer      False  \n",
       "9  Data Engineer I (seeking the December 2018 gra...      False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
